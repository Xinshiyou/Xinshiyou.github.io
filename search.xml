<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Minio初探</title>
      <link href="/2020/06/01/Minio%E5%88%9D%E6%8E%A2/"/>
      <url>/2020/06/01/Minio%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="部署调研"><a href="#部署调研" class="headerlink" title="部署调研"></a>部署调研</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>环境准备，主要是指环境配置、资源包下载/安装部署等内容。</p><h3 id="资源下载"><a href="#资源下载" class="headerlink" title="资源下载"></a>资源下载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Minio下载：RELEASE.2020-06-01T17-28-03Z</span></span></span><br><span class="line">wget https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## MC下载: RELEASE.2020-05-28T23-43-36Z</span></span></span><br><span class="line">wget https://dl.min.io/client/mc/release/linux-amd64/mc</span><br></pre></td></tr></table></figure><p><strong>资源下载(更新于2020-06-02)</strong>：<br><a href="Minio初探/minio" target="_blank">Minio(Server)</a>    &emsp; &emsp; <a href="Minio初探/mc" target="_blank">MC(Client)</a></p><h3 id="添加执行权限"><a href="#添加执行权限" class="headerlink" title="添加执行权限"></a>添加执行权限</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 最好存放在统一的位置，比如：/opt/soft/minio/ 等</span></span></span><br><span class="line">chmod +x mc</span><br><span class="line">chmod +x minio</span><br></pre></td></tr></table></figure><h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p>这里主要介绍实战部署：参考官方文档，进行部署搭建。</p><h3 id="单机部署"><a href="#单机部署" class="headerlink" title="单机部署"></a>单机部署</h3><p>单机部署主要包括两种模式：单机单租户、单机多租户。</p><h4 id="单机单租户"><a href="#单机单租户" class="headerlink" title="单机单租户"></a>单机单租户</h4><p>单机部署非常简单</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 启动服务：./minio server /data1 /data2 ...</span><br><span class="line">2. 查看服务：http://host1:9000/</span><br></pre></td></tr></table></figure><p>主要架构如下所示：<br><img src="/.io//one_ten_one_host.jpg" alt="单机单磁盘"></p><h4 id="单机多租户"><a href="#单机多租户" class="headerlink" title="单机多租户"></a>单机多租户</h4><p>单机多租户，可以配置为多租户多次盘、多租户单磁盘等模式。</p><p><img src="/.io//multi_ten_one_host.jpg" alt="单机多租户"></p><h3 id="分布式部署"><a href="#分布式部署" class="headerlink" title="分布式部署"></a>分布式部署</h3><p>分布式部署可以部署为单租户多机、多租户多机等情形，主要架构如下所示<br><img src="/.io//multi_ten_multi_host.jpg" alt="分布式部署"></p><p>部署测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># host1 ~ host4 : 配置启动</span></span></span><br><span class="line">echo "" &gt; nohup.out</span><br><span class="line">export MINIO_ACCESS_KEY=minioadmin</span><br><span class="line">export MINIO_SECRET_KEY=minioadmin</span><br><span class="line">nohup /root/minio server --address :9002 http://host1/data5 http://host2/data5 http://host3/data5 http://host4/data5   &amp;</span><br></pre></td></tr></table></figure><p>使用s3-benchmark压测结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">## 压测命令</span><br><span class="line">.&#x2F;s3-benchmark -a minioadmin -s minioadmin -b test -t 10 -u http:&#x2F;&#x2F;host1:9002 -l 5 -z &quot;1MB&quot;</span><br><span class="line"></span><br><span class="line">## 压测结果</span><br><span class="line">Parameters: url&#x3D;http:&#x2F;&#x2F;host1:9002, bucket&#x3D;test, duration&#x3D;60, threads&#x3D;10, loops&#x3D;5, size&#x3D;1MB</span><br><span class="line">Fri, 05 Jun 2020 20:01:13 GMT Loop 1: PUT time 61.6 secs, objects &#x3D; 213, speed &#x3D; 3.5MB&#x2F;sec, 3.5 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:02:14 GMT Loop 1: GET time 61.0 secs, objects &#x3D; 395, speed &#x3D; 6.5MB&#x2F;sec, 6.5 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:02:15 GMT Loop 1: DELETE time 0.9 secs, 225.1 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:03:16 GMT Loop 2: PUT time 61.7 secs, objects &#x3D; 215, speed &#x3D; 3.5MB&#x2F;sec, 3.5 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:04:17 GMT Loop 2: GET time 60.8 secs, objects &#x3D; 346, speed &#x3D; 5.7MB&#x2F;sec, 5.7 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:04:18 GMT Loop 2: DELETE time 0.8 secs, 277.0 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:05:20 GMT Loop 3: PUT time 61.6 secs, objects &#x3D; 209, speed &#x3D; 3.4MB&#x2F;sec, 3.4 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:06:21 GMT Loop 3: GET time 60.8 secs, objects &#x3D; 403, speed &#x3D; 6.6MB&#x2F;sec, 6.6 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:06:21 GMT Loop 3: DELETE time 0.8 secs, 270.2 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:07:24 GMT Loop 4: PUT time 62.6 secs, objects &#x3D; 214, speed &#x3D; 3.4MB&#x2F;sec, 3.4 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:08:25 GMT Loop 4: GET time 60.8 secs, objects &#x3D; 399, speed &#x3D; 6.6MB&#x2F;sec, 6.6 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:08:25 GMT Loop 4: DELETE time 0.8 secs, 277.8 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:09:27 GMT Loop 5: PUT time 61.6 secs, objects &#x3D; 206, speed &#x3D; 3.3MB&#x2F;sec, 3.3 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:10:28 GMT Loop 5: GET time 60.9 secs, objects &#x3D; 395, speed &#x3D; 6.5MB&#x2F;sec, 6.5 operations&#x2F;sec.</span><br><span class="line">Fri, 05 Jun 2020 20:10:29 GMT Loop 5: DELETE time 0.8 secs, 260.4 operations&#x2F;sec.</span><br><span class="line">Benchmark completed.</span><br></pre></td></tr></table></figure><p><strong>注:</strong><br>如果使用本机多磁盘，意味着开启了Erase Code模式。在测试情境下，开启了EC模式，性能下降明显。</p><h2 id="特性调研"><a href="#特性调研" class="headerlink" title="特性调研"></a>特性调研</h2><p>主要调研了Minio的擦除码、缓存、压缩等特性。以下特性调研，使用单机单租户单磁盘模式，且磁盘为HDD硬盘。</p><h3 id="使用Erase-Code"><a href="#使用Erase-Code" class="headerlink" title="使用Erase Code"></a>使用Erase Code</h3><p>当前Minio在体验方面还不是非常友好，默认情况下的EC是Data跟parity是1:1分布的。如果需要修改配比，那么需要使用环境变量或使用MC进行设置。</p><p>下面简单调研一下Minio如何配置EC，以及配置EC的效果。主要配置项为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export MINIO_STORAGE_CLASS_STANDARD&#x3D;EC:3</span><br><span class="line">export MINIO_STORAGE_CLASS_RRS&#x3D;EC:2</span><br></pre></td></tr></table></figure><p>通过命令操作单机实例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 启动之前：随便设置(可以不设置)</span></span></span><br><span class="line">export MINIO_STORAGE_CLASS_STANDARD=EC:3</span><br><span class="line">export MINIO_STORAGE_CLASS_RRS=EC:2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 通过命令查看配置</span></span></span><br><span class="line">mc admin config get myminio storage_class</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 通过命令设置配置</span></span></span><br><span class="line">mc admin config set myminio storage_class "standard=EC:2 rrs="   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 重启生效</span></span></span><br><span class="line">mc admin service restart myminio</span><br></pre></td></tr></table></figure><p>在配置了EC之后，查看目录文件夹中的数据，可以看到存在part.[num]块以及元数据描述信息</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>: <span class="string">"1.0.1"</span>,</span><br><span class="line">    <span class="attr">"format"</span>: <span class="string">"xl"</span>,</span><br><span class="line">    <span class="attr">"stat"</span>: &#123;</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">1048576</span>,</span><br><span class="line">        <span class="attr">"modTime"</span>: <span class="string">"2020-06-04T05:49:45.838591001Z"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"erasure"</span>: &#123;</span><br><span class="line">        <span class="attr">"algorithm"</span>: <span class="string">"klauspost/reedsolomon/vandermonde"</span>,</span><br><span class="line">        <span class="attr">"data"</span>: <span class="number">6</span>,</span><br><span class="line">        <span class="attr">"parity"</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="attr">"blockSize"</span>: <span class="number">10485760</span>,</span><br><span class="line">        <span class="attr">"index"</span>: <span class="number">4</span>,</span><br><span class="line">        <span class="attr">"distribution"</span>: [</span><br><span class="line">            <span class="number">3</span>,</span><br><span class="line">            <span class="number">4</span>,</span><br><span class="line">            <span class="number">5</span>,</span><br><span class="line">            <span class="number">6</span>,</span><br><span class="line">            <span class="number">7</span>,</span><br><span class="line">            <span class="number">8</span>,</span><br><span class="line">            <span class="number">9</span>,</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            <span class="number">2</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"checksum"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="attr">"name"</span>: <span class="string">"part.1"</span>,</span><br><span class="line">                <span class="attr">"algorithm"</span>: <span class="string">"highwayhash256S"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"minio"</span>: &#123;</span><br><span class="line">        <span class="attr">"release"</span>: <span class="string">"RELEASE.2020-06-01T17-28-03Z"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"meta"</span>: &#123;</span><br><span class="line">        <span class="attr">"content-type"</span>: <span class="string">"application/octet-stream"</span>,</span><br><span class="line">        <span class="attr">"etag"</span>: <span class="string">"7ede4e128789a6b6d51b834d77e00c92"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"parts"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"number"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"size"</span>: <span class="number">1048576</span>,</span><br><span class="line">            <span class="attr">"actualSize"</span>: <span class="number">1048576</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置EC为 <strong>Standard(storage_class standard=EC:2 rrs= )</strong> 之后，压测如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Parameters: url=http://host1:9001, bucket=test, duration=60, threads=10, loops=5, size=1M</span><br><span class="line">Thu, 04 Jun 2020 13:48:12 GMT Loop 1: PUT time 62.5 secs, objects = 159, speed = 2.5MB/sec, 2.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:49:13 GMT Loop 1: GET time 61.0 secs, objects = 365, speed = 6MB/sec, 6.0 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:49:14 GMT Loop 1: DELETE time 0.6 secs, 277.4 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:50:15 GMT Loop 2: PUT time 61.5 secs, objects = 182, speed = 3MB/sec, 3.0 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:51:16 GMT Loop 2: GET time 60.8 secs, objects = 358, speed = 5.9MB/sec, 5.9 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:51:17 GMT Loop 2: DELETE time 0.6 secs, 288.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:52:19 GMT Loop 3: PUT time 62.2 secs, objects = 177, speed = 2.8MB/sec, 2.8 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:53:20 GMT Loop 3: GET time 61.0 secs, objects = 349, speed = 5.7MB/sec, 5.7 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:53:20 GMT Loop 3: DELETE time 0.7 secs, 263.1 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:54:22 GMT Loop 4: PUT time 61.5 secs, objects = 171, speed = 2.8MB/sec, 2.8 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:55:23 GMT Loop 4: GET time 61.1 secs, objects = 356, speed = 5.8MB/sec, 5.8 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:55:24 GMT Loop 4: DELETE time 0.6 secs, 302.4 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:56:27 GMT Loop 5: PUT time 62.8 secs, objects = 163, speed = 2.6MB/sec, 2.6 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:57:28 GMT Loop 5: GET time 61.1 secs, objects = 318, speed = 5.2MB/sec, 5.2 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 13:57:28 GMT Loop 5: DELETE time 0.7 secs, 246.7 operations/sec.</span><br></pre></td></tr></table></figure><p>具体EC的说明可以参考：<a href="https://github.com/minio/minio/tree/master/docs/erasure/storage-class" target="_blank" rel="noopener" title="6">MinIO Storage Class Quickstart Guide</a>。</p><h3 id="压缩-compression"><a href="#压缩-compression" class="headerlink" title="压缩(compression)"></a>压缩(compression)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看压缩配置</span></span></span><br><span class="line">mc admin config get myminio compression</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 默认压缩是不启用的，启用默认设置</span></span></span><br><span class="line">mc admin config set myminio compression</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 设置压缩格式</span></span></span><br><span class="line">mc admin config set myminio compression extensions=".pdf" mime_types="application/pdf"</span><br></pre></td></tr></table></figure><p>启用压缩之后，可以看到大小不一致</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">"parts": [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"number"</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">5505321</span>,</span><br><span class="line">        <span class="attr">"actualSize"</span>: <span class="number">7464298</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>启用压缩之后的压测结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Parameters: url=http://host1:9001, bucket=test, duration=60, threads=10, loops=5, size=1M</span><br><span class="line">Thu, 04 Jun 2020 14:21:14 GMT Loop 1: PUT time 62.8 secs, objects = 157, speed = 2.5MB/sec, 2.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:22:16 GMT Loop 1: GET time 61.2 secs, objects = 334, speed = 5.5MB/sec, 5.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:22:16 GMT Loop 1: DELETE time 0.6 secs, 281.2 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:23:17 GMT Loop 2: PUT time 61.3 secs, objects = 162, speed = 2.6MB/sec, 2.6 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:24:19 GMT Loop 2: GET time 61.3 secs, objects = 312, speed = 5.1MB/sec, 5.1 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:24:19 GMT Loop 2: DELETE time 0.7 secs, 243.1 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:25:21 GMT Loop 3: PUT time 62.0 secs, objects = 180, speed = 2.9MB/sec, 2.9 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:26:23 GMT Loop 3: GET time 61.4 secs, objects = 335, speed = 5.5MB/sec, 5.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:26:24 GMT Loop 3: DELETE time 0.8 secs, 237.2 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:27:25 GMT Loop 4: PUT time 61.8 secs, objects = 185, speed = 3MB/sec, 3.0 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:28:26 GMT Loop 4: GET time 60.6 secs, objects = 300, speed = 4.9MB/sec, 4.9 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:28:27 GMT Loop 4: DELETE time 0.7 secs, 266.4 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:29:29 GMT Loop 5: PUT time 61.9 secs, objects = 180, speed = 2.9MB/sec, 2.9 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:30:30 GMT Loop 5: GET time 61.4 secs, objects = 275, speed = 4.5MB/sec, 4.5 operations/sec.</span><br><span class="line">Thu, 04 Jun 2020 14:30:31 GMT Loop 5: DELETE time 0.6 secs, 297.0 operations/sec.</span><br><span class="line">Benchmark completed.</span><br></pre></td></tr></table></figure><p>具体Compression的说明可以参考：<a href="https://github.com/minio/minio/tree/master/docs/compression" target="_blank" rel="noopener" title="7">Compression Guide</a>。</p><h3 id="缓存-cache"><a href="#缓存-cache" class="headerlink" title="缓存(cache)"></a>缓存(cache)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">## 设置缓存</span><br><span class="line">mc admin config set myminio cache drives&#x3D;&#x2F;data4&#x2F;cache,&#x2F;data5&#x2F;cache,&#x2F;data6&#x2F;cache,&#x2F;data7&#x2F;cache,&#x2F;data8&#x2F;cache</span><br><span class="line"></span><br><span class="line">## 开启atime</span><br><span class="line">### 异常报错</span><br><span class="line">Unable to initialize disk caching: Atime support required for disk caching</span><br><span class="line"></span><br><span class="line">### 问题根因</span><br><span class="line">如果需要开启缓存，那么需要磁盘截至启用atime。当前我司为了提升磁盘性能，全面禁止使用atime。主要是挂载磁盘的时候，添加的属性参数。</span><br></pre></td></tr></table></figure><p>未单独配置，未进行测试。</p><h2 id="界面功能"><a href="#界面功能" class="headerlink" title="界面功能"></a>界面功能</h2><p>界面可以实现的基本功能：</p><ol><li>创建Bucket：这里的bucket，对应到本地为文件夹的概念</li><li>创建目录：映射到单机本地文件夹的概念：lazy加载。只有目录下面实际存在文件时，才会实际创建</li><li>上传与下载文件：上传文件，直接上传到单机存储目录本地。</li><li>删除目录与删除文件：删除文件，对应到删除本地文件。可以从界面上天删除，也可以直接删除本地文件</li></ol><h2 id="MC命令行操作"><a href="#MC命令行操作" class="headerlink" title="MC命令行操作"></a>MC命令行操作</h2><h3 id="配置与操作S3"><a href="#配置与操作S3" class="headerlink" title="配置与操作S3"></a>配置与操作S3</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置：会写入到本地配置文件</span></span></span><br><span class="line">mc config host add s3_bj s3.[region].amazonaws.com "[access key id]" "[ secret key id]"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 命令行操作(基本操作)</span></span></span><br><span class="line">mc ls s3_bj/iqiyi-bigdata-hadoop-bj/tmp</span><br><span class="line">mc stat s3_bj/iqiyi-bigdata-hadoop-bj/tmp</span><br><span class="line">mc du s3_bj/iqiyi-bigdata-hadoop-bj/tmp</span><br></pre></td></tr></table></figure><h3 id="配置与操作Minio"><a href="#配置与操作Minio" class="headerlink" title="配置与操作Minio"></a>配置与操作Minio</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 添加配置</span></span></span><br><span class="line">mc config host add local_single_minio  http://host1:9001 minioadmin minioadmin</span><br></pre></td></tr></table></figure><h2 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h2><h3 id="压测命令"><a href="#压测命令" class="headerlink" title="压测命令"></a>压测命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 单机单磁盘</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 压测命令</span></span></span><br><span class="line">./s3-benchmark -a minioadmin -s minioadmin -b test -t 10 -u http://host1:9001</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 压测结果</span></span></span><br><span class="line">for threads in 10 20 30 40 50;</span><br><span class="line">  for size in "100K" "200K" "300K" "400K" "500K" "1M" "2M" "3M" "4M" "5M" ;</span><br><span class="line">    ./s3-benchmark -a minioadmin -s minioadmin -b test -t "$&#123;threads&#125;" -u http://host1:9001 -l 5 -z "$&#123;size&#125;" &gt; logs_$&#123;threads&#125;_$&#123;size&#125;</span><br><span class="line">  done;</span><br><span class="line">done;</span><br></pre></td></tr></table></figure><h3 id="压测结果"><a href="#压测结果" class="headerlink" title="压测结果"></a>压测结果</h3><p>(待整理：画图)</p><h1 id="Minio架构"><a href="#Minio架构" class="headerlink" title="Minio架构"></a>Minio架构</h1><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h2 id="分析：优缺点"><a href="#分析：优缺点" class="headerlink" title="分析：优缺点"></a>分析：优缺点</h2><h1 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h1><ol><li>配置之后，容量不对：界面不显示总的磁盘容量，只显示使用量</li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol><li><a href="https://github.com/minio/minio" target="_blank" rel="noopener">Github: Minio/minio</a></li><li><a href="https://docs.min.io" target="_blank" rel="noopener">Minio QuickStart</a></li><li><a href="https://github.com/minio/s3-benchmark" target="_blank" rel="noopener">S3-benchmark</a></li><li><a href="https://blog.min.io/s3-benchmark-using-hdd/" target="_blank" rel="noopener">S3 Benchmark: MinIO on HDDs</a></li><li><a href="https://docs.min.io/docs/multi-tenant-minio-deployment-guide.html" target="_blank" rel="noopener">MinIO Multi-Tenant Deployment Guide</a></li><li><a href="https://github.com/minio/minio/tree/master/docs/erasure/storage-class" target="_blank" rel="noopener">MinIO Storage Class Quickstart Guide</a></li><li><a href="https://github.com/minio/minio/tree/master/docs/compression" target="_blank" rel="noopener">Compression Guide</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Minio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编译CDH-6.beta-hive</title>
      <link href="/2020/06/01/%E7%BC%96%E8%AF%91Hive-CDH6/"/>
      <url>/2020/06/01/%E7%BC%96%E8%AF%91Hive-CDH6/</url>
      
        <content type="html"><![CDATA[<h2 id="hbase-handler-llap-server"><a href="#hbase-handler-llap-server" class="headerlink" title="hbase-handler/llap-server"></a>hbase-handler/llap-server</h2><h3 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) on project hive-llap-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -&gt; [Help 1]</span><br><span class="line">org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) on project hive-llap-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br><span class="line">Caused by: org.apache.maven.plugin.MojoExecutionException: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.</span><br><span class="line">    at org.apache.maven.plugins.enforcer.EnforceMojo.execute (EnforceMojo.java:209)</span><br><span class="line">    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br></pre></td></tr></table></figure><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- https:&#x2F;&#x2F;mvnrepository.com&#x2F;artifact&#x2F;org.glassfish&#x2F;javax.el --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.glassfish&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;javax.el&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.0.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="hive-webhcat"><a href="#hive-webhcat" class="headerlink" title="hive-webhcat"></a>hive-webhcat</h2><h3 id="报错信息-1"><a href="#报错信息-1" class="headerlink" title="报错信息"></a>报错信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) on project hive-webhcat: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip file</span><br><span class="line">[ERROR] </span><br><span class="line">[ERROR] Command line was:&quot;cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs &amp;&amp; &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc&quot; @options @packages</span><br><span class="line">[ERROR] -&gt; [Help 1]</span><br><span class="line">org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) on project hive-webhcat: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip file</span><br><span class="line"></span><br><span class="line">Command line was:&quot;cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs &amp;&amp; &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc&quot; @options @packages</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br><span class="line">Caused by: org.apache.maven.plugin.MojoExecutionException: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip file</span><br><span class="line"></span><br><span class="line">Command line was:&quot;cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs &amp;&amp; &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc&quot; @options @packages</span><br><span class="line">    at org.apache.maven.plugin.javadoc.JavadocReport.execute (JavadocReport.java:238)</span><br><span class="line">    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br><span class="line">Caused by: org.apache.maven.reporting.MavenReportException: Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip file</span><br><span class="line"></span><br><span class="line">Command line was:&quot;cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs &amp;&amp; &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc&quot; @options @packages</span><br><span class="line">    at org.apache.maven.plugin.javadoc.AbstractJavadocMojo.executeReport (AbstractJavadocMojo.java:1580)</span><br><span class="line">    at org.apache.maven.plugin.javadoc.JavadocReport.generate (JavadocReport.java:136)</span><br><span class="line">    at org.apache.maven.plugin.javadoc.JavadocReport.execute (JavadocReport.java:224)</span><br><span class="line">    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br></pre></td></tr></table></figure><h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 一</span><br><span class="line">删除无法打开的文件，maven重新下载</span><br><span class="line"></span><br><span class="line">## 二</span><br><span class="line">mvn clean install package -DskipTests   -Dmaven.javadoc.skip&#x3D;true  -X -rf :hive-webhcat</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
            <tag> 编译 </tag>
            
            <tag> 部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《道德经的人生智慧》读书笔记</title>
      <link href="/2020/06/01/%E9%81%93%E5%BE%B7%E7%BB%8F%E7%9A%84%E4%BA%BA%E7%94%9F%E6%99%BA%E6%85%A7/"/>
      <url>/2020/06/01/%E9%81%93%E5%BE%B7%E7%BB%8F%E7%9A%84%E4%BA%BA%E7%94%9F%E6%99%BA%E6%85%A7/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近有时间读了一本书：《道德经的智慧》。在干工作忙碌的闲暇之余，有空看看“鸡汤”书，喝喝鸡汤，也是非常不错的。本文取原文中的文段节选。</p><a id="more"></a><h2 id="1-道可道非常道，名可名非常名：道法自然的智慧"><a href="#1-道可道非常道，名可名非常名：道法自然的智慧" class="headerlink" title="1. 道可道非常道，名可名非常名：道法自然的智慧"></a>1. 道可道非常道，名可名非常名：道法自然的智慧</h2><h3 id="1-1-道可道非常道，名可名非常名"><a href="#1-1-道可道非常道，名可名非常名" class="headerlink" title="1.1. 道可道非常道，名可名非常名"></a>1.1. 道可道非常道，名可名非常名</h3><pre><code>“道”是无法用言语清晰表达出来的，如果可以，那就不是我们所说的“大道”；“道”的形态和概念如果可以为其定名，那就不可能是“道”永恒的形态与概念。</code></pre><p>&emsp;&emsp;“道”可以归纳为三个层次：理之道、物之道和人事之道。</p><h3 id="1-2-人法地，地法天，天法道，道法自然"><a href="#1-2-人法地，地法天，天法道，道法自然" class="headerlink" title="1.2. 人法地，地法天，天法道，道法自然"></a>1.2. 人法地，地法天，天法道，道法自然</h3><pre><code>人向天地取法，学习它的朴实厚德，地向天空取法，学习它的高明宽广，天向道取法，学习它的本院创生，道则向自然取法，遵从自然地规律而行事。</code></pre><p>&emsp;&emsp;”到法自然”，而这“自然”要怎理解？这里的自然其实就是我们所说的规律。老子认为，万物是按照它自身规律、发展的规律运行的。</p><h3 id="1-3-曲则全，枉则直，注则盈，敝则新，少则的，多则惑"><a href="#1-3-曲则全，枉则直，注则盈，敝则新，少则的，多则惑" class="headerlink" title="1.3. 曲则全，枉则直，注则盈，敝则新，少则的，多则惑"></a>1.3. 曲则全，枉则直，注则盈，敝则新，少则的，多则惑</h3><pre><code>遇到强大的外力压迫时，始终保持硬质容易损毁，而选择弯曲才能保全自己，委屈自己后才能再次伸展；低洼的地方反而能够积攒慢慢的水，东西过于陈旧则会被人翻新或更新；想要完成的目标少一点，反而容易完成和收获更多；而追求太多的人最终往往被自己选定的多个目标所迷惑，不清楚自己正正想要的，不清楚真正能够得到的，最终一无所获。</code></pre><h3 id="1-4-万物背阴而向阳，充气以为和"><a href="#1-4-万物背阴而向阳，充气以为和" class="headerlink" title="1.4. 万物背阴而向阳，充气以为和"></a>1.4. 万物背阴而向阳，充气以为和</h3><pre><code>万物背阴而向阳，阴阳二气相互冲融产生和气</code></pre><h3 id="1-5-故令有所属：见素抱朴，少私寡欲，绝学无忧"><a href="#1-5-故令有所属：见素抱朴，少私寡欲，绝学无忧" class="headerlink" title="1.5. 故令有所属：见素抱朴，少私寡欲，绝学无忧"></a>1.5. 故令有所属：见素抱朴，少私寡欲，绝学无忧</h3><pre><code>所以，要让人民的思想有所归属：保持纯洁朴实的本性，减少心中不该有的杂念和欲望，摒弃看似聪明的智慧、大度的仁义和浮于表面的文化，这样就能避免心生忧患。</code></pre><h3 id="1-6-天地所以能长且久者，以其不自生，故能长生"><a href="#1-6-天地所以能长且久者，以其不自生，故能长生" class="headerlink" title="1.6. 天地所以能长且久者，以其不自生，故能长生"></a>1.6. 天地所以能长且久者，以其不自生，故能长生</h3><pre><code>天和地能够长久地存在的原因，在于它们不求自己的生存，所以反而能够获得更长久的生存。</code></pre><h3 id="1-7-是以圣人去甚，去奢，去泰"><a href="#1-7-是以圣人去甚，去奢，去泰" class="headerlink" title="1.7. 是以圣人去甚，去奢，去泰"></a>1.7. 是以圣人去甚，去奢，去泰</h3><pre><code>因此，圣人要除去哪种极端的、奢侈的、过度的措施和法度。</code></pre><h2 id="2-善利万物而不争：上善若水的智慧"><a href="#2-善利万物而不争：上善若水的智慧" class="headerlink" title="2. 善利万物而不争：上善若水的智慧"></a>2. 善利万物而不争：上善若水的智慧</h2><h3 id="2-1-上善若水。水善利万物而不争，处众人之所恶，故几于道"><a href="#2-1-上善若水。水善利万物而不争，处众人之所恶，故几于道" class="headerlink" title="2.1. 上善若水。水善利万物而不争，处众人之所恶，故几于道"></a>2.1. 上善若水。水善利万物而不争，处众人之所恶，故几于道</h3><pre><code>最高的品德和修养(亦指拥有最高品德和修养的人)就如同水一样。水善于滋养、利于万物而不予万物相争，身处众人都不愿意居住生活的地方，所以水的这种境界已经很接近于“道”了。</code></pre><h3 id="2-2-企者不立，跨着不行"><a href="#2-2-企者不立，跨着不行" class="headerlink" title="2.2. 企者不立，跨着不行"></a>2.2. 企者不立，跨着不行</h3><pre><code>想要踮起脚尖站的更高的人，反而会站不稳；不想稳步前进，而想着跳跃式前进的人，反而无法走得又快又远。</code></pre><p>&emsp;&emsp;老子的这句话是说：浮躁之心不可有。做事要踏踏实实，一步一个脚印，更要如水般陈静，不疾不徐，这样才能有所成就。在这个充满诱惑的时代，人人渴望成功。所有人都梦想一觉醒来成为世界首富，都认为自己注定会成为人上之人，理应享受香车豪宅。如果说在物质贫乏的时代，阻碍人们走向成功的首要原因是外在条件不允许，桎梏使得人们㞏做梦，那么心在，阻碍人们成长和成功的正是如上种种不切实际的梦想以及由此积累的浮躁心态。</p><h3 id="2-3-上善若水"><a href="#2-3-上善若水" class="headerlink" title="2.3. 上善若水"></a>2.3. 上善若水</h3><pre><code>最高的品德和修养就如同水一样。</code></pre><h3 id="2-4-天下大事，必作于细"><a href="#2-4-天下大事，必作于细" class="headerlink" title="2.4. 天下大事，必作于细"></a>2.4. 天下大事，必作于细</h3><pre><code>天下的大事，必须从细微之处入手。</code></pre><p>&emsp;&emsp;老子认为，做事情不能仰头望天，而应脚踏实地。那些真正伟大的人物从来都不蔑视生活中的小时，既是常人认为很卑微很细小的事情，他们也都满怀热情地去做好。这就如同水一般，所过之处，填满每一个细微的缝隙，丝毫不会因为其细微而忽略情诗，人生亦是如此。</p><h3 id="2-5-高下相倾"><a href="#2-5-高下相倾" class="headerlink" title="2.5. 高下相倾"></a>2.5. 高下相倾</h3><pre><code>高与低相互依靠而存在。</code></pre><h2 id="3-见素抱朴，少私寡欲：修心养性的智慧"><a href="#3-见素抱朴，少私寡欲：修心养性的智慧" class="headerlink" title="3. 见素抱朴，少私寡欲：修心养性的智慧"></a>3. 见素抱朴，少私寡欲：修心养性的智慧</h2><h3 id="3-1-挫其锐，解其纷，和其光，同其尘，是谓“玄同”"><a href="#3-1-挫其锐，解其纷，和其光，同其尘，是谓“玄同”" class="headerlink" title="3.1. 挫其锐，解其纷，和其光，同其尘，是谓“玄同”"></a>3.1. 挫其锐，解其纷，和其光，同其尘，是谓“玄同”</h3><pre><code>将自己的锐气完美手链，却又能解开虫虫纷杂；将自己的光芒调和隐藏，又能与俗尘混同，这就是“玄同”。</code></pre><p>&emsp;&emsp;认为了生存，必须生活在社会之中。可是，在这复杂的社会中，总有着太多的纷繁俗世，让人常常回想，如果能隐居山林该多好。</p><h3 id="3-2-俗人昭昭，我独昏昏；俗人察察，我独闷闷"><a href="#3-2-俗人昭昭，我独昏昏；俗人察察，我独闷闷" class="headerlink" title="3.2. 俗人昭昭，我独昏昏；俗人察察，我独闷闷"></a>3.2. 俗人昭昭，我独昏昏；俗人察察，我独闷闷</h3><pre><code>众人都光辉炫目，唯独我好像迷迷糊糊；众人都获得明明白白，唯独我好像浑浑噩噩。我就想是在这个世界的无边海洋之中四处漂泊，没有找到可以停靠安歇的地方。世人仿佛都很灵巧，有自己的本领，同时又在发挥自己的作用，只有我玉梅笨拙仿佛一无是处。</code></pre><p>&emsp;&emsp;胸襟如海，容纳百川，境界高原，仿佛清风徐吹，回荡于山谷中的天籁之音。用出世的心做入世的事，不是每个人都能做到的。</p><h3 id="3-3-报怨以德"><a href="#3-3-报怨以德" class="headerlink" title="3.3. 报怨以德"></a>3.3. 报怨以德</h3><pre><code>用德兴去回报怨恨。</code></pre><p>&emsp;&emsp;人们常说：“比海洋宽阔的是天空，比天空更宽阔的是人的心灵。”心灵，拥有包纳世间一切事物的容量。唯宽可以容忍，唯厚可以载物。宽容，则是一种心性的修养，不仅是保持身心监控的良方，也是事业成功的重要条件。</p><h3 id="3-4-众人皆有余，而我独若遗"><a href="#3-4-众人皆有余，而我独若遗" class="headerlink" title="3.4. 众人皆有余，而我独若遗"></a>3.4. 众人皆有余，而我独若遗</h3><pre><code>众人都为自己预谋打算留下余财，只有我看似毫无智慧经常穷苦潦倒。</code></pre><p>&emsp;&emsp;不同的人对于贫穷的看法不同，标准不同，忍受贫穷的能力也不同。对于贫穷，有些人是不得不局于贫困，苦熬贫困，所以觉得贫困是可怕的，这是找艳遇物质生活的贫困。还有一些人是甘居贫困，是借贫困的环境来磨练自己的意志，这是自觉地忍受贫困。不仅注重自己的物质享受，还看中自己的精神修养，这才是积极地忍受贫困。</p><h3 id="3-5-功遂身退，天之道也"><a href="#3-5-功遂身退，天之道也" class="headerlink" title="3.5. 功遂身退，天之道也"></a>3.5. 功遂身退，天之道也</h3><pre><code>当自己功成名就的时候，就应该学会和懂得急流勇退的道理，因为这样做才符合天地自然地大道，才能让自己更加长久。</code></pre><p>&emsp;&emsp;花开果生，果结花谢，自然之道。</p><h2 id="4-无为而无不为：无为而治的智慧"><a href="#4-无为而无不为：无为而治的智慧" class="headerlink" title="4. 无为而无不为：无为而治的智慧"></a>4. 无为而无不为：无为而治的智慧</h2><h3 id="4-1-万物并作，吾以观复"><a href="#4-1-万物并作，吾以观复" class="headerlink" title="4.1. 万物并作，吾以观复"></a>4.1. 万物并作，吾以观复</h3><pre><code>世间万物共同蓬勃生长，我从万物的发展和变化中观察其循环往复的声明和运动规律。</code></pre><p>&emsp;&emsp;老子认为，天地万物，都在永远不息的动态循环旋转，在动态生生不息，并无真正的静止。一切人事的作为、思想、言语，都同此理。是非、善恶、祸福、主观与可观，都没有绝对的标准。无论是历史，还是人生，一切事物都是无穷无尽、相生相克的，没有了结之时。</p><p>&emsp;&emsp;既然生命无常，且生生不息，那么，对待生命的态度，就成为千古圣贤时常讨论的一个话题。</p><h3 id="4-2-无为而无不为"><a href="#4-2-无为而无不为" class="headerlink" title="4.2. 无为而无不为"></a>4.2. 无为而无不为</h3><pre><code>领悟“道”的道理不要妄为，就能做到无所不为。</code></pre><h3 id="4-3-故有之以为利，无之以为用"><a href="#4-3-故有之以为利，无之以为用" class="headerlink" title="4.3. 故有之以为利，无之以为用"></a>4.3. 故有之以为利，无之以为用</h3><pre><code>由此可见，如果对实实在在、看得见摸得着的材料进行改造，这样的材料本省提供了作用，而改造材料时出现了许多看不见摸不着的元素，这些元素也在为人们提供者作用。</code></pre><h3 id="4-4-我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先"><a href="#4-4-我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先" class="headerlink" title="4.4. 我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先"></a>4.4. 我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先</h3><pre><code>我有三种宝物，长久以来一直持有着、守护着、用心保存着。第一种是慈爱，第二种是俭蔷，第三种是不于天下人的前面。</code></pre><h3 id="4-5-有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母"><a href="#4-5-有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母" class="headerlink" title="4.5. 有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母"></a>4.5. 有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母</h3><pre><code>有种东西浑然而成，它在天地形成出现之前就已经存在了。它没有声音也没有具体的形象，它不依靠任何外力而独立长存，周而复始地循环运行从不停息，它甚至可以作为天地万物的母体。</code></pre><p>&emsp;&emsp;自古以来，坚持的头号大敌就是诱惑，就是耐不住寂寞。有这么一句话：“我什么都能抵制，除了诱惑。”因为耐不住寂寞和诱惑，我们丧失了志向，偏离了方向，始终登不上成功之船。</p><p>&emsp;&emsp;我们的生命是有限的，但人生却是无限精彩的。只有耐住寂寞，才是更能收获成功的人。</p><h3 id="4-6-为者败之，执者失之。是以圣人无为，故无败；无执，故无失"><a href="#4-6-为者败之，执者失之。是以圣人无为，故无败；无执，故无失" class="headerlink" title="4.6. 为者败之，执者失之。是以圣人无为，故无败；无执，故无失"></a>4.6. 为者败之，执者失之。是以圣人无为，故无败；无执，故无失</h3><pre><code>任意妄为的人会招致失败，执着强求的人会使希望落空。因此，圣人无所作为，也就不会招致失败；不曾执着，也就不会希望落空了。</code></pre><p>&emsp;&emsp;从某种意义上来讲， 成功学也是一门放弃的哲学。老子告诉我们，对有些事情是没有必要执着的，必须学会选择，学会放弃。</p><p>&emsp;&emsp;在人生中，必要的放弃不是失败，而是智慧；必要的放弃不是削减，而是升华。放弃才是一种非常正确的思维方式。</p><h3 id="4-7-五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此"><a href="#4-7-五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此" class="headerlink" title="4.7. 五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此"></a>4.7. 五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此</h3><pre><code>缤纷的五色让人眼瞎，烦乱的五音让人耳聋，混杂的无味让人口伤，从马驰骋围猎让人内存发狂，金银财宝让人德行败坏。所以，圣人只求温饱，不妨从自己，放弃物欲，只求生存。</code></pre><p>&emsp;&emsp;以声色犬马困住你，让你无暇顾及其他，只知道，此间乐，不思蜀，自己却慢慢沦为别人的傀儡。</p><h3 id="4-8-是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居"><a href="#4-8-是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居" class="headerlink" title="4.8. 是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居"></a>4.8. 是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居</h3><pre><code>正是这样，圣人在处事方面采用“无为而治”的做法，实施无言的教化方针，任凭万物自然生长而不首倡。给万物生命而不因为这一点将其据为己有，养育万物也不因为这一点而自恃能力甚高，帮助万物成就自己也不会居功自傲。</code></pre><h2 id="5-大直若屈，大巧若拙：大智若愚的智慧"><a href="#5-大直若屈，大巧若拙：大智若愚的智慧" class="headerlink" title="5. 大直若屈，大巧若拙：大智若愚的智慧"></a>5. 大直若屈，大巧若拙：大智若愚的智慧</h2><h3 id="5-1-绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧-利，盗贼无杈。此三者，以力文，不足"><a href="#5-1-绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧-利，盗贼无杈。此三者，以力文，不足" class="headerlink" title="5.1. 绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧#利，盗贼无杈。此三者，以力文，不足"></a>5.1. 绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧#利，盗贼无杈。此三者，以力文，不足</h3><p>   统治者不能自作聪明，而应丢弃那些智巧，这样人民就可以得到百倍的福利。而统治者抛弃那些虚伪的仁义，人民就能够重新变得孝敬和慈爱。抛弃巧诈和趋利的思想，盗贼也就不会出现了。“圣智”“仁义”“巧利”这三个方面，以它们作为治世的法则是远远不够的，这些并非人民的内心和根本的思想，所以它们不足以拿来治理天下。</p><p>&emsp;&emsp;过于聪明的人，常是别人猜忌的对象，因为任何有所图谋的人，都担心从事情刚开始筹划时便被识破。一旦发现有人独具慧眼，那么为了保全自己的一切，必回遣返白鸡、不择手段地加以掩盖，散布留言，捏造罪名。人须抛弃自己引以为傲的聪明技巧，才能保护好自己，才能从容地生活。</p><h3 id="5-2-自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长"><a href="#5-2-自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长" class="headerlink" title="5.2. 自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长"></a>5.2. 自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长</h3><pre><code>常常炫耀自己高明的人，反而让别人无法看到他的高明所在；总是自以为是的人，他的有点反而无法真正地得到彰显；自吹自擂鞠躬自傲的人，反而没有人会承认他的功绩；自我膨胀的人，也难以成为领袖人物。</code></pre><p>&emsp;&emsp;道家主张逍遥任性，但是在道家看来，真正的个性与众不同不是一味地炫耀自己，彰显不同，而是一种智慧的人格气质与行为方式，所以一个人学习道家的做人之道，就须知道在这个社会上为人处世，我们必须学会收敛自己，不要不看时机与环境地彰显自己的个性。因为人的优势往往会成为他致命的弱点，学会收敛锋芒才是保护自己的最佳方法。</p><h3 id="5-3-绝圣弃慧，民利百倍"><a href="#5-3-绝圣弃慧，民利百倍" class="headerlink" title="5.3. 绝圣弃慧，民利百倍"></a>5.3. 绝圣弃慧，民利百倍</h3><pre><code>统治者不能自作聪明，而应丢弃那些智巧，这样人民就可以得到百倍的福利</code></pre><h3 id="5-4-大巧若拙，大辩若讷"><a href="#5-4-大巧若拙，大辩若讷" class="headerlink" title="5.4. 大巧若拙，大辩若讷"></a>5.4. 大巧若拙，大辩若讷</h3><pre><code>最精巧的东西反而显得有点笨拙，最善于辩论的人似乎有些不善言辞。</code></pre><p>&emsp;&emsp;到家认为做认真正的大智慧便是“无知”。大智若愚的人，从来不会张扬自己拥有多少智识，而是心中空空，外表看上去痴傻呆憨，内里却是绝顶的聪明。</p><p>&emsp;&emsp;刘备深明用人不疑的道理，对手下人推心置腹，对其尽心竭力，看似毫无主见，实则成竹在胸。刘备深明韬光养晦之道，大智若愚，一是骗尽天下英雄。</p><h3 id="5-5-合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下"><a href="#5-5-合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下" class="headerlink" title="5.5. 合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下"></a>5.5. 合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下</h3><pre><code>合抱粗细的大树，是从细小的萌芽生长而来；多层高的楼台，也是从平地的泥土一点点积累而来；行使千里之远的地方，也是从脚下一步一步走出来的。</code></pre><p>&emsp;&emsp;成功绝不是一蹴而就的，只有静下心来日积月累地积累蓄力量，才能够“绳锯木断，水滴石穿”。所谓“不积跬步，无以至千里”，一切成功都是通过点点滴滴的积淀最终实现的。</p><p>&emsp;&emsp;成功就是简单的事情重复着去做。每天进步一点点是简单的，之所以有人不成功，不是他做不到，而是他不愿意做哪些简单而重复的事情。因为越简单、越容易的事情，人们也越容易不去做它。</p><h3 id="5-6-夫物芸芸，各归其根"><a href="#5-6-夫物芸芸，各归其根" class="headerlink" title="5.6. 夫物芸芸，各归其根"></a>5.6. 夫物芸芸，各归其根</h3><pre><code>万物纷纷芸芸，各自循归其本源。</code></pre><p>&emsp;&emsp;我们的态度就是别人的态度，我们以什么样的态度对待人生，人生就反过来以什么样的汇报给我们。所以说生命其实很简单，我们老老实实地做好本分，其实就已经足够。</p><h3 id="5-7-揣而锐之，不可长保"><a href="#5-7-揣而锐之，不可长保" class="headerlink" title="5.7. 揣而锐之，不可长保"></a>5.7. 揣而锐之，不可长保</h3><pre><code>如果将铁骑打磨得非常锐利，这种锋利通常难以保存很长时间。</code></pre><p>&emsp;&emsp;聪明一表财富，真正聪明的人会正确使用，他们深藏不露，不到火候不会贸然使用。一昧地急与表现自己，时时处处显露精明，不仅无益于成功，还往往招来祸患。</p><p>&emsp;&emsp;很多朋友都认为，刚工作时一定要尽力表现自己的能力，只有这样才能坐稳自己的位置，因此在工作中就处处争强好胜，挑战强者，把自己的能耐表现出来。</p><h2 id="6-知人者智，自知者明：知人自知的智慧"><a href="#6-知人者智，自知者明：知人自知的智慧" class="headerlink" title="6. 知人者智，自知者明：知人自知的智慧"></a>6. 知人者智，自知者明：知人自知的智慧</h2><h3 id="6-1-知人者智，自知者明"><a href="#6-1-知人者智，自知者明" class="headerlink" title="6.1. 知人者智，自知者明"></a>6.1. 知人者智，自知者明</h3><pre><code>能够了解他人的人是智慧的，能够了解自己的人是明智的。</code></pre><p>&emsp;&emsp;老子说“自知者明”，中国有句经典经验叫做“人贵有自知之明”。在古希腊一座智慧神庙大门上，也写着这样一句箴言———“认识你自己”，古希腊人还把它奉为“神谕”，是最高智慧的象征。</p><p>&emsp;&emsp;所谓“自知之明”，就是自己了解自己，自己能够认识自己。</p><p>&emsp;&emsp;一个人应当正确地判断自己，自觉地为自己的能力、学识、容貌、背景打分，从而得到一个清晰地判断，那些事情自己应该做，那些事情自己做不了，这样才会选择幸福的生活、快乐的职业，才有平和的心态。</p><h3 id="6-2-故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。"><a href="#6-2-故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。" class="headerlink" title="6.2. 故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。"></a>6.2. 故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。</h3><pre><code>所以，贵以贱作为根本，高一下作为基础。因此，侯王自称“孤、寡人、不毂”。这难道是不是以低贱作为根本？不是吗？所以至高的荣誉是不需要赞誉的。所以，得“道”的人不愿做光彩的美玉，而愿意成为坚硬普通的石头。</code></pre><p>&emsp;&emsp;老子在人际关系中讲究“处下”，也就是要自己处在“下方”“下位”“下层”，高要以下为根据，贵以贱为根本。这是一种智慧的定位。老子教导人们一切遵循道而行动，而道就是处下的，所以交往中也要选择“处下”。</p><p>&emsp;&emsp;很多人喜欢搞搞在上的感觉，尤其一些管理者，他们处在管理的位置上，给人的感觉经常是高高在上、颐指气使。</p><h3 id="6-3-豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客"><a href="#6-3-豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客" class="headerlink" title="6.3. 豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客"></a>6.3. 豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客</h3><pre><code>（善于行使“道”得人）他们总是小心谨慎，仿佛在冬天涉水过河，怕踏破冰层掉进寒水之中；他们总是警觉戒备，仿佛一个国王害怕邻国的军队随时来进攻自己的国家；他们总是恭敬郑重，仿佛要去远方赴一场重要的宴会，作为上宾的客人一样。</code></pre><p>&emsp;&emsp;从容应对万事，是大智慧，举手投足之间，早已考虑周祥，运筹违章之中，决胜千里之外，正如苏轼在《念奴娇.赤壁怀古》中所写的“谈笑间樯橹灰飞烟灭”。此外，平时待人接物，洞若观火，毫不含糊，这种修养和态度，便是“豫立不老”的形象。</p><h3 id="6-4-不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱"><a href="#6-4-不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱" class="headerlink" title="6.4. 不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱"></a>6.4. 不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱</h3><pre><code>不去推崇德行优秀的人才，这样可以使民众不去争名夺利；不要把稀有的珍宝看得异常珍贵，这样可以使民众不会因为想要占有而沦为强盗；不要将能够诱发贪欲的事物展示出来给民众看，这样民众的心思不会被扰乱。</code></pre><p>&emsp;&emsp;事实上，原本人心纯真无私、政治光明，随着年龄与阅历的增长，渐渐发现周围的许多人都是心有城府、勾心斗角，便不由自主地随波逐流，放弃了自己的之心道场。世风日下，人心不古，社会上风气不正，人们有失淳朴善良而流于谲诈虚伪，心底不再像古人那么淳朴，让许多老人不由感叹“今不如昔”。</p><p>&emsp;&emsp;古代贤人都推崇三代以上的圣帝明王，以之来阐场上古传统文化君道的精神。</p><h3 id="6-5-不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长"><a href="#6-5-不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长" class="headerlink" title="6.5. 不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长"></a>6.5. 不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长</h3><pre><code>不自我炫耀的人，反而更加容易被人看到；不自以为是的人，反而更容易显得名声显赫；不自吹自擂的人，反而更加功勋卓越；不自高自大自满的人，反而最终能达到更高的层次和地位，并且更加长久。</code></pre><p>&emsp;&emsp;人生难得四种病，也就是老子前后所说的四“自”————自见、自是、自伐、自矜。从正面来讲，人需要随时反省，使自己能够看见自己才对，而“不自见，故明”是说，人不可固执于自己主观的成见，如果过于执着，便会“一叶障目，不见泰山”，因此而说“不自间见，故明”。</p><h3 id="6-6-不贵其师，不爱其资，虽智大迷，是谓“要妙”"><a href="#6-6-不贵其师，不爱其资，虽智大迷，是谓“要妙”" class="headerlink" title="6.6. 不贵其师，不爱其资，虽智大迷，是谓“要妙”"></a>6.6. 不贵其师，不爱其资，虽智大迷，是谓“要妙”</h3><pre><code>常人如果不重视那些善人，不将其动作自己的老师，也不珍惜那些不善的人，不将其作为自己的借鉴，即使本人非常聪慧，也会便糊涂。这就是精深微妙的道理所在。</code></pre><p>&emsp;&emsp;我们常常会夸赞说某人聪明，也会鄙弃某人愚笨，一直以来都有聪明人和愚笨人之分，那么他们的区别是什么呢？是天生的智慧，还是情商，亦或是其他？在老子看来，聪明人和愚钝人的唯一区别是善不善于向他人学习。</p><h3 id="6-7-故或下以取，或下而取"><a href="#6-7-故或下以取，或下而取" class="headerlink" title="6.7. 故或下以取，或下而取"></a>6.7. 故或下以取，或下而取</h3><pre><code>所以，有时候谦下能够汇聚众多，有时候谦下能够获得融入。</code></pre><p>&emsp;&emsp;老子的这句话本事用来总结大国该用什么样的态度来对待小国的，他认为大国要有谦虚的态度来对待小的国家，这样才能汇聚更多的小国，而是自己壮大。其实人生又何尝不是如此，一个人要有谦虚的态度，虚心求知，只有这样才能让自己不断地进步，不断地强大。</p><p>&emsp;&emsp;一个人如果去求知，就一定要虚心，切记骄傲，否则很容易得了点皮毛自以为是起来，那只能是白费时间，浪费生命。这就是到家所说的虚怀若谷的道理。</p><h2 id="7-以其无私，故能成其私：利人利己的智慧"><a href="#7-以其无私，故能成其私：利人利己的智慧" class="headerlink" title="7. 以其无私，故能成其私：利人利己的智慧"></a>7. 以其无私，故能成其私：利人利己的智慧</h2><h3 id="7-1-知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴"><a href="#7-1-知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴" class="headerlink" title="7.1. 知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴"></a>7.1. 知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴</h3><pre><code>了解强盛的道理，却能安然处于柔弱的位置，昨天下的溪谷容纳万物；做天下的溪谷，自身就能具备常理与正德，归回婴儿般纯洁的状态。懂得清明的德行，却能安然处于幽暗的地方，昨天下的榜样，如此就能长久保持美德而没有过失，回归宇宙最原始之处的状态。深知荣耀的道理，却能安然处于卑屈的地位，做天下的深谷；做天下的深谷，就能将常理与德行修葺完全，返璞归真。</code></pre><p>&emsp;&emsp;我们从婴儿长大成人后，历经了许多事情，遭受了众多打击，也感受了无数乐趣，在社会这个大染膏中摸爬滚打几十年，成就而各种各种的心态和思想，表现得多知多懂，经验丰富了，物质富足了。可以审多人揣着钱却患得患失，常常感慨“长大了一点都不好，烦恼多了”，其实，这主要是他们离婴儿哪种至柔至顺的样子太远了，失去了自己的初心，拥有的是一颗机心。<br>&emsp;&emsp;很多人都自认为聪明，可以骗了天下人，其实，人的智慧相差无几，一个人的那点小小的伎俩怎么可能瞒得了其他人呢？</p><p>&emsp;&emsp;所以说，做认要学习道家，保持一颗初心就是保留一个真实的自我，保留一种真实的态度。视初心为生命中的至宝，怀着一颗初心生活，应该是人生追求的最高境界。</p><h3 id="7-2-夫轻诺必寡信"><a href="#7-2-夫轻诺必寡信" class="headerlink" title="7.2. 夫轻诺必寡信"></a>7.2. 夫轻诺必寡信</h3><pre><code>轻易承诺必然很少能够守信。</code></pre><p>&emsp;&emsp;中华民族是一个礼仪之邦，热情、助人为乐是中华民族的优秀文化传统之一，自古以来，中国人就十分重视人与人之间的情谊。一个篱笆三个桩，一个好汉三个帮。</p><p>&emsp;&emsp;可是老子的大智慧，在于对人性有深刻的洞察，所以他一针见血地指出，轻易许诺的人必定信用不足。老子所说这句话的目的一方面是告诫我们不要上花言巧语之人的当，另一方面让我们不要轻易许诺，不做言而无信之徒。</p><h3 id="7-3-善者，吾善之；不善者，吾亦善之，德善"><a href="#7-3-善者，吾善之；不善者，吾亦善之，德善" class="headerlink" title="7.3. 善者，吾善之；不善者，吾亦善之，德善"></a>7.3. 善者，吾善之；不善者，吾亦善之，德善</h3><pre><code>对于善良的人，我会善待他；对不不善良的人，我同样会善待他，如果用来彼此也就都得到了真正的善良之心。</code></pre><p>&emsp;&emsp;宽容是一种美德。宽容是壁立千仞的泰山，是容纳百川的江河湖海。深邃的天空容忍了雷电风暴一时的肆虐，才有风和日丽；辽阔的大海容纳了惊涛骇浪一时的猖獗，才有浩渺无垠；苍莽的森林忍耐了弱肉强食的规律，才有郁郁葱葱。</p><p>&emsp;&emsp;与爱人交往，宽容是争吵后的主动修好，是对于爱人性格缺陷的循循善诱，而不是猜测、嫉妒、中伤甚至大动干戈。</p><p>&emsp;&emsp;与朋友交往，宽容是鲍叔牙多分给管仲的黄金。他不计较管仲的自私，也能理解管仲的贪生怕死，还想齐桓公推荐管仲做自己的上司。</p><p>&emsp;&emsp;最后还需要提示一点，宽容，并非说让你对错误不闻不问，而是说，你要学会宽容的方法，这样既不会让犯了错误的人觉得尴尬、羞愧，同时又可以达到教育的目的。</p><h3 id="7-4-以其无私，故能成其私"><a href="#7-4-以其无私，故能成其私" class="headerlink" title="7.4. 以其无私，故能成其私"></a>7.4. 以其无私，故能成其私</h3><pre><code>正是因为不求自己的私信，反而能够成就自己的私心。</code></pre><p>&emsp;&emsp;现代社会争名夺利之事常见，人与人之间的竞争很激烈，利益冲突是常态。如何在竞争中取胜呢？老子告诉你要“不争”“无私”之类的话。可能对于这些话急功近利的你肯定听不下去，稍安勿躁。</p><h3 id="7-5-同于道者，道亦乐得之"><a href="#7-5-同于道者，道亦乐得之" class="headerlink" title="7.5. 同于道者，道亦乐得之"></a>7.5. 同于道者，道亦乐得之</h3><pre><code>与大道和唯一的人，大道也同样愿意帮助其成功。</code></pre><p>&emsp;&emsp;无论你做什么事，都不要做表明功夫，坚持自己的理想，不要被外在的事物所影响。因为，真正为道德做学问的人，要“富贵不能淫，贫贱不能移，威武不能屈”，节操不移，才能出世入世，志在礼他。</p><h3 id="7-6-含德之厚，比于赤子"><a href="#7-6-含德之厚，比于赤子" class="headerlink" title="7.6. 含德之厚，比于赤子"></a>7.6. 含德之厚，比于赤子</h3><pre><code>道德涵养浑厚得人，就好比出生的婴孩。</code></pre><h3 id="7-7-善为士者，不武；善战者，不怒"><a href="#7-7-善为士者，不武；善战者，不怒" class="headerlink" title="7.7. 善为士者，不武；善战者，不怒"></a>7.7. 善为士者，不武；善战者，不怒</h3><pre><code>善于当统帅的人，不会轻易使用自己的武力；善于作战的人，不会随便逞强恼怒。</code></pre><h3 id="7-8-故不得而亲，可不得而疏；不可得而利，不可得而害"><a href="#7-8-故不得而亲，可不得而疏；不可得而利，不可得而害" class="headerlink" title="7.8. 故不得而亲，可不得而疏；不可得而利，不可得而害"></a>7.8. 故不得而亲，可不得而疏；不可得而利，不可得而害</h3><pre><code>因此，既不能因为了解他而投其所好与之亲近，也不能因为了解对方而故意和他书院；不能因为了解而利用对方，也不能因为了解而伤害对方</code></pre><p>&emsp;&emsp;老子的这句话告诉了我们，朋友之间要注重感情的真挚和心灵的纯净，而不可注重表面上的亲近和喧嚣，也就是我们通常所说的“君子之交谈入水”。</p><h2 id="8-祸莫大于不知足，咎莫大于欲得：知足常乐的智慧"><a href="#8-祸莫大于不知足，咎莫大于欲得：知足常乐的智慧" class="headerlink" title="8. 祸莫大于不知足，咎莫大于欲得：知足常乐的智慧"></a>8. 祸莫大于不知足，咎莫大于欲得：知足常乐的智慧</h2><h2 id="9-祸兮福之所倚，福兮祸之所伏：福祸相依的智慧"><a href="#9-祸兮福之所倚，福兮祸之所伏：福祸相依的智慧" class="headerlink" title="9. 祸兮福之所倚，福兮祸之所伏：福祸相依的智慧"></a>9. 祸兮福之所倚，福兮祸之所伏：福祸相依的智慧</h2><h2 id="1-死者天地之理，物质自然：出生入死的智慧"><a href="#1-死者天地之理，物质自然：出生入死的智慧" class="headerlink" title="1 死者天地之理，物质自然：出生入死的智慧"></a>1 死者天地之理，物质自然：出生入死的智慧</h2>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 闲趣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Canal上手指南：mysql到kafka</title>
      <link href="/2018/11/22/canal_start/"/>
      <url>/2018/11/22/canal_start/</url>
      
        <content type="html"><![CDATA[<h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-MySQL账号"><a href="#1-1-MySQL账号" class="headerlink" title="1.1. MySQL账号"></a>1.1. MySQL账号</h3><p>根据Canal官方说明，需要申请一个MySQL数据库的账号，该账号具有如下权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER canal IDENTIFIED BY 'canal';  </span><br><span class="line">-- 至少具有如下权限</span><br><span class="line">GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';</span><br><span class="line">-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ; -- 需要具有SHOW VIEW 权限</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><p>并保证目标主机与MySQL数据库之间<strong>3306</strong>端口的连通性。</p><a id="more"></a><h3 id="1-2-安装Java"><a href="#1-2-安装Java" class="headerlink" title="1.2. 安装Java"></a>1.2. 安装Java</h3><p>由于是一个Java程序，因此需要在目标机上事先安装JDK。</p><h3 id="1-3-Kafka"><a href="#1-3-Kafka" class="headerlink" title="1.3. Kafka"></a>1.3. Kafka</h3><p>本项目目的是将Binlog数据发往Kafka，因此需要一个Kafka集群或单机节点，并保证<strong>9092</strong>端口的连通性。</p><h3 id="1-4-Zookeeper"><a href="#1-4-Zookeeper" class="headerlink" title="1.4. Zookeeper"></a>1.4. Zookeeper</h3><p>如果启用高可用，或将元数据保存在Zookeeper上，那么需要保证目标主机与ZK集群之间<strong>2181</strong>端口的连通性。</p><h2 id="2-配置工作"><a href="#2-配置工作" class="headerlink" title="2. 配置工作"></a>2. 配置工作</h2><p>&emsp;&emsp;配置Canal是一个不断摸索的过程，根据Git上面的文档，以及项目源码，如果有问题出现，基本上可以定位到问题出处。虽然Git上面有比较详尽的说明，但在测试时，还是会遇到各种各样的问题。这就需要充分理解相关配置参数的含义，以及参数之间的搭配，才能更好地使用这个工具。</p><h3 id="2-1-canal说明"><a href="#2-1-canal说明" class="headerlink" title="2.1. canal说明"></a>2.1. canal说明</h3><p>需要特别注意以下几个配置内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置ZK地址：如果需要启用高可用，目前高可用仅支持同时一个节点工作</span></span></span><br><span class="line">canal.zkServers=</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置sink方式：目前支持以下三种</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## tcp, kafka, RocketMQ</span></span></span><br><span class="line">canal.serverMode=</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 并发配置：这里是二选一</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 1. 单线程处理</span></span></span><br><span class="line">canal.instance.parser.parallel = false</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 2. 处理过程如下[源代码]</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##  * 1. 网络接收 (单线程)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##  * 2. 事件基本解析 (单线程，事件类型、DDL解析构造TableMeta、维护位点信息)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##  * 3. 事件深度解析 (多线程, DML事件数据的完整解析)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##  * 4. 投递到store (单线程)</span></span></span><br><span class="line">canal.instance.parser.parallel = true</span><br><span class="line">canal.instance.parser.parallelThreadSize = 6</span><br><span class="line">canal.instance.parser.parallelBufferSize = 4096</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># MQ配置：配置Kafka的服务器: “IP1:9092,IP2:9092,,,”</span></span></span><br><span class="line">canal.mq.servers=</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># MQ配置：设置消息序列化方式，true--json, false--protobuf</span></span></span><br><span class="line">canal.mq.flatMessage=true</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># MQ设置</span></span></span><br><span class="line">canal.mq.acks=</span><br><span class="line">canal.mq.lingerMs=</span><br></pre></td></tr></table></figure><h3 id="2-2-instance说明"><a href="#2-2-instance说明" class="headerlink" title="2.2. instance说明"></a>2.2. instance说明</h3><p>Instance中需要注意的配置项目如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># GTID设置：如果配置为true，那么需要给出：canal.instance.master.gtid=</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 一般设置为false，小的项目就够了：自动寻找，以及记忆Binlog位置</span></span></span><br><span class="line">canal.instance.gtidon=false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 设置源数据库：用户名、密码、默认数据库</span></span></span><br><span class="line">canal.instance.dbUsername=</span><br><span class="line">canal.instance.dbPassword=</span><br><span class="line">canal.instance.defaultDatabaseName = </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Kafka设置</span></span></span><br><span class="line">canal.mq.topic=</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 二选一</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 1. 配置partition数量，并配合映射规则：实际代码中，优先判断该种情况</span></span></span><br><span class="line">canal.mq.partitionsNum=3</span><br><span class="line">canal.mq.partitionHash=mytest.person:id,mytest.role:id</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 2. 配置为0，或不配置</span></span></span><br><span class="line">canal.mq.partition=</span><br></pre></td></tr></table></figure><h2 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h2><h3 id="3-1-默认数据库"><a href="#3-1-默认数据库" class="headerlink" title="3.1. 默认数据库"></a>3.1. 默认数据库</h3><p>在实际测试中，这个默认数据库的设置不知道起到了什么作用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">canal.instance.defaultDatabaseName =</span><br></pre></td></tr></table></figure><p>在获取MySQL Binlog时，这个MySQL实例的Binlog都获取到了，并传输到了Kafka中。</p><h3 id="3-2-配置错误"><a href="#3-2-配置错误" class="headerlink" title="3.2. 配置错误"></a>3.2. 配置错误</h3><p>在配置mq.yml文件时，遇到了一个基本常识错误</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 错误配置</span></span></span><br><span class="line">canalDestinations:</span><br><span class="line">  - canalDestination: example</span><br><span class="line">    topic:example</span><br><span class="line">    partition:0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 正确配置</span></span></span><br><span class="line">canalDestinations:</span><br><span class="line">  - canalDestination: example</span><br><span class="line">    topic: example</span><br><span class="line">    partition: 0</span><br></pre></td></tr></table></figure><p>即在YML配置中，基本上是这种模式的[Key: value]。</p><p>&emsp;&emsp;<strong>博主在使用的时候，场景比较简单，配置也较为简单，目标仅是让整个流程跑起来，对于其他的参数未做详细的了解以及探究，其中不免有错误之处，欢迎留言指正。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Kafka </tag>
            
            <tag> MySQL </tag>
            
            <tag> Canal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apache Spark vs. Apache Flink</title>
      <link href="/2018/10/22/flink.vs.spark/"/>
      <url>/2018/10/22/flink.vs.spark/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>&emsp;&emsp;Apache Flink，这个高性能大数据流处理框架，走到了成熟的一个阶段。通过与Apache Spark的测试比较，我们发现他们是竞对的技术，且是被推荐的实时分析框架。</p><p>&emsp;&emsp;从之前的Hadoop MR框架，大数据流处理框架在逐渐演进。在某种意义上，Spark不经大规模提升了计算性能，更重要的是允许快速、简单的构建数据分析框架，从而推广了Hadoop。</p><p>&emsp;&emsp;讨论到Flinke，与其竞争对手相比，其不仅是一些新兴技术，而且正在加速获得动力，并迅速向企业化推进。Flink支持流处理、批处理数据，同时集成对机器学习和图处理的支持。</p><p>&emsp;&emsp;<strong>但在当技术泛滥的当下，我们是否真的需要一项新的流处理技术?</strong> 目前，当下的Apache Spark已经提供了相似的特征与功能，并且最近几年已经成为一种非常流行的工具。Curt Monash对讨论的观点是：Flink基本上是德国的Spark，我认为是不必要的。因此，我们对比一下Flink与Spark的一些特点，来判断Flink是否与Spark竞争，或Flink仅仅是另一个大数据生态的泛滥工具？首先，我们比较了一下两种技术。</p><h2 id="相同之处"><a href="#相同之处" class="headerlink" title="相同之处"></a>相同之处</h2><p>&emsp;&emsp;它们都是Apache组织内的开源工具。每一个都是独立的解决方案，但他们通常集成到大数据环境中，例如Hadoop(YARN,HDFS,以及Kafka)。Spark和Flink都提供了相似的特征与API，例如支持SQL查询，图处理，以及批处理和流处理。</p><table><thead><tr><th>Spark vs. Flink</th><th>Apache Flink</th><th>Apache Spark</th></tr></thead><tbody><tr><td>SQL查询</td><td>MRQL</td><td>Spark SQL</td></tr><tr><td>图处理</td><td>Spargel(base)，Gelly(library)</td><td>GraphX</td></tr><tr><td>流处理</td><td>Flink Streaming</td><td>Spark Streaming</td></tr><tr><td>APIs</td><td>Scala,Java,Python</td><td>Scala,Java,Python,R</td></tr><tr><td>机器学习</td><td>Flink ML</td><td>MLib, ML</td></tr><tr><td>Stable Version</td><td>1.3.2</td><td>2.2.0</td></tr><tr><td>吞吐量</td><td>高</td><td>高</td></tr><tr><td>容错性</td><td>Exactly-once</td><td>Exactly-once</td></tr><tr><td>部署</td><td>Standalone,Mesos,EC2,YARN</td><td>Standalone,Mesos,EC2,YARN</td></tr><tr><td>数据源</td><td>Kafka, Amazon S3, ES, Twitter, etc</td><td>Kafka, Amazon S3, ES, Twitter, etc</td></tr></tbody></table><p>&emsp;&emsp;下面的代码说明了他们的相似性，但不尽相同。每段代码包含了固定的元素，以及计算最高分布频次的产品。一撇就可以看出每个技术方法的高度相似性，优劣与劣势也具有平衡性。只有深入挖掘不同框架的特征，才能够识别出不同姓。在这个特殊的案例中，可以看出在Flink中的maxBy函数在Spark中没有受到支持，并且Spark需要使用窗口函数，但这类API通常具有相同的数据处理构建方式。</p><p><img src="/2018/10/22/flink.vs/code_flink_spark.png" alt="Flink vs. Spark编码对比: Java中的代码比较"></p><h2 id="批处理-vs-水龙头"><a href="#批处理-vs-水龙头" class="headerlink" title="批处理 vs 水龙头"></a>批处理 vs 水龙头</h2><p>&emsp;&emsp;Flink与Spark的最大不同之处在于不同框架的计算理念不同。Spark针对批处理和流处理使用“批”的概念，而Flink是基于单纯的流方式。想想一下收集与运输水的过程： Spark处理的方式为混合大小的桶，Flink是直接按照水龙头的方式直接处理。Flink与Spark的不同之处列列举如下<br>| Spark vs. Flink | Apache Spark | Apache Flink |<br>| - | - | - |<br>| Steaming | 微“批”流 | 基于事件的流 |<br>| Batch Processing | 内存处理，DAG组织算子 | 流悠闲方式：”批”是有限的流 |<br>| 语言 | Scala | Java |<br>| 优化|全阶段代码生成与优化，DataSet查询优化执行计划。手动内存调优非常重要 | 自动化优化：根据输入、输出、算子，主动选择合适方法。C++风格的内存管理 |<br>| 数据重用与迭代 | DAG执行计划：每一个迭代需要调度与运行相同的数据。内存缓存与重用 | 执行引擎中迭代处理，基于圆形数据流(一个迭代，一个计划)。另外，提供了Delta迭代来处理改变部分数据 |<br>| 延迟性 | 批处理导致高延迟，秒级别的延迟 | 微妙级别的低延迟 |<br>| 有序流 | 新版本中，提供了基于事件处理的基本方式 | 基于时间线，有序流可以被很好的处理 |<br>| 支持 | 支持所有的hadoop分布：Cloudera, Hortonworks, etc. Databricks提供了晕平台和支持包 | 使用邮件列表或论坛 |</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>&emsp;&emsp;批处理的表现性能，依赖于不同的负载。有些Benchmark的测试，显示Flink0.9.1快于Spark1.5.1。关于机器学习库这一方面，Spark的测试显示其性能更优(Flink 1.0.3 vs. Spark1.6.0)。在2016年9月份，Flink和Spark分析了一些批处理和迭代处理的测试，这些测试表明Spark在图处理方面1.7倍快于Flink,而Flink在批处理和小规模图负载方面1.5倍快于SPark，且使用更少的资源。这表明，工具直接的性能与功能大同小异。</p><p>&emsp;&emsp;从这些性能比较中可以得出的结论是，要选择更快的框架，必须对特定的工作负载进行基准测试。针对这些主题，几乎没有最近版本的比较(Spark 2.2 vs. Flink1.3)。这很麻烦，因为这两个平台甚至在过去一年里都取得了令人印象深刻的性能提升。在我们博客的第2部分中，我们将提供我们自己的详细性能比较，请继续关注!</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>&emsp;&emsp;大数据作为不断增加的容量、对质量的高要求以及对更快的业务洞察力的需求的三重挑战，继续要求技术在任何规模的延迟和吞吐量方面保持高性能，同时允许快速开发和高质量的代码。</p><p>&emsp;&emsp;如果高吞吐量、低延迟和良好的容错性的数据流处理需求是开发的驱动因素，那么Flink提供了一个优秀的应用程序框架[1]。如果应用程序应该嵌入到Hadoop发行版中，比如Hortonworks或Cloudera，那么Spark将是一个更好的选择，因为它已经很好地集成到各自的平台中，并得到了供应商的支持。Flink和Spark都在不断改进，以提供更简单、更快和更智能的数据处理特性。</p><p>&emsp;&emsp;最终，最佳框架的决定取决于这样一个问题:“哪一个更适合我的需求?”即使是开发团队最喜欢的编程语言也可能是一个关键因素——Spark的Java API源自Scala API:这有时会导致不吸引人的Java代码。数据工程师通常更喜欢Python或Scala, Spark支持更成熟、功能更完备、速度更快的api。Spark与R的紧密集成——“数据科学的黄金之子”——在R中提供了Spark，从而很好地集成到现有的数据科学工具箱中。</p><p>&emsp;&emsp;引发最推崇的特性之一是速度可以，运行程序比Hadoop MapReduce快100倍在内存中,或磁盘上的快10倍。Flink在批处理方面提供了强大的竞争优势，通常具有相似的性能，并且显著降低了流处理的延迟。尽管Spark社区的“炒作”似乎转移到了Flink，但只有未来才能说明这对实际市场份额有多大影响。</p>]]></content>
      
      
      <categories>
          
          <category> 读书比较 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Spark </tag>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle JDBC为什么不能在Maven中直接配置？</title>
      <link href="/2018/09/12/ODBC%E5%AD%A6%E4%B9%A0/"/>
      <url>/2018/09/12/ODBC%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在实际项目中，我们通常使用这样的方式：首先，下载ODBC的Jar到本地；然后，通过Maven安装在本地库中。这样在项目中就可以使用ODBC的Jar包了，而大部分的jar是可以通过Maven中直接引用的。这是为什么呢？</p><h2 id="项目报错"><a href="#项目报错" class="headerlink" title="项目报错"></a>项目报错</h2><p>&emsp;&emsp;项目直接编译，报错如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Failed to execute goal on project sql2o-oracle: </span><br><span class="line">Could not resolve dependencies for project org.sql2o.extensions: sql2o-oracle:jar:1.6.0-RC4-SNAPSHOT: </span><br><span class="line">Could not find artifact com.oracle.jdbc:ojdbc8:jar:12.2.0.1 in central (https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2)</span><br></pre></td></tr></table></figure><p>很明显项目中的引用：com.oracle.jdbc:ojdbc8:jar:12.2.0.1，无法在公共仓库中找到。</p><h2 id="常用做法"><a href="#常用做法" class="headerlink" title="常用做法"></a>常用做法</h2><p>&emsp;&emsp;一般的做法就是下载Jar包，然后存放在本地仓库中，这样就可以直接在项目中引用。但通常这样略显麻烦，也不具有通用性。之前这样做的原因主要是涉及到许可的原因，Oracle不开放ODBC的Jar不会开放到公共仓库中。<br>&emsp;&emsp;关于ODBC方面的讨论可以参考：<a href="https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository" target="_blank" rel="noopener">Find Oracle JDBC driver in Maven repository</a> .</p><h2 id="目前实现"><a href="#目前实现" class="headerlink" title="目前实现"></a>目前实现</h2><p>&emsp;&emsp;目前可以通过POM中的配置来直接使用Oracle仓库中的Jar，环境可以参考：<a href="https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9010" target="_blank" rel="noopener">6 Configuring the Oracle Maven Repository</a> .</p><p>&emsp;&emsp;博主主要分为三步实现本地Oracle库的配置：</p><ol><li>注册账号：<a href="https://www.oracle.com/webapps/maven/register/license.html" target="_blank" rel="noopener">https://www.oracle.com/webapps/maven/register/license.html</a> 。如果已经注册过OTN(Oracle Technology Network)的账号，所以直接跳过；</li><li>配置本地Settings.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;server&gt;</span><br><span class="line">&lt;id&gt;maven.oracle.com&lt;&#x2F;id&gt;</span><br><span class="line">&lt;username&gt;[OTN username]&lt;&#x2F;username&gt;</span><br><span class="line">&lt;password&gt;[OTN password]&lt;&#x2F;password&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;basicAuthScope&gt;</span><br><span class="line">&lt;host&gt;ANY&lt;&#x2F;host&gt;</span><br><span class="line">&lt;port&gt;ANY&lt;&#x2F;port&gt;</span><br><span class="line">&lt;realm&gt;OAM 11g&lt;&#x2F;realm&gt;</span><br><span class="line">&lt;&#x2F;basicAuthScope&gt;</span><br><span class="line">&lt;httpConfiguration&gt;</span><br><span class="line">&lt;all&gt;</span><br><span class="line">&lt;params&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;http.protocol.allow-circular-redirects&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;%b,true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;params&gt;</span><br><span class="line">&lt;&#x2F;all&gt;</span><br><span class="line">&lt;&#x2F;httpConfiguration&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line">&lt;&#x2F;server&gt;</span><br></pre></td></tr></table></figure></li><li>Maven中配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;repositories&gt;</span><br><span class="line">&lt;repository&gt;</span><br><span class="line">&lt;id&gt;maven.oracle.com&lt;&#x2F;id&gt;</span><br><span class="line">&lt;releases&gt;</span><br><span class="line">&lt;enabled&gt;true&lt;&#x2F;enabled&gt;</span><br><span class="line">&lt;&#x2F;releases&gt;</span><br><span class="line">&lt;snapshots&gt;</span><br><span class="line">&lt;enabled&gt;false&lt;&#x2F;enabled&gt;</span><br><span class="line">&lt;&#x2F;snapshots&gt;</span><br><span class="line">&lt;url&gt;https:&#x2F;&#x2F;maven.oracle.com&lt;&#x2F;url&gt;</span><br><span class="line">&lt;layout&gt;default&lt;&#x2F;layout&gt;</span><br><span class="line">&lt;&#x2F;repository&gt;</span><br><span class="line">&lt;&#x2F;repositories&gt;</span><br><span class="line">&lt;pluginRepositories&gt;</span><br><span class="line">&lt;pluginRepository&gt;</span><br><span class="line">&lt;id&gt;maven.oracle.com&lt;&#x2F;id&gt;</span><br><span class="line">&lt;url&gt;https:&#x2F;&#x2F;maven.oracle.com&lt;&#x2F;url&gt;</span><br><span class="line">&lt;&#x2F;pluginRepository&gt;</span><br><span class="line">&lt;&#x2F;pluginRepositories&gt;</span><br></pre></td></tr></table></figure></li></ol><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><ol><li>虽然通过这种方式，可以直接获取相应的Jar。但实现需要知道Jar的相关信息，例如groupId、artifactId、version等。这些信息在哪里知道？</li><li>通过权限访问这种方式，略显复杂。如果是公司的本地库，可以配置统一的Jar管理，例如artifactory软件等。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://blogs.oracle.com/dev2dev/get-oracle-jdbc-drivers-and-ucp-from-oracle-maven-repository-without-ides" target="_blank" rel="noopener">Get Oracle JDBC drivers and UCP from Oracle Maven Repository (without IDEs)</a></li><li><a href="https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository/27943380#27943380" target="_blank" rel="noopener">Find Oracle JDBC driver in Maven repository</a></li><li><a href="https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9010" target="_blank" rel="noopener">6 Configuring the Oracle Maven Repository</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 问题 </tag>
            
            <tag> JDBC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive复杂类型的导入</title>
      <link href="/2018/08/10/Hive%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%BC%E5%85%A5/"/>
      <url>/2018/08/10/Hive%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%BC%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;Hive是大数据体系下ETL、数据预处理、数仓等领域比较重要的组件，应用广泛。博主空闲时间研究一下Hive的数据类型。</p><h2 id="1-Hive数据类型组成"><a href="#1-Hive数据类型组成" class="headerlink" title="1. Hive数据类型组成"></a>1. Hive数据类型组成</h2><p>&emsp;&emsp;关于Hive的数据类型，官方文档展示的比较全面，关于数据类型的详细说明<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types" target="_blank" rel="noopener">Hive数据类型</a>，这里总结如下<br>| 大类 | 类型 | 具体类型 |<br>| – | – | - |<br>| 基本类型| 数值型 |tinyint,smallint,int,bigint,float,double,decimal,numeric  |<br>| 基本类型 | 字符型 | string,varchar,char  |<br>| 基本类型 | 日期型 | timestamp,date,interval  |<br>| 基本类型 | 其他 | boolean,binary  |<br>| 复杂类型 | 数组 | array  |<br>| 复杂类型 | 映射 | map  |<br>| 复杂类型 | 结构 | struct  |<br>| 复杂类型 | 联合 | uniontype  |</p><h2 id="2-数据导入举例"><a href="#2-数据导入举例" class="headerlink" title="2. 数据导入举例"></a>2. 数据导入举例</h2><p>&emsp;&emsp;这里主要研究具体建表、产生测试数据、导入数据等内容。</p><h3 id="2-1-建表语句"><a href="#2-1-建表语句" class="headerlink" title="2.1. 建表语句"></a>2.1. 建表语句</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">create table test_hive_meta(</span><br><span class="line">    name string,</span><br><span class="line">    age int,</span><br><span class="line">    score float,</span><br><span class="line">    insert_time string,-- 刚开始定义的是date类型，后面修改为string或timestamp</span><br><span class="line">    students struct&lt;sname:string,sage:int&gt;,</span><br><span class="line">    infos map&lt;int,string&gt;,</span><br><span class="line">    scores array&lt;float&gt;</span><br><span class="line">)  comment &quot;测试数据表&quot;</span><br><span class="line">ROW FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED BY &#39;\t&#39;  </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &#39;-&#39;</span><br><span class="line">MAP KEYS TERMINATED BY &#39;:&#39;</span><br><span class="line">STORED as TEXTFILE ;</span><br></pre></td></tr></table></figure><h3 id="2-2-产生测试数据"><a href="#2-2-产生测试数据" class="headerlink" title="2.2. 产生测试数据"></a>2.2. 产生测试数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMain</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] names = <span class="keyword">new</span> String[] &#123; <span class="string">"Laird"</span>, <span class="string">"莱尔德"</span>, <span class="string">"Lambert"</span>, <span class="string">"兰伯特"</span>, <span class="string">"Lamont"</span>, <span class="string">"拉蒙特"</span>, <span class="string">"Lance"</span>,</span><br><span class="line"><span class="string">"兰斯"</span>, <span class="string">"Lang"</span>, <span class="string">"兰格"</span>, <span class="string">"Lange"</span>, <span class="string">"兰格"</span>, <span class="string">"Langston"</span>, <span class="string">"兰斯顿"</span>, <span class="string">"Lanny"</span>, <span class="string">"兰尼"</span>, <span class="string">"Larkin"</span>, <span class="string">"拉金"</span>, <span class="string">"Larry"</span>, <span class="string">"拉里"</span>,</span><br><span class="line"><span class="string">"Clementina"</span>, <span class="string">"克莱门蒂娜"</span>, <span class="string">"Clementine"</span>, <span class="string">"克莱门廷"</span>, <span class="string">"Clemmie"</span>, <span class="string">"克莱米"</span>, <span class="string">"Cleo"</span>, <span class="string">"克利奥"</span>, <span class="string">"Cleopatra"</span>, <span class="string">"克利奥帕特拉"</span>,</span><br><span class="line"><span class="string">"Colette"</span>, <span class="string">"科莱特"</span>, <span class="string">"Colleen"</span>, <span class="string">"科琳"</span>, <span class="string">"Conchita"</span>, <span class="string">"康奇塔"</span>, <span class="string">"Connie"</span>, <span class="string">"康妮，康尼"</span>, <span class="string">"Constance"</span>, <span class="string">"康斯坦斯"</span>, <span class="string">"Alvina"</span>,</span><br><span class="line"><span class="string">"阿尔文娜"</span>, <span class="string">"Alvira"</span>, <span class="string">"阿尔薇拉"</span>, <span class="string">"Amabel"</span>, <span class="string">"阿玛贝尔"</span>, <span class="string">"Amanda"</span>, <span class="string">"阿曼达"</span>, <span class="string">"Amber"</span>, <span class="string">"安伯"</span>, <span class="string">"Amelia"</span>, <span class="string">"阿米莉亚"</span>, <span class="string">"Amity"</span>,</span><br><span class="line"><span class="string">"阿米蒂"</span>, <span class="string">"Amor"</span>, <span class="string">"埃默"</span>, <span class="string">"Amy"</span>, <span class="string">"艾米"</span>, <span class="string">"Ana"</span>, <span class="string">"安娜"</span>, <span class="string">"Ware"</span>, <span class="string">"韦尔"</span>, <span class="string">"Warner"</span>, <span class="string">"沃纳"</span>, <span class="string">"Warren"</span>, <span class="string">"沃伦"</span>, <span class="string">"Washburn"</span>,</span><br><span class="line"><span class="string">"沃什伯恩"</span>, <span class="string">"Washington"</span>, <span class="string">"华盛顿"</span>, <span class="string">"Watkins"</span>, <span class="string">"沃特金斯"</span>, <span class="string">"Watt"</span>, <span class="string">"瓦特"</span>, <span class="string">"Watts"</span>, <span class="string">"沃茨"</span>, <span class="string">"Wayne"</span>, <span class="string">"韦恩"</span>, <span class="string">"Webb"</span>, <span class="string">"韦布"</span>,</span><br><span class="line"><span class="string">"Lina"</span>, <span class="string">"莉娜"</span>, <span class="string">"Linda"</span>, <span class="string">"琳达"</span>, <span class="string">"Lindy"</span>, <span class="string">"琳迪"</span>, <span class="string">"Linn"</span>, <span class="string">"林"</span>, <span class="string">"Linsey"</span>, <span class="string">"林赛"</span>, <span class="string">"Lisa"</span>, <span class="string">"莉萨"</span>, <span class="string">"Lisbeth"</span>, <span class="string">"莉斯贝思"</span>,</span><br><span class="line"><span class="string">"Lise"</span>, <span class="string">"莉萨"</span>, <span class="string">"Lisette"</span>, <span class="string">"莉塞特"</span>, <span class="string">"Liz"</span>, <span class="string">"莉兹"</span> &#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> SimpleDateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-mm-dd HH:MM:ss"</span>);</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> size = names.length;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">char</span>[] a = &#123; <span class="string">','</span> &#125;;<span class="comment">// fields termination</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">char</span>[] b = &#123; <span class="string">'-'</span> &#125;;<span class="comment">// collection item termination</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">char</span>[] c = &#123; <span class="string">':'</span> &#125;;<span class="comment">// map key termination</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">File file = <span class="keyword">new</span> File(<span class="string">"./data.txt"</span>);</span><br><span class="line"><span class="keyword">if</span> (!file.exists()) &#123;</span><br><span class="line">file.createNewFile();</span><br><span class="line">&#125;</span><br><span class="line">FileWriter fw = <span class="keyword">new</span> FileWriter(file.getAbsoluteFile());</span><br><span class="line">BufferedWriter bw = <span class="keyword">new</span> BufferedWriter(fw);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">bw.write(gen1Line());</span><br><span class="line">&#125;</span><br><span class="line">bw.close();</span><br><span class="line">System.out.println(<span class="string">"Done"</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">gen1Line</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">StringBuffer line = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">line.append(names[random.nextInt(size)]);</span><br><span class="line">line.append(a);</span><br><span class="line">line.append(random.nextInt(<span class="number">100</span>));</span><br><span class="line">line.append(a);</span><br><span class="line">line.append(random.nextDouble() * <span class="number">10</span>);</span><br><span class="line">line.append(a);</span><br><span class="line">line.append(sdf.format(<span class="keyword">new</span> Date()));</span><br><span class="line">line.append(a);</span><br><span class="line"></span><br><span class="line">line.append(names[random.nextInt(size)]);</span><br><span class="line">line.append(b);</span><br><span class="line">line.append(random.nextInt(<span class="number">100</span>));</span><br><span class="line">line.append(a);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">line.append(random.nextInt(<span class="number">100</span>));</span><br><span class="line">line.append(c);</span><br><span class="line">line.append(names[random.nextInt(size)]);</span><br><span class="line">line.append(b);</span><br><span class="line">&#125;</span><br><span class="line">line.append(random.nextInt(<span class="number">100</span>));</span><br><span class="line">line.append(c);</span><br><span class="line">line.append(names[random.nextInt(size)]);</span><br><span class="line">line.append(a);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">line.append(random.nextDouble() * <span class="number">10</span>);</span><br><span class="line">line.append(b);</span><br><span class="line">&#125;</span><br><span class="line">line.append(random.nextDouble() * <span class="number">10</span>);</span><br><span class="line">line.append(<span class="string">"\n"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> line.toString();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-导入数据测试"><a href="#2-3-导入数据测试" class="headerlink" title="2.3. 导入数据测试"></a>2.3. 导入数据测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-- 导入数据</span><br><span class="line">load data local inpath "/home/data.txt" into table test_hive_meta;</span><br><span class="line"></span><br><span class="line">-- 为了便于查看导入数据结果，打开列显示</span><br><span class="line">set hive.cli.print.header=true;</span><br><span class="line">set hive.cli.print.row.to.vertical=true;</span><br><span class="line">set hive.cli.print.row.to.vertical.num=1;</span><br></pre></td></tr></table></figure><h3 id="2-4-查看导入结果"><a href="#2-4-查看导入结果" class="headerlink" title="2.4. 查看导入结果"></a>2.4. 查看导入结果</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 查询</span><br><span class="line">select * from test_hive_meta limit 1 ;</span><br><span class="line"></span><br><span class="line">-- 结果</span><br><span class="line">nameagescoreinsert_timestudentsinfosscores</span><br><span class="line">Cleopatra110.282060652018-14-11 17:08:15&#123;"sname":"阿玛贝尔","sage":15&#125;&#123;41:"Linda",82:"康斯坦斯",94:"艾米",81:"Washington",23:"兰尼",93:"Lise",36:"沃纳",70:"Lise",39:"克利奥帕特拉",35:"Lambert",67:"Colleen"&#125;[1.8265022,6.058134,7.794176,4.096524,8.195735,5.866253,0.75852406,6.835354,2.7134678,8.078223,6.275408]</span><br></pre></td></tr></table></figure><h2 id="3-采坑"><a href="#3-采坑" class="headerlink" title="3. 采坑"></a>3. 采坑</h2><ol><li>关于date数据类型<br>发现使用date数据类型在导入的时候存在问题，刚开始使用date类型，导入类型为long，结果显示为null；后面导入数据修改为”yyyy-MM-dd HH:mm:ss”之后，结果仍为null。后面修改为string类型，导入数据为格式化的日期类型，或者修改为timestamp类型，导入类型为long。</li></ol><h2 id="4-参考文章"><a href="#4-参考文章" class="headerlink" title="4. 参考文章"></a>4. 参考文章</h2><ol><li><a href="https://cwiki.apache.org/confluence/display/hive" target="_blank" rel="noopener">Apache Hive Document</a></li><li><a href="https://blog.csdn.net/kellyzly/article/details/30267557" target="_blank" rel="noopener">hive collection data type</a></li><li><a href="http://www.aboutyun.com/thread-13220-1-1.html" target="_blank" rel="noopener">Hive中导入时间格式的数据显示为null </a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Springboot报错</title>
      <link href="/2018/08/07/SpringBoot%E6%8A%A5%E9%94%99/"/>
      <url>/2018/08/07/SpringBoot%E6%8A%A5%E9%94%99/</url>
      
        <content type="html"><![CDATA[<h2 id="报错一"><a href="#报错一" class="headerlink" title="报错一"></a>报错一</h2><ul><li><em>错误信息</em>:<br>  Cannot determine embedded database driver class for database type NONE</li><li><em>解决方案</em>：启动类中加入注解：<br>@SpringBootApplication(exclude={DataSourceAutoConfiguration.class,HibernateJpaAutoConfiguration.class})</li></ul><h2 id="报错二"><a href="#报错二" class="headerlink" title="报错二"></a>报错二</h2><ul><li><em>错误信息</em>:<br>  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘httpPutFormContentFilter’ defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedHttpPutFormContentFilter]: Factory method ‘httpPutFormContentFilter’ threw exception; nested exception is java.lang.VerifyError: Cannot inherit from final class</li><li><em>解决方案</em>：<br>  更换Spring-Parent的版本。  <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">//更改之前</span></span><br><span class="line">   &lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;2.0.2.RELEASE&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">&lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">   &lt;/dependency&gt;</span><br><span class="line">   </span><br><span class="line">   <span class="comment">// 更改之后</span></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;1.5.1.RELEASE&lt;/version&gt;</span><br><span class="line">&lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">&lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="报错三"><a href="#报错三" class="headerlink" title="报错三"></a>报错三</h2><ul><li><em>错误信息</em>:<br>  Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.filter.OrderedHttpPutFormContentFilter]: Factory method ‘httpPutFormContentFilter’ threw exception; nested exception is java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z<br>  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)<br>  at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)<br>  … 40 more<br>  Caused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z</li><li><em>解决方案</em>：</li></ul><h2 id="参考汇总"><a href="#参考汇总" class="headerlink" title="参考汇总"></a>参考汇总</h2><ol><li><a href="https://blog.csdn.net/Loser100/article/details/78190703?locationNum=9&fps=1" target="_blank" rel="noopener">SpringBoot常见问题（一）</a></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题 </tag>
            
            <tag> Springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive JDBC任务执行流程</title>
      <link href="/2018/08/04/Hive-JDBC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
      <url>/2018/08/04/Hive-JDBC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;Hive提供了多种访问方式，其中JDBC是一种。通常通过JDBC访问，可以规避用户对HDFS、Metastore的直接访问。本文研究研究一下HiveJDBC执行任务的流程。</p><h2 id="JDBC执行流程"><a href="#JDBC执行流程" class="headerlink" title="JDBC执行流程"></a>JDBC执行流程</h2><p><img src="/.io//004.png" alt="Hive客户端与服务端的交互"></p><p>&emsp;&emsp;主要流程分为三条线：</p><ol><li>执行任务，无返回<br> 执行完成，获取执行结果[boolean/int]，直接结束</li><li>执行任务，返回数据<br> 执行完成，通过接口获取数据，用户执行其他相关操作</li><li>执行任务，查询日志<br> 执行任务的同时，可以获取执行日志。通过单独的接口，可以分别获取日志与数据。</li></ol><p>&emsp;&emsp;使用JDBC查询日志，存在锁竞争的问题，因而表现出来的现象就是通过JDBC获取日志比较慢。具体可以参考：<a href="https://www.cnblogs.com/oldtrafford/p/8818756.html" target="_blank" rel="noopener">hive-jdbc获取查询日志慢的问题发现与解决</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive提交任务流程</title>
      <link href="/2018/08/04/Hive%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B/"/>
      <url>/2018/08/04/Hive%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<!-- TOC --><ul><li><a href="#1-环境描述">1. 环境描述</a></li><li><a href="#2-初识thrift">2. 初识Thrift</a><ul><li><a href="#21-基本类型">2.1. 基本类型</a></li><li><a href="#22-关键概念">2.2. 关键概念</a><ul><li><a href="#221-关键字">2.2.1. 关键字</a></li><li><a href="#222-thrift三组件">2.2.2. Thrift三组件</a></li><li><a href="#223-简单示例">2.2.3. 简单示例</a></li></ul></li></ul></li><li><a href="#3-hiveserver2提交任务">3. HiveServer2提交任务</a><ul><li><a href="#31-hiveserver2启动流程">3.1. HiveServer2启动流程</a></li><li><a href="#32-提交任务流程">3.2. 提交任务流程</a></li><li><a href="#33-服务器端执行任务流程">3.3. 服务器端执行任务流程</a></li><li><a href="#34-队列管理方式">3.4. 队列管理方式</a></li><li><a href="#35-关闭任务流程">3.5. 关闭任务流程</a></li></ul></li><li><a href="#4-hiveserver2的优缺点">4. HiveServer2的优缺点</a><ul><li><a href="#41-优点">4.1. 优点</a></li><li><a href="#42-缺点">4.2. 缺点</a></li><li><a href="#43-疑问">4.3. 疑问</a></li></ul></li><li><a href="#5-参考文章">5. 参考文章</a></li></ul><!-- /TOC --><h1 id="1-环境描述"><a href="#1-环境描述" class="headerlink" title="1. 环境描述"></a>1. 环境描述</h1><ol><li>JDK版本：<br> <strong>java version “1.8.0_181”</strong><br> <strong>Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</strong><br> <strong>Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)</strong></li><li>Thrift版本：<strong>Thrift version 0.11.0</strong></li><li>Hive版本：<strong>Hive 1.1.0-cdh5.14.2</strong></li></ol><h1 id="2-初识Thrift"><a href="#2-初识Thrift" class="headerlink" title="2. 初识Thrift"></a>2. 初识Thrift</h1><h2 id="2-1-基本类型"><a href="#2-1-基本类型" class="headerlink" title="2.1. 基本类型"></a>2.1. 基本类型</h2><table><thead><tr><th>概念</th><th>Thrift</th><th>Java</th></tr></thead><tbody><tr><td>逻辑变量</td><td>bool</td><td>boolean</td></tr><tr><td>字节变量</td><td>i8</td><td>byte</td></tr><tr><td>16位整数</td><td>i16</td><td>short</td></tr><tr><td>32位整数</td><td>i32</td><td>int</td></tr><tr><td>64位整数</td><td>i64</td><td>long</td></tr><tr><td>浮点数</td><td>double</td><td>double</td></tr><tr><td>字符串</td><td>string</td><td>java.lang.String</td></tr><tr><td>列表</td><td>list</td><td>java.util.List</td></tr><tr><td>集合</td><td>set</td><td>java.util.Set</td></tr><tr><td>映射</td><td>map</td><td>java.util.Map</td></tr></tbody></table><h2 id="2-2-关键概念"><a href="#2-2-关键概念" class="headerlink" title="2.2. 关键概念"></a>2.2. 关键概念</h2><h3 id="2-2-1-关键字"><a href="#2-2-1-关键字" class="headerlink" title="2.2.1. 关键字"></a>2.2.1. 关键字</h3><ol><li>struct</li><li>service</li><li>exception</li><li>required</li><li>optional</li><li>const</li><li>typedef</li><li>include</li></ol><h3 id="2-2-2-Thrift三组件"><a href="#2-2-2-Thrift三组件" class="headerlink" title="2.2.2. Thrift三组件"></a>2.2.2. Thrift三组件</h3><p>&emsp;&emsp;Thrift中比较重要的是TProcess、TProtocol、TTransport三个组件，通过名称就可以可知组件的功能，这里不做细究。Thrift协议栈的层级情况，如下所示：<br><img src="/.io//001.png" alt="Thrift协议栈"><br>其中主要的TProtocol包括：<em>TBinaryProtocol、TCompactProtocol、TJSONProtocol、TProtocolDecorator、TSimpleJSONProtocol</em>，主要的TServer包括<em>TSimpleServer、TThreadPoolServer、TNonblockingServer、TThreadedSelectorServer</em>。<br>&emsp;&emsp;从图中可以看出，Thrift已经帮助做了很多封装与代码的生成。作为使用者，无需细究自动生成代码内部的机制，特别是比较底层的I/O层面操作。通过编写Thrift文件，使用thrift命令可以自动生成相应的Java类，特别是TProcess基本上无需开发者介入，只需要调用即可。</p><h3 id="2-2-3-简单示例"><a href="#2-2-3-简单示例" class="headerlink" title="2.2.3. 简单示例"></a>2.2.3. 简单示例</h3><ol><li>Thrift文件<figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> java com.simple.www</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">Hello</span></span>&#123;</span><br><span class="line">        <span class="built_in">string</span> helloString(<span class="number">1</span>:<span class="built_in">string</span> para)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>服务端代码<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">TServerTransport serverTransport = <span class="keyword">new</span> TServerSocket(<span class="number">7911</span>);</span><br><span class="line">Factory proFactory = <span class="keyword">new</span> TBinaryProtocol.Factory();</span><br><span class="line">TProcessor processor = <span class="keyword">new</span> Hello.Processor&lt;HelloServiceImpl&gt;(<span class="keyword">new</span> HelloServiceImpl());</span><br><span class="line"></span><br><span class="line">Args args_ = <span class="keyword">new</span> Args(serverTransport).processor(processor).protocolFactory(proFactory)</span><br><span class="line">.executorService(Executors.newFixedThreadPool(<span class="number">10</span>));</span><br><span class="line"></span><br><span class="line">TServer server = <span class="keyword">new</span> TThreadPoolServer(args_);</span><br><span class="line">System.out.println(<span class="string">"Start server on port 7911..."</span>);</span><br><span class="line">server.serve();</span><br><span class="line">&#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>客户端代码<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">TTransport transport = <span class="keyword">new</span> TSocket(<span class="string">"localhost"</span>, <span class="number">7911</span>);</span><br><span class="line">transport.open();</span><br><span class="line"></span><br><span class="line">TProtocol protocol = <span class="keyword">new</span> TBinaryProtocol(transport);</span><br><span class="line">Hello.Client client = <span class="keyword">new</span> Hello.Client(protocol);</span><br><span class="line"></span><br><span class="line">String res = client.helloString(<span class="string">"[This is a test helloString]"</span>);</span><br><span class="line">System.out.println(<span class="string">"Result:"</span> + res);</span><br><span class="line"></span><br><span class="line">transport.close();</span><br><span class="line">System.out.println(<span class="string">"成功关闭:"</span> + transport.isOpen());</span><br><span class="line">&#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (TException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="3-HiveServer2提交任务"><a href="#3-HiveServer2提交任务" class="headerlink" title="3. HiveServer2提交任务"></a>3. HiveServer2提交任务</h1><p>&emsp;&emsp;本小节，我们考虑以下几个问题：</p><ul><li>HS2启动干了那些事情？</li><li>HSQL任务是如何提交？</li><li>HSQL任务是如何执行？</li><li>HS2如何做队列管理？</li><li>任务执行完成，资源如何释放？</li></ul><h2 id="3-1-HiveServer2启动流程"><a href="#3-1-HiveServer2启动流程" class="headerlink" title="3.1. HiveServer2启动流程"></a>3.1. HiveServer2启动流程</h2><p>&emsp;&emsp;HiveServer2的启动涉及到多个方面的资源，这里不详细讲解，主要描述初始化的大体流程。<br><img src="/.io//002.png" alt="HiveServer2启动初始化过程"></p><ul><li>首先，父类初始化一些核心参数，例如服务端口、本机地址、ServerContext、TServerEventHandler等处理事务的必备组件</li><li>其次，初始化CLIService这个类。这个类主要用作SQL请求的执行，后面说明该类执行任务的流程。接下来根据用户的设置判断启动Http模式的jetty服务，还是启动Thrift监听服务</li><li>最后，构建一个HS2WEB服务，用于展示HS2的信息。这一块就是我们看到的URL: <a href="http://hdfs-nn-1.sv.ebu.alsh.xingbianli.com:10002/hiveserver2.jsp" target="_blank" rel="noopener">http://hdfs-nn-1.sv.ebu.alsh.xingbianli.com:10002/hiveserver2.jsp</a> ，这个服务也是一个内嵌Jetty服务。主要包括：[/jmx–&gt;JMXJsonServlet.class]、[/conf–&gt;ConfServlet]、[/stacks–&gt;StackServlet]，以及日志处理[/logs]和首页[hiveserver2.jsp]。</li></ul><h2 id="3-2-提交任务流程"><a href="#3-2-提交任务流程" class="headerlink" title="3.2. 提交任务流程"></a>3.2. 提交任务流程</h2><p>&emsp;&emsp;HS2服务启动之后，客户端就可以提交任务了。那么任务是如何提交的？这就是本小节的关注重点。客户端提交任务，我们只研究JDBC模块的内容，Beeline方式提交任务可以参考JDBC模式。</p><p>&emsp;&emsp;研读HiveDriver的内容，可以发现客户端与服务端存在如下交互。<br><img src="/.io//004.png" alt="Hive客户端与服务端的交互"></p><p>&emsp;&emsp;从HiveJDBC提交任务的流程来看，主要的工作放在服务端。客户端主要用来发起任务、提交任务、获取任务结果等内容，相对比较简单。</p><h2 id="3-3-服务器端执行任务流程"><a href="#3-3-服务器端执行任务流程" class="headerlink" title="3.3. 服务器端执行任务流程"></a>3.3. 服务器端执行任务流程</h2><p>&emsp;&emsp;客户端提交任务之后，服务端执行任务。执行任务的逻辑与流程主要如下所示<br><img src="/.io//003.png" alt="HiveServer2查询执行流程"></p><h2 id="3-4-队列管理方式"><a href="#3-4-队列管理方式" class="headerlink" title="3.4. 队列管理方式"></a>3.4. 队列管理方式</h2><p>对于HS2的任务队列管理，我们犹如下疑问</p><ol><li>任务提交队列</li><li>任务执行策略：FIFO ? FAIR ?</li><li>结果回调方式</li><li>队列满了如何解决？</li></ol><p>&emsp;&emsp;提交任务就涉及到一个任务队列的管理。本小节主要关注HS2管理任务队列的方式，任务添加策略、执行的策略，以及如何处理一些异常情况。</p><p>&emsp;&emsp;针对我们提出的问题，对源码进行了研究。根据HS2源码的实现，可以看出HS2并没有对客户端提交的任务进行相关的队列处理或进行相关的调度算法实现。以Thrift方式而言，任务队列或者任务并行数的控制是通过Thrift线程并行服务来实现的，既ExecutorService。服务端针对客户端的连接服务是TThreadPoolServer，即面向连接池的服务，因此本质上而言我们可以认为它是一个FIFO的队列。其队列的实现如下所示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService executorService = <span class="keyword">new</span> ThreadPoolExecutor(minWorkerThreads, maxWorkerThreads,</span><br><span class="line">        workerKeepAliveTime, TimeUnit.SECONDS, <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;(),<span class="keyword">new</span> ThreadFactoryWithGarbageCleanup(threadPoolName));</span><br></pre></td></tr></table></figure><p>其中minWorkerThreads是通过<em>hive.server2.thrift.min.worker.threads</em>来设置的，默认值为5；maxWorkerThreads是通过<em>hive.server2.thrift.max.worker.threads</em>来设置，默认值为500。通过源码可以看出，这里的这两个设置控制的是线程池的核心线程数与最大线程数，并不是语义上的最大并行线程数与最小并行线程数。</p><p>&emsp;&emsp;由于服务端的请求是通过Thrift RPC方式并且是异步进行的，所以客户端在实现上是轮训服务端的执行状态，从而客户端看起来是同步进行的。由于客户端的请求要么让Thrift服务处理，要么让jettyServer处理，无论哪种方式如何客户端打开session数量超过maxWorkerThreads，那么客户端的提交请求过程会被堵塞，因而服务端不存在任务队列满了如何处理这种情况。</p><h2 id="3-5-关闭任务流程"><a href="#3-5-关闭任务流程" class="headerlink" title="3.5. 关闭任务流程"></a>3.5. 关闭任务流程</h2><p>&emsp;&emsp;任务运行结束，程序会关闭连接并释放资源。主要关闭流程如下所示。<br><img src="/.io//005.png" alt="HiveServere2关闭流程"><br>这里提到的关闭流程主要指的是正常关闭流程，主要是指关闭Operation、Session等。其中Yarn上运行的任务被Kill这种情况，我们认为是运行认为失败，不被包含在关闭流程中。</p><h1 id="4-HiveServer2的优缺点"><a href="#4-HiveServer2的优缺点" class="headerlink" title="4. HiveServer2的优缺点"></a>4. HiveServer2的优缺点</h1><h2 id="4-1-优点"><a href="#4-1-优点" class="headerlink" title="4.1. 优点"></a>4.1. 优点</h2><ol><li>统一口径：JDBC/Beeline等统一访问，任务集中管理</li><li>支持本地MR：一些简单的任务，可以直接运行在本地，减轻Yarn集群压力</li><li>Thrift协议：支持扩平台、扩语言[Java、Python等]、可远程等优点，继承RPC的各项优点</li><li>HA机制：解决应用端的并发与负载均衡问题</li><li>安全认证：支持多种协议，支持自定义安全认证</li><li>数据隔离：不直接将HDFS与Metastore暴露给用户</li></ol><h2 id="4-2-缺点"><a href="#4-2-缺点" class="headerlink" title="4.2. 缺点"></a>4.2. 缺点</h2><ol><li>内存：可能会OOM。作为一个独立的Java应用，需要根据业务需求，不断调整Java_OPS的设置。如果节点性能较好，尽量配置大一些</li><li>目前HiveJDBC无法获取任务ID，或Yarn上运行的ID信息，并且获取任务执行日志比较困难</li></ol><h2 id="4-3-疑问"><a href="#4-3-疑问" class="headerlink" title="4.3. 疑问"></a>4.3. 疑问</h2><ol><li>目前Thrfit支持TThreadedSelectorServer，为什么还用TThreadPoolServer ？ 即使目前的最新版本Hive 3.1，使用的仍然是TThreadPoolServer</li></ol><h1 id="5-参考文章"><a href="#5-参考文章" class="headerlink" title="5. 参考文章"></a>5. 参考文章</h1><ol><li><a href="https://blog.csdn.net/kesonyk/article/details/50924489" target="_blank" rel="noopener">Thrift RPC详解</a></li><li><a href="http://blog.163.com/kewangwu@126/blog/static/86728471201271353354581/" target="_blank" rel="noopener">Thrift的数据类型</a></li><li><a href="https://blog.csdn.net/zhanglh046/article/details/78572926" target="_blank" rel="noopener">hiveserver2详解</a></li><li><a href="http://lxw1234.com/archives/2016/05/675.htm" target="_blank" rel="noopener">HiveServer2的高可用-HA配置</a></li><li><a href="https://www.cnblogs.com/oldtrafford/p/8818756.html" target="_blank" rel="noopener">hive-jdbc获取查询日志慢的问题发现与解决</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《模式识别：算法及其实现方法》读书笔记</title>
      <link href="/2018/07/28/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/07/28/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<ol><li>作者：M.Narasimha Murty, V. Susheela Devi</li><li>翻译：王振永</li><li>出版社：哈尔滨工业大学出版社</li></ol><h1 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h1><p>&emsp;&emsp;模式识别可以定义为基于已知知识或者依据模式标书所抽象出来的统计信息进行数据分类的方法。</p><p>&emsp;&emsp;模式识别有很多重要的应用，例如多媒体文档自动识别(MDR)和自动医疗诊断。在进行MDR时，必须处理文本、音频和视频数据的集合。文本数据可以由对应一个或多个自然语言的字符和数字组成。音频数据可能是语音或音乐。视频数据可能是一个单一的图像或图像序列。</p><p>&emsp;&emsp;一个典型的模式识别应用程序中，需要对原始数据进行吹了，将其转换为一种可被机器使用的形式。音频可悲表示为现行预测编码的系数，而视频数据则可以转换到变换域来表示，比如小波变换和傅里叶变换。信号处理可以将原始输数据转换为矢量数据。</p><p>&emsp;&emsp;模式识别涉及到分类和聚类。在模式识别中，使用一组训练模式或领域知识分配类类标签。聚类可以将数据分区，这有助于我们制定决策，我们感兴趣的决策制定是数据分类。</p><h2 id="什么是模式识别"><a href="#什么是模式识别" class="headerlink" title="什么是模式识别"></a>什么是模式识别</h2><p>&emsp;&emsp;在模式识别中，为模式制定标签。有时候，可以使用分类规则而不进行任务抽象。模式是别的重要方面之一是应用前景，在农业、教育、安全、交通、金融、医疗和娱乐等领域中有着广泛的应用，具体应用包括生物识别、生物信息学、多媒体数据分析、文档识别、故障诊断以及专家系统。分类是人类的一种基本思维模式，所以模式识别可以应用在任务领域。</p><h2 id="模式识别的数据集合"><a href="#模式识别的数据集合" class="headerlink" title="模式识别的数据集合"></a>模式识别的数据集合</h2><p>&emsp;&emsp;在互联网有大量的数据集可供使用。一个受欢迎的网站是UCIrvine的机器学习库(<a href="http://www.ics.uci.edu/MLRepository.html)，它包含许多不同大小的数据集，可以用于各种分类算法。其中很多设置给出了一些分类方法的分类精度，可以作为研究的基准。用于数据挖掘的大型数据集可在网站kdd.ics.uci.edu和www.kdnuggets.com/datasets/中找到。" target="_blank" rel="noopener">www.ics.uci.edu/MLRepository.html)，它包含许多不同大小的数据集，可以用于各种分类算法。其中很多设置给出了一些分类方法的分类精度，可以作为研究的基准。用于数据挖掘的大型数据集可在网站kdd.ics.uci.edu和www.kdnuggets.com/datasets/中找到。</a></p><h2 id="模式识别的理论框架"><a href="#模式识别的理论框架" class="headerlink" title="模式识别的理论框架"></a>模式识别的理论框架</h2><p>&emsp;&emsp;有多重理论框架能解决模式识别问题，其中最主要的两种为：</p><ol><li>统计模式识别</li><li>结构模式识别</li></ol><p>&emsp;&emsp;在这两种方式中，统计模式识别使用更为广泛，在文献中大量出现。</p><h1 id="模式集合的表征"><a href="#模式集合的表征" class="headerlink" title="模式集合的表征"></a>模式集合的表征</h1><p>&emsp;&emsp;模式是一个物理对象或抽象概念。</p><h2 id="模式结合表征的数据结构"><a href="#模式结合表征的数据结构" class="headerlink" title="模式结合表征的数据结构"></a>模式结合表征的数据结构</h2><h3 id="矢量的模式集合表征"><a href="#矢量的模式集合表征" class="headerlink" title="矢量的模式集合表征"></a>矢量的模式集合表征</h3><p>&emsp;&emsp;矢量是一种显而易见的模式表征。</p><h3 id="字符串的模式模式集合表征"><a href="#字符串的模式模式集合表征" class="headerlink" title="字符串的模式模式集合表征"></a>字符串的模式模式集合表征</h3><p>&emsp;&emsp;字符串可以看做某种语言的句子，例如一个DNA序列或蛋白质序列。举例说明，某遗传因子可以被分别由A、G、C和T表示的腺嘌呤、鸟嘌呤、胞嘌呤和胸嘌呤四种含氢基构成的染色体DNA的一片区域。基因数据被排列在一个序列中，例如<br>    GATTGTCAAG…</p><h3 id="模式集合的逻辑表述方法"><a href="#模式集合的逻辑表述方法" class="headerlink" title="模式集合的逻辑表述方法"></a>模式集合的逻辑表述方法</h3><p>&emsp;&emsp;(此处无内容)</p><h3 id="模式的模糊集合及粗糙集合"><a href="#模式的模糊集合及粗糙集合" class="headerlink" title="模式的模糊集合及粗糙集合"></a>模式的模糊集合及粗糙集合</h3><p>&emsp;&emsp;模糊可以用在无法精确表述的情况下，因此可以用来对主观的、不完备的以及不精确的数据进行建模。在一个模糊集合中，对象从属于成员值从0至1变化的集合。</p><h3 id="基于树和图的表征"><a href="#基于树和图的表征" class="headerlink" title="基于树和图的表征"></a>基于树和图的表征</h3><p>&emsp;&emsp;树和图是用来表征模式和模式类别的常见数据结构。树或图中的每一个节点可以表示一个或多个模式。</p><ol><li>最小生成树</li><li>频繁模式树</li></ol><h2 id="模式聚类的表征"><a href="#模式聚类的表征" class="headerlink" title="模式聚类的表征"></a>模式聚类的表征</h2><p>&emsp;&emsp;聚类是将含有相似特征的模式组在一起并将不同特征的对象放在不同的组的过程。这里有两个数据结构，一个是模式的划分P，另一个是一系列簇的代表C。</p><h3 id="相似度量方法"><a href="#相似度量方法" class="headerlink" title="相似度量方法"></a>相似度量方法</h3><p>&emsp;&emsp;为了对模式进行分类，模式之间需要相互比较并与某个标准进行比较。</p><ol><li>基于距离的度量方法<br> &emsp;&emsp;一个量化的方法具有如下性质<ul><li>正自反性d(x,y)=0</li><li>对称性d(x,y)=d(y,x)</li><li>三角不等性d(x,y)&lt;=d(x,z)+d(z,y)<br>&emsp;&emsp;常用的度量方法成为民科夫斯基计量，形式如下<br>$$d^m(X,Y)=(\sum_{k=1}^d|x_k-y_k|^m)^{\frac{1}{m}}$$<br>&emsp;&emsp;当m为1时称它为曼哈顿距离或$L_1$距离。最常用的距离为当m的值为2时的欧式距离或$L_2$距离。可以得到<br>$$d^2(X,Y)=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+…+(x_d-y_d)^2}$$<br>在这种模式下，$L_{\inf}$为<br>$$d^{\infty}=max_{k=1,…,d}|x_k-y_k|$$<br>当使用距离度量时，应当保证所有的特征有相同的取值范围，舍弃那些被认为更重要的具有更大范围的属性，就好像赋予它更大的权重。为保证所有特征具有相同的范围，应当采取特征值标准化。<br>&emsp;&emsp;马氏距离也是一种在分类中常见的距离度量，它可由下式得出<br>$$d^2(X,Y)=(X-Y)^T\sum^{-1}(X-Y)$$<br>其中$\sum$是西方差矩阵。</li></ul></li><li>基于加权距离的度量方法<br> &emsp;&emsp;当认为某个属性更重要时，可以再它们的值上加权重。加权的距离度量形式如下<br> $$d(X,Y)=(\sum_{k-1}^d\omega_k*(x_k-y_k)^m)^{\frac{1}{m}}$$<br> 其中$\omega_k$是第k维相关的权重。</li><li>非度量相似函数<br> &emsp;&emsp;相似函数在此范畴下既不遵从三角不等式也不遵从对称性。这些相似函数往往在图像以及数据串中十分有效。它们对异常值和极端噪声数据具有鲁棒性。<br> &emsp;&emsp;一种不具有对称性的非量化聚利是发散度距离(KL距离)。它是一个从“真实”概念分布p到”目标”概念分布q的自然距离函数。对于离散概率分布，如果$p={p_1,..p_n}$并且$q={q_1,…q_n}$，那么KL距离定义为<br> $$KL(p,q)=\sum_ip_i\log_2(\frac{p_i}{q_i})$$<br> 对于连续概率密度，用积分代替求和。</li><li>编辑距离<br> &emsp;&emsp;编辑距离计算两个字符串之间的距离，它也称为莱文斯汀距离。</li><li>互近邻距离</li><li>概念内聚性</li><li>核函数<br> &emsp;&emsp;核函数可以用来描述模式x和y之间的距离。<ol><li>多项式核函数。x和y之间的相似度可以用多项式核函数表述为$$K(x,y)=\epsilon(x)^{<code>}\epsilon(y)=(x^{</code>}y+1)^2$$<br> 通过这种方法，输入空间中的线性相关矢量转换为核空间的线性无关矢量。</li><li>径向基(RBF)核函数。核定义如下$$K(x,y)=\exp^{\frac{-|x-y|^2}{2\sigma^2}}$$</li></ol></li></ol><h2 id="模式的尺寸"><a href="#模式的尺寸" class="headerlink" title="模式的尺寸"></a>模式的尺寸</h2><p>&emsp;&emsp;样本的大小取决于所考虑的属性。</p><h3 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h3><p>&emsp;&emsp;数据标准化的过程可以使所有的模式具有统一的尺度。</p><h3 id="相似度度量的选择方法"><a href="#相似度度量的选择方法" class="headerlink" title="相似度度量的选择方法"></a>相似度度量的选择方法</h3><p>&emsp;&emsp;相似度计算可以处理不等长度问题，一个相似度计算的例子为编辑距离。</p><h2 id="数据集合的抽象"><a href="#数据集合的抽象" class="headerlink" title="数据集合的抽象"></a>数据集合的抽象</h2><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>&emsp;&emsp;特征提取涉及到对所需样本特征的发掘和提取。特征操作从数据中提取特征以识别或解析有意义的信息。这在图像中有重大意义，因为此时特征提取需要自动识别多种特征。特征提取是模式识别中一部重要的预处理步骤。</p><h3 id="Fisher线性判别法"><a href="#Fisher线性判别法" class="headerlink" title="Fisher线性判别法"></a>Fisher线性判别法</h3><p>&emsp;&emsp;Fisher线性判别法将高纬度数据映射到一条线上并在这个空间上施行分类。如果有两个类别，那么映射最大化了两个类别之间的均值的距离并且最小化了美衣美类别中的方差。能够最大化所有线性映射V的Fisher准则定义如下：$$J(V)=\frac{|mean_1-mean_2|^2}{s_1^2+s_2^2}$$<br>其中，$mean_1$和$mean_2$分别代表类别1和类别2样本的均值；$s_1$与$s_2$分别代表了各自的方法。</p><h3 id="主成分分析法"><a href="#主成分分析法" class="headerlink" title="主成分分析法"></a>主成分分析法</h3><p>&emsp;&emsp;主成分分析(PCA)是一个数学方法，它将大量相关变量转化为小数量的不相关变量，这些不相关变量称为主要成分。最主要成分尽可能地反映了数据中的变化性，次之成分尽可能地反映了剩余的变化。PCA在更低纬的空间内找出了最精确的数据代表。数据被映射到方差最大的方向上。</p><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>&emsp;&emsp;用于分类的特征并不总是有意义的，移除那些对于分类没用的特征，可能会得到哦更高的分类准确度。特征选择则可以加速分类过程，同时确保分类精确是最佳的。特征选择有如下特点</p><ul><li>减少样本分类以及分类设计的开销、维度简化等。使用一个有限的特征集简化样本的描述以及分类复杂度。因此分类将变得更快，使用更少的存储器。</li><li>分类精度的提高。分类精度的提高取决于以下因素<ol><li>样本的大小、特征数量、分类复杂度</li><li>在同一个光以及和的情况下，随着维度的增加，到最近点的距离逐步接近最远点的距离。<br>所有特征的选择基本上都是遍历不同的特征子集。</li></ol></li></ul><h3 id="穷举搜索法"><a href="#穷举搜索法" class="headerlink" title="穷举搜索法"></a>穷举搜索法</h3><p>&emsp;&emsp;穷举搜索法是解决所有特征选择问题的最直接方法，搜索所有特征子集并且找到最佳子集。</p><h3 id="分支定界搜索法"><a href="#分支定界搜索法" class="headerlink" title="分支定界搜索法"></a>分支定界搜索法</h3><p>&emsp;&emsp;分支定界搜索法通过利用在获得最终准则值过程中所产生的一些中间结果避免了穷举搜索。</p><h3 id="最优特征选择法"><a href="#最优特征选择法" class="headerlink" title="最优特征选择法"></a>最优特征选择法</h3><p>&emsp;&emsp;最有特征选择法是一种只选择最有特征的简单方法。独立计算所有特体特征，并选择m个最佳特征。这种方法虽然简单，但是很可能失败，由于特征之间并非完全独立。</p><h3 id="顺序选择法"><a href="#顺序选择法" class="headerlink" title="顺序选择法"></a>顺序选择法</h3><h3 id="浮动顺序选择法"><a href="#浮动顺序选择法" class="headerlink" title="浮动顺序选择法"></a>浮动顺序选择法</h3><h3 id="最大最小特征选择法"><a href="#最大最小特征选择法" class="headerlink" title="最大最小特征选择法"></a>最大最小特征选择法</h3><h3 id="随机搜索法"><a href="#随机搜索法" class="headerlink" title="随机搜索法"></a>随机搜索法</h3><h3 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h3><h2 id="分类分析方法"><a href="#分类分析方法" class="headerlink" title="分类分析方法"></a>分类分析方法</h2><p>&emsp;&emsp;在使用分类器之前，有必要评估它的表现。需要考虑的分类器参数列举如下</p><ol><li>分类器的准确性</li><li>设计时间和分类时间</li><li>所需要的空间</li><li>解释说明能力<br>如果一种对样本的分类方法对使用者解释得很清楚，那么它的解释说明能力就很好。</li><li>噪声容限<br>它是指一个分类器处理异常值和错误分类样本的能力。</li></ol><p>&emsp;&emsp;要想评估一个分类方法有多好，可以凭他提训练集本身。不同的检验方法列举如下</p><ol><li>保持法</li><li>随机子抽样</li><li>分叉校验</li><li>拔靴法</li></ol><h2 id="聚类分析方法"><a href="#聚类分析方法" class="headerlink" title="聚类分析方法"></a>聚类分析方法</h2><h1 id="最近邻分类器"><a href="#最近邻分类器" class="headerlink" title="最近邻分类器"></a>最近邻分类器</h1><h1 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h1><h1 id="隐式马尔科夫模型"><a href="#隐式马尔科夫模型" class="headerlink" title="隐式马尔科夫模型"></a>隐式马尔科夫模型</h1><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h1 id="多分类组合"><a href="#多分类组合" class="headerlink" title="多分类组合"></a>多分类组合</h1><h1 id="聚类方法"><a href="#聚类方法" class="headerlink" title="聚类方法"></a>聚类方法</h1><h1 id="本书总结"><a href="#本书总结" class="headerlink" title="本书总结"></a>本书总结</h1><h1 id="应用实例：手写数字识别"><a href="#应用实例：手写数字识别" class="headerlink" title="应用实例：手写数字识别"></a>应用实例：手写数字识别</h1><h2 id="数字数据的描述"><a href="#数字数据的描述" class="headerlink" title="数字数据的描述"></a>数字数据的描述</h2><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h2 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h2><h2 id="典型模型的选择"><a href="#典型模型的选择" class="headerlink" title="典型模型的选择"></a>典型模型的选择</h2><h2 id="识别结果"><a href="#识别结果" class="headerlink" title="识别结果"></a>识别结果</h2>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MachineLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DataX之SplitPK原理</title>
      <link href="/2018/07/25/DataX%E4%B9%8BSplitPK%E5%8E%9F%E7%90%86/"/>
      <url>/2018/07/25/DataX%E4%B9%8BSplitPK%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;DataX的简单介绍，可以参考<a href="https://blog.csdn.net/awdac/article/details/80822233" target="_blank" rel="noopener">Alibaba DataX调研使用</a> ，这里不做详细介绍。在同步数据时，如果数据源是RDBMS，存在配置参数<strong>splitPk</strong>。那么该参数是如何起作用的，如何配置？</p><h2 id="配置方式"><a href="#配置方式" class="headerlink" title="配置方式"></a>配置方式</h2><p>&emsp;&emsp;<strong>splitPk</strong>的配置方式，主要参考(DataX文档)[<a href="https://github.com/alibaba/DataX]。" target="_blank" rel="noopener">https://github.com/alibaba/DataX]。</a></p><ol><li>描述：<br> &emsp;&emsp;MysqlReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。<br> &emsp;&emsp;推荐splitPk用户使用表主键，因为表主键<strong>通常情况下比较均匀</strong>，因此切分出来的分片也不容易出现数据热点。</li><li>目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！</li></ol><h2 id="作用原理"><a href="#作用原理" class="headerlink" title="作用原理"></a>作用原理</h2><h2 id="优点缺点"><a href="#优点缺点" class="headerlink" title="优点缺点"></a>优点缺点</h2><p>&emsp;&emsp;由于DataX是一款通用的插件式异构数据同步工具，因此在处理RDBMS时组装的SQL具有通用性，没有针对个别数据库做处理。因此这就无可避免的造成了解决方案的非最优化性，一些数据库可能会存在更优化的处理方式。</p><p>&emsp;&emsp;DataX的<strong>spliPk</strong>配置，假设切分字段为比较均匀的情况，如果切分字段恰好分布不均匀，那么DataX同步数据存在问题。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> DataX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven之Pom配置学习总结</title>
      <link href="/2018/07/17/Maven%E4%B9%8BPom%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
      <url>/2018/07/17/Maven%E4%B9%8BPom%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><p>&emsp;&emsp;POM中可以配置一些<em>properties</em>，这些属性一般而言实在各种pom中使用，但也可以在一些配置文件中使用，例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># pom文件配置</span></span></span><br><span class="line">&lt;properties&gt;</span><br><span class="line">&lt;database.driver&gt;com.mysql.jdbc.Driver&lt;/database.driver&gt;</span><br><span class="line">&lt;database.url&gt;jdbc:mysql://localhost:3306/database?autoReconnect=true</span><br><span class="line">&lt;/database.url&gt;</span><br><span class="line">&lt;database.username&gt;myusername&lt;/database.username&gt;</span><br><span class="line">&lt;database.password&gt;mypassword&lt;/database.password&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;profiles&gt;</span><br><span class="line">&lt;profile&gt;</span><br><span class="line">&lt;id&gt;qa&lt;/id&gt;</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">&lt;database.driver&gt;com.mysql.jdbc.Driver&lt;/database.driver&gt;</span><br><span class="line">&lt;database.url&gt;jdbc:mysql://qadb01:3306/database?autoReconnect=true&lt;/database.url&gt;</span><br><span class="line">&lt;database.username&gt;qauser&lt;/database.username&gt;</span><br><span class="line">&lt;database.password&gt;qapassword&lt;/database.password&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line">&lt;/profile&gt;</span><br><span class="line"></span><br><span class="line">&lt;profile&gt;</span><br><span class="line">&lt;id&gt;production&lt;/id&gt;</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">&lt;database.driver&gt;com.mysql.jdbc.Driver&lt;/database.driver&gt;</span><br><span class="line">&lt;database.url&gt;jdbc:mysql://pdb01:3306/database?autoReconnect=true&lt;/database.url&gt;</span><br><span class="line">&lt;database.username&gt;produser&lt;/database.username&gt;</span><br><span class="line">&lt;database.password&gt;prodpassword&lt;/database.password&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line">&lt;/profile&gt;</span><br><span class="line">&lt;/profiles&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># properties</span></span></span><br><span class="line">driverClassName=$&#123;database.driver&#125;</span><br><span class="line">url=$&#123;database.url&#125;</span><br><span class="line">username=$&#123;database.username&#125;</span><br><span class="line">password=$&#123;database.password&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;通过如上配置，默认情况下直接使用外层的<em>properties</em>属性，但也可以通过制定来更改为我们需要的配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install -Pqa/-Pproduction</span><br></pre></td></tr></table></figure><p>通过编译之后，可以看到我们设置的变量替换为pom文件中的变量。</p><h2 id><a href="#" class="headerlink" title></a></h2><h2 id="各种plugin"><a href="#各种plugin" class="headerlink" title="各种plugin"></a>各种plugin</h2><h3 id="maven-antrun-plugin"><a href="#maven-antrun-plugin" class="headerlink" title="maven-antrun-plugin"></a>maven-antrun-plugin</h3><p><strong>maven-antrun-plugin</strong>，主要是用来从Maven内运行Ant任务的功能，甚至可以将Ant脚本嵌入到POM。这个插件不是提供污染POM的手段意图，因此它鼓励所有Ant任务移动到build.xml文件并使用Ant的POM调用它。这个插件的主要目的之一是方便从Ant基础项目迁移到Maven。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;executions&gt;</span><br><span class="line">&lt;execution&gt;</span><br><span class="line">&lt;phase&gt;validate&lt;/phase&gt;</span><br><span class="line">&lt;goals&gt;</span><br><span class="line">&lt;goal&gt;run&lt;/goal&gt;</span><br><span class="line">&lt;/goals&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;tasks&gt;</span><br><span class="line">&lt;echo&gt;$&#123;PATH&#125;=$&#123;env.PATH&#125;&lt;/echo&gt;</span><br><span class="line">&lt;echo&gt;User<span class="string">'s Home Directory: $&#123;user.home&#125;&lt;/echo&gt;</span></span><br><span class="line">&lt;echo&gt;Project's Base Director: $&#123;basedir&#125;&lt;/echo&gt;</span><br><span class="line">&lt;/tasks&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;/execution&gt;</span><br><span class="line">&lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="maven-clean-plugin"><a href="#maven-clean-plugin" class="headerlink" title="maven-clean-plugin"></a>maven-clean-plugin</h3><p><strong>maven-clean-plugin</strong>最常用的maven插件，主要用于清理target文件等内容。</p><h3 id="maven-resources-plugin"><a href="#maven-resources-plugin" class="headerlink" title="maven-resources-plugin"></a>maven-resources-plugin</h3><p><strong>maven-resources-plugin</strong>用于替换资源文件中的占位符。</p><h3 id="maven-install-plugin"><a href="#maven-install-plugin" class="headerlink" title="maven-install-plugin"></a>maven-install-plugin</h3><p><strong>maven-install-plugin</strong>用于安装jar包，将生成的jar文件复制到maven的本地仓库中。</p><h3 id="maven-compiler-plugin"><a href="#maven-compiler-plugin" class="headerlink" title="maven-compiler-plugin"></a>maven-compiler-plugin</h3><p><strong>maven-compiler-plugin</strong>编译Java源码，一般只需要设置编译的JDK版本即可。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.6.0&lt;/version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">        &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="maven-dependency-plugin"><a href="#maven-dependency-plugin" class="headerlink" title="maven-dependency-plugin"></a>maven-dependency-plugin</h3><p><strong>maven-dependency-plugin</strong>用于将依赖的jar包复制到指定的文件夹里去。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.10&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;id&gt;copy-dependencies&lt;/id&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;copy-dependencies&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="maven-jar-plugin"><a href="#maven-jar-plugin" class="headerlink" title="maven-jar-plugin"></a>maven-jar-plugin</h3><p><strong>maven-jar-plugin</strong>的主要作用是打包成可运行的jar，打包时制定manifest参数。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.4&lt;/version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;archive&gt;</span><br><span class="line">            &lt;manifest&gt;</span><br><span class="line">                &lt;addClasspath&gt;true&lt;/addClasspath&gt;</span><br><span class="line">                &lt;classpathPrefix&gt;/data/lib&lt;/classpathPrefix&gt;</span><br><span class="line">                &lt;mainClass&gt;com.zhang.spring.App&lt;/mainClass&gt;</span><br><span class="line">            &lt;/manifest&gt;</span><br><span class="line">        &lt;/archive&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="maven-shade-plugin"><a href="#maven-shade-plugin" class="headerlink" title="maven-shade-plugin"></a>maven-shade-plugin</h3><p><strong>maven-shade-plugin</strong><br>用于把多个jar包，打成1个jar包。一般Java项目都会依赖其他第三方jar包，最终打包时，希望把其他jar包包含在一个jar包里</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.4.3&lt;/version&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;transformers&gt;</span><br><span class="line">                    &lt;transformer</span><br><span class="line">                        implementation=<span class="string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>&gt;</span><br><span class="line">                        &lt;manifestEntries&gt;</span><br><span class="line">                            &lt;Main-Class&gt;com.meiyou.topword.App&lt;/Main-Class&gt;</span><br><span class="line">                            &lt;X-Compile-Source-JDK&gt;$&#123;maven.compile.source&#125;&lt;/X-Compile-Source-JDK&gt;</span><br><span class="line">                            &lt;X-Compile-Target-JDK&gt;$&#123;maven.compile.target&#125;&lt;/X-Compile-Target-JDK&gt;</span><br><span class="line">                        &lt;/manifestEntries&gt;</span><br><span class="line">                    &lt;/transformer&gt;</span><br><span class="line">                &lt;/transformers&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="maven-surefire-plugin"><a href="#maven-surefire-plugin" class="headerlink" title="maven-surefire-plugin"></a>maven-surefire-plugin</h3><p><strong>maven-surefire-plugin</strong>主要使用来测试Maven项目的源码，能够兼容Junit3、Junit4以及TestNG等框架。默认情况下，maven-surefire-plugin的Test目标会自动测试源码路径下所有符合一组命名模式的测试类。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;  </span><br><span class="line">    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  </span><br><span class="line">    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;  </span><br><span class="line">    &lt;version&gt;2.5&lt;/version&gt;  </span><br><span class="line">    &lt;configuration&gt;  </span><br><span class="line">        &lt;includes&gt;  </span><br><span class="line">            &lt;include&gt;**<span class="comment">/*Tests.java&lt;/include&gt;  </span></span><br><span class="line"><span class="comment">        &lt;/includes&gt;  </span></span><br><span class="line"><span class="comment">        &lt;excludes&gt;  </span></span><br><span class="line">            &lt;exclude&gt;**/*ServiceTest.java&lt;/exclude&gt;  </span><br><span class="line">            &lt;exclude&gt;**/TempDaoTest.java&lt;/exclude&gt;  </span><br><span class="line">        &lt;/excludes&gt;  </span><br><span class="line">    &lt;/configuration&gt;  </span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h3 id="groovy-maven-plugin"><a href="#groovy-maven-plugin" class="headerlink" title="groovy-maven-plugin"></a>groovy-maven-plugin</h3><p><strong>groovy-maven-plugin</strong>主要是用于Maven编译Groovy源代码。</p><h3 id="jruby-maven-plugin"><a href="#jruby-maven-plugin" class="headerlink" title="jruby-maven-plugin"></a>jruby-maven-plugin</h3><p><strong>jruby-maven-plugin</strong>主要用于ruby的源代码编译。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式Java应用读书笔记</title>
      <link href="/2018/07/10/%E5%88%86%E5%B8%83%E5%BC%8FJava%E5%BA%94%E7%94%A8%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/07/10/%E5%88%86%E5%B8%83%E5%BC%8FJava%E5%BA%94%E7%94%A8%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式Java应用"><a href="#分布式Java应用" class="headerlink" title="分布式Java应用"></a>分布式Java应用</h1><p><img src="/.io//001.png" alt="分布式Java应用"></p><a id="more"></a><h2 id="基于消息方式实现系统间的通信"><a href="#基于消息方式实现系统间的通信" class="headerlink" title="基于消息方式实现系统间的通信"></a>基于消息方式实现系统间的通信</h2><p>&emsp;&emsp;当系统之间要通信时，就向外发送消息，消息可以是字节流、字节数组，甚至是Java对象，其他系统接收到消息后进行相应的业务处理。消息方式的系统间通信，通常是基于网络协议实现，常用的实现系统间通信的协议有:TCP/IP和UDP/IP。</p><p>&emsp;&emsp;TCP/IP和UDP/IP可用于完成数据的传输，但要完成系统间的通信，还需要对数据进行处理。从程序角度而言，BIO就是发起IO的读或写操作时，均为阻塞方式，只有当程序读到了流或将流写入操作系统后，才会释放资源。</p><p>&emsp;&emsp;NIO是基于事件驱动思想的，实现上通常采用Reactor模式，从程序角度而言，当发起IO的读或写操作时，是阻塞的；当socket有流可读或可写入socket时，操作熊会相应的通知到应用程序进行处理。对网络IO而言，主要有链接建立、流读取或流写入三种事件，Linux2.6以后的版本采用了epoll方式来实现NIO。</p><p>&emsp;&emsp;另外一种方式AIO。AIO为异步IO方式，同样基于事件驱动思想，实现上采用了Proactor模式。与NIO相比，AIO具有以下特点</p><ul><li>简化了程序的编写：流的读取与写入都有操作系统来完成</li><li>省去了NIO程序要遍历事件通知队列(selector)的代价</li></ul><h2 id="基于远程调用方式实现系统间的通信"><a href="#基于远程调用方式实现系统间的通信" class="headerlink" title="基于远程调用方式实现系统间的通信"></a>基于远程调用方式实现系统间的通信</h2><h1 id="大型分布式Java应用和SOA"><a href="#大型分布式Java应用和SOA" class="headerlink" title="大型分布式Java应用和SOA"></a>大型分布式Java应用和SOA</h1><h2 id="基于SCA实现SOA平台"><a href="#基于SCA实现SOA平台" class="headerlink" title="基于SCA实现SOA平台"></a>基于SCA实现SOA平台</h2><h2 id="基于ESB实现SOA平台"><a href="#基于ESB实现SOA平台" class="headerlink" title="基于ESB实现SOA平台"></a>基于ESB实现SOA平台</h2><h2 id="基于Tuscany实现SOA平台"><a href="#基于Tuscany实现SOA平台" class="headerlink" title="基于Tuscany实现SOA平台"></a>基于Tuscany实现SOA平台</h2><h2 id="基于Mule实现SOA平台"><a href="#基于Mule实现SOA平台" class="headerlink" title="基于Mule实现SOA平台"></a>基于Mule实现SOA平台</h2><h1 id="深入理解JVM"><a href="#深入理解JVM" class="headerlink" title="深入理解JVM"></a>深入理解JVM</h1><p><img src="/.io//003.png" alt="深入理解JVM"></p><h2 id="Java代码的执行机制"><a href="#Java代码的执行机制" class="headerlink" title="Java代码的执行机制"></a>Java代码的执行机制</h2><h2 id="JVM内存管理"><a href="#JVM内存管理" class="headerlink" title="JVM内存管理"></a>JVM内存管理</h2><p>&emsp;&emsp;Java开发人员不需要显式分配内存和回收内存，而是由JVM来自动管理内存的分配及回收。这对开发人员而言大大降低了编写程序的难度，但副作用可能是在不知不觉中浪费了很多内存，导致JVM花费很多时间进行内存的回收。另外还会带来的副作用是由于不清楚JVM内存的分配和回收机制，造成内存泄漏，最终导致JVM内存不够用。因此对于Java开发人员而言，不能因为JVM自动内存管理就不掌握内存分配和回收的知识了。</p><h3 id="内存空间"><a href="#内存空间" class="headerlink" title="内存空间"></a>内存空间</h3><p>&emsp;&emsp;SunJDK在实现时遵守JVM规范，将内存空间划分为方法区、堆、本地方法栈、PC寄存器及JVM方法栈。</p><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><p>&emsp;&emsp;方法区存在了要记在的类的信息、类中的静态变量、类中定义为final类型的常亮、类中的Field信息、类中的方法信息，当开发人员在程序中通过Class对象的getName、isInterface等方法来获取信息时，这些数据都来自于方法区域。方法区域也是全局共享的，在一定条件下他也会被GC，当方法区域要使用的内存超过其允许的大小是，会抛出OutOfMemory的错误信息。</p><p>&emsp;&emsp;在SunJDK中这块区域对应Permanet Generation，又称为持久代，默认最小值为16MB，最大值为64MB，其可以通过-XX:PermSize及-XX:MaxPermSize来制定最小值和最大值。</p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>&emsp;&emsp;堆用于存储对象实例和数组值，可以认为java中所有通过new创建的对象的内存都在此分配，Hep中对象所占的内存由GC进行回收，在32位操作系统上最大为2GB。在64位操作系统上没有限制，其大小可以通过-Xmx和-Xms来控制。</p><p>&emsp;&emsp;为了让内存回收更加高效，SunJDK自1.2开始对堆采用了分代管理的方式。</p><ol><li>新生代(New Generation)<br> &emsp;&emsp;大多数情况下，java层序中新建的对象都从新生代中分配内存，新生代由Eden Space和两块相同大小的SurvivorSpace构成，可通过-Xmn参数来制定新生代的大小。</li><li>旧生代(Old Generation或Tenuring Generation))<br> &emsp;&emsp;旧生代用户存放新生代中经过多次垃圾回收仍然存货的对象，例如缓存对象，新建的对象也有可能在就剩代中直接分配内存。主要有两种情况：一种为大对象，另一种为大的数组对象，且数组中无引用外部对象。</li></ol><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>&emsp;&emsp;本地方法栈用于支持native方法的执行，存储了每个native方法调用的状态，在SunJDK的实现中本地方法栈和JVM方法栈是同一个。</p><h4 id="PC寄存器和JVM方法栈"><a href="#PC寄存器和JVM方法栈" class="headerlink" title="PC寄存器和JVM方法栈"></a>PC寄存器和JVM方法栈</h4><p>&emsp;&emsp;每个线程均会创建PC寄存器和JVM方法栈，PC寄存器占用的可能为CPU寄存器或操作系统内存，JVM方法栈占用的为操作系统内存，JVM方法栈为线程私有，其在内存分配上非常高效。</p><p>&emsp;&emsp;当JVM方法栈空间不足时，会抛出StackOverflowError的错误，在SunJDK中可以通过-Xss来制定其大小。</p><h2 id="JVM线程资源同步与交互机制"><a href="#JVM线程资源同步与交互机制" class="headerlink" title="JVM线程资源同步与交互机制"></a>JVM线程资源同步与交互机制</h2><h1 id="分布式Java应用和Sun-JDK类库"><a href="#分布式Java应用和Sun-JDK类库" class="headerlink" title="分布式Java应用和Sun JDK类库"></a>分布式Java应用和Sun JDK类库</h1><h2 id="集合包"><a href="#集合包" class="headerlink" title="集合包"></a>集合包</h2><h2 id="并发包"><a href="#并发包" class="headerlink" title="并发包"></a>并发包</h2><h2 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h2><h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><h2 id="寻找性能瓶颈"><a href="#寻找性能瓶颈" class="headerlink" title="寻找性能瓶颈"></a>寻找性能瓶颈</h2><h2 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h2><h1 id="构架高可用的系统"><a href="#构架高可用的系统" class="headerlink" title="构架高可用的系统"></a>构架高可用的系统</h1><h2 id="避免系统出现单点"><a href="#避免系统出现单点" class="headerlink" title="避免系统出现单点"></a>避免系统出现单点</h2><h2 id="提高应用自身的可用性"><a href="#提高应用自身的可用性" class="headerlink" title="提高应用自身的可用性"></a>提高应用自身的可用性</h2><h1 id="构建可伸缩的系统"><a href="#构建可伸缩的系统" class="headerlink" title="构建可伸缩的系统"></a>构建可伸缩的系统</h1><h2 id="垂直伸缩"><a href="#垂直伸缩" class="headerlink" title="垂直伸缩"></a>垂直伸缩</h2><h2 id="水平伸缩"><a href="#水平伸缩" class="headerlink" title="水平伸缩"></a>水平伸缩</h2>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty权威指南读书笔记</title>
      <link href="/2018/07/09/Netty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/07/09/Netty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;Netty权威指南，是一本广受欢迎的Netty书籍。博主研读的是2014年6月第一版，第二次印刷的书本。</p><a id="more"></a><h1 id="基础篇-走进Java-NIO"><a href="#基础篇-走进Java-NIO" class="headerlink" title="基础篇  走进Java NIO"></a>基础篇  走进Java NIO</h1><h2 id="Java的I-O演进之路"><a href="#Java的I-O演进之路" class="headerlink" title="Java的I/O演进之路"></a>Java的I/O演进之路</h2><h3 id="I-O入门"><a href="#I-O入门" class="headerlink" title="I/O入门"></a>I/O入门</h3><p>&emsp;&emsp;Java1.4之前，Java的I/O还不完善，开发人员在开发该性能I/O时，会遇到困难：</p><ul><li>没有缓冲区，I/O性能存在问题</li><li>没有Channe概念，只有输入/输出流</li><li>同步阻塞I/O(BIO)通讯，导致通讯线程长时间阻塞</li><li>支持字符集有限，硬件可移植性不好</li></ul><p>&emsp;&emsp;高性能开发领域，很长一段时间里一直被C++/C长期占据，Java的BIO被大家所诟病。</p><h4 id="Linux网络I-O模型"><a href="#Linux网络I-O模型" class="headerlink" title="Linux网络I/O模型"></a>Linux网络I/O模型</h4><ol><li>阻塞I/O模型</li><li>费阻塞I/O模型</li><li>I/O复用模型</li><li>信号驱动I/O模型</li><li>异步I/O模型</li></ol><h4 id="I-O多路复用技术"><a href="#I-O多路复用技术" class="headerlink" title="I/O多路复用技术"></a>I/O多路复用技术</h4><p>&emsp;&emsp;I/O多路复用的应用场景</p><ul><li>服务器需要同时处理多个监听状态或连接状态的套接字</li><li>服务器需要同时处理多种网络协议的套接字</li></ul><p>&emsp;&emsp;Linux网络I/O模型总结：select–&gt;epoll</p><ol><li>支持一个进程打开的socket描述符不受限制(仅受限于系统的最大文件句柄数)</li><li>I/O效率不会随着FD数目的增加而线性下降</li><li>使用mmap加速内核与用户空间的消息传递</li><li>epoll的API更加简单</li></ol><h3 id="Java的I-O演进"><a href="#Java的I-O演进" class="headerlink" title="Java的I/O演进"></a>Java的I/O演进</h3><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h2 id="NIO入门"><a href="#NIO入门" class="headerlink" title="NIO入门"></a>NIO入门</h2><p>&emsp;&emsp;主要讲解BIO、NIO、NIO2.0的使用。主要包括</p><ol><li>传统的BIO模型</li><li>基于NIO的费阻塞编程</li><li>基于NIO2.0的异步费阻塞(AIO)编程</li><li>为什么需要使用NIO</li><li>为什么选择Netty</li></ol><h3 id="传统BIO编程"><a href="#传统BIO编程" class="headerlink" title="传统BIO编程"></a>传统BIO编程</h3><p>&emsp;&emsp;使用传统的BIO模型，最大的问题是缺乏伸缩能力，当客户端并发数增加后，服务端的线程个数和客户端的并发访问数呈1：1的正比关系。有线程是JVM非常宝贵的资源，当线程数膨胀之后，系统的性能将急剧下降。</p><h3 id="伪异步IO编程"><a href="#伪异步IO编程" class="headerlink" title="伪异步IO编程"></a>伪异步IO编程</h3><p>&emsp;&emsp;针对BIO模型的一个优化方案是做线程池。通过线程池控制线程数量，并能够灵活的调整并发线程的数量，防止海量并发接入导致线程耗尽。</p><p>&emsp;&emsp;伪异步IO编程实际上是对BIO的一个简单优化，但它并没有从本质上回避BIO的缺点，可能会造成如下后果</p><ol><li>相应缓慢</li><li>线程池技术，前面进入线程池的任务可能会影响后面任务的运行</li><li>线程池满了之后，后续加入任务会被阻塞</li></ol><h3 id="NIO编程"><a href="#NIO编程" class="headerlink" title="NIO编程"></a>NIO编程</h3><p>&emsp;&emsp;NIO概念的理解。一种是New IO，这也是官方的叫法。另外一种是Non-Block IO，即非阻塞IO。</p><h4 id="NIO类库"><a href="#NIO类库" class="headerlink" title="NIO类库"></a>NIO类库</h4><ol><li>缓冲区Buffer</li></ol><ul><li>ByteBuffer</li><li>CharBuffer</li><li>IntBuffer</li><li>LongBuffer</li><li>FloatBuffer</li><li>DoubleBuffer</li></ul><ol start="2"><li>通道Channel<ul><li>网络读写SelectableChannel</li><li>文件操作的FileChannel</li></ul></li><li>多路复用器Selector</li></ol><h3 id="AIO编程"><a href="#AIO编程" class="headerlink" title="AIO编程"></a>AIO编程</h3><p>&emsp;&emsp;NIO2.0引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道通过两种方式获取操作结果</p><ol><li>java.util.concurrent.Future</li><li>在执行异步操作的时候，传入一个java.nio.channel</li></ol><p>&emsp;&emsp;<em>不同模型的比较</em><br>||异步阻塞IO(BIO)|伪异步IO|非阻塞IO(NIO)|异步IO(AIO)|<br>|:-:|:-:|:-:|:-:|:-:|<br>客户端个数：IO线程数|1:1|M:N(M&gt;N)|M:1(1个IO线程处理多个客户端进程)|M:0(不需要启动额外的线程，被动回调)|<br>IO类型(阻塞)|阻塞IO|阻塞IO|阻塞IO|非阻塞IO|非阻塞IO|<br>IO类型(同步)|同步IO|同步IO|同步IO(多路复用)|异步IO|<br>API使用难度|简单|简单|非常复杂|复杂|<br>调试难度|简单|简答|复杂|复杂|<br>可靠性|非常差|差|高|高|<br>吞吐量|低|中|高|高|</p><h3 id="选择Netty的理由"><a href="#选择Netty的理由" class="headerlink" title="选择Netty的理由"></a>选择Netty的理由</h3><ol><li>为什么不选择原生Java NIO</li></ol><ul><li>NIO的类库和API使用复杂</li><li>具备额外技能作铺垫</li><li>可靠性能差，工作难度较大</li><li>JDK NIO存在BUG</li></ul><ol start="2"><li>为什么选择Netty</li></ol><ul><li>API使用简单，开发门槛较低</li><li>功能强大，预支了多种解码器，支持多种主流协议</li><li>定制能力强</li><li>性能高</li><li>成熟、稳定</li><li>社区活跃，班底迭代周期短，发现的BUG被及时修复</li></ul><h1 id="入门篇-Netty-NIO开发指南"><a href="#入门篇-Netty-NIO开发指南" class="headerlink" title="入门篇 Netty NIO开发指南"></a>入门篇 Netty NIO开发指南</h1><h2 id="Netty入门应用"><a href="#Netty入门应用" class="headerlink" title="Netty入门应用"></a>Netty入门应用</h2><p>&emsp;&emsp;使用Netty实现TimeServer服务器端与客户端通讯服务</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">## 服务器端代码</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimerServer</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bind</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        <span class="comment">// 配置服务端的NIO线程组</span></span><br><span class="line">        EventLoopGroup bossGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">        EventLoopGroup workGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            ServerBootstrap b = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">            b.group(bossGroup,workGroup)</span><br><span class="line">            .channel(NioServerSocketChannel<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">            .<span class="title">option</span>(<span class="title">ChannelOption</span>.<span class="title">SO_BACKLOG</span>,1024)</span></span><br><span class="line"><span class="class">            .<span class="title">childHandler</span>(<span class="title">new</span> <span class="title">ChildChannelHandler</span>())</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 绑定端口，同步等待成功</span></span><br><span class="line">            ChannelFuture f = b.bind(port).sync();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 等待服务端口监听端口关闭</span></span><br><span class="line">            f.channel().closeFuture().sync();</span><br><span class="line">        &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">            <span class="comment">// 优雅退出，释放线层组资源</span></span><br><span class="line">            bossGroup.shutdownGracefully();</span><br><span class="line">            workGroup.shutdownGracefully();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">ChildChannelHandler</span> <span class="keyword">extends</span> <span class="title">ChannelInitializer</span>&lt;<span class="title">SocketChannel</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">iniitChannel</span><span class="params">(SocketChannel args0)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            args0.pipeline()/addLast(<span class="keyword">new</span> TimeServerHandler());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@desc</span> 测试时间服务器</span></span><br><span class="line"><span class="comment">    */</span> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> port = <span class="number">8080</span>;</span><br><span class="line">        <span class="keyword">if</span>(args!=<span class="keyword">null</span> &amp;&amp; args.length&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">try</span>&#123;</span><br><span class="line">                port = Integer.valueOf(args[<span class="number">0</span>]);</span><br><span class="line">            &#125;<span class="keyword">catch</span>(NumberFormatException e)&#123;</span><br><span class="line">                <span class="comment">// 采用默认值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> TimeServer().bind(port);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Netty时间服务器服务端TimeServerHandler */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimerServerHandler</span> <span class="keyword">extends</span> <span class="title">ChannelHandlerAdapter</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelRead</span><span class="params">(ChannelHandlerContext ctx,Object msg)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    </span><br><span class="line">        Bytebuf buf = (ByteBuf)msg;</span><br><span class="line">        <span class="keyword">byte</span>[] req = <span class="keyword">new</span> <span class="keyword">byte</span>[buf.readableBytes()];</span><br><span class="line">        buf.readBytes(req);</span><br><span class="line"></span><br><span class="line">        String body = <span class="keyword">new</span> String(req,<span class="string">"UTF-8"</span>);</span><br><span class="line">        System.out.println(<span class="string">"The time server receive order : "</span>+body);</span><br><span class="line"></span><br><span class="line">        String currentTime = <span class="string">"QUERY TIME ORDER"</span>.equalsIngnoreCase(body)?<span class="keyword">new</span> java.util.Date(System.currentTimeMilles()).toString():<span class="string">"BAD ORDER"</span>;</span><br><span class="line">        </span><br><span class="line">        Bytebuf resp = Unpooled.copiedBuffer(currentTime.getBytes());</span><br><span class="line">        ctx.write(resp);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelReadComplete</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        ctx.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exceptionCaught</span><span class="params">(ChannelHandlerContext ctx,Throwable cause)</span></span>&#123;</span><br><span class="line">        ctx.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## 客户端代码</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeClient</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(<span class="keyword">int</span> port,String host)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置客户端NIO线程组</span></span><br><span class="line">        EventLoopGroup group = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            Bootstrap b = <span class="keyword">new</span> Bootstrap();</span><br><span class="line">            g.group(group)</span><br><span class="line">            .channel(NioSocketChannel<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">            .<span class="title">option</span>(<span class="title">ChannelOption</span>.<span class="title">TCP_NODELAY</span>,<span class="title">trye</span>)</span></span><br><span class="line"><span class="class">            .<span class="title">handler</span>(<span class="title">new</span> <span class="title">ChannelInitializer</span>&lt;<span class="title">SocketHandler</span>&gt;()</span>&#123;</span><br><span class="line">                <span class="meta">@override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">                    ch.pipeline().addLast(<span class="keyword">new</span> TimeClientChannel());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">             <span class="comment">// 发起异步连接操作</span></span><br><span class="line">            ChannelFuture f = b.connect(host,port).sync();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 等待客户端链路关闭</span></span><br><span class="line">            f.channel().closeFuture().sync();</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">            group.shutdownGracefully();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** 主要测试方法 */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(Stirng[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> port = <span class="number">8080</span>;</span><br><span class="line">        <span class="comment">// read port from input parameters if possible</span></span><br><span class="line">        <span class="keyword">new</span> TimeClient().bind(port,hostname[ or <span class="string">"localhost"</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeClientHandler</span> <span class="keyword">extends</span> <span class="title">ChannelHandlerAdapter</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ByteBuf firstMessage;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TimeClientHandler</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">byte</span>[] req = <span class="string">"QUERY TIME ORDER"</span>.getBytes();</span><br><span class="line">        firstMessage =Unpooled.buffer(req.length);</span><br><span class="line">        firstMessage.writeBytes(req);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelActive</span><span class="params">(ChannleHandlerContext ctx)</span> </span>&#123;</span><br><span class="line">        ctx.writeAndFlush(firstMessage);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelRead</span><span class="params">(ChannelHandlerContext ctx,Object msg)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        ByteBuf buf = (ByteBuf)msg;</span><br><span class="line">        <span class="keyword">byte</span>[] req = <span class="keyword">new</span> String(buf.readableBytes());</span><br><span class="line">        buf.readBytes(req);</span><br><span class="line">        String body = <span class="keyword">new</span> String(req,<span class="string">"UTF-8"</span>);</span><br><span class="line">        System.out.println(<span class="string">"Now is : "</span>+body);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exceptionCaught</span><span class="params">(ChannelHandlerContext ctx,Throwable cause)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 释放资源</span></span><br><span class="line">        ctx.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="TCP黏包-拆包的解决之道"><a href="#TCP黏包-拆包的解决之道" class="headerlink" title="TCP黏包/拆包的解决之道"></a>TCP黏包/拆包的解决之道</h2><p>&emsp;&emsp;使用TCP协议，在发送或传输过程中都需要考虑黏包、拆包问题。</p><h3 id="TCP黏包-拆包"><a href="#TCP黏包-拆包" class="headerlink" title="TCP黏包/拆包"></a>TCP黏包/拆包</h3><p>&emsp;&emsp;TCP是一个流协议，是一串没有边界的字符流。TCP底层并不了解上层数据业务数据的含义，他会根据TCP缓冲区的实践情况进行划分，所以在业务上完整的一个包可能会被拆分成多个包进行发送，也有可能多个小包封装成一个大包进行发送，这就是所谓的黏包、拆包问题。</p><p>&emsp;&emsp;问题产生的原因：</p><ol><li>应用程序write的字节大小大于套接字缓冲区大小</li><li>进行MSS大小的TCP分段</li><li>以太网帧的payload大于MTU进行IP分片</li></ol><p>&emsp;&emsp;解决策略</p><ol><li>消息定长，如果不够空位补齐</li><li>在包尾部增加会回车换行符，例如FTP协议</li><li>将消息分为消息头和消息体，消息头中包含消息的总长度</li><li>更复杂的应用层协议</li></ol><h3 id="Netty解决读半包问题"><a href="#Netty解决读半包问题" class="headerlink" title="Netty解决读半包问题"></a>Netty解决读半包问题</h3><p>&emsp;&emsp;为了解决TCP黏包、拆包问题，Netty引入了多种编码解码器用于处理半包问题，只要能够熟悉掌握这些类库，解决黏包问题非常容易。</p><p>&emsp;&emsp;LineBasedFrameDecoder的原理是依次遍历ByteBuf中的可读字节，判断是否存在换行符”\n”、”\r\n”。如果有，就以此为结束位置，从可读索引到结束位置的字节就组成了一行。</p><p>&emsp;&emsp;StringDecorder的功能非常简单，就是将发送的对象转换成字符串，然后继续条用Handler。LineBasedFrameDecoder+StringDecoder组合就是按照行切分的文本解码器，它用来支持解决TCP的黏包和拆包。</p><h2 id="分隔符和定长符解码器的应用"><a href="#分隔符和定长符解码器的应用" class="headerlink" title="分隔符和定长符解码器的应用"></a>分隔符和定长符解码器的应用</h2><p>&emsp;&emsp;TCP以流的方式进程数据传输，上层的应用协议对消息进行了区分，往往采用如下方式</p><ol><li>消息长度固定</li><li>将回车作为换行符</li><li>将特殊的分隔符作为消息的结束位置</li><li>通过在消息头中定义长度字段来标识消息的长度</li></ol><h3 id="DelimiterBasedFrameDecoder应用开发"><a href="#DelimiterBasedFrameDecoder应用开发" class="headerlink" title="DelimiterBasedFrameDecoder应用开发"></a>DelimiterBasedFrameDecoder应用开发</h3><p>&emsp;&emsp;DelimiterBasedFrameDecoder可以根据自定义分隔符作为结束位置，在使用的时候传入两个参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new DelimiterBasedFrameDecoder(1024,Bytebuf:: delimiter)</span><br></pre></td></tr></table></figure><p>其中第一个参数表示消息的最大长度，第二参数表示分隔符。</p><h3 id="FixedLengthFrameDecoder应用开发"><a href="#FixedLengthFrameDecoder应用开发" class="headerlink" title="FixedLengthFrameDecoder应用开发"></a>FixedLengthFrameDecoder应用开发</h3><p>&emsp;&emsp;FixedLengthFrameDecoder是固定长度解码器，它能够按照固定的长度对消息进行自动解码，开发者不需要考虑TCP的黏包和拆包问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new FixedLengthFrameDecoder(10)</span><br></pre></td></tr></table></figure><p>其中10表示固定长度。</p><h1 id="中级篇-Netty编解码开发指南"><a href="#中级篇-Netty编解码开发指南" class="headerlink" title="中级篇 Netty编解码开发指南"></a>中级篇 Netty编解码开发指南</h1><p>&emsp;&emsp;了解Netty内置的编码器之后，继续学习Netty的编码解码款框架的应用，例如java序列化、二进制编码、Google Protobuf和JBoss的Marshallling序列化框架。</p><h2 id="编解码技术"><a href="#编解码技术" class="headerlink" title="编解码技术"></a>编解码技术</h2><p>&emsp;&emsp;基于Java提供的对象输入/输出流ObjectInputStreaming和ObjectOutputStreaming，可以直接把Java对象作为可存储的字节流写入文件，也可以传输到网上。对程序员而言，序列化可提高开发效率。</p><p>&emsp;&emsp;Java序列化的目的</p><ol><li>网络传输</li><li>对象持久化</li></ol><h3 id="Java序列化缺点"><a href="#Java序列化缺点" class="headerlink" title="Java序列化缺点"></a>Java序列化缺点</h3><ol><li>无法跨语言</li><li>序列化后的码流太大</li><li>序列化性能太低</li></ol><h3 id="业界主流的编解码框架"><a href="#业界主流的编解码框架" class="headerlink" title="业界主流的编解码框架"></a>业界主流的编解码框架</h3><ol><li><p>Google Protobuf<br> 主要特点</p><ul><li>结构化存储</li><li>搞笑的编解码性能</li><li>语言无关、平台无关、扩展性好</li><li>官方支持Java、C++和Python三种语言<br>为什么不适用XML走位通讯协议？一方面，解析的时间开销；另一方便，XML为了可读性牺牲的空间开销都非常大。<br>protobuf引入了数据描述文件和代码生成机制，主要优点</li><li>文件化的数据结构描述语言，可以实现语言和平台无关，特别适合系统间集成</li><li>通过标识字段的顺序，实现协议的兼容</li><li>代码生成机制，不需要手动编写同样数据结构的C++和Java版本</li><li>方便后续的管理和维护</li></ul></li><li><p>Facebook Thrift<br> thrift主要有一下部分组成</p><ul><li>语言系统以及IDL编译器：负责由用户给定的IDL文件生成相应语言的接口代码</li><li>TProtocal: RPC的协议层，可以选择多个不同的对象序列化方式，如JSON何Binary</li><li>TTransport: RPC的传输层，同样可以选择不同的传输层实现，如socket、NIO、MemeroyBuffer等</li><li>TProcessor:作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口</li><li>TServer: 聚合TProtocal、TTransport和TProcessor等对象<br>Thrift支持三种不同的编解码</li><li>通用的二进制编码</li><li>压缩二进制编解码</li><li>优化的可选字段压缩编解码</li></ul></li><li><p>JBoss Marshalling<br> JBoss Marshalling是一个序列化的API，修正了JDK自带的序列化包的很多问题。相比于前面两种编解码协议，JBoss Marshalling更多是应用于JBoss内部，应用范围有限。</p><h2 id="Java序列化"><a href="#Java序列化" class="headerlink" title="Java序列化"></a>Java序列化</h2></li></ol><p>&emsp;&emsp;Java序列化在Netty NIO框架中的使用方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">## 服务器端：ChannleInitializer&lt;SocketChannel&gt;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span></span>&#123;</span><br><span class="line">    ch.pipeline()</span><br><span class="line">        .addLast(<span class="keyword">new</span> ObjectDecoder(<span class="number">1024</span>*<span class="number">1024</span>,Classresolvers.weakCachingConcurrentResolver(<span class="keyword">this</span>.getClass().getClassLoader())));</span><br><span class="line">    ch.pipeline().addLast(<span class="keyword">new</span> OjectEncoder());</span><br><span class="line">    <span class="comment">// add other handler</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Google-Protobuf编解码"><a href="#Google-Protobuf编解码" class="headerlink" title="Google Protobuf编解码"></a>Google Protobuf编解码</h2><p>&emsp;&emsp;Profotbuf是一个灵活的、小巧的、高效的、结构化的数据序列化框架，相比于XML等传统的序列化工具，它更小、更快、更简单。Profobuf支持一次可以到处使用，甚至跨语言使用，通过代码生成工具可以自动生成不同语言版本的源代码，甚至可以在不同版本的数据结构进程间进行数据传递实现数据结构的前后兼容。</p><h3 id="Protobuf开发环境搭建"><a href="#Protobuf开发环境搭建" class="headerlink" title="Protobuf开发环境搭建"></a>Protobuf开发环境搭建</h3><h3 id="Netty的Protobuf服务端开发"><a href="#Netty的Protobuf服务端开发" class="headerlink" title="Netty的Protobuf服务端开发"></a>Netty的Protobuf服务端开发</h3><p>&emsp;&emsp;各种不同版本的示例程序代码，不同点在于ChannelHandlerAdapter的实现方式。其中本部分基于Protobuf的Netty实现方式如下所示</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">## 服务器端</span><br><span class="line"><span class="keyword">public</span>  <span class="class"><span class="keyword">class</span> <span class="title">ServerHandler</span> <span class="keyword">extends</span> <span class="title">ChannelHandlerAdapter</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelRead</span><span class="params">(ChannelHandlerContext ctx,Object msg)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// protobuf object</span></span><br><span class="line">        Test.TestReq req = (Test.TestReq )msg;<span class="comment">// 直接强制转化为目标类</span></span><br><span class="line">        <span class="comment">// 其他处理</span></span><br><span class="line">        ctx.writeAndFlush([Target Content]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## 客户端代码类似</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里使用到的ProtofReq对象，是通过Protobuf自动化生成的类。</p><h2 id="JBoss-Marshelling编解码"><a href="#JBoss-Marshelling编解码" class="headerlink" title="JBoss Marshelling编解码"></a>JBoss Marshelling编解码</h2><p>&emsp;&emsp;JBose Marshalling的序列化编解码框架，应用领域有限不做赘述。</p><h1 id="高级篇-Netty多协议开发和应用"><a href="#高级篇-Netty多协议开发和应用" class="headerlink" title="高级篇 Netty多协议开发和应用"></a>高级篇 Netty多协议开发和应用</h1><h2 id="Http协议开发应用"><a href="#Http协议开发应用" class="headerlink" title="Http协议开发应用"></a>Http协议开发应用</h2><p>&emsp;&emsp;Http协议是建立在TCP传输层协议之上的应用层协议，是一个属于应用层的面向对象的协议。与1990年提出，经过多年的发展逐渐完善。Netty的Http协议栈是基于Netty的NIO通讯框架，因此Netty的Http协议也是异步非阻塞的。</p><h3 id="Http协议介绍"><a href="#Http协议介绍" class="headerlink" title="Http协议介绍"></a>Http协议介绍</h3><p>&emsp;&emsp;Http协议主要有一下特点</p><ul><li>支持Client/Server模式</li><li>简单：客户端发送请求时，只需要制定服务URL，携带必要的请求参数或消息体即可</li><li>灵活-Http允许传输任意类型的数据，传输类型在Http消息头中的Content-Type加以标记</li><li>无状态-Http协议是无状态协议，既对于事物处理没有记忆能力。</li></ul><h4 id="Http请求消息"><a href="#Http请求消息" class="headerlink" title="Http请求消息"></a>Http请求消息</h4><ol><li>消息组成<ul><li>Http请求行</li><li>Http消息头</li><li>Http请求正文</li></ul></li><li>请求方法<ul><li>GET：请求资源</li><li>POST: 请求资源并附加提交数据</li><li>HEAD: 请求消息报头</li><li>PUT: 请求存储一个资源</li><li>DELETE: 请求服务器删除一个资源</li><li>TRACE: 请求服务器会送收到的请求消息，主要用于测试或诊断</li><li>Connect: 保留将来使用</li><li>Options: 请求查询服务器的性能</li></ul></li></ol><h4 id="Http相应消息"><a href="#Http相应消息" class="headerlink" title="Http相应消息"></a>Http相应消息</h4><ol><li>效应状态<ul><li>1XX: 指示消息。请求已接收，继续处理</li><li>2XX: 成功。请求已被成功接收、理解、接收</li><li>3XX：重定向。要完成请求必须进行更进一步的操作</li><li>4XX: 客户端错误。请求有语法错误或请无法实现</li><li>5XX: 服务端错误。服务器未能处理请求</li></ul></li><li>常见相应代码与描述<table><thead><tr><th align="center">状态码</th><th align="left"><center>状态描述</center></th></tr></thead><tbody><tr><td align="center">200</td><td align="left">OK:客户端请求成功</td></tr><tr><td align="center">400</td><td align="left">Bad Request: 客户端请求存在语法错误，不能被服务器所理解</td></tr><tr><td align="center">401</td><td align="left">Unauthorized: 请未经授，这个状态代码必须和WWW-Authenticate报头域一起使用</td></tr><tr><td align="center">403</td><td align="left">Forbidden:服务器收到请求，但拒绝提供服务</td></tr><tr><td align="center">404</td><td align="left">Not Found: 请求资源不存在</td></tr><tr><td align="center">500</td><td align="left">Internal Server Error: 服务器发生不可预期的错误</td></tr><tr><td align="center">503</td><td align="left">Server Unavailabkle: 服务器当前不能处理客户端的请求，一段时间之后可能恢复</td></tr></tbody></table></li></ol><h3 id="Http协议的Netty处理"><a href="#Http协议的Netty处理" class="headerlink" title="Http协议的Netty处理"></a>Http协议的Netty处理</h3><p>&emsp;&emsp;服务器端重点代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@override</span> <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-decoder"</span>,<span class="keyword">new</span> HttpRequestDecoder());</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-aggregator"</span>,<span class="keyword">new</span> HttpObjectAgregator(<span class="number">65536</span>));</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-encoder"</span>,<span class="keyword">new</span> HttpResponseEncoder());</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-chunked"</span>,<span class="keyword">new</span> ChunkedWriteHandler());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自定义: extends SimpleChannelInboundsHandler&lt;FullHttpRequest&gt;</span></span><br><span class="line">    ch.pipleline().addLast(<span class="string">"fileServerHandler"</span>,<span class="keyword">new</span> HttpFileServerHandler(url);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Netty-Http-XML协议栈开发"><a href="#Netty-Http-XML协议栈开发" class="headerlink" title="Netty Http+XML协议栈开发"></a>Netty Http+XML协议栈开发</h3><p>&emsp;&emsp;由于Http协议的通用性，异构系统间的通讯交互采用Http协议，通过Http协议承载业务数据进行消息交互。例如流行的Http+XML，或RestFUL+JSON。</p><p>&emsp;&emsp;在java领域，最常用的Http协议栈就是基于Serverlet规范的Tomcat等Web容器。由于Google等大佬的强力推荐，Jetty等轻量级Web容器也得到了广泛的应用。但许多场景下，基于Http的应用都是后台应用，Http仅仅是承载数据交换的一个通道，是一个载体而不是Web容器。这种场景下，一般不需要Tomcat这种重量型的Web容器。</p><p>&emsp;&emsp;另外网络安全日益严峻的今天，重量级的Web容器由于功能繁琐，会存在很多安全漏洞，典型的如Tomcat。这意味着需要为Wb容器做很多安全加固工作去修补这些漏洞，然而开发中并没有用到这些功能，这就带来了并发和维护成本。在这种场景下，选择一个更加轻量级的http协议栈是个更好的选择。</p><p><img src="/.io//001.png" alt="Http+XML协议栈开发"></p><p>Netty Http+XML重点代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(SocketChannel ch)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-decoder"</span>,<span class="keyword">new</span> HttpResponseDecoder());</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-aggregator"</span>,<span class="keyword">new</span> HttpObjectAgregator(<span class="number">65536</span>));</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"xml-decoder"</span>,<span class="keyword">new</span> HttpXMLResponseDecoder(Order<span class="class">.<span class="keyword">class</span>,<span class="title">true</span>))</span>;</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"http-encoder"</span>,<span class="keyword">new</span> HttpRequestEncoder());</span><br><span class="line">    ch.pipleline().addLast(<span class="string">"xml-encoder"</span>,<span class="keyword">new</span> HttpXMLRequestEncoder());</span><br><span class="line"></span><br><span class="line">    ch.pipleline().addLast(<span class="string">"fileServerHandler"</span>,<span class="keyword">new</span> HttpXMLHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;尽管本文中开发的Http+XML协议栈是一个高性能、通用的协议栈，但这里忽略了异常处理、可扩展性的API和配置能力。所以如果想要做产品化的协议栈，还需要一些额外的完善。</p><h2 id="WebSocket协议开发"><a href="#WebSocket协议开发" class="headerlink" title="WebSocket协议开发"></a>WebSocket协议开发</h2><p>&emsp;&emsp;一直以来，网络在很多程度上都是围绕着Http的请求/相应模式而构建的。长期以来存在这个各种技术让服务器得知有数据可用时，立即将数据发送到客户端。最常用的一种技术手段是对服务器发起链接创建假象，被称为长轮循。利用长轮循，客户端可以打开指向服务器的Http连接，而服务器会一直保持链接打开，直到发送响应。服务器只要有数据，就会发送响应。这些问题都存在一个同样的问题，Http协议的开销，到时他们不适用于低延迟应用。</p><p>&emsp;&emsp;为了解决这些问题，WebSocket将网络套接字引入到了客户端和服务器端，浏览器和服务器之间可以通过套接字建立持久的连接，双方随时都可以互发数据给对方，而不是由客户端控制的一对一应答模式。</p><h3 id="Http协议弊端"><a href="#Http协议弊端" class="headerlink" title="Http协议弊端"></a>Http协议弊端</h3><p>&emsp;&emsp;Http主要弊端总结</p><ul><li>半双工模式。不能同时传送数据，意味着一个时刻，只有一个方向上的数据传送</li><li>Http消息冗长复杂。Http消息包括消息头、消息体、换行符等，通常情况下采用文本传输，，相比于其他的二进制通讯，冗长而复杂</li><li>针对服务器推送的黑客攻击，例如长轮询</li></ul><p>&emsp;&emsp;比较新的一种轮询技术是Comet，使用了Ajax。这种技术虽然可达到双工通信，但依然需要发送请求，而且在Comet中，普遍采用了长连接，这也会大量消耗服务器款到和资源。</p><p>&emsp;&emsp;为了解决Http协议效率底下的问题，HTML5定义了WebSocket协议，能更好的节省服务器资源和宽带并达到定时通信。</p><h3 id="WebSocket入门"><a href="#WebSocket入门" class="headerlink" title="WebSocket入门"></a>WebSocket入门</h3><p>&emsp;&emsp;WebSocket主要特点</p><ul><li>单一的TCP连接，采用了全双工模式通信</li><li>对代理、防火墙和路由器透明</li><li>无头部信息、Cookies和身份验证</li><li>无安全开销</li><li>通过Ping/Pong帧保持链路激活</li><li>服务器可以主动传递消息给客户端，不再需要客户端轮询</li></ul><p>&emsp;&emsp;WebSocket的目的是为了取代轮询和Coment技术，使客户端浏览器具备像C/S架构下桌面系统一样的实时通信能力。</p><ol><li>建立连接<br> <strong>客户端–&gt;握手请求–&gt;服务器–&gt;握手相应</strong></li><li>生命周期<br> &emsp;&emsp;握手成功之后，客户端和服务器端就可以通过”messages”的方式进行通信了，一个消息由一个或多个帧组成，WebSocket的消息并不一定对应某一个特定网络层的帧，它可以被分割成多个或被合并。</li><li>关闭连接<br> &emsp;&emsp;为关闭WebSocket连接，客户端和服务端需要通过一个安全的方法关闭底层TCP连接以及TLS会话。如果合适，丢弃任何核能已经接受的字节。<br> &emsp;&emsp;WebSocket的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个关闭控制流，当对接接收到关闭控制帧时，需要主动关闭WebSocket连接。</li></ol><h3 id="Netty-WebSocket开发"><a href="#Netty-WebSocket开发" class="headerlink" title="Netty WebSocket开发"></a>Netty WebSocket开发</h3><p>&emsp;&emsp;Netty基于Http协议开发了WebSocket协议栈，利用Netty的WebSocket协议栈可非常方便的开发出WebSocket客户端和服务器端。</p><p>基于Netty的WebSocket编程主要代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebSocketServerHandler</span> <span class="keyword">extends</span> <span class="title">SimpleChannelInBoundHandler</span>&lt;<span class="title">Object</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> WebSocketServerHandshaker handshaker;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// define Logger</span></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">messageReceived</span><span class="params">(ChannelHandlerContext ctx,Object msg)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 传统的Http接口</span></span><br><span class="line">        <span class="keyword">if</span>(msg <span class="keyword">instanceof</span> FullHttpRequest)&#123;</span><br><span class="line">            handleHttpRequest(ctx,(FullHttpRequest)msg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// WebSocket接入</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(msg <span class="keyword">instanceof</span> WebSocketFrame)&#123;</span><br><span class="line">            handleWebSocketFrame(ctx,(WebSocketFrame)msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelReadComplete</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        ftx.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exceptionCaught</span><span class="params">(ChannelHandlerContext ctx, Throwable e)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        cause.printStackTrace();</span><br><span class="line">        ctx.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// define local method</span></span><br><span class="line">    <span class="comment">// handle websocket http request</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleHttpRequst</span><span class="params">(ChannelHandlerContext ctx,FullHttpRequest req)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果Http编码失败，返回Http异常</span></span><br><span class="line">        <span class="keyword">if</span>(!req.getDecoderResult().isSuccesss() || (!<span class="string">"websocket"</span>.equals(req.headers().get(<span class="string">"Upgrade"</span>))))&#123;</span><br><span class="line">            sendHttpResponse(ctx,req,<span class="keyword">new</span> DefaultFullHttpResponse(HTTP_1_1,BAD_REQUEST));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 构造握手相应返回，本机测试</span></span><br><span class="line">        WebSocketServerHandShakerFactory wsFactory = <span class="keyword">new</span> WebSocketServerHandShakerFactory(<span class="string">"ws://localhost:8080/websocket"</span>,<span class="keyword">null</span>,<span class="keyword">false</span>);</span><br><span class="line">        handshaker = wsFactory.newHandshaker(req);</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">null</span>==handshaker)&#123;</span><br><span class="line">            WebSocketServerHandShakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel());</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            handshaker.handshake(ctx.channel(),req);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// handler websocket request</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleWebSocketRequest</span><span class="params">(ChannelHandlerContext ctx,WebSocketFrame req)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断是否关闭链路指令</span></span><br><span class="line">        <span class="keyword">if</span>(frame <span class="keyword">instanceof</span> CloseWebSocketFrame)&#123;</span><br><span class="line">            handshaker.close(ctx.channel(),(CloseWebSocketFrame)farme.retain());</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断是否Ping消息</span></span><br><span class="line">        <span class="keyword">if</span>(frame <span class="keyword">instanceof</span> PingWebSocketFrame)&#123;</span><br><span class="line">            ctx.channel().write(<span class="keyword">new</span> PongWebSocketFrame(frame.contenet().retain()));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 本利仅支持文本消息，比支持二进制消息</span></span><br><span class="line">    <span class="keyword">if</span>(!(frame <span class="keyword">instanceof</span> TextWebSocketFrame))&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(String.format(<span class="string">"$s frame types not supported"</span>,frame.getClass().getName()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//返回应答消息</span></span><br><span class="line">    String request = ((TextWebSocketFrame)frame).text();</span><br><span class="line">    ctx.channel().write(<span class="keyword">new</span> TextWebSocketFrame(request+<span class="string">", 欢迎使用Netty WebSocket服务，现在时间："</span>+<span class="keyword">new</span> java.util.Date().toString());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sendHttpResponse</span><span class="params">(ChannelHandlerContext ctx,FullHttpRequest req,FullHttpResponse res)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 返回应答给客户端</span></span><br><span class="line">        <span class="keyword">if</span>(req.getStatus().code()!=<span class="number">200</span>)&#123;</span><br><span class="line">            ByteBuf buf = Unpooled.copiedBuffer(res.getStatus().toString(),CharsetUtil.UTF_8);</span><br><span class="line">            res.content().writeBytes(buf);</span><br><span class="line">            buf.release();</span><br><span class="line">            setContentLength(res,res.content().readableBytes());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果是非Kill-Alive，关闭连接</span></span><br><span class="line">        ChannelFuture f = ctx.channel().writeAndFlush(res);</span><br><span class="line">        <span class="keyword">if</span>(!isKeepAlive(req) || res.getStatus.code()!=<span class="number">200</span>)&#123;</span><br><span class="line">            f.addListener(ChannelFutureListener.CLOSE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;本章主要介绍了Http协议的弊端和WebSocket的一些技术背景，随后对WebSocket的优势和基础入门进行了介绍，包括WebSocket的握手请求和相应、连接的建立与关闭、WebSocket的生命周期等内容。</p><h2 id="UDP协议开发"><a href="#UDP协议开发" class="headerlink" title="UDP协议开发"></a>UDP协议开发</h2><p>&emsp;&emsp;UDP是用户数据报协议(User Datagram Protocol, UDP)的简称，其主要作用是将网络数据流量压缩成数据报形式，提供面向事物的简单消息传送服务。与TCP相比，UDP协议直接利用IP协议进行UDP数据报的传输，UDP面向的是无连接、不可靠的数据投递服务。当使用UDP时，用户应用必须负责解决数据报丢失、重复、排序、差错确认等问题。</p><p>&emsp;&emsp;由于UDP具有资源消耗小、处理速度快的优点，所以通常视频、音频等可靠性要求不高的数据传输一般会使用UDP，即便有一定的丢包率，也不会对功能造成严重的影响。</p><h3 id="UDP协议简介"><a href="#UDP协议简介" class="headerlink" title="UDP协议简介"></a>UDP协议简介</h3><p>&emsp;&emsp;UDP数据分为首部和数据两个部分。首部简单，为8个字节，包括</p><ul><li>源端口：源端口号，2个字节，最大值为65535</li><li>目的端口：目的端口号，2个字节，最大为65535</li><li>长度：2个字节，UDP用户数据报的总长度</li><li>校验和：2字节，用于校验UDP数据报的数字段和包含UDP数据报首部的“伪首部”。</li></ul><p>&emsp;&emsp;UDP协议的特点</p><ul><li>UDP传送数据前并不与对方建立连接，即UDP是无连接的。在数据发送前，发送方和接收方相互交换信息是双方同步</li><li>UDP对接受到的数据报不发送确认信号，发送端不知道数据是否被正确接受，也不会重发数据</li><li>UDP发送数据比TCP快，系统开销少：UDP简单、灵活。</li></ul><h3 id="UDP服务端开发"><a href="#UDP服务端开发" class="headerlink" title="UDP服务端开发"></a>UDP服务端开发</h3><p><img src="/.io//002.png" alt="UDP开发流程"></p><h3 id="UDP客户端开发"><a href="#UDP客户端开发" class="headerlink" title="UDP客户端开发"></a>UDP客户端开发</h3><p>&emsp;&emsp;总体而言UDP开发相对简单，客户端开发可参考服务器端开发代码。</p><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;由于UDP相比于TCP的应用领域窄一些，所以本章不做详细论述。</p><h2 id="文件传输"><a href="#文件传输" class="headerlink" title="文件传输"></a>文件传输</h2><p>&emsp;&emsp;文件是最常见的数据源之一，在程序中经常需要将数据存储到文件中。在NIO的类库之前，Java所有的文件操作分为两类</p><ul><li>基于字节流的InputStream和OutputStream</li><li>基于字符流的Reader和Writer</li></ul><p>&emsp;&emsp;通过NIO提供的Channel类库，可以方便的以“管道”方式对文件进行各种IO操作，相比于传统的IO操作有了较高改进。</p><h3 id="文件的基础知识"><a href="#文件的基础知识" class="headerlink" title="文件的基础知识"></a>文件的基础知识</h3><p>&emsp;&emsp;文件是计算机中一种基本的数据存储形式，在时间存储数据时，如果对数据进行的读写速度要求不是很高，存储数量也不是很大，使用文件作为一种持久化的方式是比较好的选择。文件需要注意几个概念</p><ul><li>文件路径</li><li>文件名称</li></ul><h3 id="Netty文件传输开发"><a href="#Netty文件传输开发" class="headerlink" title="Netty文件传输开发"></a>Netty文件传输开发</h3><p>&emsp;&emsp;文件传输通常使用FTP或Http附件的方式。事实上通过TCP Socket+File的方式进行文件传输也有一定的应用场景，尽管不是主流，但掌握这种文件阐释方式还是非常重要的，特别是针对跨主机的JVM进城之间进行持久化数据的相互交换。</p><p>&emsp;&emsp;示例Netty程序的应用场景</p><ol><li>Netty文件服务器启动，绑定8000作为内部监听端口</li><li>在CMD控制台上，通过telnet和文件服务器建立tcp连接</li><li>在控制台输入需要下载的文件绝对路径</li><li>文件服务器接受到请求消息后进行合法性判断，如果文件存在，则将文件发送给CDM控制台</li><li>CMD控制台打印文件名和文件内存</li></ol><p>&emsp;&emsp;主要处理类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSererHandler</span> <span class="keyword">extends</span> <span class="title">SimpleChannelInBoundHandler</span>&lt;<span class="title">String</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CR = System.getProperty(<span class="string">"line.separator"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">messageReceived</span><span class="params">(ChannelHandlerContext ctx,String msg)</span></span>&#123;</span><br><span class="line">        File f = <span class="keyword">new</span> File(msg);</span><br><span class="line">        <span class="keyword">if</span>(!f.exists())&#123;</span><br><span class="line">            ctx.writeAndFlush(<span class="string">"Not a file :"</span>+f+CR);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(!f.isFile())&#123;</span><br><span class="line">            ctx.writeAndFlush(<span class="string">"File not found :"</span>+f+CR);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ctx.write(f+<span class="string">" "</span>+f.length()+CR);</span><br><span class="line">        RandomAccessFile raf = <span class="keyword">new</span> RandomAccessFile(msg,<span class="string">'r'</span>);</span><br><span class="line">        FileRegion fr = <span class="keyword">new</span> DefaultFileRegion(raf,getChannel(),<span class="number">0</span>,raf.length());</span><br><span class="line">        ctx.write(region);</span><br><span class="line">        ctx.writeAndFlush(CR);</span><br><span class="line">        raf.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="私有协议栈开发"><a href="#私有协议栈开发" class="headerlink" title="私有协议栈开发"></a>私有协议栈开发</h2><p>&emsp;&emsp;通信协议从广义上区分，可以分为共有协议和私有协议。由于私有协议的灵活性，它往往会在某个公司或组织内部使用，按需定制。绝大数私有协议传输层都是基于TCP/IP，所以利用Netty的NIO TCP协议栈可以非常方便的进行私有协议的定制和开发。</p><h3 id="私有协议介绍"><a href="#私有协议介绍" class="headerlink" title="私有协议介绍"></a>私有协议介绍</h3><p>&emsp;&emsp;传统中的Java应用中，通常使用以下四种方式进行跨界点调用</p><ul><li>通过RMI进行远程服务调用</li><li>通过java的socket+java序列化的方式进行扩节点调用</li><li>利用一些开源的RPC，例如Thrift,Avro</li><li>利用标准的共有协议进行调用，例如Http+XML、RestFull+JSON</li></ul><h3 id="Netty协议栈功能设计"><a href="#Netty协议栈功能设计" class="headerlink" title="Netty协议栈功能设计"></a>Netty协议栈功能设计</h3><h4 id="协议栈拓扑图"><a href="#协议栈拓扑图" class="headerlink" title="协议栈拓扑图"></a>协议栈拓扑图</h4><h4 id="协议栈功能描述"><a href="#协议栈功能描述" class="headerlink" title="协议栈功能描述"></a>协议栈功能描述</h4><h4 id="通信模型"><a href="#通信模型" class="headerlink" title="通信模型"></a>通信模型</h4><h4 id="消息定义"><a href="#消息定义" class="headerlink" title="消息定义"></a>消息定义</h4><h4 id="Netty协议栈支持的字段类型"><a href="#Netty协议栈支持的字段类型" class="headerlink" title="Netty协议栈支持的字段类型"></a>Netty协议栈支持的字段类型</h4><h4 id="Netty协议栈的编码规范"><a href="#Netty协议栈的编码规范" class="headerlink" title="Netty协议栈的编码规范"></a>Netty协议栈的编码规范</h4><h4 id="链路的建立"><a href="#链路的建立" class="headerlink" title="链路的建立"></a>链路的建立</h4><h4 id="链路的关闭"><a href="#链路的关闭" class="headerlink" title="链路的关闭"></a>链路的关闭</h4><h4 id="可靠性设计"><a href="#可靠性设计" class="headerlink" title="可靠性设计"></a>可靠性设计</h4><ol><li>心跳机制</li><li>重连集资</li><li>重复登录保护</li><li>消息缓冲重发</li></ol><h4 id="安全性设计"><a href="#安全性设计" class="headerlink" title="安全性设计"></a>安全性设计</h4><p>&emsp;&emsp;安全策略</p><ul><li>IP+白名单</li><li>ASE加密的用户名+密码认证机制</li></ul><h4 id="可靠性设计-1"><a href="#可靠性设计-1" class="headerlink" title="可靠性设计"></a>可靠性设计</h4><h3 id="Netty协议栈开发"><a href="#Netty协议栈开发" class="headerlink" title="Netty协议栈开发"></a>Netty协议栈开发</h3><h1 id="源码分析篇-Netty功能介绍和源码分析"><a href="#源码分析篇-Netty功能介绍和源码分析" class="headerlink" title="源码分析篇 Netty功能介绍和源码分析"></a>源码分析篇 Netty功能介绍和源码分析</h1><h2 id="ByteBuf和相关辅助类"><a href="#ByteBuf和相关辅助类" class="headerlink" title="ByteBuf和相关辅助类"></a>ByteBuf和相关辅助类</h2><p>&emsp;&emsp;</p><h2 id="Channel和Unsafe"><a href="#Channel和Unsafe" class="headerlink" title="Channel和Unsafe"></a>Channel和Unsafe</h2><p>&emsp;&emsp;</p><h2 id="ChannelPipeline和ChannelHandler"><a href="#ChannelPipeline和ChannelHandler" class="headerlink" title="ChannelPipeline和ChannelHandler"></a>ChannelPipeline和ChannelHandler</h2><p>&emsp;&emsp;</p><h2 id="EventLoop和EventLoopGroup"><a href="#EventLoop和EventLoopGroup" class="headerlink" title="EventLoop和EventLoopGroup"></a>EventLoop和EventLoopGroup</h2><p>&emsp;&emsp;</p><h2 id="Future和Promise"><a href="#Future和Promise" class="headerlink" title="Future和Promise"></a>Future和Promise</h2><p>&emsp;&emsp;</p><h1 id="架构和行业应用篇-Netty高级特性"><a href="#架构和行业应用篇-Netty高级特性" class="headerlink" title="架构和行业应用篇 Netty高级特性"></a>架构和行业应用篇 Netty高级特性</h1><p>&emsp;&emsp;</p><h2 id="Java多线程编程在Netty中的应用"><a href="#Java多线程编程在Netty中的应用" class="headerlink" title="Java多线程编程在Netty中的应用"></a>Java多线程编程在Netty中的应用</h2><p>&emsp;&emsp;作为异步事件驱动、高性能的NIO框架，Netty代码中大量运用了Java多线程编程技巧，并发编程处理的恰当与否，将直接影响到架构的性能。</p><h3 id="Java内存模型与多线程编程"><a href="#Java内存模型与多线程编程" class="headerlink" title="Java内存模型与多线程编程"></a>Java内存模型与多线程编程</h3><h4 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h4><p>&emsp;&emsp;JVM定义了内存规范，规避了各种操作系统、虚拟机实现和硬件的内存访问差异，以确保Java程序在所有操作系统上和平台上能够实现一次编写、到处运行的效果。</p><p>&emsp;&emsp;Java内存模型的制定既要严谨，保证语义无歧义，还要尽量制定的宽松一些，运行硬件和虚拟机厂商有足够的灵活性来充分利用硬件的特性提升Java内存访问性能。</p><ol><li>工作内存和主内存</li><li>Java内存交互协议<ul><li>lock</li><li>unlock</li><li>read</li><li>write</li><li>load</li><li>store</li><li>assign</li><li>use</li></ul></li><li>java的线程 <ul><li>内核线程</li><li>用户线程</li><li>混合实现</li></ul></li></ol><h3 id="Netty的并发编程实践"><a href="#Netty的并发编程实践" class="headerlink" title="Netty的并发编程实践"></a>Netty的并发编程实践</h3><h4 id="对共享的可变数据进行正确的同步"><a href="#对共享的可变数据进行正确的同步" class="headerlink" title="对共享的可变数据进行正确的同步"></a>对共享的可变数据进行正确的同步</h4><h4 id="正确使用锁"><a href="#正确使用锁" class="headerlink" title="正确使用锁"></a>正确使用锁</h4><h4 id="volatile的正确使用"><a href="#volatile的正确使用" class="headerlink" title="volatile的正确使用"></a>volatile的正确使用</h4><p>&emsp;&emsp;volatile修饰之后，具有两种特性</p><ul><li>线程可见性</li><li>禁止指令重排</li></ul><h4 id="CAS指令和元子类"><a href="#CAS指令和元子类" class="headerlink" title="CAS指令和元子类"></a>CAS指令和元子类</h4><p>&emsp;&emsp;互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能的额外损耗，因此这种同步被称为阻塞同步，它是一种悲观的并发策略，称为悲观锁。随着硬件和操作系统指令集的发展和优化，产生了非阻塞同步，被称为乐观锁。</p><p>&emsp;&emsp;目前Java中的非阻塞同步就是CAS，基本上是通过系统操作指令来完成。</p><h4 id="线程安全类的使用"><a href="#线程安全类的使用" class="headerlink" title="线程安全类的使用"></a>线程安全类的使用</h4><p>&emsp;&emsp;在JDK1.5之后，Java平台新增了java.util.concurrent这个包，提供了一些列线程安全集合、容器和线程池，利用这些新的线程安全类极大地降低了Java多线程编程的难度，提升了开发效率。新的并发编程包中的工具可以分为</p><ul><li>线程池Executor Framework以及定时任务相关的类库，包括Timer等</li><li>并发集合，包括List、Queue、Map和Set等</li><li>新的同步器，例如读写锁ReadWriteLock等</li><li>新的原子包装类，例如AtomicInteger等</li></ul><h2 id="Netty架构剖析"><a href="#Netty架构剖析" class="headerlink" title="Netty架构剖析"></a>Netty架构剖析</h2><h3 id="Netty逻辑架构"><a href="#Netty逻辑架构" class="headerlink" title="Netty逻辑架构"></a>Netty逻辑架构</h3><ol><li>reactor通信调度层</li><li>职责链channelpipeline</li><li>业务逻辑编排层</li></ol><h3 id="关键架构质量属性"><a href="#关键架构质量属性" class="headerlink" title="关键架构质量属性"></a>关键架构质量属性</h3><ol><li>高性能</li><li>可靠性<ul><li>链路有效性检测</li><li>内存保护机制</li><li>优雅停机</li><li>可定制型</li><li>可扩展性</li></ul></li></ol><h2 id="Netty行业应用"><a href="#Netty行业应用" class="headerlink" title="Netty行业应用"></a>Netty行业应用</h2><ol><li>Dubbo</li><li>大数据领域</li><li>游戏领域</li></ol><h2 id="Netty未来展望"><a href="#Netty未来展望" class="headerlink" title="Netty未来展望"></a>Netty未来展望</h2>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Netty </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>五种加快Hive查询的方式</title>
      <link href="/2018/07/07/%E4%BA%94%E7%A7%8D%E5%8A%A0%E5%BF%ABHive%E8%BF%90%E8%A1%8C%E7%9A%84%E6%96%B9%E5%BC%8F/"/>
      <url>/2018/07/07/%E4%BA%94%E7%A7%8D%E5%8A%A0%E5%BF%ABHive%E8%BF%90%E8%A1%8C%E7%9A%84%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;作为一个工作在Hadoop领域的数据科学家，我经常使用<a href="https://github.com/apache/hive" target="_blank" rel="noopener">Apache Hive</a> 来探索数据，进行ad-hoc查询，或构建数据流。</p><a id="more"></a><p>&emsp;&emsp;直到现在，优化Hive查询的方向大部分聚焦在数据层次技术，例如分区，或分桶，或定制个性化文件格式。</p><p>&emsp;&emsp;在最近几年，围绕着Hive社区的<a href="https://zh.hortonworks.com/blog/100x-faster-hive/" target="_blank" rel="noopener">Stinger Initiative</a> 的创新驱动，Hive的查询时间有了明显的提升，这使得Hive能够在速度和尺度上较好的支持批处理和交互式查询。</p><p>&emsp;&emsp;然而，许多数据科学教依然不熟悉这些能够使Hive查询最快运行的基础技术手段和最佳实践。在本篇博文中，我展示了几种平时用到的简单技术手段来提高Hive查询的性能。</p><h2 id="使用Tez"><a href="#使用Tez" class="headerlink" title="使用Tez"></a>使用Tez</h2><p>&emsp;&emsp;Hive可以使用<a href="https://zh.hortonworks.com/apache/tez/" target="_blank" rel="noopener">Apache Tez</a> 作为执行引擎，替换传统的Map-Reduce引擎。我不会在这里细说Tez更多的详细细节，相反，我只是做一个简单的推荐：如果在你的环境中没有开启，那么可以通过如下设置在你的Hive查询中开启Tez</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.execution.engine&#x3D;tez;</span><br></pre></td></tr></table></figure><p>通过以上的设置，执行的Hive查询可以充分使用Tez的优势。</p><h2 id="使用ORCFile"><a href="#使用ORCFile" class="headerlink" title="使用ORCFile"></a>使用ORCFile</h2><p>&emsp;&emsp;Hive支持ROCFILE文件格式，一种新的表数据存储格式，其通过一些技术支持可观的查询速度提升，这些技术包括预测性下钻、压缩等技术手段。</p><p>&emsp;&emsp;对每一张表使用ORCFILE文件格式，对于Hive查询的性能提升应该是非常轻松和巨大的好处。</p><p>&emsp;&emsp;作为示例，假设两张大表A和B(存储为文本格式，这里不具体列出表中列的信息)。一个简单的查询如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">SELECT A.customerID, A.name, A.age, A.address join</span><br><span class="line"></span><br><span class="line">B.role, B.department, B.salary</span><br><span class="line"></span><br><span class="line">ON A.customerID&#x3D;B.customerID;</span><br><span class="line"></span><br><span class="line">This query may take a long time to execute since tables A and B are both stored as TEXT. Converting these tables to ORCFile format will usually reduce query time significantly:</span><br><span class="line"></span><br><span class="line">CREATE TABLE A_ORC (</span><br><span class="line"></span><br><span class="line">customerID int, name string, age int, address string</span><br><span class="line"></span><br><span class="line">) STORED AS ORC tblproperties (“orc.compress&quot; &#x3D; “SNAPPY”);</span><br><span class="line">INSERT INTO TABLE A_ORC SELECT * FROM A;</span><br><span class="line">CREATE TABLE B_ORC (</span><br><span class="line"></span><br><span class="line">customerID int, role string, salary float, department string</span><br><span class="line"></span><br><span class="line">) STORED AS ORC tblproperties (“orc.compress&quot; &#x3D; “SNAPPY”);</span><br><span class="line">INSERT INTO TABLE B_ORC SELECT * FROM B;</span><br><span class="line">SELECT A_ORC.customerID, A_ORC.name,</span><br><span class="line"></span><br><span class="line">A_ORC.age, A_ORC.address join</span><br><span class="line"></span><br><span class="line">B_ORC.role, B_ORC.department, B_ORC.salary</span><br><span class="line"></span><br><span class="line">ON A_ORC.customerID&#x3D;B_ORC.customerID;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;ORC支持压缩存储，也可以不压缩存储。如压缩存储，支持ZLIB和SNAPPY压缩格式。</p><p>&emsp;&emsp;将表格的数据存储格式更改为ORC，通常是本团队的职责。根据他们的工作排班，这通常需要花费一些时间。受众于ORCFILE的绝大好处，我通常建议将文本存储格式转化为ORC存储格式。这样的话，查询通常会有明显的速度提升，而不需要依赖其他团队。</p><h2 id="使用向量化"><a href="#使用向量化" class="headerlink" title="使用向量化"></a>使用向量化</h2><p>&emsp;&emsp;支持向量化查询，能够提升一些操作的性能，例如扫描、聚合、过滤和join操作。通过一次1000条的批处理，替代每次一条的处理方式。</p><p>&emsp;&emsp;Hive0.13引入了向量化支持，这个特性显著地提升了查询的执行时间，并且该特性能够方便的通过以下两个参数设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.vectorized.execution.enabled&#x3D;true;</span><br><span class="line">set hive.vectorized.execution.reduce.enable&#x3D;true;</span><br></pre></td></tr></table></figure><h2 id="基于代价的优化：CBO"><a href="#基于代价的优化：CBO" class="headerlink" title="基于代价的优化：CBO"></a>基于代价的优化：CBO</h2><p>&emsp;&emsp;Hive在最终执行之前，会进行查询语句的逻辑优化和物理执行计划的优化。这些优化并不是基于CBO的，直到现在。</p><p>&emsp;&emsp;最近，CBO被加入到Hive中，基于代价优化能够进一步优化性能，导致了一些潜在的不同选择：如何组织join，什么类型的join可以优化，不支持并行化处理等等。</p><p>&emsp;&emsp;使用CDO优化，在查询之前设置一下参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set hive.cbo.enable&#x3D;true;</span><br><span class="line">set hive.compute.query.using.stats&#x3D;true;</span><br><span class="line">set hive.stats.fetch.column.stats&#x3D;true;</span><br><span class="line">set hive.stats.fetch.partition.stats&#x3D;true;</span><br></pre></td></tr></table></figure><p>这些设置之后，通过运行Hive的analyze能够收集CDO优化目标的多种统计参数。</p><h2 id="使用好SQL"><a href="#使用好SQL" class="headerlink" title="使用好SQL"></a>使用好SQL</h2><p>&emsp;&emsp;SQL是一种非常强大的声明式语言。像其他声明式语言，存在不止一种写SQL语句的方式。虽然语句的功能相同，但可能存在多种不同的表达式。</p><p>&emsp;&emsp;作为一个示例，考虑如下表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE clicks (</span><br><span class="line">timestamp date, sessionID string, url string, source_ip string</span><br><span class="line">) STORED as ORC tblproperties (“orc.compress” &#x3D; “SNAPPY”);</span><br><span class="line">Each record represents a click event, and we would like to find the latest URL for each sessionID;</span><br></pre></td></tr></table></figure><p>通过如下方式同样可以实现该功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT clicks.* FROM clicks inner join</span><br><span class="line">(select sessionID, max(timestamp) as max_ts from clicks</span><br><span class="line">group by sessionID) latest</span><br><span class="line">ON clicks.sessionID &#x3D; latest.sessionID and</span><br><span class="line">clicks.timestamp &#x3D; latest.max_ts;</span><br></pre></td></tr></table></figure><p>以上查询，我们构建了一个子查询来收集每个session中最近事件的时间戳，并使用一个inner join来关联过滤外部的结果。</p><p>&emsp;&emsp;虽然这种一种从功能性上考虑的实现方式，实际上还存在更佳的实现方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM</span><br><span class="line">(SELECT *, RANK() over (partition by sessionID,</span><br><span class="line">order by timestamp desc) as rank</span><br><span class="line">FROM clicks) ranked_clicks</span><br><span class="line">WHERE ranked_clicks.rank&#x3D;1;</span><br></pre></td></tr></table></figure><p>这里使用了OLAP函数(over，rank)来达到同样的功能，而不适用join。</p><p>&emsp;&emsp;显然移除了非必要的join操作几乎导致更好的表现性能，并当数据量较大时，这种性能差异更大。通常，许多查询语句并不是最优的，因此需要仔细查看每一个SQL语句，是不是存在优化空间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&emsp;&emsp;Apache Hive是数据分析师、数据科学家手中强大的工具，并支持批处理和实时交互查询。</p><p>&emsp;&emsp;在本博文中，我讨论了一些有用的技巧来提升Hive查询的性能，这些技巧都是我日常工作中常用到的。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive相关的两个疑问</title>
      <link href="/2018/07/05/Hive%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%A4%E4%B8%AA%E7%96%91%E9%97%AE/"/>
      <url>/2018/07/05/Hive%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%A4%E4%B8%AA%E7%96%91%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="0-问题引出"><a href="#0-问题引出" class="headerlink" title="0. 问题引出"></a>0. 问题引出</h2><p>&emsp;&emsp;从疑问出发，寻根问底探究原理：</p><ol><li>Hive CLI/Hive Beeline/Hive JDBC断开连接之后，运行在Yarn上的任务是否继续运行？</li><li>我们知道JDBC是无法做缓存的，那么HUE是如何改善查询速度的？</li></ol><a id="more"></a><p>&emsp;&emsp;本部分研究第一个问题，即客户端的状态是否影响Yarn上正在运行的任务。</p><p>&emsp;&emsp;首先我们从现象谈起然后逐渐找到问题的答案，既是一个解疑的过程也是一个探究研究问题思路的过程，更是一个增长知识的过程。</p><h2 id="1-现象描述"><a href="#1-现象描述" class="headerlink" title="1. 现象描述"></a>1. 现象描述</h2><p>&emsp;&emsp;在Hadoop生态中执行Hive任务时，经常会出现各种各样的问题。今天发现了一个特别有意思的事情，执行调度的同学说他们执行的任务，在beeline调用端任务失败，但业务同学去数据库查看相应的数据记录，初步发现没有异常同步成功。这就引起了一个问题：当beeline异常断开时，当前运行的yarn的任务是否同步退出？还是继续执行完成？</p><p>&emsp;&emsp;根据这个问题，我首先做了现象的重现，结果发现：断开连接之后，执行在yarn上的任务会同步结束。分别通过HIVE CLI、Beeline、JDBC三种方式做得测试，结果都表明断开连接之后，任务无法接续运行。除了一种情况那就是HIVE CLI模式下，直接通过KILL命令杀死Hive进程，Hive客户端的JVM直接退出，但正在Yarn上运行的任务未退出继续运行，直到结束。</p><h2 id="2-三种访问Hive的路径"><a href="#2-三种访问Hive的路径" class="headerlink" title="2. 三种访问Hive的路径"></a>2. 三种访问Hive的路径</h2><p><img src="/.io//001.png" alt="Hive的三种访问方式"><br>其中Hive Beeline使用的也是Thrift API访问Hive，其基本原理与JDBC访问类似。</p><h2 id="3-寻根问底"><a href="#3-寻根问底" class="headerlink" title="3. 寻根问底"></a>3. 寻根问底</h2><h3 id="3-1-Hive-CLI"><a href="#3-1-Hive-CLI" class="headerlink" title="3.1. Hive CLI"></a>3.1. Hive CLI</h3><ol><li><p>主要类：<strong>org.apache.hadoop.hive.cli.CliDriver</strong></p></li><li><p>ctrl+c方式断开：<br>CliDriver注册了信号处理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> interruptRequested;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(Signal signal)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> initialRequest = !interruptRequested;</span><br><span class="line">  interruptRequested = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Kill the VM on second ctrl+c</span></span><br><span class="line">  <span class="keyword">if</span> (!initialRequest) &#123;</span><br><span class="line">    console.printInfo(<span class="string">"Exiting the JVM"</span>);</span><br><span class="line">    System.exit(<span class="number">127</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Interrupt the CLI thread to stop the current statement and return to prompt</span></span><br><span class="line">  console.printInfo(<span class="string">"Interrupting... Be patient, this might take some time."</span>);</span><br><span class="line">  console.printInfo(<span class="string">"Press Ctrl+C again to kill JVM"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// First, kill any running MR jobs</span></span><br><span class="line">  HadoopJobExecHelper.killRunningJobs();</span><br><span class="line">  TezJobExecHelper.killRunningJobs();</span><br><span class="line">  HiveInterruptUtils.interrupt();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;通过以上的源码可以看出，如果我们使用 <strong>ctrl+c</strong> 命令会触发Kill操作，依次处理了 <strong>HadoopJob</strong> 、<strong>TezJob</strong> 以及Hive的退出操作；如果前后两次使用 <strong>ctrl+c</strong> 命令，那么直接Kill JVM。</p></li><li><p>直接Kill -9方式退出Hive：针对Yarn MR任务模式，对于LocalMRJob不做讨论。<br>通过阅读源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmd_trimmed.startsWith(<span class="string">"!"</span>)) &#123;</span><br><span class="line"></span><br><span class="line">String shell_cmd = cmd_trimmed.substring(<span class="number">1</span>);</span><br><span class="line">shell_cmd = <span class="keyword">new</span> VariableSubstitution(<span class="keyword">new</span> HiveVariableSource() &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Map&lt;String, String&gt; <span class="title">getHiveVariable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> SessionState.get().getHiveVariables();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;).substitute(ss.getConf(), shell_cmd);</span><br><span class="line"></span><br><span class="line"><span class="comment">// shell_cmd = "/bin/bash -c \'" + shell_cmd + "\'";</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  ShellCmdExecutor executor = <span class="keyword">new</span> ShellCmdExecutor(shell_cmd, ss.out, ss.err);</span><br><span class="line">  ret = executor.execute();</span><br><span class="line">  <span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line">    console.printError(<span class="string">"Command failed with exit code = "</span> + ret);</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">  console.printError(<span class="string">"Exception raised from Shell command "</span> + e.getLocalizedMessage(),</span><br><span class="line">    stringifyException(e));</span><br><span class="line">  ret = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"> &#125;  <span class="keyword">else</span> &#123; <span class="comment">// local mode</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;可以看出CliDriver对于命令的处理是通过 <strong>调用外部线程</strong> 进行的。如果直接结束JVM，那么外部线程没有影响继续运行，所以我们看到的表象就是任务继续运行知道运行结束。</p></li></ol><h3 id="3-2-Beeline"><a href="#3-2-Beeline" class="headerlink" title="3.2. Beeline"></a>3.2. Beeline</h3><ol><li><p>访问主类： <strong>org.apache.hive.beeline.BeeLine</strong></p></li><li><p>通过ctrl+c方式断开：通过ctrl+c方式断开连接，Hive会捕捉到相应的信号，从而进行相关处理。信号处理的handler定义如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">## Apache Hive： Beeline</span><br><span class="line">  <span class="keyword">private</span> Statement stmt = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  SunSignalHandler () &#123;</span><br><span class="line">    <span class="comment">// Interpret Ctrl+C as a request to cancel the currently</span></span><br><span class="line">    <span class="comment">// executing query.</span></span><br><span class="line">    Signal.handle (<span class="keyword">new</span> Signal (<span class="string">"INT"</span>), <span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStatement</span><span class="params">(Statement stmt)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.stmt = stmt;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span> <span class="params">(Signal signal)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (stmt != <span class="keyword">null</span>) &#123;</span><br><span class="line">        stmt.cancel();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException ex) &#123;</span><br><span class="line">      <span class="comment">// ignore</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>从处理的代码中可以看出，如果出现 <strong>ctrl+c</strong> 信号，Hive会取消目前相关操作。</p></li><li><p>异常断开：包括超时、宕机等异常情况<br>如果是Thrift RPC的连接断开，那么从源码中可以看出</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HIVE_SERVER2_CLOSE_SESSION_ON_DISCONNECT(<span class="string">"hive.server2.close.session.on.disconnect"</span>, <span class="keyword">true</span>,</span><br><span class="line">      <span class="string">"Session will be closed when connection is closed. Set this to false to have session outlive its parent connection."</span>)</span><br></pre></td></tr></table></figure><p>如果connection断开，那么session会立马被关闭，进而HiveServer2关闭session的操作，如下所示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">## ThriftBinaryCLIService</span><br><span class="line">ThriftCLIServerContext context = (ThriftCLIServerContext) serverContext;</span><br><span class="line">SessionHandle sessionHandle = context.getSessionHandle();</span><br><span class="line"><span class="keyword">if</span> (sessionHandle != <span class="keyword">null</span>) &#123;</span><br><span class="line">  LOG.info(<span class="string">"Session disconnected without closing properly. "</span>);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">boolean</span> close = cliService.getSessionManager().getSession(sessionHandle).getHiveConf()</span><br><span class="line">      .getBoolVar(ConfVars.HIVE_SERVER2_CLOSE_SESSION_ON_DISCONNECT);</span><br><span class="line">    LOG.info((close ? <span class="string">""</span> : <span class="string">"Not "</span>) + <span class="string">"Closing the session: "</span> + sessionHandle);</span><br><span class="line">    <span class="keyword">if</span> (close) &#123;</span><br><span class="line">      cliService.closeSession(sessionHandle);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (HiveSQLException e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Failed to close session: "</span> + e, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此处cliService的关闭最终会导致 <strong>HiveSessionImpl</strong> 的关闭操作，其中关闭路径为：<strong>CLIService.closeSession–&gt;SessionManager.closeSession–&gt; HiveSession.close</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">## HiveSessionImpl</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">      acquire(<span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line">      <span class="comment">// Iterate through the opHandles and close their operations</span></span><br><span class="line">      List&lt;OperationHandle&gt; ops = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">synchronized</span> (opHandleSet) &#123;</span><br><span class="line">        ops = <span class="keyword">new</span> ArrayList&lt;&gt;(opHandleSet);</span><br><span class="line">        opHandleSet.clear();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">for</span> (OperationHandle opHandle : ops) &#123;</span><br><span class="line">        operationManager.closeOperation(opHandle);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Cleanup session log directory.</span></span><br><span class="line">      cleanupSessionLogDir();</span><br><span class="line">      HiveHistory hiveHist = sessionState.getHiveHistory();</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">null</span> != hiveHist) &#123;</span><br><span class="line">        hiveHist.closeStream();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        sessionState.resetThreadName();</span><br><span class="line">        sessionState.close();</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        sessionState = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> HiveSQLException(<span class="string">"Failure to close"</span>, ioe);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (sessionState != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          sessionState.resetThreadName();</span><br><span class="line">          sessionState.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">          LOG.warn(<span class="string">"Error closing session"</span>, t);</span><br><span class="line">        &#125;</span><br><span class="line">        sessionState = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (sessionHive != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          Hive.closeCurrent();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">          LOG.warn(<span class="string">"Error closing sessionHive"</span>, t);</span><br><span class="line">        &#125;</span><br><span class="line">        sessionHive = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      release(<span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>从这里可以看到Session通过迭代将所有的操作逐渐关闭，并清除Session相关日志、关闭任务历史日志流。</p></li></ol><h3 id="3-3-Hive-JDBC"><a href="#3-3-Hive-JDBC" class="headerlink" title="3.3. Hive JDBC"></a>3.3. Hive JDBC</h3><ol><li>访问主类：<strong>org.apache.hive.jdbc.HiveDriver</strong></li><li>通过ctrl+c方式断开/异常断开<br>&emsp;&emsp;对于<em>Hive JDBC</em>这种连接方式而言，不存在ctrl+c直接断开RPC连接这种说法。我们通过程序测试的话，ctrl+c直接退出或kill的是我们的程序[JVM]，断开程序之后session连接自然断开。<br>&emsp;&emsp;这里的处理方式如<em>Beeline</em>类似，同样是<em>HiveServer2</em>通过session来管理任务的退出。</li></ol><h3 id="3-4-Thrift概述"><a href="#3-4-Thrift概述" class="headerlink" title="3.4 Thrift概述"></a>3.4 Thrift概述</h3><p>&emsp;&emsp;Thrift是由Facebook提出的一种RPC/序列化框架贡献给了Apache，主要包括了代码生成机制、Protocol定义与传输、Server服务层等。</p><h4 id="3-4-1-主要组成"><a href="#3-4-1-主要组成" class="headerlink" title="3.4.1 主要组成"></a>3.4.1 主要组成</h4><ul><li>TProtocol : 数据编码解码，主要包括TBinaryProtocol、TJSONProtocol、TCompactProtocol[密集压缩]、TDebugProtocol[用户易读的方式]]]</li><li>TTransport : 数据传输，主要类型包括TFileTransport、THttpTransport、TSocket、TZlibTransport【TBufferedTransport、TFramedTransport、TMemoryBuffer】</li><li>TServer : 服务类，主要有TSimpleServer、TThreadPoolServer[标准阻塞式IO的多线程服务器]、TNonblockingServer[费阻塞多线程模式]</li><li>TProcessor : 负责调度用户定义的接口</li></ul><h4 id="3-4-2-Thrift架构"><a href="#3-4-2-Thrift架构" class="headerlink" title="3.4.2 Thrift架构"></a>3.4.2 Thrift架构</h4><p><img src="/.io//002.jpg" alt="Thrift架构"></p><h2 id="4-问题是否解决"><a href="#4-问题是否解决" class="headerlink" title="4. 问题是否解决"></a>4. 问题是否解决</h2><p>&emsp;&emsp;通过以上分析可以得出结论：</p><ol><li>Hive Cli模式下，直接<em>Kill -9</em>结束当前的Hive进程，是无法让运行在Yarn上的任务退出，原因在于实际执行任务的<strong>另有其人</strong>；</li><li>使用Beeline或JDBC连接Hive时，可以设置<strong>hive.server2.close.session.on.disconnect=false</strong>来阻止session的关闭操作[<em>未测试</em>]；</li></ol><p>&emsp;&emsp;我们基本获知了Hive通过几种方式访问集群资源时，访问的方式、驱动主类、程序退出资源释放的流程等内容。因此，以上的分析基本上解答了我们的问题。即除了<em>Hive CLI</em>方式通过[<em>Kill -9</em>]直接退出JVM之外，其他情况基本上都会停止Yarn任务的运行。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chromeheadless安装与使用</title>
      <link href="/2018/07/01/Chromeheadless%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/07/01/Chromeheadless%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;如果是小规模爬虫或模拟效果要求不高的话，使用Selenium HtmlUniDriver基本可以满足需求。但HtmlUnitDriver是基于JS模拟浏览器原理，存在许多浏览器可以做，但它其实无法操作的功能，比如截图等高级功能。</p><a id="more"></a><p>&emsp;&emsp;之前爬虫使用Phantomjs，感觉效果还不错，而且使用方便。Phantomjs可以设置远程模式，方便本地调试；方便设置代理，但这里有一个坑，就是<em>代理地址不能是https协议</em>，不然会出问题。但Phantomjs已经目前已经停止更新与维护，而且Google Chrome推出了Headless版本，使用浏览器模式更加符合真是的环境。</p><h2 id="安装采坑"><a href="#安装采坑" class="headerlink" title="安装采坑"></a>安装采坑</h2><p>&emsp;&emsp;Chrome Headless安装没有想象中的简单。刚开始直接通过安装包或添加Chrome源安装均失败，失败的原因是存在各种各样的依赖包。后来找到的Chrome安装的一个脚本，使用这个脚本能够不断地安装缺少的依赖包，从而能够安航成功。</p><h3 id="安装系统"><a href="#安装系统" class="headerlink" title="安装系统"></a>安装系统</h3><p>Centos6.9Final</p><h3 id="安装方式一-通过添加chrome源来安装chrome"><a href="#安装方式一-通过添加chrome源来安装chrome" class="headerlink" title="安装方式一:通过添加chrome源来安装chrome"></a>安装方式一:通过添加chrome源来安装chrome</h3><figure class="highlight plain"><figcaption><span>添加</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">## 添加Chrome源</span><br><span class="line">[google]</span><br><span class="line">name&#x3D;Google – i386</span><br><span class="line">baseurl&#x3D;http:&#x2F;&#x2F;dl.google.com&#x2F;linux&#x2F;rpm&#x2F;stable&#x2F;i386</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;dl-ssl.google.com&#x2F;linux&#x2F;linux_signing_key.pub</span><br><span class="line"></span><br><span class="line">64位系统：</span><br><span class="line">[google64]</span><br><span class="line">name&#x3D;Google – x86_64</span><br><span class="line">baseurl&#x3D;http:&#x2F;&#x2F;dl.google.com&#x2F;linux&#x2F;rpm&#x2F;stable&#x2F;x86_64</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;dl-ssl.google.com&#x2F;linux&#x2F;linux_signing_key.pub</span><br><span class="line"></span><br><span class="line">## 安装</span><br><span class="line">1.sudo yum install google-chrome-stable 来安装最新稳定版</span><br><span class="line">2.sudo yum install google-chrome-unstable 最新版chrome</span><br></pre></td></tr></table></figure><p>这里有个问题，可能博主使用的Centos环境有问题。通过此方式安装之后存在各种依赖问题，导致无法安装成功。</p><h3 id="安装方式二：下载安装"><a href="#安装方式二：下载安装" class="headerlink" title="安装方式二：下载安装"></a>安装方式二：下载安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## Ubuntu系统安装，此方通过修改URL路径，适用于Centos</span><br><span class="line">sudo apt-get install libxss1 libappindicator1 libindicator7</span><br><span class="line">wget https:&#x2F;&#x2F;dl.google.com&#x2F;linux&#x2F;direct&#x2F;google-chrome-stable_current_amd64.deb</span><br><span class="line">sudo dpkg -i google-chrome-stable_current_amd64.deb</span><br><span class="line">sudo apt-get install -f</span><br></pre></td></tr></table></figure><p>跟上面一种方式一样， 存在各种依赖问题，导致无法安装成功。</p><h3 id="使用脚本安装"><a href="#使用脚本安装" class="headerlink" title="使用脚本安装"></a>使用脚本安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https:&#x2F;&#x2F;intoli.com&#x2F;install-google-chrome.sh | bash</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;通过上网查阅发现<a href="https://intoli.com这个网站是专门从事headless" target="_blank" rel="noopener">https://intoli.com这个网站是专门从事headless</a> browsers使用简化，提供云服务的一家公司。其中在该公司的博客中，可以看到许多关于Google Chrome的文章。</p><p>&emsp;&emsp;该公司提供的这个脚本，能够自动查找相关依赖，并安装。这样我们就不必担心依赖问题，导致无法安装成功。</p><h2 id="使用进阶"><a href="#使用进阶" class="headerlink" title="使用进阶"></a>使用进阶</h2><p>&emsp;&emsp;安装Chrome Headless之后，就可以直接使用了。不过这里有一个注意的点，那就是需要安装ChromeDriver这个东东。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## 下载</span><br><span class="line">wget https:&#x2F;&#x2F;chromedriver.storage.googleapis.com&#x2F;2.40&#x2F;chromedriver_linux64.zip</span><br><span class="line"></span><br><span class="line">## 解压</span><br><span class="line">tar xvf chromedriver_linux64.zip</span><br><span class="line"></span><br><span class="line">## 权限</span><br><span class="line">chmod 755 chromedriver</span><br></pre></td></tr></table></figure><h3 id="初级使用"><a href="#初级使用" class="headerlink" title="初级使用"></a>初级使用</h3><p>&emsp;&emsp;初级使用的目标是可以运行起来，不报错，能够完成预期的目标。<br>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;**</span><br><span class="line"> * @desc main method</span><br><span class="line"> * @param args</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static void main(String[] args) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">       String driverPath &#x3D; &quot;&#x2F;root&#x2F;chrome&#x2F;chromedriver&quot;;</span><br><span class="line">       String targetURL &#x3D; &quot;&quot;;</span><br><span class="line"></span><br><span class="line">System.setProperty(&quot;webdriver.chrome.driver&quot;, driverPath);</span><br><span class="line">ChromeDriver driver &#x3D; getDriver();</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 对网页内容作处理</span><br><span class="line">       Document doc &#x3D; getDocument(targetURL);</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 如果对网页做操作，直接使用Driver</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @desc get chrome driver</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static ChromeDriver getDriver() &#123;</span><br><span class="line"></span><br><span class="line">String userAgent &#x3D; AppForum.getAgents();</span><br><span class="line">ChromeOptions options &#x3D; new ChromeOptions();</span><br><span class="line">options.setBinary(&quot;&#x2F;usr&#x2F;bin&#x2F;google-chrome-stable&quot;);</span><br><span class="line">options.addArguments(&quot;--no-sandbox&quot;, &quot;--test-type&quot;，&quot;--headless&quot;, &quot;--disable-gpu&quot;);</span><br><span class="line"></span><br><span class="line">DesiredCapabilities capabilities &#x3D; DesiredCapabilities.chrome();</span><br><span class="line">capabilities.setCapability(ChromeOptions.CAPABILITY, options);</span><br><span class="line">capabilities.setJavascriptEnabled(true);</span><br><span class="line"></span><br><span class="line">ChromeDriver driver &#x3D; new ChromeDriver(capabilities);</span><br><span class="line">driver.manage().timeouts().setScriptTimeout(5, TimeUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">return driver;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @desc crawler html content</span><br><span class="line"> * @param url</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Document getDocument(String url) &#123;</span><br><span class="line"></span><br><span class="line">ChromeDriver driver &#x3D; getDriver();</span><br><span class="line">Document doc &#x3D; null;</span><br><span class="line">try &#123;</span><br><span class="line">driver.get(url);</span><br><span class="line">doc &#x3D; Jsoup.parse(driver.getPageSource());</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">try &#123;</span><br><span class="line">driver.quit();</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return doc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="中阶使用"><a href="#中阶使用" class="headerlink" title="中阶使用"></a>中阶使用</h3><p>中阶也即提高级，主要区别是开发研究一些重要的功能，比如时候网速、加载速度等内容</p><ol><li>禁止图片加载</li><li>等待加载</li><li>使用UserAgent代理</li><li>禁止一些选项的加载</li><li>使用Driver执行特定JS等</li></ol><p>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">   &#x2F;**</span><br><span class="line"> * @desc main method</span><br><span class="line"> * @param args</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static void main(String[] args) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">       String driverPath &#x3D; &quot;&#x2F;root&#x2F;chrome&#x2F;chromedriver&quot;;</span><br><span class="line">       String targetURL &#x3D; &quot;&quot;;</span><br><span class="line"></span><br><span class="line">System.setProperty(&quot;webdriver.chrome.driver&quot;, driverPath);</span><br><span class="line">ChromeDriver driver &#x3D; getDriver();</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 对网页内容作处理</span><br><span class="line">       Document doc &#x3D; getDocument(targetURL);</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 如果对网页做操作，直接使用Driver</span><br><span class="line">       &#x2F;&#x2F; 执行JS：滚动效果</span><br><span class="line">       driver.executeScript(&quot;scrollTo(0,10000)&quot;);</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 等待加载示例</span><br><span class="line">       &#x2F;&#x2F; 1. 超时加载等待</span><br><span class="line">       driver.manage().timeouts().implicitlyWait(20, TimeUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">       &#x2F;&#x2F; 2. 等待加载组件</span><br><span class="line">       WebDriverWait wait &#x3D; new WebDriverWait(driver, 20);</span><br><span class="line">       wait.until(ExpectedConditions.presenceOfElementLocated(By.cssSelector(&quot;.red_box&quot;)));</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @desc get chrome driver</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static ChromeDriver getDriver() &#123;</span><br><span class="line"></span><br><span class="line">HashMap&lt;String, Object&gt; prefs &#x3D; new HashMap&lt;String, Object&gt;();</span><br><span class="line">prefs.put(&quot;profile.default_content_settings&quot;, 2);</span><br><span class="line">prefs.put(&quot;profile.default_content_setting_values&quot;, 2);</span><br><span class="line">prefs.put(&quot;profile.managed_default_content_settings.images&quot;, 2);</span><br><span class="line"></span><br><span class="line">String userAgent &#x3D; AppForum.getAgents();</span><br><span class="line">ChromeOptions options &#x3D; new ChromeOptions();</span><br><span class="line">options.setBinary(&quot;&#x2F;usr&#x2F;bin&#x2F;google-chrome-stable&quot;);</span><br><span class="line">options.setExperimentalOption(&quot;prefs&quot;, prefs);</span><br><span class="line">options.addArguments(&quot;--user-agent&#x3D;&quot; + userAgent，&quot;--no-sandbox&quot;, &quot;--test-type&quot;);</span><br><span class="line">options.addArguments(&quot;--disable-infobars&quot;, &quot;--headless&quot;, &quot;--disable-gpu&quot;，&quot;--enable-strict-powerful-feature-restrictions&quot;);</span><br><span class="line">options.addArguments(&quot;--disable-plugins&quot;, &quot;--disable-images&quot;, &quot;--start-maximized&quot;);</span><br><span class="line"></span><br><span class="line">DesiredCapabilities capabilities &#x3D; DesiredCapabilities.chrome();</span><br><span class="line">capabilities.setCapability(ChromeOptions.CAPABILITY, options);</span><br><span class="line">capabilities.setJavascriptEnabled(true);</span><br><span class="line"></span><br><span class="line">return new ChromeDriver(capabilities);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @desc crawler html content</span><br><span class="line"> * @param url</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Document getDocument(String url) &#123;</span><br><span class="line"></span><br><span class="line">ChromeDriver driver &#x3D; getDriver();</span><br><span class="line">Document doc &#x3D; null;</span><br><span class="line">try &#123;</span><br><span class="line">driver.get(url);</span><br><span class="line">doc &#x3D; Jsoup.parse(driver.getPageSource());</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">&#125; finally &#123;</span><br><span class="line">try &#123;</span><br><span class="line">driver.quit();</span><br><span class="line">driver.close();</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return doc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="高级使用"><a href="#高级使用" class="headerlink" title="高级使用"></a>高级使用</h3><h4 id="设置代理服务器"><a href="#设置代理服务器" class="headerlink" title="设置代理服务器"></a>设置代理服务器</h4><p>&emsp;&emsp;代理服务器的设置，可以参考Google-chrome的帮助信息，在代码层面很容易实现。</p><p><img src="/.io//001.png" alt="Google-chrome帮助信息"></p><h4 id="Driver生命周期"><a href="#Driver生命周期" class="headerlink" title="Driver生命周期"></a>Driver生命周期</h4><p>&emsp;&emsp;在我们的代码中“new ChromeDriver()”的时候，产生了多个外部进程，如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root      8508  8499  1 04:26 ?        00:00:01 &#x2F;usr&#x2F;bin&#x2F;google-chrome-stable --disable-background-networking --disable-client-side-phishing-detection --disable-default-apps --disable-gpu --disable-hang-monitor --disable-images --disable-infobars --disable-plugins --disable-popup-blocking --disable-prompt-on-repost --disable-sync --disable-web-resources --enable-automation --enable-logging --enable-strict-powerful-feature-restrictions --force-fieldtrials&#x3D;SiteIsolationExtensions&#x2F;Control --headless --ignore-certificate-errors --load-extension&#x3D;&#x2F;tmp&#x2F;.org.chromium.Chromium.7tAd3h&#x2F;internal --log-level&#x3D;0 --metrics-recording-only --no-first-run --no-sandbox --password-store&#x3D;basic --remote-debugging-port&#x3D;0 --start-maximized --test-type --use-mock-keychain --user-agent&#x3D;Mozilla&#x2F;4.0 (compatible;MSIE7.0;WindowsNT5.1;Trident&#x2F;4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0) --user-data-dir&#x3D;&#x2F;tmp&#x2F;.org.chromium.Chromium.4Sd7ob data:,</span><br><span class="line">root      8515  8508  0 04:26 ?        00:00:00 &#x2F;opt&#x2F;google&#x2F;chrome&#x2F;chrome --type&#x3D;zygote --no-sandbox --enable-logging --headless --log-level&#x3D;0 --headless --user-agent&#x3D;Mozilla&#x2F;4.0 (compatible;MSIE7.0;WindowsNT5.1;Trident&#x2F;4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0) --enable-crash-reporter</span><br><span class="line">root      8539  8508  0 04:26 ?        00:00:00 &#x2F;opt&#x2F;google&#x2F;chrome&#x2F;chrome --type&#x3D;gpu-process --enable-logging --headless --log-level&#x3D;0 --no-sandbox --headless --user-agent&#x3D;Mozilla&#x2F;4.0 (compatible;MSIE7.0;WindowsNT5.1;Trident&#x2F;4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0) --enable-crash-reporter --gpu-preferences&#x3D;KAAAAAAAAACAAACAAQAAAAAAAAAAAGAAEAAAAAAAAAAAAAAAAAAAAAgAAAAAAAAA --use-gl&#x3D;swiftshader-webgl --override-use-software-gl-for-tests --headless --user-agent&#x3D;Mozilla&#x2F;4.0 (compatible;MSIE7.0;WindowsNT5.1;Trident&#x2F;4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0) --enable-crash-reporter --enable-logging --log-level&#x3D;0 --service-request-channel-token&#x3D;84633B7AB3844DE44C0ADE5922EAFCB4</span><br><span class="line">root      8551  8515  9 04:26 ?        00:00:12 &#x2F;opt&#x2F;google&#x2F;chrome&#x2F;chrome --type&#x3D;renderer --enable-automation --enable-logging --log-level&#x3D;0 --no-sandbox --test-type --use-gl&#x3D;swiftshader-webgl --disable-gpu-compositing --service-pipe-token&#x3D;0D2C2CC1CF67A5903FDFECE210FEB597 --lang&#x3D;en-US --headless --user-agent&#x3D;Mozilla&#x2F;4.0 (compatible;MSIE7.0;WindowsNT5.1;Trident&#x2F;4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0) --enable-crash-reporter --num-raster-threads&#x3D;1 --service-request-channel-token&#x3D;0D2C2CC1CF67A5903FDFECE210FEB597 --renderer-client-id&#x3D;4 --shared-files&#x3D;v8_context_snapshot_data:100,v8_natives_data:101</span><br></pre></td></tr></table></figure><p>可以看出其中只有一个Google-chrome浏览器的进程，其余三个是对应ChromeDriver的进程。这些进程实际上是通过系统层面来管理，我们的程序无法直接去操作进程的状态，比如Kill/Shutdown等，因此需要格外主要这些进程的生命周期。</p><p>&emsp;&emsp;如果我们的程序正常退出或意外推出了，这些进程有可能还存在于系统当中，占有一定资源，一般来说这些进程占有的资源从50MB-300MB之间，甚至更多。保留在系统中的这些进程，最终会成为”僵尸”进程，不退出也不释放资源。</p><p>&emsp;&emsp;一种简单粗暴的做法是，在系统中启动一个crontab任务，定期清理超过一定时间的chrome进程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">## 执行脚本：这里设置的阈值为5分钟</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">## check PID&#39;s process time</span><br><span class="line"></span><br><span class="line">function show_elapsed_time()</span><br><span class="line">&#123;</span><br><span class="line"> user_hz&#x3D;$(getconf CLK_TCK)</span><br><span class="line"> pid&#x3D;$1</span><br><span class="line"> jiffies&#x3D;$(cat &#x2F;proc&#x2F;$pid&#x2F;stat | cut -d&quot; &quot; -f22)</span><br><span class="line"> sys_uptime&#x3D;$(cat &#x2F;proc&#x2F;uptime | cut -d&quot; &quot; -f1)</span><br><span class="line"> last_time&#x3D;$(( $&#123;sys_uptime%.*&#125; - $jiffies&#x2F;$user_hz ))</span><br><span class="line"> if [ $last_time -gt 600 ] ; then</span><br><span class="line">echo &quot;kill process : $pid&quot;</span><br><span class="line">kill -9 $pid</span><br><span class="line"> fi</span><br><span class="line"> echo &quot;the process $pid lasts for $last_time seconds.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &#96;date &quot;+%Y-%m-%d %H:%M:%S&quot;&#96;</span><br><span class="line">for item in &#96;ps -ef | grep &quot;google-chrome&quot; | grep -v grep | awk &#39;&#123;print $2&#125;&#39; &#96;;</span><br><span class="line">do</span><br><span class="line">echo &quot;PID: $item&quot;</span><br><span class="line">show_elapsed_time $item</span><br><span class="line">done;</span><br><span class="line"></span><br><span class="line">## crontab命令</span><br><span class="line">*&#x2F;1 * * * * sh &#x2F;root&#x2F;chrome&#x2F;check.sh &gt;&gt; &#x2F;root&#x2F;chrome&#x2F;logs.txt</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;如果是正常退出，或者能够检测到ShutdownHook，可以在ShutdownHook里面全部Kill外部的Chrome进程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Runtime.getRuntime.addShutdownHook(new Thread()&#123;</span><br><span class="line">    public void run()&#123;</span><br><span class="line">        &#x2F;&#x2F; 执行脚本，获取外部Chrome进程PID</span><br><span class="line">        &#x2F;&#x2F; 通过PID，KILL进程</span><br><span class="line">        &#x2F;&#x2F; 这里需要用到JNA：</span><br><span class="line">        &#x2F;&#x2F;&lt;dependency&gt;</span><br><span class="line">        &#x2F;&#x2F;&lt;groupId&gt;net.java.dev.jna&lt;&#x2F;groupId&gt;</span><br><span class="line">        &#x2F;&#x2F;&lt;artifactId&gt;jna&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &#x2F;&#x2F;&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Tab使用"><a href="#Tab使用" class="headerlink" title="Tab使用"></a>Tab使用</h4><p>&emsp;&emsp;这里还有一个优化的点就是，是不是考虑使用tab标签页来完成每个URL，不需要每次都产生一个Chrome对象，减少程序开支。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 部署 </tag>
            
            <tag> Chrome </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-API读取CDH-Hadoop-Parquet文件</title>
      <link href="/2018/06/29/Java-API%E8%AF%BB%E5%8F%96CDH-Hadoop-Parquet%E6%96%87%E4%BB%B6/"/>
      <url>/2018/06/29/Java-API%E8%AF%BB%E5%8F%96CDH-Hadoop-Parquet%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;由于工作需要，基于目前公司集群存在较多的服务器且存在大量的内存，因此考虑直接将数据Load进内存进行数据处理，测试是否能够加快处理速度；鉴于以上目的，版主尝试使用Parquet的Java API读入Parquet文件。</p><a id="more"></a><p>&emsp;&emsp;目前关于使用Java API访问HDFS的文章较多，但是没有相关的配置比较容易出错；同时Java API读写Parquet虽然文章较多，但多数为基于本地文件的读写实例。因此，有必要研究一下Java API读写HDFS上的Parquet文件。 </p><h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><h3 id="相关程序的运行，需要一个运行环境。本文的运行环境为："><a href="#相关程序的运行，需要一个运行环境。本文的运行环境为：" class="headerlink" title="相关程序的运行，需要一个运行环境。本文的运行环境为："></a>相关程序的运行，需要一个运行环境。本文的运行环境为：</h3><ul><li><strong>Eclipse+Maven</strong></li><li><strong>CDH5.8.0</strong></li><li><strong>JDK1.8.0</strong></li></ul><h3 id="需要的相关JAR"><a href="#需要的相关JAR" class="headerlink" title="需要的相关JAR"></a>需要的相关JAR</h3><ul><li>*<em>Hadoop-Common、Hadoop-Client(Maven) *</em></li><li><strong>parquet-avro-1.5.0-cdh5.8.0</strong></li><li><strong>parquet-format-2.1.0-cdh5.8.0.</strong></li><li><strong>parquet-hadoop-1.5.0-cdh5.8.0</strong></li><li><strong>parquet-column-1.5.0-cdh5.8.0</strong></li><li><strong>htrace-core4-4.0.1-incubating</strong></li></ul><hr><h2 id="相关代码（单节点）"><a href="#相关代码（单节点）" class="headerlink" title="相关代码（单节点）"></a>相关代码（单节点）</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Configuration conf;</span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.hdfs.impl"</span>, <span class="string">"org.apache.hadoop.hdfs.DistributedFileSystem"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalArgumentException,</span></span><br><span class="line"><span class="function">IOException </span>&#123;</span><br><span class="line"><span class="keyword">long</span> begin = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.length &lt; <span class="number">1</span>) &#123;<span class="comment">// Input arguments</span></span><br><span class="line">System.out.println(<span class="string">"Less params"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">String date = args[<span class="number">0</span>];<span class="comment">// Input Date Arguments</span></span><br><span class="line">String hdfsPath = <span class="string">"hdfs://NameNodeURL:port/user/hive/default/ip24data_parquet_all/pt="</span></span><br><span class="line">+ date;</span><br><span class="line">HashMap&lt;String, DATA&gt; map = <span class="keyword">new</span> HashMap&lt;String, DATA&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"deprecation"</span>)</span><br><span class="line">AvroParquetReader&lt;GenericRecord&gt; reader = <span class="keyword">new</span> AvroParquetReader&lt;GenericRecord&gt;(</span><br><span class="line">conf, <span class="keyword">new</span> Path(hdfsPath + <span class="string">"//00000"</span> + i + <span class="string">"_0"</span>));</span><br><span class="line">GenericRecord record = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">while</span> ((record = reader.read()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">String key = record.get(<span class="string">"vin"</span>).toString()</span><br><span class="line">+ record.get(<span class="string">"data_date"</span>).toString();</span><br><span class="line">DATA cnt = <span class="keyword">new</span> DATA(record.get(<span class="string">"vin"</span>), record.get(<span class="string">"data_date"</span>),</span><br><span class="line">record.get(<span class="string">"latitude"</span>), record.get(<span class="string">"longitude"</span>),</span><br><span class="line">record.get(<span class="string">"work_model"</span>));</span><br><span class="line">map.put(key, cnt);</span><br><span class="line">&#125;</span><br><span class="line">reader.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"Left APP: "</span>+<span class="keyword">new</span> Date().toString());</span><br><span class="line">System.out.println(<span class="string">"Total TIme used : ms: "</span>+(System.currentTimeMillis()-begin));</span><br><span class="line">System.out.println(<span class="string">"Only Load Data: size: "</span>+map.size());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="需要注意的地方："><a href="#需要注意的地方：" class="headerlink" title="需要注意的地方："></a>需要注意的地方：</h3><ol><li><strong>htrace-core4-4.0.1-incubating.jar</strong>，可以在相应的环境中找到，或到Maven/Htrace的官网上去找到；Htrace管网上的一般为源码，需要自行编译。</li><li>关于HDFS识别问题：第一次测试，没有添加任何配置，结果报错：</li></ol><p> <strong>NO FileSystem for scheme: hdfs</strong>，因此添加了<strong>fs.hdfs.impl</strong>的配置信息。关于HDFS其他的配置信息，可以根据hdfs的配置信息设置。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="http://www.programcreek.com/java-api-examples/index.php?api=parquet.hadoop.ParquetWriter" target="_blank" rel="noopener">ParquetWrite Java Code Example</a></li><li><a href="http://www.programcreek.com/java-api-examples/index.php?api=parquet.hadoop.ParquetReader" target="_blank" rel="noopener">ParquetReader Java Coder Example</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Java </tag>
            
            <tag> Parquet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群配置</title>
      <link href="/2018/06/29/Hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/06/29/Hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;自己动手搭建一个Hadoop集群，对于Hadoop的学习、理解非常有帮助，从中能够学习到Hadoop常用的端口、配置文件、配置信息等内容。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="预先准备"><a href="#预先准备" class="headerlink" title="预先准备"></a>预先准备</h3><ol><li>四台机器：master、slave1、slave2、slave3；</li><li>在master上开通外网访问权限，slave1\slave2\slave3无需外网访问权限；</li><li>下载JDK1.8.0_111；</li><li>在master上安装vim\wget\telnet等组件；</li><li>打通MASTER与SLAVE之间的通道(生成Key/复制Key)：ssh-keygen -t rsa；</li><li>将Master与Slave的IP地址添加到/etc/hosts里面：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">172.198.0.12 MASTER</span><br><span class="line">172.198.0.13 SLAVE1</span><br><span class="line">172.198.0.14 SLAVE2</span><br><span class="line">172.198.0.15 SLAVE3</span><br></pre></td></tr></table></figure></li></ol><h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><ol><li>版主下载的是tar文件，因此只需要解压即可；</li><li>配置/etc/profile文件：export JAVA_HOME=/home/appuser/jdk1.8.0_111/, export PATH=$PATH:$JAVA_HOME/bin；</li><li>配置用户.bash_profile: export  JAVA_HOME=/home/appuser/jdk1.8.0_111；</li></ol><p>如果想要配置立刻生效，可以使用source /etc/profile命令。</p><h3 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h3><p>安装思路：首先在MASTER节点中配置完成，然后复制到SLAVE节点中。</p><p><em>配置文件</em></p><p>core-site.xml:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;home&#x2F;appuser&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.default.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>hdfs-site.xml:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;home&#x2F;appuser&#x2F;hadoop&#x2F;tmp&#x2F;namedir&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;home&#x2F;appuser&#x2F;hadoop&#x2F;tmp&#x2F;datadir&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;2&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.http.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;master:50070&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.seconday.http-address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;slave1:50070&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.webhdfs.enabled&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>mapred-site.xml:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapred.job.tracker&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;master:9001&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;master:10020&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.map.tasks&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;20&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.reduce.tasks&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;20&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;master:19888&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>hadoop-env.sh:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;home&#x2F;appuser&#x2F;jdk1.8.0_111</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p><em>分发到SLAVE节点</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Copy Hadoop File</span><br><span class="line">scp -r ~&#x2F;hadoop-2.6.0&#x2F; slave1:~&#x2F;</span><br><span class="line">scp -r ~&#x2F;hadoop-2.6.0&#x2F; slave2:~&#x2F;</span><br><span class="line">scp -r ~&#x2F;hadoop-2.6.0&#x2F; slave3:~&#x2F;</span><br><span class="line"># Copy Jdk File</span><br><span class="line">scp -r ~&#x2F;jdk1.8.0_111&#x2F; slave1:~&#x2F;</span><br><span class="line">scp -r ~&#x2F;jdk1.8.0_111&#x2F; slave2:~&#x2F;</span><br><span class="line">scp -r ~&#x2F;jdk1.8.0_111&#x2F; slave3:~&#x2F;</span><br></pre></td></tr></table></figure><p><em>格式化NamdeNode</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hadoop namenode -format</span><br></pre></td></tr></table></figure><p>如果在Log中出现：<em>successfully …</em>，说明格式化成功。</p><p><em>启动Hadoop集群</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~&#x2F;hadoop-2.6.0&#x2F;sbin&#x2F;start-all.sh</span><br></pre></td></tr></table></figure><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>有时候DataNode启动不成功，这时候需要查看对应机器的logs，一般能够找到原因。大部分的原因在于Master与Slave的通讯出现问题，特别是Clone的虚拟机；</li><li>NameNode一般会启动成功，如果不能启动成功，可以查看相应的logs，或查看配置是否出现问题。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HDFS </tag>
            
            <tag> 配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark集群配置</title>
      <link href="/2018/06/29/Spark%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/06/29/Spark%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;相比Hadoop的配置，Spark配置起来相对简单。本文结合自身的配置经验，写下配置Spark的过程。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>&emsp;&emsp;在正式配置之前，需要确定环境是否适合安装Spark集群。</p><ol><li>确保已经安装JDK/JRE；</li><li>安装Hadoop(非必要)；</li><li>确保已经安装SCALA；</li><li>MASTER\SLAVE的IP地址已经配置在/etc/hosts中。</li></ol><h2 id="Spark配置"><a href="#Spark配置" class="headerlink" title="Spark配置"></a>Spark配置</h2><p><em>配置文件</em>:spark-env.sh：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/home/appuser/jdk</span><br><span class="line">export SCALA_HOME=/home/appuser/scala</span><br><span class="line">export SPARK_HOME=/home/appuser/spark</span><br><span class="line">export HADOOP_HOME=/home/appuser/hadoop</span><br><span class="line">export HADOOP_CONF_DIR=/home/appuser/hadoop/etc/hadoop</span><br><span class="line">export SPARK_MASTER_HOST=master</span><br></pre></td></tr></table></figure><p>slaves：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><p><em>分发到SLAVE节点</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r ~/spark-1.6.0-bin-hadoop2.6/ slave1:~/</span><br><span class="line">scp -r ~/spark-1.6.0-bin-hadoop2.6/ slave2:~/</span><br><span class="line">scp -r ~/spark-1.6.0-bin-hadoop2.6/ slave3:~/</span><br></pre></td></tr></table></figure><p> <em>启动Spark集群</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/spark-2.6.0-bin-hadoop2.6/sbin/start-all.sh</span><br></pre></td></tr></table></figure><h2 id="配置验证"><a href="#配置验证" class="headerlink" title="配置验证"></a>配置验证</h2><p><em>HTTP登陆</em><br>在浏览器中输入：<a href="http://master:50070/" target="_blank" rel="noopener">http://master:50070/</a> ，可以看到HDFS的相关配置信息及DataNode的活跃情况。</p><p><em>Spark-shell启动</em><br>启动Spark-shell，可以检测是否配置准确。当然，也可以使用Spark-submit提交Spark自带的例子，查看结果及运行情况。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>Work启动，但Http中没有Worker节点：说明Slave节点与Master的通讯出现问题，或Slave节点无法向Master注册，导致虽然Woker启动但不能在Master中找到。这时候需要检查/etc/hosts中的配置是否准确、合理；</li><li>Woker启动失败，这种情况说明配置可能存在问题，需要仔细检查；</li><li>版主多次尝试在spark-env.sh中配置master-port\worker-port，但是都失败，具体原因探索中。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux安装MySQL</title>
      <link href="/2018/06/29/Linux%E5%AE%89%E8%A3%85MySQL/"/>
      <url>/2018/06/29/Linux%E5%AE%89%E8%A3%85MySQL/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在Windows上安装MySQL比较简单，配置、启动服务，第一次进入不需要输入密码。但是在Centos6上安装MySQL，发现第一次安装会出现密码问题，因此有必要记录下自己的安装、配置过程，以供遗忘。</p><a id="more"></a><h2 id="1-安装Reposity-RPM"><a href="#1-安装Reposity-RPM" class="headerlink" title="1. 安装Reposity RPM"></a>1. 安装Reposity RPM</h2><ol><li>登陆MySQL官网，进入社区版下载页面，选择Redhat。<a href="http://dev.mysql.com/downloads/" target="_blank" rel="noopener">MySQL官网</a>；</li><li>根据官网安装步骤，安装RPM。</li></ol><p>安装RPM的过程一般不会出现问题。当然，也可以下载RPM直接安装。</p><h2 id="2-安装MySQL"><a href="#2-安装MySQL" class="headerlink" title="2. 安装MySQL"></a>2. 安装MySQL</h2><p>安装好Reposity之后，可以使用命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install mysql-community-server</span><br></pre></td></tr></table></figure><p>启动服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service mysqld start</span><br></pre></td></tr></table></figure><h3 id="2-1-设置MySQL"><a href="#2-1-设置MySQL" class="headerlink" title="2.1. 设置MySQL"></a>2.1. 设置MySQL</h3><h3 id="2-2-登陆"><a href="#2-2-登陆" class="headerlink" title="2.2. 登陆"></a>2.2. 登陆</h3><p>不同于Windows上面的启动，在Linux上启动，MySQL会自动生成一个Password：<br><img src="http://img.blog.csdn.net/20161126112836982" alt="初始化ＭｙＳＱＬ"><br>使用该密码登陆MySQL:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure><h3 id="2-3-修改配置"><a href="#2-3-修改配置" class="headerlink" title="2.3. 修改配置"></a>2.3. 修改配置</h3><p>为了能够通过密码验证，方便修改密码，进行如下设置：<br><img src="http://img.blog.csdn.net/20161126113842822" alt="123456"></p><p>具体相关设置的含义，可以参考<a href="MySQL5.7.12新密码登录方式及密码策略">MySQL5.7.12新密码登录方式及密码策略</a>。</p><p>第一次登陆，如果没有修改密码，无法完成其他操作，会提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">You must reset your password using ALTER USER statement before executing this statement.</span><br></pre></td></tr></table></figure><p>可以通过如下命令修改密码：</p><pre><code>alter user root@localhost identified by &apos;You Password&apos;;</code></pre><p>然后就可以创建用户、数据库等其他操作了。</p><h2 id="3-注"><a href="#3-注" class="headerlink" title="3. 注"></a>3. 注</h2><ol><li>CENTOS版本为6.9 X86_64；</li><li>MySQL版本为mysql57-community-release-el6-9。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 安装部署 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase集群安装配置-四节点-Centos6.9</title>
      <link href="/2018/06/29/Hbase%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-%E5%9B%9B%E8%8A%82%E7%82%B9-Centos6-9/"/>
      <url>/2018/06/29/Hbase%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-%E5%9B%9B%E8%8A%82%E7%82%B9-Centos6-9/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近在研究Hadoop相关组件的安装，本篇主要研究Hbase的安装。Hbase作为Hadoop家族中重要的数据库解决方案，对以后的Hive等数据库都有非常大的帮助。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>&emsp;&emsp;本节主要阐述Hbase集群的环境。<br>    1. 系统环境：Linux6.9；<br>    2. JAVA：JDK1.8.0_111；<br>    3. Hadoop：2.6.0；<br>    4. Zookeeper：3.4.9（3节点：slave1/slave2/slave3）。</p><h2 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h2><p>&emsp;&emsp;一般Apache的项目，可以从官网上选择相应的镜像作为下载站点，版主以清华大学的<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank" rel="noopener">镜像</a>作为下载站点，速度比较快。下载完成以后，直接解压即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xf hbase-1.2.4-bin.tar.gz</span><br></pre></td></tr></table></figure><p>直接解压到当前路径下。</p><h2 id="配置启动"><a href="#配置启动" class="headerlink" title="配置启动"></a>配置启动</h2><p>&emsp;&emsp;Hbase的配置，主要是对于Hbase-env.sh/Hbase-site.sh的配置。</p><p>Hbase环境配置Hbase-env.sh：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">## 配置主要HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;home&#x2F;appuser&#x2F;jdk</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;home&#x2F;appuser&#x2F;hadoop</span><br><span class="line">export HBASE_HOME&#x3D;&#x2F;home&#x2F;appuser&#x2F;hbase</span><br><span class="line"></span><br><span class="line"># 配置RegionServer</span><br><span class="line">export HBASE_REGIONSERVERS&#x3D;&#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;conf&#x2F;regionservers</span><br><span class="line"></span><br><span class="line"># true:Hbase自己管理Zookeeper</span><br><span class="line"># flase:通过独立Zookeeper管理</span><br><span class="line">export HBASE_MANAGES_ZK&#x3D;false</span><br></pre></td></tr></table></figure><p>Hbase主要参数配置Hbase-site.sh：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&#x2F;user&#x2F;hbase&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.replication&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.master&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;maste:60000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;slave1,slave2,slave3&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.clientport&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;2181&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>Hbase的regionservers配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure><p>基于以上配置之后，可以在Master节点启动Hbase ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~&#x2F;hbase&#x2F;bin&#x2F;start-hbase.sh start</span><br></pre></td></tr></table></figure><p>如果出现以下类似信息，说明只在Master节点启动，RegionServer没有启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">starting regionserver, logging to &#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;logs&#x2F;hbase-appuser-regionserver-hs-slave1.out</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;128m; support was removed in 8.0</span><br></pre></td></tr></table></figure><p>如果启动成功，会出现下面的类似信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">starting master, logging to &#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;logs&#x2F;hbase-appuser-master-master.out</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave3: starting regionserver, logging to &#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;logs&#x2F;hbase-appuser-regionserver-slave3.out</span><br><span class="line">slave2: starting regionserver, logging to &#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;logs&#x2F;hbase-appuser-regionserver-hs-slave2.out</span><br><span class="line">slave1: starting regionserver, logging to &#x2F;home&#x2F;appuser&#x2F;hbase&#x2F;logs&#x2F;hbase-appuser-regionserver-hs-slave1.out</span><br><span class="line">slave3: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave3: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave2: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave2: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave1: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize&#x3D;128m; support was removed in 8.0</span><br><span class="line">slave1: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize&#x3D;128m; support was removed in 8.0</span><br></pre></td></tr></table></figure><h2 id="测试Hbase"><a href="#测试Hbase" class="headerlink" title="测试Hbase"></a>测试Hbase</h2><p><em>首先</em>可以启动Hbase测试是否正确安装Hbase，如果启动过程没有报错信息，那么安装成功：<br><img src="/.io//001.png" alt="1"></p><p><em>其次</em>可以创建表，写入内容，查看是否正常，如果正常说明安装成功：<br><img src="/.io//002.png" alt="2"></p><p>通过以上操作以后，可以查看Hadoop相应路径上是否存在数据：<br><img src="/.io//003.png" alt="3"></p><p><em>另外</em>，可以通过WebUI确定RegionServer是否启动，端口是否正常，地址：[You URL:16010/]：<br><img src="/.io//004.png" alt="4"></p><p>通过页面可以看出确实存在3个RegionServer，且每个Server只有一个Region 。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>Hbase-site中配置的NAME中的值，最好选择小写。版主第一次使用大写，结果配置没有生效；</li><li>每台机器上都配置JAVA_HOME变量，安装JDK。如果没有，会报错Java Not Found；</li><li>Zookeeper选择奇数(1,3,5,7…)台机器安装，本例3个节点安装。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 部署 </tag>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive2.0.0安装配置</title>
      <link href="/2018/06/29/Hive2-0-0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/06/29/Hive2-0-0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="环境依赖"><a href="#环境依赖" class="headerlink" title="环境依赖"></a>环境依赖</h2><p>&emsp;&emsp;Hive必须运行在Hadoop之上，则需要先安装Hadoop环境。关于Hadoop的安装可以参考我前文的<a href="http://blog.csdn.net/awdac/article/details/53333470" target="_blank" rel="noopener">博客</a>，也可以参考原文作者的<a href="http://my.oschina.net/u/204498/blog/519789" target="_blank" rel="noopener">链接</a>。</p><a id="more"></a><h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><p><strong>1.下载Hive</strong><br><a href="http://apache.mirrors.ionfish.org/hive/" target="_blank" rel="noopener">http://apache.mirrors.ionfish.org/hive/</a><br>我安装的是apache-hive-1.2.1-bin.tar.gz</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hftclclw0001 ~]$ pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 ~]$ wget http:&#x2F;&#x2F;apache.mirrors.ionfish.org&#x2F;hive&#x2F;hive-1.2.1&#x2F;apache-hive-1.2.1-bin.tar.gz</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 ~]$ ll</span><br><span class="line">total 637256</span><br><span class="line">drwx------ 10 hadoop root      4096 Oct 27 02:22 apache-hive-1.2.1-bin</span><br><span class="line">-rw-------  1 hadoop root  92834839 Jun 26 18:34 apache-hive-1.2.1-bin.tar.gz</span><br><span class="line">drwx------  3 hadoop root      4096 Oct 27 09:05 data</span><br><span class="line">drwx------ 11 hadoop root      4096 Oct 21 03:20 hadoop-2.7.1</span><br><span class="line">-rw-------  1 hadoop root 210606807 Oct 20 09:00 hadoop-2.7.1.tar.gz</span><br><span class="line">drwx------  2 hadoop root      4096 Oct 23 02:08 install-sqoop</span><br><span class="line">drwx------ 13 hadoop root      4096 Oct 20 09:22 spark-1.5.1-bin-hadoop2.6</span><br><span class="line">-rw-------  1 hadoop root 280901736 Oct 20 09:19 spark-1.5.1-bin-hadoop2.6.tgz</span><br><span class="line">drwx------ 22 hadoop root      4096 Oct 23 02:08 sqoop-1.99.6-bin-hadoop200</span><br><span class="line">-rw-------  1 hadoop root  68177818 May  5 22:34 sqoop-1.99.6-bin-hadoop200.tar.gz</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 ~]$ cd apache-hive-1.2.1-bin&#x2F;conf&#x2F;</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 conf]$ pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;conf</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 conf]$ vi hive-env.sh</span><br><span class="line"></span><br><span class="line">HADOOP_HOME&#x3D;&#x2F;home&#x2F;hadoop&#x2F;hadoop-2.7.1 &#x3D;&gt;配置Hadoop_Home</span><br><span class="line"></span><br><span class="line">export HIVE_CONF_DIR&#x3D;&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;conf&#x3D;&gt;配置HIVE_conf_home</span><br><span class="line">export HIVE_AUX_JARS_PATH&#x3D;&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;lib&#x2F;</span><br></pre></td></tr></table></figure><p>我使用了mysql作为metastore ，则需要在lib目录下添加mysql的驱动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hftclclw0001 lib]$ pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;lib</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 lib]$ ll | grep mysql</span><br><span class="line">-rw-------  1 hadoop root   848401 Oct 27 01:48 mysql-connector-java-5.1.25-bin.jar</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 conf]$ vi hive-site.xml</span><br><span class="line">[hadoop@hftclclw0001 conf]$ cat hive-site.xml </span><br><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.metastore.local&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;&#x2F;value&gt;                                    &#x3D;&gt;metastore我的mysql不是在该server上</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;jdbc:mysql:&#x2F;&#x2F;&#123;ip:port&#125;&#x2F;&#123;databases&#125;&lt;&#x2F;value&gt;        &#x3D;&gt; mysql服务的ip和端口号</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionDriveName&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;com.mysql.jdbc.Driver&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#123;username&#125;&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#123;password&#125;&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.warehouse.dir&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#x2F;hive&#x2F;warehouse&lt;&#x2F;value&gt;                      &#x3D;&gt;hive的仓库目录，需要在HDFS上创建，并修改权限</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.uris&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;value&gt;thrift:&#x2F;&#x2F;&#123;ip&#125;:&#123;port&#125;&lt;&#x2F;value&gt;                 &#x3D;&gt;本机ip和端口号，启动metastore服务</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line">[hadoop@hftclclw0001 conf]$ vi hive-log4j.properties                &#x3D;&gt; Log4j的配置，可以修改日志目录</span><br></pre></td></tr></table></figure><p><strong>2.启动metastore</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hftclclw0001 bin]$ pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;bin</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 bin]$ .&#x2F;hive --service metastore &amp;</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 bin]$ ps ax|grep metastore</span><br></pre></td></tr></table></figure><p><strong>3.启动HiveServer2</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hftclclw0001 bin]$ pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin&#x2F;bin</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 bin]$ .&#x2F;hive --service hiveserver2 &amp;</span><br><span class="line"></span><br><span class="line">[hadoop@hftclclw0001 bin]$ ps ax|grep HiveServer2</span><br></pre></td></tr></table></figure><p><strong>4.启动shell 或是 beeline</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hftclclw0001 bin]$ .&#x2F;hive shell</span><br></pre></td></tr></table></figure><h2 id="metastore"><a href="#metastore" class="headerlink" title="metastore"></a>metastore</h2><p>原文请参考：<a href="http://www.cloudera.com/content/www/en-us/documentation/archive/cdh/4-x/4-2-0/CDH4-Installation-Guide/cdh4ig_topic_18_4.html" target="_blank" rel="noopener">Configuring the Hive Metastore</a>。</p><p>1.内置模式：将数据保存在内置的Derby数据库中，这种方式最简单，但是Derby每次只能访问一个数据文件。<br>Drive ==&gt;  Metastore  ==&gt; Derby</p><p>2.本地模式：将元数据保存在本地的独立数据库(如mysql)等<br>Driver ===&gt; Metastore<br>Driver ===&gt; Metastore       ===&gt; DB<br>Driver ===&gt; Metastore<br>每个server都需要配置metastore，并启动metastore服务</p><p>3.远程模式：使用thrift访问metastore<br>Client1<br>Client2   ===&gt; Metastore ===&gt; DB<br>Client3 </p><p>4.配置：<br>如上述配置，我们已经启动了metastore服务在上述hftclclw0001机器上，<br>我们在另一台server上，如hftclcld0001机器上，安装hive，配置如上述配置一直，仅仅修改hive-site.xml如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.uris&lt;&#x2F;name&gt;</span><br><span class="line">            &lt;value&gt;thrift:&#x2F;&#x2F;&#123;ip&#125;:&#123;port&#125;&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>即我们通过thrift协议，访问hftclclw0001上面的metastore，并访问hive的元数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hftclcld0001 apache-hive-1.2.1-bin]# pwd</span><br><span class="line">&#x2F;home&#x2F;hadoop&#x2F;apache-hive-1.2.1-bin</span><br><span class="line"></span><br><span class="line">[root@hftclcld0001 apache-hive-1.2.1-bin]# .&#x2F;bin&#x2F;hive shell</span><br><span class="line">hive&gt; </span><br><span class="line"></span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">hive      &#x3D;&gt;能访问到hive的metastore，访问到元数据(我们之前创建的)</span><br><span class="line">human_resources</span><br><span class="line">Time taken: 0.388 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li><a href="http://www.36dsj.com/archives/60604" target="_blank" rel="noopener">Apache Hive2.0的新特性介绍</a></li><li><a href="https://my.oschina.net/leejun2005/blog/272188" target="_blank" rel="noopener">Hive 各版本关键新特性</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 部署 </tag>
            
            <tag> Hive </tag>
            
            <tag> 安装 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FNLP编译安装</title>
      <link href="/2018/06/29/FNLP%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"/>
      <url>/2018/06/29/FNLP%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近在研究dl4j的学习，其中有使用FNLP作为分词的例子。版主尝试编译源码，经过不断的查找验证，得到可行的方式。</p><a id="more"></a><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>&emsp;&emsp;FNLP的源码已经在github上，地址为：(<a href="https://github.com/FudanNLP/fnlp),感兴趣的朋友可以下载编译学习。同时针对下载困难的Jar包，FNLP的作者利用国内百度云盘作为下载地址，可以下载相关Jar包和Model，地址为：(http://pan.baidu.com/s/1D7CVc)。根据Github上作者的提示，将Model文件通过百度云盘下载到相应路径下，就可以编译。" target="_blank" rel="noopener">https://github.com/FudanNLP/fnlp),感兴趣的朋友可以下载编译学习。同时针对下载困难的Jar包，FNLP的作者利用国内百度云盘作为下载地址，可以下载相关Jar包和Model，地址为：(http://pan.baidu.com/s/1D7CVc)。根据Github上作者的提示，将Model文件通过百度云盘下载到相应路径下，就可以编译。</a></p><p>版主利用GIT来克隆源码到本地：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;FudanNLP&#x2F;fnlp.git</span><br></pre></td></tr></table></figure><p>然后利用Maven3来编译源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install</span><br></pre></td></tr></table></figure><p>但是在编译过程中遇到Plugin的错误：<br><img src="/.io//001.png" alt="特殊他"><br>只有使用跳过测试的选项，才可以通过编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install -Dmaven.test.skip&#x3D;true</span><br></pre></td></tr></table></figure><p><img src="/.io//002.png" alt="test-success"></p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>Maven下载Jar包中，比较困难的是trove4j-3.0.3.jar，最好到百度云盘中直接下载，本地Maven安装，具体可以参考：<a href="http://blog.sina.com.cn/s/blog_4a1bfe2c0100x149.html" target="_blank" rel="noopener">Maven install:install-file </a>；</li><li>相关模型需要自己动手下载到相关路径下，也就是~/git/fnlp/models/这个路径下面；</li><li>其他相关NLP的工具，其中有Apache的OpenNLP、哈工大的NLP等。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 部署 </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dl4j+fnlp关联度TopN</title>
      <link href="/2018/06/29/dl4j-fnlp%E5%85%B3%E8%81%94%E5%BA%A6TopN/"/>
      <url>/2018/06/29/dl4j-fnlp%E5%85%B3%E8%81%94%E5%BA%A6TopN/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近在学习deeplearning4j，简称为dl4j。其中有许多示例，可以编译源码以后，运行runexample.sh来查看相关的结果。其中有分词的例子，所以想要学习一下分词，特别是中文分词的实例。</p><a id="more"></a><p>&emsp;&emsp;关于中文分词，比较好的一个例子就是<a href="http://blog.csdn.net/a398942089/article/details/51970691" target="_blank" rel="noopener">DeepLearning4J入门——让计算机阅读《天龙八部》</a>，版主也想要研究一下该例子，并通过学习加深对分词的理解。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>&emsp;&emsp;版主使用的环境，基本上与原文作者使用的类似：</p><ol><li>Eclipse：导入<a href="https://github.com/deeplearning4j" target="_blank" rel="noopener">dl4j-examples.git</a>；</li><li>Windows7系统：单台CPU机器；</li><li>Maven3：主要用于FNLP的编译，获取fnlp-core的JAR包，当然也可以直接下载百度云盘上的JAR包。</li></ol><h2 id="dl4j自带自带实例"><a href="#dl4j自带自带实例" class="headerlink" title="dl4j自带自带实例"></a>dl4j自带自带实例</h2><p>&emsp;&emsp;感兴趣的朋友，可以下载dl4j-examples的源码，自己动手编译源码运行一下。dl4j分词的实例，主要是【17】这一个例子：<br><img src="/.io//001.png" alt="dl4j-examples-17"></p><p>&emsp;&emsp;刚开始，可能需要下载数据，大约为80M左右，同时需要研究原代码，因为直接运行的话会报错：<br><img src="/.io//002.png" alt="dl4j-error"><br>版主写此文时，可以在网上找到该缺失文件，地址为：<a href="http://pan.baidu.com/s/1kTCQqft" target="_blank" rel="noopener"> GoogleNews-vectors-negative300</a>。</p><h2 id="中文分词学习"><a href="#中文分词学习" class="headerlink" title="中文分词学习"></a>中文分词学习</h2><p>&emsp;&emsp;参考引文的代码，可以完成编译。值得注意的是，版主在编译的时候遇到几个问题：</p><ol><li>直接下载【天龙八部】，用Eclipse直接打开，发现时乱码。将文本的格式设置为UTF-8无BOM以后，可以正常显示；</li><li>使用MAVEN下载FNLP-CORE时，发现速度非常慢。可以直接到FNLP的百度云盘下载相关JAR包，或自行编译FNLP源码得到JAR包，然后再本地使用<strong>mvn install:install-fiile</strong>安装到本地库中；</li><li>关于代码运行的顺序问题：首先运行<em>processFile</em>的代码，这样可以通过tlbb.txt生成分词文件tlbb_t.txt；然后通过<em>ZhWord2Vector</em>来获得结果。<br>为了后来学习者减少雷区，版主将Eclipse工程结构送上：<br><img src="/.io//003.png" alt="pp"><br><img src="/.io//004.png" alt="qq"><br>版主的结构与原文类似，但有一些差异，各种差异读者可自行体会_^_。</li></ol><p>分词的结果，与参考文中的结果也略有差异，如果有知晓原因的，请告诉版主：<br><img src="http://img.blog.csdn.net/20161128223852350" alt="ll"></p><p>版主使用的训练参数：</p><blockquote><p>minWordFrequency(10).iterations(4).layerSize(100).seed(45).windowSize(5)</p></blockquote><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>参考文：<a href="http://blog.csdn.net/a398942089/article/details/51970691" target="_blank" rel="noopener">http://blog.csdn.net/a398942089/article/details/51970691</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SAS中实用函数</title>
      <link href="/2018/06/29/SAS%E4%B8%AD%E5%AE%9E%E7%94%A8%E5%87%BD%E6%95%B0/"/>
      <url>/2018/06/29/SAS%E4%B8%AD%E5%AE%9E%E7%94%A8%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;SAS博大精深，版主初涉此领域，经常遇到一些问题，需要Baidu搜索，为了防止遗忘，记录下来。</p><a id="more"></a><h2 id="关于日期时间"><a href="#关于日期时间" class="headerlink" title="关于日期时间"></a>关于日期时间</h2><p>SAS中的时间日期格式非常多，重要的函数有如下几种：</p><blockquote><p>Day函数：得到日期的天，例如：day(‘2016-09-01’d)=1；<br>Month函数：得到日期的月份，例如：month(‘2016-09-01’d)=9；<br>Year函数：得到日期的年份，例如：year(‘2016-09-01’d)=2016；</p><p>Hour函数：得到时间的小时，例如：hour(‘18:10:01’t)=18；<br>Minute函数：得到时间的分钟，例如：minute(‘18:10:01’t)=10；</p><p>Datepart函数：获取日期时间类型中的日期部分；<br>Timepart函数：获取日期时间类型中的时间部分。</p></blockquote><p>关于SAS中日期时间格式的表示方式，我一般使用如下几种： </p><blockquote><p>yymmdd10.：这种格式可以将要日期表示为: yyyy-MM-dd的样式；<br>hhmmss.:这种格式可以将时间类型格式化为：HH:mm:ss的形式。</p></blockquote><p>关于时间类型的计算，一般用到如下几个函数：</p><blockquote><p>intck：根据间隔，计算两个日期之间的间隔数；<br>intnx：计算某个间隔数之后的一个日期。</p></blockquote><h2 id="关于编程"><a href="#关于编程" class="headerlink" title="关于编程"></a>关于编程</h2><ol><li>感受最深的一个就是retain关键字。我们知道SAS是按行计算的，一般来讲程序只能处理当前行的内容，如何灵活操作呢？retain关键词帮我们实现这个功能。它能够定义一下变量，能够累计（累加、累乘等），这样我们可以分组计算，可以汇总等操作。</li><li>第二个比较好用的就是output：可以自定义output的位置，这样就能控制输入。默认情况下，程序处理到一行的最后默认有一个output。</li></ol><h2 id="EG使用"><a href="#EG使用" class="headerlink" title="EG使用"></a>EG使用</h2><p>&emsp;&emsp;使用SAS ENTERPRISE GUIDER的一个好处就是，可以自动生成代码，虽然最后执行的还是SAS BASE，但对编程来说已经非常方便了。例如，数据的导入、到处，数据探索：画图、回归模型、时序模型等都能方便的操作。</p><p> &emsp;&emsp;界面化的设计，使得初学者即可方便使用，只要配置参数、选择方法就能很好的完成任务。使得使用着能够将更多的时间投入到研究模型的设计、业务的理解/解释等方面，从复杂的编程中得到解脱。</p><p>&emsp;&emsp;另外，SAS提供的数据挖掘工具EM可以方便的实现从数据探索、参数变换/选择、模型选择、模型评价等一系列的功能，更好地实现模型的自动化优化。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>&emsp;&emsp;SAS在金融行业应用非常广泛，有着巨大的用户群体，也有非常健全的帮助文档体系，这些对于初学者来说是非常有帮助的。感兴趣的朋友，可以到SAS官网山找到相关帮助文档。</p>]]></content>
      
      
      <categories>
          
          <category> SAS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ignite+CDH5.8安装配置</title>
      <link href="/2018/06/29/Ignite-CDH5-8%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/06/29/Ignite-CDH5-8%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;最近在研究基于内存处理技术，其中就有比较出名的Apache Ignite的项目。应用场景是，通过Spark/Java等工具处理Parquet文件，但是直接通过Java API处理Parquet文件的性能较差，主要原因在于不能实现并行化处理。</p><a id="more"></a><h2 id="Ignite特性"><a href="#Ignite特性" class="headerlink" title="Ignite特性"></a>Ignite特性</h2><p>&emsp;&emsp;Ignite的应用场景比较多，主要用在数据库缓存方便。当然，集合Ignite也可以结合Spark共享RDD用作缓存处理。</p><p>&emsp;&emsp;更多关于 Ignite的介绍，可以查看<a href="https://www.zybuluo.com/liyuj/note/481591" target="_blank" rel="noopener">官方文档V1.7</a>。如果对实际操作比较感兴趣，可以查看Ignite在Github上的<a href="https://github.com/apache/ignite/tree/master/examples" target="_blank" rel="noopener">实例代码</a>。</p><h2 id="安装Ignite"><a href="#安装Ignite" class="headerlink" title="安装Ignite"></a>安装Ignite</h2><p>&emsp;&emsp;版主使用四节点实现分布式Ignite的安装，由于 Ignite具有自动发现机制，因此即使不进行配置，在同一局域网中也可以实现多个Server的分布式配置。</p><h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><ol><li>CDH5.8.0；</li><li>JDK1.8.0；</li><li>Spark1.6。</li></ol><h3 id="配置代码"><a href="#配置代码" class="headerlink" title="配置代码"></a>配置代码</h3><p>&emsp;&emsp;同一般Spark集群不同的地方在于，Ignite安装在Yarn节点上，且配置Yarn节点与Spark Geteway环境变量，在/XXX/conf.cloudera.spark_on_yarn2/spark-env.sh文件中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Optionally set IGNITE_HOME here.</span><br><span class="line"># IGNITE_HOME&#x3D;&#x2F;path&#x2F;to&#x2F;ignite</span><br><span class="line">IGNITE_LIBS&#x3D;&quot;\$&#123;IGNITE_HOME&#125;&#x2F;libs&#x2F;*&quot;</span><br><span class="line">for file in \$&#123;IGNITE_HOME&#125;&#x2F;libs&#x2F;*</span><br><span class="line">do</span><br><span class="line">if [ -d \$&#123;file&#125; ] &amp;&amp; [ &quot;\$&#123;file&#125;&quot;!&#x3D;&quot;\$&#123;IGNITE_HOME&#125;&quot;&#x2F;libs&#x2F;optional ]; then</span><br><span class="line"> IGNITE_LIBS&#x3D;\$&#123;IGNITE_LIBS&#125;:\$&#123;file&#125;&#x2F;*</span><br><span class="line">fi</span><br><span class="line">done</span><br><span class="line">export SPARK_DIST_CLASSPATH&#x3D;$IGNITE_LIBS</span><br></pre></td></tr></table></figure><p>这里与官方文档中唯一的区别在于，官方文档中使用的CLASSPATH为<em>SPARK_CLASSPATH</em>，这里使用的CLASSPATH为<em>SPARK_DIST_CLASSPATH</em>。</p><h2 id="测试Ignite"><a href="#测试Ignite" class="headerlink" title="测试Ignite"></a>测试Ignite</h2><p>使用简单测试代码(spark-shell)：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.ignite.configuration._</span><br><span class="line"><span class="keyword">import</span> org.apache.ignite.spark._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用default-config下面的配置</span></span><br><span class="line"><span class="keyword">val</span> igniteContext = <span class="keyword">new</span> <span class="type">IgniteContext</span>(sc, () =&gt; <span class="keyword">new</span> <span class="type">IgniteConfiguration</span>())</span><br><span class="line"><span class="comment">// val igniteContext = new IgniteContext(sc, "config/default-config.xml")</span></span><br><span class="line"><span class="keyword">val</span> cache = igniteContext.fromCache[<span class="type">Integer</span>,<span class="type">Integer</span>](<span class="string">"partitioned"</span>)</span><br><span class="line">println(<span class="string">"Name: "</span>+cache.cacheName+<span class="string">"\tCount: "</span>+cache.count())</span><br><span class="line">    </span><br><span class="line">cache.savePairs(sc.parallelize(<span class="number">1</span> to <span class="number">10000</span>, <span class="number">10</span>).map( item =&gt; (item, item)))</span><br><span class="line">println(<span class="string">"Name: "</span>+cache.cacheName+<span class="string">"\tCount: "</span>+cache.count())</span><br></pre></td></tr></table></figure><p>报错信息：</p><blockquote><p>java.lang.NoClassDefFoundError: javax/cache/configuration/MutableConfiguration</p></blockquote><p>&emsp;&emsp;这个类主要是在cache-api中，在Ignite的libs里面有，将给Jar包的路径包含在Jars的路径中即可。另外一种，可能的解决方案为：<a href="http://apache-ignite-users.70518.x6.nabble.com/Ignite-Installation-with-Spark-under-CDH-td4457.html" target="_blank" rel="noopener">Ignite Installation with Spark under CDH</a>。 </p><blockquote><p>ClassNoDefMethodError: org.apache.ignite.configuration.IgniteConfiguration</p></blockquote><p>&emsp;&emsp;缺少Jar包：将要<em>Ignite</em>下面的<em>Ignite-core</em>包含在<em>Jars</em>里面，或者配置路径。</p><p>&emsp;&emsp;另，<em>Ignite-Spark</em>这个<em>Jar</em>包不回在<em>Ignite_Home/libs</em>下面，所以需要手动下载到相应的路径下面，最好的办法就是将<em>libs</em>下面所有的<em>Jar</em>包放在<em>spark_home/jars</em>下面。</p><blockquote><p> org.apache.ignite.IgniteCheckedException: Work directory does not exist and cannot be created</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
            <tag> 部署 </tag>
            
            <tag> 配置 </tag>
            
            <tag> Ignite </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单Python爬取链接二手房信息</title>
      <link href="/2018/06/29/%E7%AE%80%E5%8D%95Python%E7%88%AC%E5%8F%96%E9%93%BE%E6%8E%A5%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/"/>
      <url>/2018/06/29/%E7%AE%80%E5%8D%95Python%E7%88%AC%E5%8F%96%E9%93%BE%E6%8E%A5%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<h2 id="Python爬虫"><a href="#Python爬虫" class="headerlink" title="Python爬虫"></a>Python爬虫</h2><p>&emsp;&emsp;博主目前学习Python爬虫，主要从简单的代码入手，然后逐步理解爬虫的精髓，逐渐学习复杂的爬虫技术等内容。</p><a id="more"></a><p>&emsp;&emsp;本文主要研究使用简单的线程、urllib、bs4.BeautifulSoup等爬取链家网站二手房信息。主要的原理在于链家网站具有比较简单的网页结构，同时也是静态网页；使用的手段，主要是通过网页之间的地址链接，不断获取房子详细页面的内容。</p><h2 id="主要用到的包"><a href="#主要用到的包" class="headerlink" title="主要用到的包"></a>主要用到的包</h2><p>本文主要使用以下package:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import Queue</span><br><span class="line"></span><br><span class="line">import MysqlDB</span><br><span class="line">import parserURL</span><br><span class="line"></span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">import urllib</span><br><span class="line"></span><br><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure><p>使用的线程信息，但由于存在链家可能存在反扒措施，或对同一IP存在访问数限制，因此这里主要使用单一线程。</p><h2 id="主要代码"><a href="#主要代码" class="headerlink" title="主要代码"></a>主要代码</h2><p>浏览页面网页解析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">## 解析网页信息</span><br><span class="line">class parserURL(threading.Thread):</span><br><span class="line">    </span><br><span class="line">    counts &#x3D; 0</span><br><span class="line">    preurl &#x3D; &quot;&quot;</span><br><span class="line">    </span><br><span class="line">    def __init__(self, html_queue, two_html_queue):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.html_queue &#x3D; html_queue</span><br><span class="line">        self.two_html_queue &#x3D; two_html_queue</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        while True:</span><br><span class="line">            try:</span><br><span class="line">                self.detail_url_parser()</span><br><span class="line">                self.counts &#x3D; self.counts + 1</span><br><span class="line">                if self.counts % 100 &#x3D;&#x3D; 0:</span><br><span class="line">                    time.sleep(60)</span><br><span class="line">            except Exception:</span><br><span class="line">                self.html_queue.put(self.preurl)</span><br><span class="line">                print &quot;parserURL: Hello, world&quot;</span><br><span class="line">    </span><br><span class="line">    def detail_url_parser(self):</span><br><span class="line">        s &#x3D; self.html_queue.get()</span><br><span class="line">        print &quot;parserURL: &quot;, s</span><br><span class="line">        self.preurl &#x3D; s</span><br><span class="line">        s &#x3D; urllib.urlopen(s).read()</span><br><span class="line">        s &#x3D; BeautifulSoup(s, &#39;html.parser&#39;).find(&#39;ul&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;house-lst&#39;&#125;)</span><br><span class="line">        lis &#x3D; s.find_all(&#39;li&#39;)</span><br><span class="line">        </span><br><span class="line">        for li in lis:</span><br><span class="line">            detail &#x3D; li.find(&#39;h2&#39;).find(&#39;a&#39;)</span><br><span class="line">            detail_href &#x3D; detail[&#39;href&#39;]</span><br><span class="line">            self.two_html_queue.put(&quot;http:&#x2F;&#x2F;sh.lianjia.com&quot; + detail_href)</span><br></pre></td></tr></table></figure><p>解析房子详细页面信息，并将爬取内容写入数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">sql &#x3D; &quot;insert into house_infos(tag,type,total_price,house_type,house_area,house_avg_price,house_floor,house_year,house_desc,house_direction,first_pay,monthly_pay,district,district_address,city) values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)&quot;</span><br><span class="line">## 解析二手房信息</span><br><span class="line">class parserErShouFang(threading.Thread):</span><br><span class="line">    </span><br><span class="line">    counts &#x3D; 0</span><br><span class="line">    preurl &#x3D; &quot;&quot;</span><br><span class="line">    </span><br><span class="line">    def __init__(self, db, tag, city, house_type, html_queue):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.html_queue &#x3D; html_queue</span><br><span class="line">        self.db &#x3D; db</span><br><span class="line">        self.tag &#x3D; tag</span><br><span class="line">        self.city &#x3D; city</span><br><span class="line">        self.house_type &#x3D; house_type</span><br><span class="line">        </span><br><span class="line">    def run(self):</span><br><span class="line">        while True:</span><br><span class="line">            try:</span><br><span class="line">                self.ershoufang_html()</span><br><span class="line">                self.counts &#x3D; self.counts + 1</span><br><span class="line">                if self.counts % 500 &#x3D;&#x3D; 0:</span><br><span class="line">                    time.sleep(60)</span><br><span class="line">            except Exception:</span><br><span class="line">                print &quot;parserErShowFang: Hello, world!&quot;</span><br><span class="line">                self.html_queue.put(self.preurl)</span><br><span class="line">    </span><br><span class="line">    def ershoufang_html(self):</span><br><span class="line">        param &#x3D; []</span><br><span class="line"></span><br><span class="line">        h &#x3D; self.html_queue.get()</span><br><span class="line">        self.preurl &#x3D; h</span><br><span class="line">        print &quot;sdf: &quot;, h</span><br><span class="line">        s &#x3D; urllib.urlopen(h).read()</span><br><span class="line">        s &#x3D; BeautifulSoup(s, &#39;html.parser&#39;)</span><br><span class="line">        </span><br><span class="line">        param.append(self.tag)</span><br><span class="line">        param.append(self.house_type)</span><br><span class="line">        </span><br><span class="line">        # 价格信息</span><br><span class="line">        price &#x3D; s.find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;price&#39;&#125;).find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;mainInfo bold&#39;&#125;).text</span><br><span class="line">        param.append(price)</span><br><span class="line">        # 户型信息</span><br><span class="line">        huxing &#x3D; s.find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;room&#39;&#125;).find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;mainInfo&#39;&#125;).text.replace(&#39; &#39;, &#39;&#39;)</span><br><span class="line">        param.append(huxing)</span><br><span class="line">        # 面积信息</span><br><span class="line">        area &#x3D; s.find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;area&#39;&#125;).find(&#39;div&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;mainInfo&#39;&#125;).text.replace(&#39; &#39;, &#39;&#39;)</span><br><span class="line">        param.append(area)</span><br><span class="line"></span><br><span class="line">        lis &#x3D; s.find(&#39;table&#39;, attrs&#x3D;&#123;&#39;class&#39;:&#39;aroundInfo&#39;&#125;).find_all(&#39;td&#39;)</span><br><span class="line">        for l in lis:</span><br><span class="line">            p &#x3D; l.text.replace(&#39;\t&#39;, &#39;&#39;).replace(&#39;\r\n&#39;, &#39;&#39;).replace(&#39; &#39;, &#39;&#39;).replace(&#39;\n&#39;, &#39;&#39;)</span><br><span class="line">            tmp &#x3D; p.split(&#39;\n&#39;)</span><br><span class="line">            for q in tmp:</span><br><span class="line">                pq &#x3D; q.split(u&#39;\uff1a&#39;)</span><br><span class="line">                if pq[0].startswith(u&#39;房源编号&#39;):</span><br><span class="line">                    break;</span><br><span class="line">                if len(pq) &gt; 1:</span><br><span class="line">                    param.append(pq[1])</span><br><span class="line">                    print pq[0], pq[1]</span><br><span class="line">        param.append(self.city)</span><br><span class="line">        </span><br><span class="line">        self.db.execute(sql, param)</span><br></pre></td></tr></table></figure><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>&emsp;&emsp;博主采用的手段比较低级，主要通过网页中的标签来获取相应的数据，后期可能通过xpath、正则表达式等方式来获取相应的内容。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIFAR-10的Matlab可视化与转化</title>
      <link href="/2018/06/29/CIFAR-10%E7%9A%84Matlab%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E8%BD%AC%E5%8C%96/"/>
      <url>/2018/06/29/CIFAR-10%E7%9A%84Matlab%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%8E%E8%BD%AC%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;进来研究dl4j-examples里面的相关实例，经常用到例如MNIST、CIFAR等二进制图像集合。原程序用到的是二进制文件格式的读取，而如果想要看到里面数值具体的含义，需要对二进制文件进行可视化。</p><a id="more"></a><p>&emsp;&emsp;Matlab使用方便、编程简单，且无论在数值计算，还是在图像处理、模拟过程等方面都非常具有优势，缺点就是软件不开源、价格昂贵，因此滋生了如博主一样的广大盗版软件使用者_^_ 。</p><h2 id="Matlab基础"><a href="#Matlab基础" class="headerlink" title="Matlab基础"></a>Matlab基础</h2><ol><li>导入数据：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load(&#39;you data path&#39;)</span><br><span class="line">%获取文件名称、路径</span><br><span class="line">[filename,filepath]&#x3D;uigetfile()</span><br></pre></td></tr></table></figure></li><li>读写图像：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[X, map] &#x3D; imread(filename,format);%读入操作</span><br><span class="line">imgray &#x3D; rgb2gray(X);%转化为灰度图像</span><br><span class="line">imwrite(image,filename);%图像写入文件操作</span><br></pre></td></tr></table></figure></li><li>图像展示：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">imshow(X,map);%显示图像</span><br><span class="line">% 同一界面中显示多个图像</span><br><span class="line">figure%假设显示四个图像</span><br><span class="line">subplot(221),imshow(image1)</span><br><span class="line">subplot(222),imshow(image2)</span><br><span class="line">subplot(223),imshow(image3)</span><br><span class="line">subplot(224),imshow(image4)</span><br></pre></td></tr></table></figure></li><li>其它常识：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clear all%清空所有变量</span><br><span class="line">close all%关闭所有Figure界面</span><br><span class="line">quit&#x2F;exit%退出Matlab</span><br></pre></td></tr></table></figure></li></ol><h2 id="CIFAR-10数据集"><a href="#CIFAR-10数据集" class="headerlink" title="CIFAR-10数据集"></a>CIFAR-10数据集</h2><p>&emsp;&emsp;该数据集的访问地址为<a href="http://www.cs.toronto.edu/~kriz/cifar.html，其中Python版本的图像显示可以参考[python实现cifar10数据集的可视化]" target="_blank" rel="noopener">http://www.cs.toronto.edu/~kriz/cifar.html，其中Python版本的图像显示可以参考[python实现cifar10数据集的可视化]</a>(<a href="http://blog.csdn.net/zengxyuyu/article/details/53232533" target="_blank" rel="noopener">http://blog.csdn.net/zengxyuyu/article/details/53232533</a> “python实现cifar10数据集的可视化”)。</p><p>Matlab版本的数据集中包含以下文件：</p><ul><li>batchs.meta.mat</li><li>data_batch_1.mat</li><li>data_batch_2.mat</li><li>data_batch_3.mat</li><li>data_batch_4.mat</li><li>data_batch_5.mat</li><li>readme.html</li><li>test_batch.mat<br>其中data_batch_i(1,2,3,4,5).mat中包含10000个32$*$32图片，共有50000张图片；test_batch.mat为测试集数据，共有10000张图片。</li></ul><h2 id="Matlab代码"><a href="#Matlab代码" class="headerlink" title="Matlab代码"></a>Matlab代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for j&#x3D;1:5,%读取训练集数据</span><br><span class="line">％读入第j个batch的数据</span><br><span class="line">    load([&#39;data_batch_&#39; num2str(j) &#39;.mat&#39;])</span><br><span class="line">    for i&#x3D;1:size(data,1),％循环转化并写入文件</span><br><span class="line">        p&#x3D;data(i,:);</span><br><span class="line">        label&#x3D;labels(i);</span><br><span class="line"></span><br><span class="line">        fig&#x3D;zeros(32,32,3);</span><br><span class="line">        fig(:,:,1)&#x3D;reshape(p(1:1024),32,32)&#39;;</span><br><span class="line">        fig(:,:,2)&#x3D;reshape(p(1025:2048),32,32)&#39;;</span><br><span class="line">        fig(:,:,3)&#x3D;reshape(p(2049:end),32,32)&#39;;</span><br><span class="line">        </span><br><span class="line">        ％将数据保存为PNG格式</span><br><span class="line">        imwrite(fig&#x2F;256,[&#39;image&#x2F;batch_&#39; num2str(j) &#39;_label_&#39; num2str(label) &#39;_&#39; num2str(i)  &#39;.png&#39;])</span><br><span class="line">    end;</span><br><span class="line">end;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac上MySQL出现错误：mysql.sock-错误</title>
      <link href="/2018/06/29/Mac%E4%B8%8AMySQL%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF%EF%BC%9Amysql-sock-%E9%94%99%E8%AF%AF/"/>
      <url>/2018/06/29/Mac%E4%B8%8AMySQL%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF%EF%BC%9Amysql-sock-%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;刚开始安装MySQL时，是直接使用brew安装的。安装之后直接能够使用，无需配置相关参数。使用一段时间之后，由于导出数据的需要，所以进行了相关配置，但出现了/tmp/mysql.sock error的问题。这里分享我解决此问题的方案。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ol><li>MAC OS；</li><li>MySQL V5.7;</li></ol><h2 id="修改配置信息"><a href="#修改配置信息" class="headerlink" title="修改配置信息"></a>修改配置信息</h2><p>&emsp;&emsp;主要是修改/private/etc/my.cnf文件，如果不存在，将安装文件下面support-files/my-default.conf，重命名并复制到该路径下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">［client］</span><br><span class="line">sock&#x3D;You path</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">sock&#x3D; You path</span><br></pre></td></tr></table></figure><p>其中两个路径必须相同。然后需要重新启动mysql即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># [mysql.sh]</span><br><span class="line">  1 #!&#x2F;bin&#x2F;bash</span><br><span class="line">  2 </span><br><span class="line">  3 </span><br><span class="line">  4 mysql_path&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line">  5 if [[ $1 &#x3D;&#x3D; &quot;start&quot; ]];</span><br><span class="line">  6 then</span><br><span class="line">  7     $mysql_path&#x2F;mysqld_safe -uroot &amp;&gt;.&#x2F;log_error.txt &amp;</span><br><span class="line">  8     echo $?</span><br><span class="line">  9     echo &quot;mysql start...&quot;</span><br><span class="line"> 10 elif [[ $1 &#x3D;&#x3D; &quot;stop&quot; ]];</span><br><span class="line"> 11 then</span><br><span class="line"> 12     $mysql_path&#x2F;mysqladmin -uroot shutdown &amp;&gt;.&#x2F;log_error.txt</span><br><span class="line"> 13     echo $?</span><br><span class="line"> 14     echo &quot;mysql stop...&quot;</span><br><span class="line"> 15 elif [[ $1 &#x3D;&#x3D; &quot;restart&quot; ]];</span><br><span class="line"> 16 then</span><br><span class="line"> 17     echo &quot;mysql restart...&quot;</span><br><span class="line"> 18 else</span><br><span class="line"> 19     echo &quot;please input start|stop|restart &quot;</span><br><span class="line"> 20 fi</span><br></pre></td></tr></table></figure><p>启动命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo .&#x2F;mysql.sh stop</span><br><span class="line">sudo .&#x2F;mysql.sh start</span><br></pre></td></tr></table></figure><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>&emsp;&emsp;如果出现其他的错误，请删除/usr/local/var/mysql下面的.err、.pid文件，然后就可以重新启动。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac上MySQL配置数据导出</title>
      <link href="/2018/06/29/Mac%E4%B8%8AMySQL%E9%85%8D%E7%BD%AE%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/"/>
      <url>/2018/06/29/Mac%E4%B8%8AMySQL%E9%85%8D%E7%BD%AE%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;MAC上使用brew安装的MySQL默认没有导出权限，需要手动配置。</p><a id="more"></a><h2 id="导出报错"><a href="#导出报错" class="headerlink" title="导出报错"></a>导出报错</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The MySQL server is running with the --secure-file-priv option</span><br></pre></td></tr></table></figure><p>在MySQL中查看secure-file-priv的值，发现为NULL：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select @@secure-file-priv;</span><br></pre></td></tr></table></figure><h2 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、MAC OS;</span><br><span class="line">2、MySQL 5.7;</span><br></pre></td></tr></table></figure><h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><p>&emsp;&emsp;直接安装的MySQL没有导出权限，这可以通过启动MySQL的log信息看到，其默认是关闭的。可以通过my.cnf来配置导出权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#[&#x2F;private&#x2F;etc&#x2F;my.cnf]</span><br><span class="line">[mysqld]</span><br><span class="line">secure-file-priv&#x3D;&quot;Your Path&quot;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;其中”Your Path”是你需要制定的能够访问的路径。配置好之后，可以重新启动MySQL的服务来使配置生效。启动方式，可以参考博主前面的文章。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 配置 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java邮件客户端发送邮件＋附件</title>
      <link href="/2018/06/29/Java%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%EF%BC%8B%E9%99%84%E4%BB%B6/"/>
      <url>/2018/06/29/Java%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%EF%BC%8B%E9%99%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;目前研究一下使用Java发送带有附件的邮件，从网上搜索了一下发现都存在各种各样的问题。在这里总结一下，展示一下基础代码，防止遗忘。</p><a id="more"></a><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">sendMail</span><span class="params">(String subject, String toMail,</span></span></span><br><span class="line"><span class="function"><span class="params">String content, String... files)</span> </span>&#123;</span><br><span class="line"><span class="keyword">boolean</span> isFlag = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">String smtpFromMail = <span class="string">"你的QQ号码@qq.com"</span>; <span class="comment">// 账号</span></span><br><span class="line">String pwd = <span class="string">"QQ上面申请的授权码"</span>; <span class="comment">// 密码</span></span><br><span class="line"><span class="keyword">int</span> port = <span class="number">465</span>; <span class="comment">// 端口</span></span><br><span class="line">String host = <span class="string">"smtp.qq.com"</span>; <span class="comment">// 端口</span></span><br><span class="line"></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(<span class="string">"mail.smtp.host"</span>, host);</span><br><span class="line">props.setProperty(<span class="string">"mail.smtp.socketFactory.class"</span>,</span><br><span class="line"><span class="string">"javax.net.ssl.SSLSocketFactory"</span>);</span><br><span class="line">props.put(<span class="string">"mail.smtp.auth"</span>, <span class="string">"true"</span>);</span><br><span class="line">Session session = Session.getDefaultInstance(props);</span><br><span class="line">session.setDebug(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">MimeMessage message = <span class="keyword">new</span> MimeMessage(session);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">message.setFrom(<span class="keyword">new</span> InternetAddress(smtpFromMail, <span class="string">"QQ邮件测试"</span>));</span><br><span class="line">message.addRecipient(Message.RecipientType.TO,</span><br><span class="line"><span class="keyword">new</span> InternetAddress(toMail));</span><br><span class="line">message.setSubject(subject);</span><br><span class="line">message.addHeader(<span class="string">"charset"</span>, <span class="string">"UTF-8"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 添加正文内容 */</span></span><br><span class="line">Multipart multipart = <span class="keyword">new</span> MimeMultipart();</span><br><span class="line">BodyPart contentPart = <span class="keyword">new</span> MimeBodyPart();</span><br><span class="line">contentPart.setText(content);</span><br><span class="line"></span><br><span class="line">contentPart.setHeader(<span class="string">"Content-Type"</span>,</span><br><span class="line"><span class="string">"text/html; charset=UTF-8"</span>);</span><br><span class="line">multipart.addBodyPart(contentPart);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 添加附件 */</span></span><br><span class="line"><span class="keyword">for</span> (String file : files) &#123;</span><br><span class="line">File usFile = <span class="keyword">new</span> File(file);</span><br><span class="line">MimeBodyPart fileBody = <span class="keyword">new</span> MimeBodyPart();</span><br><span class="line">DataSource source = <span class="keyword">new</span> FileDataSource(file);</span><br><span class="line">fileBody.setDataHandler(<span class="keyword">new</span> DataHandler(source));</span><br><span class="line">sun.misc.BASE64Encoder enc = <span class="keyword">new</span> sun.misc.BASE64Encoder();</span><br><span class="line">fileBody.setFileName(<span class="string">"=?GBK?B?"</span></span><br><span class="line">+ enc.encode(usFile.getName().getBytes()) + <span class="string">"?="</span>);</span><br><span class="line">multipart.addBodyPart(fileBody);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message.setContent(multipart);</span><br><span class="line">message.setSentDate(<span class="keyword">new</span> Date());</span><br><span class="line">message.saveChanges();</span><br><span class="line">Transport transport = session.getTransport(<span class="string">"smtp"</span>);</span><br><span class="line"></span><br><span class="line">transport.connect(host, port, smtpFromMail, pwd);</span><br><span class="line">transport.sendMessage(message, message.getAllRecipients());</span><br><span class="line">transport.close();</span><br><span class="line">isFlag = <span class="keyword">true</span>;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">isFlag = <span class="keyword">false</span>;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> isFlag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">boolean</span> res = Main.sendMail(<span class="string">"这是一封测试邮件"</span>, <span class="string">"想要发送的邮件地址"</span>,</span><br><span class="line"><span class="string">"朋友好久不见"</span>, <span class="string">"附件路径"</span>);</span><br><span class="line">System.out.println(<span class="string">"Resuylt: "</span> + res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><ol><li>使用Java客户端配置QQ邮箱发送邮件，需要现在QQ邮箱网页上申请授权码，发送邮件时放在密码的位置；</li><li>特别需要注意发送邮件的标题、正文内容的编码格式问题，不然容易造成乱码现象。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 邮件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本分类</title>
      <link href="/2018/06/29/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
      <url>/2018/06/29/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在文本分析中，其中有一类比较重要的应用就是将文本进行分类。这一类应用非常广泛，比如：情感分析［（正面、负面、中性）评价、（快乐、愤怒、痛苦）情感］、文章分类［汽车、时政、科技］等。</p><a id="more"></a><p>&emsp;&emsp;这里总结一些，防止遗忘。</p><h2 id="分词工具"><a href="#分词工具" class="headerlink" title="分词工具"></a>分词工具</h2><p>&emsp;&emsp;在Java平台上，一般可以使用Word分词，可以参考：<a href="https://my.oschina.net/apdplat/blog/228619，Github：https://github.com/ysc/word" target="_blank" rel="noopener">https://my.oschina.net/apdplat/blog/228619，Github：https://github.com/ysc/word</a> 。WORD分词的作者，比较了各类主流分词软件的各种性能，可以参考：<a href="https://github.com/ysc/cws_evaluation" target="_blank" rel="noopener">https://github.com/ysc/cws_evaluation</a> 。更详细的说明，可以参考作者的Github主页：<a href="https://github.com/ysc" target="_blank" rel="noopener">https://github.com/ysc</a> 。</p><p>&emsp;&emsp;在Python平台上，最著名的莫过于Jieba分词包啦，没听过的可以自行百度。</p><h2 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h2><h3 id="Spark环境"><a href="#Spark环境" class="headerlink" title="Spark环境"></a>Spark环境</h3><p>&emsp;&emsp;使用Spark进行分类的一般步骤：</p><ol><li>输入样本，进行分词； </li><li>输入分词之后的词组：一行表示一个输入样本，其中各个分词使用空格、逗号、分号等分割；</li><li>使用HashingTF进行转换为向量；</li><li>根据标签数据，进行训练；</li><li>输入未分类样本，进行标签预测；</li><li>计算准确率。</li></ol><h3 id="DL4J环境"><a href="#DL4J环境" class="headerlink" title="DL4J环境"></a>DL4J环境</h3><p>&emsp;&emsp;使用DeepLearning4J训练文本分类，需要事先计算词向量：</p><ol><li>样本分词；</li><li>计算词向量，并保存为向量文件；</li><li>根据LSTM等网络模型，输入词向量，进行训练；</li><li>得到训练结果，输出为文件。</li></ol><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>&emsp;&emsp;为了得到更好的效果涉及文本方面的模型，一般需要进行:<br>    1. 自定义词库：行业词库，实体词，名次，极性词库，情感词库等；<br>    2. 进行其它的相关模型，比如word2vec、关键词提取等辅助模型，提高精确度；<br>    3. 根据不同的语境、环境，进行特殊的处理，一般来说比较容易实现的就是指定一些”规则”。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>爬虫＋模拟登录</title>
      <link href="/2018/06/29/%E7%88%AC%E8%99%AB%EF%BC%8B%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95/"/>
      <url>/2018/06/29/%E7%88%AC%E8%99%AB%EF%BC%8B%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在一些爬虫中，需要用到账号登录进入，才能看到需要爬取的内容，因此实现程序自动模拟登录非常有必要。</p><p>&emsp;&emsp;目前大部分网站的登录，都是使用表单提交的方法实现的，这一类网站的模拟登录，相信度娘已经给出来的许多实例。还有一类网站不是使用网页自带表单提交的方法，网站自己实现了js方法来登录，这就需要进行特别的模拟浏览器行为。</p><a id="more"></a><p>&emsp;&emsp;本文用到的主要技术手段包括Selenium+Phantomjs+Jsoup。</p><h2 id="WebDriver"><a href="#WebDriver" class="headerlink" title="WebDriver"></a>WebDriver</h2><p>&emsp;&emsp;这里我们使用<em>Phantomjs</em>最为浏览器驱动，下面的方式是实现传入<em>Phantomjs</em>路径获取<em>WebDriver</em>的方法。其中随机产生UserAgent、打开JS运行开关，并设置了20S的默认超时时间。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@DESC</span> 获取PhantomJSDriver</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> phantomJS</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> WebDriver</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> WebDriver <span class="title">getPhantomJs</span><span class="params">(String phantomJS)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    System.setProperty(<span class="string">"phantomjs.binary.path"</span>, phantomJS);</span><br><span class="line"></span><br><span class="line">    DesiredCapabilities desiredCapabilities = DesiredCapabilities</span><br><span class="line">        .phantomjs();</span><br><span class="line">    desiredCapabilities.setJavascriptEnabled(<span class="keyword">true</span>);</span><br><span class="line">    String headers = getHeaders();<span class="comment">// 生成随机User_Agent</span></span><br><span class="line">    desiredCapabilities.setCapability(<span class="string">"phantomjs.page.settings.userAgent"</span>,</span><br><span class="line">        headers);</span><br><span class="line">    desiredCapabilities.setCapability(</span><br><span class="line">        <span class="string">"phantomjs.page.customHeaders.User-Agent"</span>, headers);</span><br><span class="line"></span><br><span class="line">    PhantomJSDriver driver = <span class="keyword">new</span> PhantomJSDriver(desiredCapabilities);</span><br><span class="line">    driver.manage().timeouts().implicitlyWait(<span class="number">20</span>, TimeUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> driver;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="模拟登录"><a href="#模拟登录" class="headerlink" title="模拟登录"></a>模拟登录</h2><p>&emsp;&emsp;这里主要是通过WebDriver访问网页，并在WebDriver上做一些实际的操作，例如查找网页元素、给网页元素赋值、运行相关的JS以及获取cookies等操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    WebDriver wd = getPhantomJs(<span class="string">"Your Phantomjs Path"</span>);</span><br><span class="line">    wd.get(<span class="string">"Target Website"</span>);</span><br><span class="line">    wd.findElement(By.id(<span class="string">"txtUserName"</span>)).sendKeys(</span><br><span class="line">        <span class="string">"Your Account"</span>);</span><br><span class="line">    wd.findElement(By.id(<span class="string">"txtPassword"</span>)).sendKeys(<span class="string">"Your Passwd"</span>);</span><br><span class="line">    JavascriptExecutor js = (JavascriptExecutor) wd;</span><br><span class="line">    js.executeScript(<span class="string">"网站登录方法［一般会在JS中找到，或触发，或点击］"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;<span class="comment">// 等待登录加载完成</span></span><br><span class="line">    Thread.sleep(PAUSE_TIME);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    Set&lt;Cookie&gt; coks = wd.manage().getCookies();</span><br><span class="line">    wd.quit();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 保存登录的Cookies</span></span><br><span class="line">    Map&lt;String, String&gt; cookies = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Cookie ck : coks)</span><br><span class="line">    cookies.put(ck.getName(), ck.getValue());</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟登陆 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我与汽车之家的三生三世</title>
      <link href="/2018/06/29/%E6%88%91%E4%B8%8E%E6%B1%BD%E8%BD%A6%E4%B9%8B%E5%AE%B6%E7%9A%84%E4%B8%89%E7%94%9F%E4%B8%89%E4%B8%96/"/>
      <url>/2018/06/29/%E6%88%91%E4%B8%8E%E6%B1%BD%E8%BD%A6%E4%B9%8B%E5%AE%B6%E7%9A%84%E4%B8%89%E7%94%9F%E4%B8%89%E4%B8%96/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;说起爬虫，目前存在许多流行的爬虫框架。其中最著名的莫过于Python语言方面的Scrapy，Java语言方面的Webcollector等。它们都是开源的轻量级爬虫工具，根据不同的使用场景、业务特点、开发人员的语言偏好，可以选择不同功能的开源框架。当然老司机，也可能自己开发一种爬虫功能框架，毕竟自己编写的才能够更好的配置、控制、使用爬虫，完成爬虫业务的需求。</p><a id="more"></a><h2 id="第一生"><a href="#第一生" class="headerlink" title="第一生"></a>第一生</h2><p>&emsp;&emsp;初进入爬虫坑洞感觉爬虫很难。刚开始选择的是使用Jsoup＋Java基本爬虫任务，当初是小量的数据，主要是做个人的研究学习数据。</p><p>&emsp;&emsp;刚开始汽车之家没有复杂的反扒虫策略，所以非常顺利的爬取到了需要的数据，这时候感觉不过如此。</p><p>&emsp;&emsp;后来想要更新一下数据发现以前的代码不能使用了，瞬间傻呆了。逐渐排除各种干扰因素，加上使用Chrome开发者工具不断的研究发现，汽车之家的发爬虫策略发生了升级。短短不到一个月的时间，汽车之家网站内部的一些板块采用了高级的发爬虫功能措施。</p><h2 id="第二生"><a href="#第二生" class="headerlink" title="第二生"></a>第二生</h2><p>&emsp;&emsp;针对汽车之家的反爬虫措施结合百度的内容，我发现使用PhantomJS+Java调用的方式，可以获取到汽车之家相关模块的内容。</p><p>&emsp;&emsp;使用Phantomjs无界面模拟浏览器可以运行JS，这样就可以跳过汽车之家设置的各种坑，还可以使用JS获取被隐藏掉的文字内容。这样又可以爬虫到想要的数据啦 ，而且感觉高大上了不少。</p><p>&emsp;&emsp;但是偶然的机会发现，汽车之家好像又出了一套新的发爬虫规则，这就是IP访问限制。这样就不能自由的爬虫了，需要找到新的解决方案。</p><h2 id="第三生"><a href="#第三生" class="headerlink" title="第三生"></a>第三生</h2><p>&emsp;&emsp;如果同一个IP地址大量的访问汽车之家网站，就会存在以下情况</p><ol><li>有一些访问会出现Timeout的情况；</li><li>返回码为429，也就是限制访问的请求数。</li></ol><p>&emsp;&emsp;这时候如果想要继续获取汽车之家的数据，就要从IP代理的角度或其它措施来处理了。这些措施的落地，一般是需要破费的。</p><p>&emsp;&emsp;刚开始使用爬取免费的IP代理，比如西刺IP、IP181、快代理等代理网站，但是时间一长免费代理IP基本上就废掉了。这时候还是需要使用付费的代理IP：一方面，不需要自己去考虑代理问题了，有服务商提供维护工作；另一方面，避免出现各种被攻击事件发生，相当于添加了一个隔离层。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&emsp;&emsp;通过爬虫数据，总结如下：<br>    1. 爬虫数据是一个时间输出的过程，大量的爬虫时间消耗来获取数据；<br>    2. 大规模爬虫，是需要破费的；<br>    3. 数据越来越成为一种资产的表现形式；<br>    4. 网站在爬虫与反爬虫的对抗中不断的升级，防御网络、识别黑户模型不断完善。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>各大地图API关于逆地理位置编码</title>
      <link href="/2018/06/29/%E5%90%84%E5%A4%A7%E5%9C%B0%E5%9B%BEAPI%E5%85%B3%E4%BA%8E%E9%80%86%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/"/>
      <url>/2018/06/29/%E5%90%84%E5%A4%A7%E5%9C%B0%E5%9B%BEAPI%E5%85%B3%E4%BA%8E%E9%80%86%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;物理网时代(IOT)，设备供应商可以获得大量的GPS信息，移动物品的GPS信息尤其重要。通过研究GPS的轨迹，或停留位置等信息，可以获得对营销、售后、商业合作等重要的信息。</p><a id="more"></a><p>&emsp;&emsp;想要了解GPS信息，首先需要通过编码，获取GPS的物理地址，以及GPS转化、编码等内容。本文作者遇到GPS逆编码问题，对比了百度地图API、高德地图API、腾讯地图API等三家国内主要地图供应商的API调用、条数限制、并发限制等内容。</p><h2 id="百度地图API"><a href="#百度地图API" class="headerlink" title="百度地图API"></a>百度地图API</h2><p>&emsp;&emsp;百度地图逆地址编码API，是放在Web服务API这一类中。存在两种方式：一，通过地址，获取百度坐标信息GPS；二，通过GPS，获取具体地址信息。</p><p>&emsp;&emsp;通过调用百度API逆地址编码，可以获得详细的地址信息，以及周边的POI信息，POI信息在该接口中给出了最近的10个。</p><h3 id="调用方式"><a href="#调用方式" class="headerlink" title="调用方式"></a>调用方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;api.map.baidu.com&#x2F;geocoder&#x2F;v2&#x2F;?address&#x3D;北京市海淀区上地十街10号&amp;output&#x3D;json&amp;ak&#x3D;你的ak&amp;callback&#x3D;showLocation</span><br></pre></td></tr></table></figure><p>具体可以参考百度地图API官方网站：<a href="http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding" target="_blank" rel="noopener">http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding</a></p><h3 id="配额限制"><a href="#配额限制" class="headerlink" title="配额限制"></a>配额限制</h3><table><thead><tr><th align="center">分类</th><th align="center">未认证</th><th align="center">个人认证</th><th align="center">企业认证</th></tr></thead><tbody><tr><td align="center">日配额（次）</td><td align="center">6,000</td><td align="center">300,000</td><td align="center">3000,000</td></tr><tr><td align="center">分钟并发量（次/分钟）</td><td align="center">3,000</td><td align="center">10,000</td><td align="center">60,000</td></tr><tr><td align="center">表中列出了，目前百度地图API存在的每日配额与并发量限制的具体数字。</td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h2 id="高德地图API"><a href="#高德地图API" class="headerlink" title="高德地图API"></a>高德地图API</h2><p>&emsp;&emsp;高德地图在移动端的市场占有率较高，在用户中的口碑也较好。我们研究了地图对逆地址编码的API的调用与配置限制。</p><h3 id="调用方式-1"><a href="#调用方式-1" class="headerlink" title="调用方式"></a>调用方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;restapi.amap.com&#x2F;v3&#x2F;geocode&#x2F;geo?parameters</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;其中输入参数包括但不限于：高德Key、address等参数。高德地图API的详细介绍，请参考官方主页：<a href="http://lbs.amap.com/api/webservice/guide/api/georegeo" target="_blank" rel="noopener">http://lbs.amap.com/api/webservice/guide/api/georegeo</a></p><h3 id="配额限制-1"><a href="#配额限制-1" class="headerlink" title="配额限制"></a>配额限制</h3><p>&emsp;&emsp;高德地图配额限制也是区分为个人开发者与企业开发者，相比百度地图个人开发者与企业开发者之间的配额差距更大。</p><p>![配额管理]](001.png)</p><h2 id="腾讯地图API"><a href="#腾讯地图API" class="headerlink" title="腾讯地图API"></a>腾讯地图API</h2><p>&emsp;&emsp;在查找soso地图的时候，发现soso地图官网上已经确实大部分文档，通过连接可以发现已经转移到腾讯地图。</p><h3 id="调用方式-2"><a href="#调用方式-2" class="headerlink" title="调用方式"></a>调用方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;apis.map.qq.com&#x2F;ws&#x2F;geocoder&#x2F;v1&#x2F;?location&#x3D;</span><br></pre></td></tr></table></figure><p>其中location为”lat,lng”这样的格式，具体API的详细介绍参考官网：<a href="http://lbs.qq.com/webservice_v1/guide-gcoder.html" target="_blank" rel="noopener">http://lbs.qq.com/webservice_v1/guide-gcoder.html</a></p><h3 id="配额限制-2"><a href="#配额限制-2" class="headerlink" title="配额限制"></a>配额限制</h3><p>&emsp;&emsp;腾讯地图API的限制比较简单，且不能申请增加配额，除非身份变为企业用户。</p><pre><code>日限制：1万次/Key/接口并发限制：5次/秒/Key/接口</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>逆地理位置编码，通过Webservice API 的方式调用，都存在每日/并发量限制；</li><li>但通过SDK、JavaScript API等方式调用，基本上是无限制条用；</li><li>三家地图API供应商中，百度对免费开发者最慷慨，获取的信息也是比较全面的；</li><li>腾讯地图API对企业申请，是最严格的，需要提供营业执照等证件。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无限制获取GPS对应地址的一种方法</title>
      <link href="/2018/06/29/%E6%97%A0%E9%99%90%E5%88%B6%E8%8E%B7%E5%8F%96GPS%E5%AF%B9%E5%BA%94%E5%9C%B0%E5%9D%80%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
      <url>/2018/06/29/%E6%97%A0%E9%99%90%E5%88%B6%E8%8E%B7%E5%8F%96GPS%E5%AF%B9%E5%BA%94%E5%9C%B0%E5%9D%80%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;市面上基本没有免费获取地理位置的方法，特别是对实时性要求比较高的情况下，基本上都是付费服务。</p><p>&emsp;&emsp;本文使用Google地图API，在实时性要求不太高的情况下，能够不断获取GPS对应地址位置信息。</p><a id="more"></a><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>&emsp;&emsp;调用Google地图API</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;maps.google.cn&#x2F;maps&#x2F;api&#x2F;geocode&#x2F;json?latlng&#x3D;lat,lng</span><br></pre></td></tr></table></figure><p>返回的数据为5条距离该GPS最近的地表信息，第一条一般为距离最近的建筑物信息。我们获取的信息为：formatted_address，即为格式化的地址信息。样例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">中国浙江省嘉兴市南湖区凤启路98号</span><br></pre></td></tr></table></figure><p>可以看出，该地中具有国家、省份、城市、区县、路名、具体位置等信息，完全符合我们的实际需求。</p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p>&emsp;&emsp;本文作者通过随机生成的30万条GPS数据测试，能够获取最终结果不会存在获取不到的情况。</p><p>&emsp;&emsp;通常情况下该API获取的内容存在状态字段，即：status字段。一般为“OK”，即爬去成功的，其他状态一般是请求出错、并发异常等内容引起的。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><pre><code>1. 该API对并发存在一定要求，因此无法大量、频繁并发获取内容；2. 比较好的一个方法是，通过高匿代理来获取API信息，每个代理使用几个线程，这样能够达到快速、高频并发的要求。</code></pre>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPS经纬度转化为百度地图/Google坐标及互转方案</title>
      <link href="/2018/06/29/GPS%E7%BB%8F%E7%BA%AC%E5%BA%A6%E8%BD%AC%E5%8C%96%E4%B8%BA%E7%99%BE%E5%BA%A6%E5%9C%B0%E5%9B%BE-Google%E5%9D%90%E6%A0%87%E5%8F%8A%E4%BA%92%E8%BD%AC%E6%96%B9%E6%A1%88/"/>
      <url>/2018/06/29/GPS%E7%BB%8F%E7%BA%AC%E5%BA%A6%E8%BD%AC%E5%8C%96%E4%B8%BA%E7%99%BE%E5%BA%A6%E5%9C%B0%E5%9B%BE-Google%E5%9D%90%E6%A0%87%E5%8F%8A%E4%BA%92%E8%BD%AC%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;转载自：<a href="https://blog.csdn.net/ma969070578/article/details/41013547" target="_blank" rel="noopener">WGS84，GCJ02， BD09坐标转换</a></p><a id="more"></a><h2 id="GPS类"><a href="#GPS类" class="headerlink" title="GPS类"></a>GPS类</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public class Gps &#123;</span><br><span class="line"> </span><br><span class="line">private double wgLat;</span><br><span class="line">private double wgLon;</span><br><span class="line"> </span><br><span class="line">public Gps(double wgLat, double wgLon) &#123;</span><br><span class="line">setWgLat(wgLat);</span><br><span class="line">setWgLon(wgLon);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public double getWgLat() &#123;</span><br><span class="line">return wgLat;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public void setWgLat(double wgLat) &#123;</span><br><span class="line">this.wgLat &#x3D; wgLat;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public double getWgLon() &#123;</span><br><span class="line">return wgLon;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public void setWgLon(double wgLon) &#123;</span><br><span class="line">this.wgLon &#x3D; wgLon;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">@Override</span><br><span class="line">public String toString() &#123;</span><br><span class="line">return wgLat + &quot;,&quot; + wgLon;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="转化Util"><a href="#转化Util" class="headerlink" title="转化Util"></a>转化Util</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 各地图API坐标系统比较与转换;</span><br><span class="line"> * WGS84坐标系：即地球坐标系，国际上通用的坐标系。设备一般包含GPS芯片或者北斗芯片获取的经纬度为WGS84地理坐标系,</span><br><span class="line"> * 谷歌地图采用的是WGS84地理坐标系（中国范围除外）;</span><br><span class="line"> * GCJ02坐标系：即火星坐标系，是由中国国家测绘局制订的地理信息系统的坐标系统。由WGS84坐标系经加密后的坐标系。</span><br><span class="line"> * 谷歌中国地图和搜搜中国地图采用的是GCJ02地理坐标系; BD09坐标系：即百度坐标系，GCJ02坐标系经加密后的坐标系;</span><br><span class="line"> * 搜狗坐标系、图吧坐标系等，估计也是在GCJ02基础上加密而成的。 chenhua</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class PositionUtil &#123;</span><br><span class="line"></span><br><span class="line">public static final String BAIDU_LBS_TYPE &#x3D; &quot;bd09ll&quot;;</span><br><span class="line"></span><br><span class="line">public static double pi &#x3D; 3.1415926535897932384626;</span><br><span class="line">public static double a &#x3D; 6378245.0;</span><br><span class="line">public static double ee &#x3D; 0.00669342162296594323;</span><br><span class="line"> </span><br><span class="line">&#x2F;**</span><br><span class="line"> * 84 to 火星坐标系 (GCJ-02) World Geodetic System &#x3D;&#x3D;&gt; Mars Geodetic System</span><br><span class="line"> * </span><br><span class="line"> * @param lat</span><br><span class="line"> * @param lon</span><br><span class="line"> * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Gps gps84_To_Gcj02(double lat, double lon) &#123;</span><br><span class="line">if (outOfChina(lat, lon)) &#123;</span><br><span class="line">return null;</span><br><span class="line">&#125;</span><br><span class="line">double dLat &#x3D; transformLat(lon - 105.0, lat - 35.0);</span><br><span class="line">double dLon &#x3D; transformLon(lon - 105.0, lat - 35.0);</span><br><span class="line">double radLat &#x3D; lat &#x2F; 180.0 * pi;</span><br><span class="line">double magic &#x3D; Math.sin(radLat);</span><br><span class="line">magic &#x3D; 1 - ee * magic * magic;</span><br><span class="line">double sqrtMagic &#x3D; Math.sqrt(magic);</span><br><span class="line">dLat &#x3D; (dLat * 180.0) &#x2F; ((a * (1 - ee)) &#x2F; (magic * sqrtMagic) * pi);</span><br><span class="line">dLon &#x3D; (dLon * 180.0) &#x2F; (a &#x2F; sqrtMagic * Math.cos(radLat) * pi);</span><br><span class="line">double mgLat &#x3D; lat + dLat;</span><br><span class="line">double mgLon &#x3D; lon + dLon;</span><br><span class="line">return new Gps(mgLat, mgLon);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;**</span><br><span class="line"> * * 火星坐标系 (GCJ-02) to 84 * * @param lon * @param lat * @return</span><br><span class="line"> * *&#x2F;</span><br><span class="line">public static Gps gcj_To_Gps84(double lat, double lon) &#123;</span><br><span class="line">Gps gps &#x3D; transform(lat, lon);</span><br><span class="line">double lontitude &#x3D; lon * 2 - gps.getWgLon();</span><br><span class="line">double latitude &#x3D; lat * 2 - gps.getWgLat();</span><br><span class="line">return new Gps(latitude, lontitude);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;**</span><br><span class="line"> * 火星坐标系 (GCJ-02) 与百度坐标系 (BD-09) 的转换算法 将 GCJ-02 坐标转换成 BD-09 坐标</span><br><span class="line"> * </span><br><span class="line"> * @param gg_lat</span><br><span class="line"> * @param gg_lon</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Gps gcj02_To_Bd09(double gg_lat, double gg_lon) &#123;</span><br><span class="line">double x &#x3D; gg_lon, y &#x3D; gg_lat;</span><br><span class="line">double z &#x3D; Math.sqrt(x * x + y * y) + 0.00002 * Math.sin(y * pi);</span><br><span class="line">double theta &#x3D; Math.atan2(y, x) + 0.000003 * Math.cos(x * pi);</span><br><span class="line">double bd_lon &#x3D; z * Math.cos(theta) + 0.0065;</span><br><span class="line">double bd_lat &#x3D; z * Math.sin(theta) + 0.006;</span><br><span class="line">return new Gps(bd_lat, bd_lon);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;**</span><br><span class="line"> * * 火星坐标系 (GCJ-02) 与百度坐标系 (BD-09) 的转换算法 * * 将 BD-09 坐标转换成GCJ-02 坐标 * * @param</span><br><span class="line"> * bd_lat * @param bd_lon * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Gps bd09_To_Gcj02(double bd_lat, double bd_lon) &#123;</span><br><span class="line">double x &#x3D; bd_lon - 0.0065, y &#x3D; bd_lat - 0.006;</span><br><span class="line">double z &#x3D; Math.sqrt(x * x + y * y) - 0.00002 * Math.sin(y * pi);</span><br><span class="line">double theta &#x3D; Math.atan2(y, x) - 0.000003 * Math.cos(x * pi);</span><br><span class="line">double gg_lon &#x3D; z * Math.cos(theta);</span><br><span class="line">double gg_lat &#x3D; z * Math.sin(theta);</span><br><span class="line">return new Gps(gg_lat, gg_lon);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#x2F;**</span><br><span class="line"> * (BD-09)--&gt;84</span><br><span class="line"> * @param bd_lat</span><br><span class="line"> * @param bd_lon</span><br><span class="line"> * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static Gps bd09_To_Gps84(double bd_lat, double bd_lon) &#123;</span><br><span class="line"> </span><br><span class="line">Gps gcj02 &#x3D; PositionUtil.bd09_To_Gcj02(bd_lat, bd_lon);</span><br><span class="line">Gps map84 &#x3D; PositionUtil.gcj_To_Gps84(gcj02.getWgLat(),</span><br><span class="line">gcj02.getWgLon());</span><br><span class="line">return map84;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static boolean outOfChina(double lat, double lon) &#123;</span><br><span class="line">if (lon &lt; 72.004 || lon &gt; 137.8347)</span><br><span class="line">return true;</span><br><span class="line">if (lat &lt; 0.8293 || lat &gt; 55.8271)</span><br><span class="line">return true;</span><br><span class="line">return false;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static Gps transform(double lat, double lon) &#123;</span><br><span class="line">if (outOfChina(lat, lon)) &#123;</span><br><span class="line">return new Gps(lat, lon);</span><br><span class="line">&#125;</span><br><span class="line">double dLat &#x3D; transformLat(lon - 105.0, lat - 35.0);</span><br><span class="line">double dLon &#x3D; transformLon(lon - 105.0, lat - 35.0);</span><br><span class="line">double radLat &#x3D; lat &#x2F; 180.0 * pi;</span><br><span class="line">double magic &#x3D; Math.sin(radLat);</span><br><span class="line">magic &#x3D; 1 - ee * magic * magic;</span><br><span class="line">double sqrtMagic &#x3D; Math.sqrt(magic);</span><br><span class="line">dLat &#x3D; (dLat * 180.0) &#x2F; ((a * (1 - ee)) &#x2F; (magic * sqrtMagic) * pi);</span><br><span class="line">dLon &#x3D; (dLon * 180.0) &#x2F; (a &#x2F; sqrtMagic * Math.cos(radLat) * pi);</span><br><span class="line">double mgLat &#x3D; lat + dLat;</span><br><span class="line">double mgLon &#x3D; lon + dLon;</span><br><span class="line">return new Gps(mgLat, mgLon);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static double transformLat(double x, double y) &#123;</span><br><span class="line">double ret &#x3D; -100.0 + 2.0 * x + 3.0 * y + 0.2 * y * y + 0.1 * x * y</span><br><span class="line">+ 0.2 * Math.sqrt(Math.abs(x));</span><br><span class="line">ret +&#x3D; (20.0 * Math.sin(6.0 * x * pi) + 20.0 * Math.sin(2.0 * x * pi)) * 2.0 &#x2F; 3.0;</span><br><span class="line">ret +&#x3D; (20.0 * Math.sin(y * pi) + 40.0 * Math.sin(y &#x2F; 3.0 * pi)) * 2.0 &#x2F; 3.0;</span><br><span class="line">ret +&#x3D; (160.0 * Math.sin(y &#x2F; 12.0 * pi) + 320 * Math.sin(y * pi &#x2F; 30.0)) * 2.0 &#x2F; 3.0;</span><br><span class="line">return ret;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static double transformLon(double x, double y) &#123;</span><br><span class="line">double ret &#x3D; 300.0 + x + 2.0 * y + 0.1 * x * x + 0.1 * x * y + 0.1</span><br><span class="line">* Math.sqrt(Math.abs(x));</span><br><span class="line">ret +&#x3D; (20.0 * Math.sin(6.0 * x * pi) + 20.0 * Math.sin(2.0 * x * pi)) * 2.0 &#x2F; 3.0;</span><br><span class="line">ret +&#x3D; (20.0 * Math.sin(x * pi) + 40.0 * Math.sin(x &#x2F; 3.0 * pi)) * 2.0 &#x2F; 3.0;</span><br><span class="line">ret +&#x3D; (150.0 * Math.sin(x &#x2F; 12.0 * pi) + 300.0 * Math.sin(x &#x2F; 30.0</span><br><span class="line">* pi)) * 2.0 &#x2F; 3.0;</span><br><span class="line">return ret;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line"> </span><br><span class="line">&#x2F;&#x2F; 北斗芯片获取的经纬度为WGS84地理坐标 31.426896,119.496145</span><br><span class="line">Gps gps &#x3D; new Gps(31.426896, 119.496145);</span><br><span class="line">System.out.println(&quot;gps :&quot; + gps);</span><br><span class="line">Gps gcj &#x3D; gps84_To_Gcj02(gps.getWgLat(), gps.getWgLon());</span><br><span class="line">System.out.println(&quot;gcj :&quot; + gcj);</span><br><span class="line">Gps star &#x3D; gcj_To_Gps84(gcj.getWgLat(), gcj.getWgLon());</span><br><span class="line">System.out.println(&quot;star:&quot; + star);</span><br><span class="line">Gps bd &#x3D; gcj02_To_Bd09(gcj.getWgLat(), gcj.getWgLon());</span><br><span class="line">System.out.println(&quot;bd  :&quot; + bd);</span><br><span class="line">Gps gcj2 &#x3D; bd09_To_Gcj02(bd.getWgLat(), bd.getWgLon());</span><br><span class="line">System.out.println(&quot;gcj :&quot; + gcj2);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> GPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解析离线地图包可行性分析</title>
      <link href="/2018/06/29/%E8%A7%A3%E6%9E%90%E7%A6%BB%E7%BA%BF%E5%9C%B0%E5%9B%BE%E5%8C%85%E5%8F%AF%E8%A1%8C%E6%80%A7%E5%88%86%E6%9E%90/"/>
      <url>/2018/06/29/%E8%A7%A3%E6%9E%90%E7%A6%BB%E7%BA%BF%E5%9C%B0%E5%9B%BE%E5%8C%85%E5%8F%AF%E8%A1%8C%E6%80%A7%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;当今数据作为一家公司最重要的资产，可被该公司用来租赁、买卖、二次开发等使用。但外部人员非合理使用该公司数据，可能构成违法犯罪行为。</p><a id="more"></a><p>&emsp;&emsp;各大地图供应商，包括但不限于百度、腾讯、高德等都有自己的地理数据编码格式，以及开放出来的API供开发者/用户使用。</p><p>&emsp;&emsp;通过研究发现，解析离线地图包来获取地图数据的方式是不可行的。主要基于以下几点：</p><pre><code>1.  离线地图包，存在数据加密。在不知道解密方式的情况下，解密的时间成本可能为无限大。2.  可能构成违法犯罪行为。恶意破击离线地图包，获取地图数据，可能被认为是一种破坏地图公司资产的一种行为。3.  地图公司，不可能将地图所有数据都放在离线地图包中。核心数据，可能是要通过请求Server的方式来获得。</code></pre><p>&emsp;&emsp;所以解析地图包的方式，基本上是不可行的。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JXL简单操作xls表格文件--写入文件</title>
      <link href="/2018/06/29/JXL%E7%AE%80%E5%8D%95%E6%93%8D%E4%BD%9Cxls%E8%A1%A8%E6%A0%BC%E6%96%87%E4%BB%B6-%E5%86%99%E5%85%A5%E6%96%87%E4%BB%B6/"/>
      <url>/2018/06/29/JXL%E7%AE%80%E5%8D%95%E6%93%8D%E4%BD%9Cxls%E8%A1%A8%E6%A0%BC%E6%96%87%E4%BB%B6-%E5%86%99%E5%85%A5%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;工作时用到写入Excel的场景，发现有Apache POI提供的jar包与JXL的jar包。实际操作时，个人感觉poi比较高大上，基本上能够实现excel的大部分功能，包括字体设置、表格设置等内容，但相对门槛较高，操作复杂。相比POI，JXL操作简单，容易入门，相比而言得到的EXCEL文档也是比简单，不需要特殊的格式化。</p><a id="more"></a><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write2xlsStr</span><span class="params">(WritableWorkbook book, String[] title,</span></span></span><br><span class="line"><span class="function"><span class="params">List&lt;String[]&gt; lst)</span> <span class="keyword">throws</span> RowsExceededException, WriteException,</span></span><br><span class="line"><span class="function">IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">WritableSheet sheet = book.createSheet(<span class="string">"Page_First"</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> colSize = title.length;</span><br><span class="line"><span class="keyword">int</span> rowSize = lst.size();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colSize; i++)</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(i, <span class="number">0</span>, title[i]));</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colSize; j++)</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(j, i + <span class="number">1</span>, lst.get(i)[j]));</span><br><span class="line">book.write();</span><br><span class="line">book.close();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write2xlsLst</span><span class="params">(WritableWorkbook book, String[] title,</span></span></span><br><span class="line"><span class="function"><span class="params">List&lt;List&lt;String&gt;&gt; lst)</span> <span class="keyword">throws</span> RowsExceededException,</span></span><br><span class="line"><span class="function">WriteException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">WritableSheet sheet = book.createSheet(<span class="string">"Page_First"</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> colSize = title.length;</span><br><span class="line"><span class="keyword">int</span> rowSize = lst.size();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colSize; i++)</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(i, <span class="number">0</span>, title[i]));</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++)</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colSize; j++)</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(j, i + <span class="number">1</span>, lst.get(i).get(j)));</span><br><span class="line">book.write();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> WritableWorkbook <span class="title">getWorkBook</span><span class="params">(String filename)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="keyword">return</span> Workbook.createWorkbook(<span class="keyword">new</span> File(filename));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write2xlsMap</span><span class="params">(WritableWorkbook book, String sheetname,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">int</span> index, List&lt;Map&lt;String, Object&gt;&gt; lst)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> RowsExceededException, WriteException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">WritableSheet sheet = book.createSheet(sheetname, index);</span><br><span class="line"><span class="keyword">int</span> colSize = lst.get(<span class="number">0</span>).keySet().size();</span><br><span class="line"><span class="keyword">int</span> rowSize = lst.size();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (colSize &lt; <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">if</span> (rowSize &lt; <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> ind = <span class="number">0</span>;</span><br><span class="line">String[] title = <span class="keyword">new</span> String[colSize];</span><br><span class="line"><span class="keyword">for</span> (String str : lst.get(<span class="number">0</span>).keySet()) &#123;</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(ind, <span class="number">0</span>, str));</span><br><span class="line">title[ind++] = str;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> col_index = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> row_index = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> names = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rowSize; i++) &#123;</span><br><span class="line">col_index = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colSize; j++) &#123;</span><br><span class="line">sheet.addCell(<span class="keyword">new</span> Label(col_index, row_index + <span class="number">1</span>, <span class="string">""</span></span><br><span class="line">+ lst.get(row_index).get(title[col_index])));</span><br><span class="line">col_index++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (row_index++ &gt; MAX_ITEMS) &#123;</span><br><span class="line">row_index = <span class="number">0</span>;</span><br><span class="line">sheet = book.createSheet(sheetname + <span class="string">"add_"</span> + (names), index</span><br><span class="line">+ (names++));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">book.write();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用时，可参考如下方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WritableWorkbook book &#x3D; getWorkBook(&quot;Filepath&quot;);</span><br><span class="line">&#x2F;&#x2F; your data format: list for list&lt;map&gt; data</span><br><span class="line">write2xlsMap(book,...);</span><br><span class="line">book.close();</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Excel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一种可行性Java爬虫框架</title>
      <link href="/2018/06/29/%E4%B8%80%E7%A7%8D%E5%8F%AF%E8%A1%8C%E6%80%A7Java%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/"/>
      <url>/2018/06/29/%E4%B8%80%E7%A7%8D%E5%8F%AF%E8%A1%8C%E6%80%A7Java%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;简单的Java爬虫框架流程图，不包括容灾机制、异常处理等内容。</p><a id="more"></a><h2 id="框架流程图"><a href="#框架流程图" class="headerlink" title="框架流程图"></a>框架流程图</h2><p><img src="/.io//001.png" alt="Java爬虫可行性框架"></p><p>&emsp;&emsp;搭建分布式爬虫系统，框架的主要工作是打通队列、存储之间的联系。之后的工作，包括爬虫策略、容灾机制、错误处理等，都是通过爬虫节点来处理。<br>&emsp;&emsp;事实上，只要框架搭建好之后，不断完善本地爬虫策略【使用内存队列】，就能够很好的实现分布式爬虫。</p><h2 id="爬虫节点"><a href="#爬虫节点" class="headerlink" title="爬虫节点"></a>爬虫节点</h2><p>爬虫节点设计的主要内容，包括但不限于：<br>    1. 爬虫深度；<br>    2. 爬虫策略；<br>    3. 爬虫方式；<br>    4. 内容解析；<br>    5. 错误异常处理机制；<br>    6. 多线程处理.<br>等内容。<br></p><h2 id="主要框架"><a href="#主要框架" class="headerlink" title="主要框架"></a>主要框架</h2><p>目前比较完善的Java爬虫框架，主要包括<br>    1. WebCollector，主要用于单机模式；<br>    2. WebMagic，易于扩展，能够实现分布式爬虫策略。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>判断GPS省市/区县非API调用方法</title>
      <link href="/2018/06/29/%E5%88%A4%E6%96%ADGPS%E7%9C%81%E5%B8%82-%E5%8C%BA%E5%8E%BF%E9%9D%9EAPI%E8%B0%83%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2018/06/29/%E5%88%A4%E6%96%ADGPS%E7%9C%81%E5%B8%82-%E5%8C%BA%E5%8E%BF%E9%9D%9EAPI%E8%B0%83%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;判断一个GPS点是否位于某省市/区县内，通常可以调用地图API来解决，通过调用逆地理信息API，可以获得完整的地址信息，因此可以判断该GPS的省市/区县。</p><a id="more"></a><p>&emsp;&emsp;本文基于省市/区县的隶属关系，及其形状的几何关系，判断一个GPS点的隶属信息。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>&emsp;&emsp;如何判断一个点是否位于某几何形状之内呢？<br>&emsp;&emsp;参考文献：<a href="http://blog.csdn.net/bitcarmanlee/article/details/60591192" target="_blank" rel="noopener">判断一个点是否在多边形区域内</a></p><h2 id="判断"><a href="#判断" class="headerlink" title="判断"></a>判断</h2><p>&emsp;&emsp;根据中国各省/直辖市边界，以及省市包含二级行政划分的边界信息，以及三级区县划分的边界信息，可以逐层判断是否包含该GPS。最后，可以获得GPS位于的省市/区县信息。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p><img src="/.io//001.png" alt="判断隶属关系"></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java使用付费代理的两种实现方法</title>
      <link href="/2018/06/29/Java%E4%BD%BF%E7%94%A8%E4%BB%98%E8%B4%B9%E4%BB%A3%E7%90%86%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/"/>
      <url>/2018/06/29/Java%E4%BD%BF%E7%94%A8%E4%BB%98%E8%B4%B9%E4%BB%A3%E7%90%86%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;免费代理，如西刺代理、快代理等代理网站公布的代理地址，常常存在几个问题：<br>        &nbsp;&nbsp;1. 存在反扒措施，如限制爬虫频率、存在并发数限制、封IP等；<br>        &nbsp;&nbsp;2. 免费代理存在时效性，无法长时间使用。</p><p>&emsp;&emsp;目前获得稳定性能的最佳途径就是购买代理服务资源，通过代理服务商给出的IP:Port，UserName:Password来访问代理服务器，从而获得良好的代理体验。</p><a id="more"></a><p>&emsp;&emsp;本文简单介绍，使用代理服务器的几种方式。</p><h2 id="CURL访问"><a href="#CURL访问" class="headerlink" title="CURL访问"></a>CURL访问</h2><p>使用curl访问代理资源的方法如下所示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -x username:passwd@agentIP:agentPort URL</span><br></pre></td></tr></table></figure><p>这样可以通过代理服务器访问到相应的网络资源。注：通常，-X标识请求方法。</p><h2 id="Java设置系统变量方法"><a href="#Java设置系统变量方法" class="headerlink" title="Java设置系统变量方法"></a>Java设置系统变量方法</h2><p>使用Java通过代理服务器来访问资源，通常可以如下设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">System.setProperty(&quot;http.proxyHost&quot;,&quot;Proxy Server&quot;);</span><br><span class="line">System.setProperty(&quot;http.proxyPort&quot;,&quot;Proxy port&quot;);</span><br><span class="line">System.setProperty(&quot;http.proxyUser&quot;,&quot;User&quot;);</span><br><span class="line">System.setProperty(&quot;http.proxyPassword&quot;,&quot;password&quot;);</span><br></pre></td></tr></table></figure><p>通过设置系统变量的方法来设置代理服务器的地址、端口，以及用户名、密码等变量。</p><h2 id="Java使用授权方式"><a href="#Java使用授权方式" class="headerlink" title="Java使用授权方式"></a>Java使用授权方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 授权密码</span><br><span class="line">Authenticator.setDefault(new BasicAuthenticator(proxy_user,proxy_pass));</span><br><span class="line">Proxy proxy &#x3D; new java.net.Proxy(java.net.Proxy.Type.HTTP,new InetSocketAddress(proxy_ip,proxy_port));</span><br></pre></td></tr></table></figure><p>通过Java类实现动态授权，设置代理参数。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch-存放地理信息数据+百度POI分析</title>
      <link href="/2018/06/29/Elasticsearch-%E5%AD%98%E6%94%BE%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E6%95%B0%E6%8D%AE-%E7%99%BE%E5%BA%A6POI%E5%88%86%E6%9E%90/"/>
      <url>/2018/06/29/Elasticsearch-%E5%AD%98%E6%94%BE%E5%9C%B0%E7%90%86%E4%BF%A1%E6%81%AF%E6%95%B0%E6%8D%AE-%E7%99%BE%E5%BA%A6POI%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;ES是一个全文搜索引擎，同时也是一个NoSQL数据库，其存放数据方便与检索数据性能优越，受到普遍欢迎。</p><a id="more"></a><h2 id="ES架构"><a href="#ES架构" class="headerlink" title="ES架构"></a>ES架构</h2><p>参考文章：<a href="http://www.cnblogs.com/tgzhu/p/6098339.html" target="_blank" rel="noopener">架构及原理</a></p><h2 id="ES地理数据操作"><a href="#ES地理数据操作" class="headerlink" title="ES地理数据操作"></a>ES地理数据操作</h2><p>&emsp;&emsp;参考文章：<a href="http://blog.csdn.net/u012332735/article/details/54971638" target="_blank" rel="noopener">Elasticsearch地理位置总结</a></p><h2 id="ES实际操作"><a href="#ES实际操作" class="headerlink" title="ES实际操作"></a>ES实际操作</h2><h3 id="建立Index"><a href="#建立Index" class="headerlink" title="建立Index"></a>建立Index</h3><p>&emsp;&emsp;一般有两种方式</p><ol><li>ES Head通过界面化操作，直接可以建立Index:<br><img src="/.io//001.png" alt="create es idex"><br><img src="/.io//002.png" alt="detail page"></li><li>通过ES API可以创建Index。一般可以选择Java/Python的ES接口API，可以实现该功能。</li></ol><h3 id="建立Type"><a href="#建立Type" class="headerlink" title="建立Type"></a>建立Type</h3><p>&emsp;&emsp;虽然ES允许事先不建立Index，就可以直接插入数据。但这种方式存在安全隐患，比如类型转换，类型设置等方面的隐患。最好的方式就是实现创建Index/Type，定义好需要插入数据的类型，方便后期检索。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &#39;ES Server IP:9200&#x2F;Test?pretty&#39; -H &#39;Content-Type: application&#x2F;json&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">&quot;settings&quot;: &#123;</span><br><span class="line">&quot;index&quot;: &#123;</span><br><span class="line">&quot;number_of_shards&quot;: 5,</span><br><span class="line">&quot;number_of_replicas&quot;: 2</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;mappings&quot;: &#123;</span><br><span class="line">&quot;test&quot;: &#123;</span><br><span class="line">&quot;properties&quot;: &#123;</span><br><span class="line">&quot;province&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;city&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;district&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;street&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;name&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;location&quot;: &#123;</span><br><span class="line">&quot;type&quot;: &quot;geo_point&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><p>&emsp;&emsp;这里使用Java API实现将数据插入ES的功能，关于ES Client的使用，可以参考文章：<a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/index.html</a></p><h2 id="选择ES的目的"><a href="#选择ES的目的" class="headerlink" title="选择ES的目的"></a>选择ES的目的</h2><ol><li>通过ES，可以实现去重的功能：因为不同位置爬去POI，可能重复；</li><li>通过ES的地理位置，可以方便的获取某个GPS坐标点附近的POI信息，也可以计算距离信息等；</li><li>ES查询性能优越，数据压缩存储，相比MongoDB数据库占用更少的空间。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch-vs-mongodb</title>
      <link href="/2018/06/29/elasticsearch-vs-mongodb/"/>
      <url>/2018/06/29/elasticsearch-vs-mongodb/</url>
      
        <content type="html"><![CDATA[<h2 id="原文翻译"><a href="#原文翻译" class="headerlink" title="原文翻译"></a>原文翻译</h2><p>&emsp;&emsp;选择Elasticsearch还是选择MongoDB，该问题我已经被许多初学者、朋友或需要作出技术架构决策的开发者问及好多次了。那么应该选择MongoDB，还是选择ElasticSearch呢？因此，这里我简短的介绍一下MongoDB与Elasticsearch的不同之处，且言明在什么场景下那个作为首要选项。我假设读者已经了解了关于MongoDB/Elasticsearch的基本概念。</p><a id="more"></a><p>&emsp;&emsp;假设两者都存储Key-Value数据对且允许查询数据对象中的内容。但两者来自不同的场景，且具有不同的目的。</p><p>&emsp;&emsp;MongoDB是一个通用性数据库，Elasticsearch是一个Lucene支持的分布式文本检索引擎。针对大型数据集的索引与检索功能，Elasticsearch性能非常优越。当你有关于数据的附加属性且你能够知道具体需要查询的记录时，通常可以使用Elasticsearch。因为Elasticsearch针对这一功能进行特殊优化过的，所以它在其他方面的性能相对弱一些。例如相对其他No-SQL数据库而言，ELasticsearch在增加新数据时，速度相对较慢。在Elasticsearch索引中语法过程是在客户端中定义的，所以实际索引过程不能像实际存储一样得到优化。</p><p>&emsp;&emsp;实践中，Elasticsearch通常与No-SQL或SQL数据库配合使用，其中数据库作为持久化存储组件，而Elasticsearch基于数据内容做更加复杂的搜索查询。例如我们在Mebelkart时，曾经使用Elasticsearch基于MySQL做全产品、零售商、产品浏览、类别目录等的索引，我们从Elasticsearch索引中做读取(复杂查询)、全文检索等操作。如果你需要建立一个带有复杂过滤或搜索操作的应用，Elasticsearch/Solr是目前唯一最佳的选择。</p><p>&emsp;&emsp;当然可以把Elasticsearch作为首选项，但更好的方式是基于如No-SQL/MySQL的持久化数据库使用Elasticsearch。持久化存储能够提供约束限制、准确性保证、鲁棒性等条件，你只需要将数据添加/更新到Elasticsearch即可。</p><h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>&emsp;&emsp;翻译文章来源：<a href="http://www.ranjeetvimal.com/elasticsearch-vs-mongodb/" target="_blank" rel="noopener">elasticsearch vs mongodb</a></p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> ES </tag>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTML全文转化为PDF技术选型研究与流行方法汇总</title>
      <link href="/2018/06/29/HTML%E5%85%A8%E6%96%87%E8%BD%AC%E5%8C%96%E4%B8%BAPDF%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E7%A0%94%E7%A9%B6%E4%B8%8E%E6%B5%81%E8%A1%8C%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>/2018/06/29/HTML%E5%85%A8%E6%96%87%E8%BD%AC%E5%8C%96%E4%B8%BAPDF%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E7%A0%94%E7%A9%B6%E4%B8%8E%E6%B5%81%E8%A1%8C%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在实际也无需求中，需要用到网页快照功能，并能够查看历史网页快照功能，因此需要实现网页格式的固化保存，保存为图片或PDF文件的形式。</p><a id="more"></a><h2 id="1-技术研究"><a href="#1-技术研究" class="headerlink" title="1. 技术研究"></a>1. 技术研究</h2><p>&emsp;&emsp;做这样研究了网上许多技术，大都存在各种各样的缺陷。</p><h3 id="1-1-html2canvas-amp-jsPDF"><a href="#1-1-html2canvas-amp-jsPDF" class="headerlink" title="1.1. html2canvas&amp;jsPDF"></a>1.1. html2canvas&amp;jsPDF</h3><p>&emsp;&emsp;感兴趣的读者，可以参考： <a href="https://github.com/linwalker/render-html-to-pdf" target="_blank" rel="noopener">https://github.com/linwalker/render-html-to-pdf</a><br>&emsp;&emsp;该种方法，主要是通过JS调用实现，无法通过脚本，或者Java API的方法调用来实现转化工作。</p><h3 id="1-2-iTextRender-amp-pdfWriter"><a href="#1-2-iTextRender-amp-pdfWriter" class="headerlink" title="1.2. iTextRender&amp;pdfWriter"></a>1.2. iTextRender&amp;pdfWriter</h3><p>&emsp;&emsp;这种方式能够实现简单的Html2PDF功能，但存在以下缺点</p><ol><li>对网页格式要求较高；</li><li>无法对图片等复杂元素进行处理。<br>主要参考博文：<br><a href="http://swordshadow.iteye.com/blog/1983935" target="_blank" rel="noopener">Itext的PDF生成方案</a><br><a href="http://skyfar666.iteye.com/blog/2001353" target="_blank" rel="noopener">freemarker+ITextRenderer 生成html转pdf</a><br><a href="http://www.cnblogs.com/reese-blogs/p/5546806.html" target="_blank" rel="noopener">iTextRenderer(Flying Saucer) HTML转PDF</a></li></ol><h3 id="1-3-pdf-kit"><a href="#1-3-pdf-kit" class="headerlink" title="1.3. pdf-kit"></a>1.3. pdf-kit</h3><p>&emsp;&emsp;pdf-kit主要通过JS生成PDF文件，在HTML截图方面比较欠缺，作者没有发现能够用于截图功能。<br><a href="http://pdfkit.org/" target="_blank" rel="noopener">PDF-KIT官网</a></p><h3 id="1-4-cssbox"><a href="#1-4-cssbox" class="headerlink" title="1.4. cssbox"></a>1.4. cssbox</h3><p>&emsp;&emsp;cssbox主要用作前段css渲染功能，但没有提供输出为图片或PDF接口。<br><a href="http://cssbox.sourceforge.net/" target="_blank" rel="noopener">CSSBOX源码文件与说明</a></p><h3 id="1-5-Phantomjs"><a href="#1-5-Phantomjs" class="headerlink" title="1.5. Phantomjs"></a>1.5. Phantomjs</h3><p>&emsp;&emsp;爬虫或自动化测试重量级程序，能够实现爬虫功能与自动化测试任务。并能够使用代理服务器，或输出HTML为图片或DPF文件的形式。能够输出单个网页控件的图片或DPF文件，实现精准输出。</p><p>&emsp;&emsp;但Phantomjs存在如下问题：</p><ol><li>相应速度较慢；</li><li>调用繁琐，需要自己写JS脚本。</li></ol><h3 id="1-6-Headless-Chrome-or-other-browser"><a href="#1-6-Headless-Chrome-or-other-browser" class="headerlink" title="1.6. Headless Chrome or other browser"></a>1.6. Headless Chrome or other browser</h3><p>&emsp;&emsp;使用无头浏览器，调用snapshot接口，能够实现截图功能。</p><h3 id="1-7-HtmlUnitDriver调用浏览器API"><a href="#1-7-HtmlUnitDriver调用浏览器API" class="headerlink" title="1.7. HtmlUnitDriver调用浏览器API"></a>1.7. HtmlUnitDriver调用浏览器API</h3><p>使用HtmlUnitDriver调用浏览器API，如Chrome、Firefox、IE等主浏览器，均能实现截图功能。</p><p>缺点：</p><ol><li>需要编写程序，调用API；</li><li>无法直接调用脚本实现截图功能。</li></ol><h2 id="2-wkhtmltopdf"><a href="#2-wkhtmltopdf" class="headerlink" title="2. wkhtmltopdf"></a>2. wkhtmltopdf</h2><p>&emsp;&emsp;该程序能够实现将Html转化为图片，或PDF文件的功能，具体下载地址为：<a href="https://wkhtmltopdf.org/downloads.html" target="_blank" rel="noopener">wkhtmltopdf官网下载</a></p><h3 id="2-1-安装流程"><a href="#2-1-安装流程" class="headerlink" title="2.1. 安装流程"></a>2.1. 安装流程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">## Download from Org website</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;wkhtmltopdf&#x2F;wkhtmltopdf&#x2F;releases&#x2F;download&#x2F;0.12.4&#x2F;wkhtmltox-0.12.4_linux-generic-amd64.tar.xz</span><br><span class="line"></span><br><span class="line">## uncompress</span><br><span class="line"> tar xvJf wkhtmltox-0.12.4_linux-generic-amd64.tar.xz</span><br><span class="line"></span><br><span class="line">## install font : chinese : 宋体</span><br><span class="line">## &#x2F;usr&#x2F;share&#x2F;fonts&#x2F;XXX</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;安装中文字体，主要是考虑到网页内容为中文会出现中文乱码问题。</p><h3 id="2-2-调用"><a href="#2-2-调用" class="headerlink" title="2.2. 调用"></a>2.2. 调用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## to pdf</span><br><span class="line">wkhtmltopdf http:&#x2F;&#x2F;www.baidu.com ~&#x2F;baidu.pdf</span><br><span class="line"></span><br><span class="line">## to image</span><br><span class="line">wkhtmltopdf http:&#x2F;&#x2F;www.baidu.com ~&#x2F;baidu.png</span><br></pre></td></tr></table></figure><p>具体详情，可以参考wkhtml2pdf的帮助信息。</p><h3 id="2-3-选择原因"><a href="#2-3-选择原因" class="headerlink" title="2.3. 选择原因"></a>2.3. 选择原因</h3><ol><li>可以通过shell直接调用；</li><li>支持多线程并发操作；</li><li>调用简单、方便。</li></ol><h3 id="2-4-存在缺点"><a href="#2-4-存在缺点" class="headerlink" title="2.4. 存在缺点"></a>2.4. 存在缺点</h3><ol><li>存在TimeoutError；</li><li>偶尔存在加载阻塞，无法正常加载网页内容。这些网页通常是信息量较大、存在高清图片等问题。</li></ol><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><ol><li>如果需要HTML全文转化，那么wkHtml2PDF可以作为首要选项；</li><li>如果需要获取HTML中部分元素进行转化为图片、PDF，那么phtomjs是一个很好的选择。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 总结 </tag>
            
            <tag> Html </tag>
            
            <tag> PDF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-RDD/DataFrame-map保存数据的两种方式</title>
      <link href="/2018/06/29/Spark-RDD-DataFrame-map%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
      <url>/2018/06/29/Spark-RDD-DataFrame-map%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;使用Spark RDD或DataFrame，有时需要在foreachPartition或foreachWith里面保存数据到本地或HDFS。</p><a id="more"></a><h2 id="1-直接保存数据"><a href="#1-直接保存数据" class="headerlink" title="1. 直接保存数据"></a>1. 直接保存数据</h2><p>&emsp;&emsp;当然如果不需要在map里面保存数据，那么针对RDD可以有如下方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd &#x3D; &#x2F;&#x2F; target rdd</span><br><span class="line">rdd.saveAsHadoopFile &#x2F;&#x2F; add some parameters</span><br></pre></td></tr></table></figure><p>针对DataFrame可以有如下方式保存数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val df &#x3D; &#x2F;&#x2F; target dataframe</span><br><span class="line">&#x2F;&#x2F; 保存中间数据</span><br><span class="line">df.registerTempTable(&quot;temp table name&quot;)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 持久化数据</span><br><span class="line">df.save &#x2F;&#x2F; 使用save函数，指定模式等参数</span><br><span class="line">df.saveAsParquetFile&#x2F;&#x2F; depressed</span><br><span class="line">df.saveAsTable&#x2F;&#x2F; depressed</span><br></pre></td></tr></table></figure><h2 id="2-foreach里面保存数据"><a href="#2-foreach里面保存数据" class="headerlink" title="2. foreach里面保存数据"></a>2. foreach里面保存数据</h2><p>&emsp;&emsp;调用foreachXXX之后，里面的每条记录都是Iterator[YYY]形式的数据，是可迭代数据。</p><h3 id="2-1-保存到文件"><a href="#2-1-保存到文件" class="headerlink" title="2.1. 保存到文件"></a>2.1. 保存到文件</h3><p>保存到文件相对简单，可以直接使用上面的save保存，例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def save2HDFS(sc: SparkContext, input: Iterator[Row]): Unit &#x3D; &#123;</span><br><span class="line">val result &#x3D; input.map(item &#x3D;&gt; item.getString(0) + &quot;,&quot; + item.getInt(1)).toSeq</span><br><span class="line">    val tmpRDD &#x3D; sc.parallelize(result)</span><br><span class="line">    tmpRDD.saveAsObjectFile(&quot;&#x2F;&#x2F;path&quot;) &#x2F;&#x2F; 1</span><br><span class="line">    tmpRDD.saveAsTextFile(&quot;&#x2F;&#x2F;path&quot;) &#x2F;&#x2F; 2</span><br><span class="line">    tmpRDD.saveAsTextFile(&quot;&quot;,CompressClass) &#x2F;&#x2F; 3 内容编码类，继承自org.apache.hadoop.io.compress.CompressionCodec</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-保存到数据库"><a href="#2-2-保存到数据库" class="headerlink" title="2.2. 保存到数据库"></a>2.2. 保存到数据库</h3><p>&emsp;&emsp;在foreachXXX里面，可以将数据保存到数据库，这里使用的方式为JDBC的方式。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save2DB</span></span>(input: <span class="type">Iterator</span>[<span class="type">Row</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">var</span> temp: <span class="type">Row</span> = <span class="literal">null</span></span><br><span class="line">   <span class="keyword">while</span> (input.hasNext) &#123;</span><br><span class="line">     temp = input.next <span class="comment">// 将迭代数据保存为入库数据</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">var</span> dbconn: <span class="type">Connection</span> = <span class="literal">null</span></span><br><span class="line">   <span class="keyword">var</span> stmt: <span class="type">Statement</span> = <span class="literal">null</span></span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     dbconn = <span class="type">DriverManager</span>.getConnection(<span class="string">""</span>, <span class="string">""</span>, <span class="string">""</span>)</span><br><span class="line">     stmt = dbconn.createStatement()</span><br><span class="line">     stmt.execute(<span class="string">"truncate table TableName"</span>)</span><br><span class="line">   &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; &#123;</span><br><span class="line">       <span class="comment">// println("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;清空表失败")</span></span><br><span class="line">       <span class="comment">// e.printStackTrace()</span></span><br><span class="line">     &#125;</span><br><span class="line">   &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">     &#123; <span class="comment">// close connection</span></span><br><span class="line">       <span class="keyword">if</span> (stmt != <span class="literal">null</span>)</span><br><span class="line">         stmt.close()</span><br><span class="line">       <span class="keyword">if</span> (dbconn != <span class="literal">null</span>)</span><br><span class="line">         dbconn.close()</span><br><span class="line">     &#125;</span><br><span class="line">     &#123; <span class="comment">// modify poiner to NULL</span></span><br><span class="line">       stmt = <span class="literal">null</span></span><br><span class="line">       dbconn = <span class="literal">null</span></span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="3-DataFrame读入写出操作"><a href="#3-DataFrame读入写出操作" class="headerlink" title="3. DataFrame读入写出操作"></a>3. DataFrame读入写出操作</h2><p>&emsp;&emsp;DataFrame可以方便的将要各种数据源的数据，读入到内存中，也可以方便的将DF数据写为各种格式的数据。</p><h3 id="3-1-读入操作"><a href="#3-1-读入操作" class="headerlink" title="3.1. 读入操作"></a>3.1. 读入操作</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.read.jdbc<span class="comment">// JDBC数据源</span></span><br><span class="line">sqlContext.read.json<span class="comment">// JSON数据源</span></span><br><span class="line">sqlContext.read.parquet<span class="comment">// Parquet数据源</span></span><br></pre></td></tr></table></figure><h3 id="3-2-写出操作"><a href="#3-2-写出操作" class="headerlink" title="3.2. 写出操作"></a>3.2. 写出操作</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tarDF =  <span class="comment">// target dataframe </span></span><br><span class="line">tarDF.write.jdbc<span class="comment">// 写入JDBC数据库</span></span><br><span class="line">tarDF.write.json<span class="comment">// 写入JSON数据源</span></span><br><span class="line">tarDF.write.parquet<span class="comment">// 写入Parquet数据源</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;以上几种数据源，是Spark自身带有驱动程序的。其他文件格式，需要相应的驱动程序，或相应的安装包支持。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Crontab整点运行问题</title>
      <link href="/2018/06/29/Crontab%E6%95%B4%E7%82%B9%E8%BF%90%E8%A1%8C%E9%97%AE%E9%A2%98/"/>
      <url>/2018/06/29/Crontab%E6%95%B4%E7%82%B9%E8%BF%90%E8%A1%8C%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;无论是使用Linux自带crontab程序，还是使用cron-utils的crontab语法解析，都存在整点运行问题。</p><a id="more"></a><h2 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h2><p>使用crontab语法的时候，如果是固定间隔运行，如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0  0&#x2F;5  * * * *</span><br><span class="line">30 *&#x2F;30 * * * *</span><br></pre></td></tr></table></figure><p>其中分钟间隔只能是60的因子，如果不是60的因子，那么存在整点运行问题。如运行计划为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10 0&#x2F;29 * * * *</span><br></pre></td></tr></table></figure><p>那么运行时刻可能为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Mon Oct 09 15:29:10 CST 2017</span><br><span class="line">Mon Oct 09 15:58:10 CST 2017</span><br><span class="line">Mon Oct 09 16:00:10 CST 2017</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这里的运行计划，多出来一个16:00:10，这是不在我们的运行计划中的。</p><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>作者使用的是cron-utils，所以可以使用程序控制，实现规避整点运行的问题。</p><h3 id="计算crontab时间间隔"><a href="#计算crontab时间间隔" class="headerlink" title="计算crontab时间间隔"></a>计算crontab时间间隔</h3><p>代码先上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * @DESC caluate the max seperates</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static long calcMaxSep(ExecutionTime executionTime,</span><br><span class="line">DateTime updateCurrentFireTime) &#123;</span><br><span class="line"></span><br><span class="line">DateTime nextFireTime &#x3D; executionTime</span><br><span class="line">.nextExecution(updateCurrentFireTime);</span><br><span class="line">DateTime nextFireTime1 &#x3D; executionTime.nextExecution(nextFireTime);</span><br><span class="line"></span><br><span class="line">long b1 &#x3D; nextFireTime.toDate().getTime()</span><br><span class="line">- updateCurrentFireTime.toDate().getTime();</span><br><span class="line">long b2 &#x3D; nextFireTime1.toDate().getTime()</span><br><span class="line">- updateCurrentFireTime.toDate().getTime();</span><br><span class="line">b2 &#x3D; b2 &#x2F; 2;</span><br><span class="line"></span><br><span class="line">long b3 &#x3D; nextFireTime1.toDate().getTime()</span><br><span class="line">- nextFireTime.toDate().getTime();</span><br><span class="line"></span><br><span class="line">return getMaxByTri(b1, b2, b3);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @DESC get max of input three numbers</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static long getMaxByTri(long b1, long b2, long b3) &#123;</span><br><span class="line">&#x2F;&#x2F; return b1 &gt; b2 ? (b1 &gt; b3 ? b1 : b3) : (b2 &gt; b3 ? b2 : b3);</span><br><span class="line">return Math.max(b1, Math.max(b2, b3));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;基本原理：三个运行时刻，不可能都存在整点运行问题，除非设置就是整点运行的。分析三个运行时间之间的时间间隔，如果是正常区间，那三个时间应该是一致的；如果区间内或边界存在整点问题，那么应该可以通过该方法解决。作者通过该方法获取运行时间间隔，没有发现问题。</p><h3 id="通过间隔获取下一个运行时刻"><a href="#通过间隔获取下一个运行时刻" class="headerlink" title="通过间隔获取下一个运行时刻"></a>通过间隔获取下一个运行时刻</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public static void updateTask(SchedulerTask task) &#123;</span><br><span class="line">task.setCurrentFiredTime(task.getNextFiredTime());&#x2F;&#x2F; 直接获取计算好的下次执行时间，不再重新计算</span><br><span class="line">DateTime updateCurrentFireTime &#x3D; new DateTime(task.getNextFiredTime());</span><br><span class="line">DateTime nextFireTime &#x3D; nextFireTime(updateCurrentFireTime,Long.parseLong(task.getDescribe()));</span><br><span class="line">task.setNextFiredTime(nextFireTime.toDate());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public static int adaptTask(SchedulerTask task, Date time) &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 调整任务，需要重新计算</span><br><span class="line">Cron quartzCron &#x3D; getCron(task.getCron());</span><br><span class="line">ExecutionTime executionTime &#x3D; ExecutionTime.forCron(quartzCron);</span><br><span class="line">DateTime updateCurrentFireTime &#x3D; new DateTime(time);</span><br><span class="line">updateCurrentFireTime &#x3D; executionTime.nextExecution(new DateTime());</span><br><span class="line">task.setCurrentFiredTime(updateCurrentFireTime.toDate());</span><br><span class="line"></span><br><span class="line">DateTime nextFireTime &#x3D; nextFireTime(updateCurrentFireTime,Long.parseLong(task.getDescribe()));</span><br><span class="line">task.setNextFiredTime(nextFireTime.toDate());</span><br><span class="line"></span><br><span class="line">return isExecutable(task, time);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public static DateTime nextFireTime(DateTime currentFireTime, long added) &#123;</span><br><span class="line">return currentFireTime.withDurationAdded(added, 1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果正常运行，通过时间间隔获取下一个运行时间点；如果运行异常，重新计算初始运行时间点。</p><h2 id="限制条件"><a href="#限制条件" class="headerlink" title="限制条件"></a>限制条件</h2><ol><li>本方法适用于周期运行的时间点</li><li>本方法不适用于日、星期、月、年等存在区间限制，也即crontab表达式，后面几个都是”*”</li></ol>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RSA-加密算法备忘</title>
      <link href="/2018/06/29/RSA-%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/"/>
      <url>/2018/06/29/RSA-%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E5%A4%87%E5%BF%98/</url>
      
        <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.math.BigInteger;</span><br><span class="line"><span class="keyword">import</span> java.security.InvalidKeyException;</span><br><span class="line"><span class="keyword">import</span> java.security.KeyFactory;</span><br><span class="line"><span class="keyword">import</span> java.security.NoSuchAlgorithmException;</span><br><span class="line"><span class="keyword">import</span> java.security.interfaces.RSAPublicKey;</span><br><span class="line"><span class="keyword">import</span> java.security.spec.InvalidKeySpecException;</span><br><span class="line"><span class="keyword">import</span> java.security.spec.RSAPublicKeySpec;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.crypto.BadPaddingException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.Cipher;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.IllegalBlockSizeException;</span><br><span class="line"><span class="keyword">import</span> javax.crypto.NoSuchPaddingException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.codec.binary.Hex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RSAUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** <span class="doctag">@DESC</span> RSA加密算法 */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">rsaCrypt</span><span class="params">(String modeHex, String exponentHex, String messageg)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IllegalBlockSizeException, BadPaddingException,</span></span><br><span class="line"><span class="function">NoSuchAlgorithmException, InvalidKeySpecException,</span></span><br><span class="line"><span class="function">NoSuchPaddingException, InvalidKeyException,</span></span><br><span class="line"><span class="function">UnsupportedEncodingException </span>&#123;</span><br><span class="line"></span><br><span class="line">KeyFactory factory = KeyFactory.getInstance(<span class="string">"RSA"</span>);</span><br><span class="line"></span><br><span class="line">BigInteger m = <span class="keyword">new</span> BigInteger(modeHex, <span class="number">16</span>);</span><br><span class="line">BigInteger e = <span class="keyword">new</span> BigInteger(exponentHex, <span class="number">16</span>); </span><br><span class="line">RSAPublicKeySpec spec = <span class="keyword">new</span> RSAPublicKeySpec(m, e);</span><br><span class="line"></span><br><span class="line">RSAPublicKey pub = (RSAPublicKey) factory.generatePublic(spec);</span><br><span class="line">Cipher enc = Cipher.getInstance(<span class="string">"RSA"</span>);</span><br><span class="line">enc.init(Cipher.ENCRYPT_MODE, pub);</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] encryptedContentKey = enc.doFinal(messageg.getBytes(<span class="string">"GB2312"</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> String(Hex.encodeHex(encryptedContentKey));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 备忘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weibo单节点爬虫设计</title>
      <link href="/2018/06/29/Weibo%E5%8D%95%E8%8A%82%E7%82%B9%E7%88%AC%E8%99%AB%E8%AE%BE%E8%AE%A1/"/>
      <url>/2018/06/29/Weibo%E5%8D%95%E8%8A%82%E7%82%B9%E7%88%AC%E8%99%AB%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p><img src="/.io//001.png" alt="weibo_crawler"></p><p>&emsp;&emsp;微博目前开发数据接口，如果用于商业用途最好通过此接口来获取微博数据。作者爬去少量数据，仅用于研究学习。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Phantomjs服务模式：从性能并发方面谈起</title>
      <link href="/2018/06/29/Phantomjs%E6%9C%8D%E5%8A%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E4%BB%8E%E6%80%A7%E8%83%BD%E5%B9%B6%E5%8F%91%E6%96%B9%E9%9D%A2%E8%B0%88%E8%B5%B7/"/>
      <url>/2018/06/29/Phantomjs%E6%9C%8D%E5%8A%A1%E6%A8%A1%E5%BC%8F%EF%BC%9A%E4%BB%8E%E6%80%A7%E8%83%BD%E5%B9%B6%E5%8F%91%E6%96%B9%E9%9D%A2%E8%B0%88%E8%B5%B7/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;作为比较好的动态网页爬虫手段，phantomjs在许多方面令人比较满意。调用Phantomjs的方式，一般有如下几种情况。</p><a id="more"></a><h2 id="1-命令行模式"><a href="#1-命令行模式" class="headerlink" title="1. 命令行模式"></a>1. 命令行模式</h2><p>&emsp;&emsp;在CMD或Shell中，直接输入phantomjs回车，进入命令行模式，能够完成各种操作。但一般情况是通过命令用调用phantomjs来完成爬虫或模拟工作，具体的代码放在JS中。如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">..&#x2F;bin&#x2F;phantomjs --debug&#x3D;yes .&#x2F;server.js 8910</span><br><span class="line">..&#x2F;bin&#x2F;phantomjs --debug&#x3D;yes .&#x2F;hello.js</span><br></pre></td></tr></table></figure><p>其中phantomjs参数直接放在phantomjs后面，脚本作为参数放在其次，最后添加脚本的参数列表。</p><h2 id="2-selenium调用"><a href="#2-selenium调用" class="headerlink" title="2. selenium调用"></a>2. selenium调用</h2><p>&emsp;&emsp;selenium是一套完整的测试爬虫工具，能够调用IE、Chrome、Firefox等浏览器内核API完成相应的功能，也可以调用如Phantomjs、HtmlUnitDriver等模拟浏览器作为调用接口。</p><p>&emsp;&emsp;调用浏览器内核与不调用浏览器内核的浏览器[这里指的是HtmlUnitDriver]，浏览器内核的API，可以完成截图功能及其他浏览器功能，但HtmlunitDriver采用的是JS模拟浏览器的策略，因此不具备截图等浏览器功能。</p><h3 id="2-1-Java-selenium-Phantomjs调用"><a href="#2-1-Java-selenium-Phantomjs调用" class="headerlink" title="2.1. Java+selenium+Phantomjs调用"></a>2.1. Java+selenium+Phantomjs调用</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> PhantomJSDriver <span class="title">getPhantomJs</span><span class="params">(String phantomJS,</span></span></span><br><span class="line"><span class="function"><span class="params">String userAgent, <span class="keyword">boolean</span> loadImages, <span class="keyword">boolean</span> jsEnabled,</span></span></span><br><span class="line"><span class="function"><span class="params">String encoding,<span class="keyword">boolean</span> proxyEnabled,String... proxys)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">System.setProperty(<span class="string">"phantomjs.binary.path"</span>, phantomJS);</span><br><span class="line">DesiredCapabilities desiredCapabilities = DesiredCapabilities</span><br><span class="line">.phantomjs();</span><br><span class="line"><span class="keyword">if</span> (userAgent != <span class="keyword">null</span>) &#123;</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line"><span class="string">"phantomjs.page.settings.userAgent"</span>, userAgent);</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line"><span class="string">"phantomjs.page.customHeaders.User-Agent"</span>, userAgent);</span><br><span class="line">&#125;</span><br><span class="line">desiredCapabilities.setJavascriptEnabled(jsEnabled);</span><br><span class="line">PhantomJSDriver driver = <span class="keyword">null</span>;</span><br><span class="line">List&lt;String&gt; cli = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">cli.add(<span class="string">"--load-images="</span> + loadImages);</span><br><span class="line">cli.add(<span class="string">"--output-encoding="</span> + encoding);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (proxyEnabled) &#123;</span><br><span class="line">String proxy_ip = proxys[<span class="number">0</span>];</span><br><span class="line">String proxy_port = proxys[<span class="number">1</span>];</span><br><span class="line">String proxy_user = proxys[<span class="number">2</span>];</span><br><span class="line">String proxy_pass = proxys[<span class="number">3</span>];</span><br><span class="line">cli.add(<span class="string">"--proxy="</span>+proxy_ip+<span class="string">":"</span>+ proxy_port));</span><br><span class="line">cli.add(<span class="string">"--proxy-auth="</span> +proxy_user+<span class="string">":"</span> +proxy_pass);</span><br><span class="line">&#125;</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line">PhantomJSDriverService.PHANTOMJS_CLI_ARGS, cli);</span><br><span class="line">driver = <span class="keyword">new</span> PhantomJSDriver(desiredCapabilities);</span><br><span class="line">driver.manage().timeouts()</span><br><span class="line">.implicitlyWait(WAIT_TIME, TimeUnit.MILLISECONDS);</span><br><span class="line">driver.manage().deleteAllCookies();</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> driver;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-Java-selenium-HtmlunitDriver调用"><a href="#2-2-Java-selenium-HtmlunitDriver调用" class="headerlink" title="2.2. Java+selenium+HtmlunitDriver调用"></a>2.2. Java+selenium+HtmlunitDriver调用</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> HtmlUnitDriver <span class="title">getHtmlUnitDriver</span><span class="params">(String userAgent,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">boolean</span> jsEnabled, <span class="keyword">boolean</span> loadImages, <span class="keyword">boolean</span> proxyEnabled,</span></span></span><br><span class="line"><span class="function"><span class="params">String... proxys)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">DesiredCapabilities desiredCapabilities = DesiredCapabilities</span><br><span class="line">.htmlUnit();</span><br><span class="line">desiredCapabilities.setCapability(<span class="string">"phantomjs.page.settings.loadImages"</span>,</span><br><span class="line"><span class="keyword">false</span>);</span><br><span class="line">desiredCapabilities.setJavascriptEnabled(jsEnabled);</span><br><span class="line"><span class="keyword">if</span> (userAgent != <span class="keyword">null</span>) &#123;</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line"><span class="string">"phantomjs.page.settings.userAgent"</span>, userAgent);</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line"><span class="string">"phantomjs.page.customHeaders.User-Agent"</span>, userAgent);</span><br><span class="line">&#125;</span><br><span class="line">desiredCapabilities.setCapability(</span><br><span class="line">PhantomJSDriverService.PHANTOMJS_CLI_ARGS,</span><br><span class="line"><span class="keyword">new</span> String[] &#123; <span class="string">"--load-images="</span> + loadImages &#125;);</span><br><span class="line">HtmlUnitDriver driver = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">if</span> (proxyEnabled) &#123;</span><br><span class="line"></span><br><span class="line">String proxy_ip = proxys[<span class="number">0</span>];</span><br><span class="line">String proxy_port = proxys[<span class="number">1</span>];</span><br><span class="line">String proxy_user = proxys[<span class="number">2</span>];</span><br><span class="line">String proxy_pass = proxys[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">Proxy proxy = <span class="keyword">new</span> Proxy();</span><br><span class="line">proxy.setHttpProxy(proxy_ip + <span class="string">":"</span> + proxy_port);</span><br><span class="line">desiredCapabilities.setCapability(CapabilityType.PROXY, proxy);</span><br><span class="line">driver = <span class="keyword">new</span> HtmlUnitDriver(desiredCapabilities) &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> WebClient <span class="title">modifyWebClient</span><span class="params">(WebClient client)</span> </span>&#123;</span><br><span class="line">DefaultCredentialsProvider creds = <span class="keyword">new</span> DefaultCredentialsProvider();</span><br><span class="line">creds.addCredentials(proxy_user, proxy_pass);</span><br><span class="line">client.setCredentialsProvider(creds);</span><br><span class="line"><span class="keyword">return</span> client;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">&#125; <span class="keyword">else</span></span><br><span class="line">driver = <span class="keyword">new</span> HtmlUnitDriver(desiredCapabilities);</span><br><span class="line">driver.manage().timeouts()</span><br><span class="line">.implicitlyWait(<span class="number">10</span> * <span class="number">1000</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">driver.manage().deleteAllCookies();</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> driver;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-服务器模式"><a href="#3-服务器模式" class="headerlink" title="3. 服务器模式"></a>3. 服务器模式</h2><p>&emsp;&emsp;phantomjs服务器模式，需要在服务端开启服务，然后在客户端发起Http请求然后返回想要的内容，就是一个C/S模式的服务。</p><h3 id="3-1-服务端"><a href="#3-1-服务端" class="headerlink" title="3.1. 服务端"></a>3.1. 服务端</h3><p>server.js内容如下所示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">var webserver = require('webserver').create();</span><br><span class="line">var page = require('webpage').create();</span><br><span class="line">var system = require('system');</span><br><span class="line">var port = system.args[1];</span><br><span class="line">webserver.listen(system.args[1], function(request, response) &#123;</span><br><span class="line">    var url = request.headers.url;// conf target url in headers</span><br><span class="line">    page.open(url, function(status) &#123;</span><br><span class="line">        var title = page.evaluate(function() &#123;</span><br><span class="line">            return $(":root").html();// return pageSource</span><br><span class="line">        &#125;);</span><br><span class="line">        response.write(title);</span><br><span class="line">        response.close();</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>命令行启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/phantomjs example/server.js 8910</span><br></pre></td></tr></table></figure><h3 id="3-2-客户端"><a href="#3-2-客户端" class="headerlink" title="3.2. 客户端"></a>3.2. 客户端</h3><p>&emsp;&emsp;在客户端发起http请求，无论是get，还是post只要能够获取到Headers里面的目标URL，就可以返回pageSource。当然，这里最好使用异步加载网页内容。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; params = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">params.put(<span class="string">"url"</span>, targetURL);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">HttpPost</span><span class="params">(String url, String postDataStr)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> MalformedURLException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">URLConnection conn = <span class="keyword">new</span> URL(url).openConnection();</span><br><span class="line">conn.addRequestProperty(<span class="string">"method"</span>, <span class="string">"post"</span>);</span><br><span class="line">conn.addRequestProperty(<span class="string">"ContentType"</span>,</span><br><span class="line"><span class="string">"application/x-www-form-urlencoded"</span>);</span><br><span class="line">conn.addRequestProperty(<span class="string">"method"</span>, <span class="string">"post"</span>);</span><br><span class="line">conn.addRequestProperty(<span class="string">"http.socket.timeout"</span>, <span class="string">"60000"</span>);</span><br><span class="line">conn.setDoOutput(<span class="keyword">true</span>);</span><br><span class="line">conn.getOutputStream().write(</span><br><span class="line">URLEncoder.encode(postDataStr, <span class="string">"utf-8"</span>).getBytes());</span><br><span class="line"></span><br><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(</span><br><span class="line">conn.getInputStream()));</span><br><span class="line">String line = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>)</span><br><span class="line">sb.append(line);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-比较"><a href="#4-比较" class="headerlink" title="4. 比较"></a>4. 比较</h2><table><thead><tr><th align="center">方式</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="center">命令行模式</td><td align="left">1、调用简单</td><td align="left">1、需要配合JS<br>2、无法大规模并发控制</td></tr><tr><td align="center">服务器模式</td><td align="left">1、减少内存<br>2、客户端方便</td><td align="left">1、存在并发限制，最多10个线程<br>2、试验产品，可能存在安全隐患</td></tr><tr><td align="center">selenium调用</td><td align="left">1、客户端精准控制<br>2、调用比较方面，无需写JS<br>3、可大规模并发</td><td align="left">1、“吃”内存：内存随线程数增加较快<br>2、需手动释放内存，确保phantomjs释放</td></tr></tbody></table><h2 id="5-注"><a href="#5-注" class="headerlink" title="5. 注"></a>5. 注</h2><ol><li>由于目前phantomjs已停止更新维护，所以可以选择其他带有webkit内核的模拟浏览器，如Headless Chrome等作为测试/爬虫的首选。</li><li>phantomjs使用代理，最好使用无密码代理。</li></ol><h2 id="6-参考"><a href="#6-参考" class="headerlink" title="6. 参考"></a>6. 参考</h2><ol><li><a href="https://pip.readthedocs.io/en/stable/installing/" target="_blank" rel="noopener">Phantomjs正确打开方式</a></li><li><a href="http://www.cnblogs.com/kavmors/p/4731883.html" target="_blank" rel="noopener">Phantomjs 进程通信方式</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Phantomjs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaNLP-分词学习与研究：word分词</title>
      <link href="/2018/06/29/JavaNLP-%E5%88%86%E8%AF%8D%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%A0%94%E7%A9%B6%EF%BC%9Aword%E5%88%86%E8%AF%8D/"/>
      <url>/2018/06/29/JavaNLP-%E5%88%86%E8%AF%8D%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%A0%94%E7%A9%B6%EF%BC%9Aword%E5%88%86%E8%AF%8D/</url>
      
        <content type="html"><![CDATA[<p>转载自：<a href="https://github.com/ysc/word" target="_blank" rel="noopener">Java分布式中文分词组件 - word分词</a></p><h3 id="Java分布式中文分词组件-word分词"><a href="#Java分布式中文分词组件-word分词" class="headerlink" title="Java分布式中文分词组件 - word分词"></a>Java分布式中文分词组件 - word分词</h3><a id="more"></a><h4 id="word分词是一个Java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。能通过自定义配置文件来改变组件行为，能自定义用户词库、自动检测词库变化、支持大规模分布式环境，能灵活指定多种分词算法，能使用refine功能灵活控制分词结果，还能使用词频统计、词性标注、同义标注、反义标注、拼音标注等功能。提供了10种分词算法，还提供了10种文本相似度算法，同时还无缝和Lucene、Solr、ElasticSearch、Luke集成。注意：word1-3需要JDK1-8"><a href="#word分词是一个Java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。能通过自定义配置文件来改变组件行为，能自定义用户词库、自动检测词库变化、支持大规模分布式环境，能灵活指定多种分词算法，能使用refine功能灵活控制分词结果，还能使用词频统计、词性标注、同义标注、反义标注、拼音标注等功能。提供了10种分词算法，还提供了10种文本相似度算法，同时还无缝和Lucene、Solr、ElasticSearch、Luke集成。注意：word1-3需要JDK1-8" class="headerlink" title="word分词是一个Java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。能通过自定义配置文件来改变组件行为，能自定义用户词库、自动检测词库变化、支持大规模分布式环境，能灵活指定多种分词算法，能使用refine功能灵活控制分词结果，还能使用词频统计、词性标注、同义标注、反义标注、拼音标注等功能。提供了10种分词算法，还提供了10种文本相似度算法，同时还无缝和Lucene、Solr、ElasticSearch、Luke集成。注意：word1.3需要JDK1.8"></a>word分词是一个Java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。能通过自定义配置文件来改变组件行为，能自定义用户词库、自动检测词库变化、支持大规模分布式环境，能灵活指定多种分词算法，能使用refine功能灵活控制分词结果，还能使用词频统计、词性标注、同义标注、反义标注、拼音标注等功能。提供了10种分词算法，还提供了10种文本相似度算法，同时还无缝和Lucene、Solr、ElasticSearch、Luke集成。注意：word1.3需要JDK1.8</h4><h3 id="捐赠致谢"><a href="#捐赠致谢" class="headerlink" title="捐赠致谢"></a><a href="https://github.com/ysc/QuestionAnsweringSystem/wiki/donation" target="_blank" rel="noopener">捐赠致谢</a></h3><h3 id="API在线文档："><a href="#API在线文档：" class="headerlink" title="API在线文档："></a>API在线文档：</h3><p>   <a href="http://apdplat.org/word/apidocs/1.0/" target="_blank" rel="noopener">word 1.0 API</a></p><p>   <a href="http://apdplat.org/word/apidocs/1.1/" target="_blank" rel="noopener">word 1.1 API</a></p><p>   <a href="http://apdplat.org/word/apidocs/1.2/" target="_blank" rel="noopener">word 1.2 API</a></p><p>   <a href="http://apdplat.org/word/apidocs/1.3/" target="_blank" rel="noopener">word 1.3 API</a></p><h3 id="编译好的jar包下载"><a href="#编译好的jar包下载" class="headerlink" title="编译好的jar包下载"></a><a href="http://pan.baidu.com/s/1dDziDFz" target="_blank" rel="noopener">编译好的jar包下载</a></h3><h3 id="Maven依赖："><a href="#Maven依赖：" class="headerlink" title="Maven依赖："></a>Maven依赖：</h3><p>   在pom.xml中指定dependency，可用版本有1.0、1.1、1.2、1.3、1.3.1：</p><pre><code>&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apdplat&lt;/groupId&gt;        &lt;artifactId&gt;word&lt;/artifactId&gt;        &lt;version&gt;1.3&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>word 1.3.1这个版本是从代码分支<a href="https://github.com/ysc/word/tree/ForElasticsearch1.7.2/" target="_blank" rel="noopener">ForElasticsearch1.7.2</a>中编译出来的，主要目的是支持<br>与lucene4.10.4、solr4.10.4和elasticsearch1.7.2兼容的版本。</p><h3 id="分词使用方法："><a href="#分词使用方法：" class="headerlink" title="分词使用方法："></a>分词使用方法：</h3><h4 id="1、快速体验"><a href="#1、快速体验" class="headerlink" title="1、快速体验"></a>1、快速体验</h4><pre><code>运行项目根目录下的脚本demo-word.bat可以快速体验分词效果用法: command [text] [input] [output]命令command的可选值为：demo、text、filedemotext 杨尚川是APDPlat应用级产品开发平台的作者file d:/text.txt d:/word.txtexit</code></pre><h4 id="2、对文本进行分词"><a href="#2、对文本进行分词" class="headerlink" title="2、对文本进行分词"></a>2、对文本进行分词</h4><pre><code>移除停用词：List&lt;Word&gt; words = WordSegmenter.seg(&quot;杨尚川是APDPlat应用级产品开发平台的作者&quot;);保留停用词：List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;杨尚川是APDPlat应用级产品开发平台的作者&quot;);            System.out.println(words);输出：移除停用词：[杨尚川, apdplat, 应用级, 产品, 开发平台, 作者]保留停用词：[杨尚川, 是, apdplat, 应用级, 产品, 开发平台, 的, 作者]</code></pre><h4 id="3、对文件进行分词"><a href="#3、对文件进行分词" class="headerlink" title="3、对文件进行分词"></a>3、对文件进行分词</h4><pre><code>String input = &quot;d:/text.txt&quot;;String output = &quot;d:/word.txt&quot;;移除停用词：WordSegmenter.seg(new File(input), new File(output));保留停用词：WordSegmenter.segWithStopWords(new File(input), new File(output));</code></pre><h4 id="4、自定义配置文件"><a href="#4、自定义配置文件" class="headerlink" title="4、自定义配置文件"></a>4、自定义配置文件</h4><pre><code>默认配置文件为类路径下的word.conf，打包在word-x.x.jar中自定义配置文件为类路径下的word.local.conf，需要用户自己提供如果自定义配置和默认配置相同，自定义配置会覆盖默认配置配置文件编码为UTF-8</code></pre><h4 id="5、自定义用户词库"><a href="#5、自定义用户词库" class="headerlink" title="5、自定义用户词库"></a>5、自定义用户词库</h4><pre><code>自定义用户词库为一个或多个文件夹或文件，可以使用绝对路径或相对路径用户词库由多个词典文件组成，文件编码为UTF-8词典文件的格式为文本文件，一行代表一个词可以通过系统属性或配置文件的方式来指定路径，多个路径之间用逗号分隔开类路径下的词典文件，需要在相对路径前加入前缀classpath:指定方式有三种：    指定方式一，编程指定（高优先级）：        WordConfTools.set(&quot;dic.path&quot;, &quot;classpath:dic.txt，d:/custom_dic&quot;);        DictionaryFactory.reload();//更改词典路径之后，重新加载词典    指定方式二，Java虚拟机启动参数（中优先级）：        java -Ddic.path=classpath:dic.txt，d:/custom_dic    指定方式三，配置文件指定（低优先级）：        使用类路径下的文件word.local.conf来指定配置信息        dic.path=classpath:dic.txt，d:/custom_dic如未指定，则默认使用类路径下的dic.txt词典文件</code></pre><h4 id="6、自定义停用词词库"><a href="#6、自定义停用词词库" class="headerlink" title="6、自定义停用词词库"></a>6、自定义停用词词库</h4><pre><code>使用方式和自定义用户词库类似，配置项为：stopwords.path=classpath:stopwords.txt，d:/custom_stopwords_dic</code></pre><h4 id="7、自动检测词库变化"><a href="#7、自动检测词库变化" class="headerlink" title="7、自动检测词库变化"></a>7、自动检测词库变化</h4><pre><code>可以自动检测自定义用户词库和自定义停用词词库的变化包含类路径下的文件和文件夹、非类路径下的绝对路径和相对路径如：classpath:dic.txt，classpath:custom_dic_dir,d:/dic_more.txt，d:/DIC_DIR，D:/DIC2_DIR，my_dic_dir，my_dic_file.txtclasspath:stopwords.txt，classpath:custom_stopwords_dic_dir，d:/stopwords_more.txt，d:/STOPWORDS_DIR，d:/STOPWORDS2_DIR，stopwords_dir，remove.txt</code></pre><h4 id="8、显式指定分词算法"><a href="#8、显式指定分词算法" class="headerlink" title="8、显式指定分词算法"></a>8、显式指定分词算法</h4><pre><code>对文本进行分词时，可显式指定特定的分词算法，如：WordSegmenter.seg(&quot;APDPlat应用级产品开发平台&quot;, SegmentationAlgorithm.BidirectionalMaximumMatching);SegmentationAlgorithm的可选类型为：     正向最大匹配算法：MaximumMatching逆向最大匹配算法：ReverseMaximumMatching正向最小匹配算法：MinimumMatching逆向最小匹配算法：ReverseMinimumMatching双向最大匹配算法：BidirectionalMaximumMatching双向最小匹配算法：BidirectionalMinimumMatching双向最大最小匹配算法：BidirectionalMaximumMinimumMatching全切分算法：FullSegmentation最少词数算法：MinimalWordCount最大Ngram分值算法：MaxNgramScore</code></pre><h4 id="9、分词效果评估"><a href="#9、分词效果评估" class="headerlink" title="9、分词效果评估"></a>9、分词效果评估</h4><pre><code>运行项目根目录下的脚本evaluation.bat可以对分词效果进行评估评估采用的测试文本有253 3709行，共2837 4490个字符评估结果位于target/evaluation目录下：corpus-text.txt为分好词的人工标注文本，词之间以空格分隔test-text.txt为测试文本，是把corpus-text.txt以标点符号分隔为多行的结果standard-text.txt为测试文本对应的人工标注文本，作为分词是否正确的标准result-text-***.txt，***为各种分词算法名称，这是word分词结果perfect-result-***.txt，***为各种分词算法名称，这是分词结果和人工标注标准完全一致的文本wrong-result-***.txt，***为各种分词算法名称，这是分词结果和人工标注标准不一致的文本</code></pre><h4 id="10、分布式中文分词器"><a href="#10、分布式中文分词器" class="headerlink" title="10、分布式中文分词器"></a>10、分布式中文分词器</h4><pre><code>1、在自定义配置文件word.conf或word.local.conf中指定所有的配置项*.path使用HTTP资源，同时指定配置项redis.*2、配置并启动提供HTTP资源的web服务器，将项目：https://github.com/ysc/word_web部署到tomcat3、配置并启动redis服务器</code></pre><h4 id="11、词性标注"><a href="#11、词性标注" class="headerlink" title="11、词性标注"></a>11、词性标注</h4><pre><code>将分词结果作为输入参数，调用PartOfSpeechTagging类的process方法，词性保存在Word类的partOfSpeech字段中如下所示：List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;我爱中国&quot;);System.out.println(&quot;未标注词性：&quot;+words);//词性标注PartOfSpeechTagging.process(words);System.out.println(&quot;标注词性：&quot;+words);输出内容：未标注词性：[我, 爱, 中国]标注词性：[我/r, 爱/v, 中国/ns]</code></pre><h4 id="12、refine"><a href="#12、refine" class="headerlink" title="12、refine"></a>12、refine</h4><pre><code>我们看一个切分例子：List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;我国工人阶级和广大劳动群众要更加紧密地团结在党中央周围&quot;);System.out.println(words);结果如下：[我国, 工人阶级, 和, 广大, 劳动群众, 要, 更加, 紧密, 地, 团结, 在, 党中央, 周围]假如我们想要的切分结果是：[我国, 工人, 阶级, 和, 广大, 劳动, 群众, 要, 更加, 紧密, 地, 团结, 在, 党中央, 周围]也就是要把“工人阶级”细分为“工人 阶级”，把“劳动群众”细分为“劳动 群众”，那么我们该怎么办呢？我们可以通过在word.refine.path配置项指定的文件classpath:word_refine.txt中增加以下内容：工人阶级=工人 阶级劳动群众=劳动 群众然后，我们对分词结果进行refine：words = WordRefiner.refine(words);System.out.println(words);这样，就能达到我们想要的效果：[我国, 工人, 阶级, 和, 广大, 劳动, 群众, 要, 更加, 紧密, 地, 团结, 在, 党中央, 周围]我们再看一个切分例子：List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;在实现“两个一百年”奋斗目标的伟大征程上再创新的业绩&quot;);System.out.println(words);结果如下：[在, 实现, 两个, 一百年, 奋斗目标, 的, 伟大, 征程, 上, 再创, 新的, 业绩]假如我们想要的切分结果是：[在, 实现, 两个一百年, 奋斗目标, 的, 伟大征程, 上, 再创, 新的, 业绩]也就是要把“两个 一百年”合并为“两个一百年”，把“伟大, 征程”合并为“伟大征程”，那么我们该怎么办呢？我们可以通过在word.refine.path配置项指定的文件classpath:word_refine.txt中增加以下内容：两个 一百年=两个一百年伟大 征程=伟大征程然后，我们对分词结果进行refine：words = WordRefiner.refine(words);System.out.println(words);这样，就能达到我们想要的效果：[在, 实现, 两个一百年, 奋斗目标, 的, 伟大征程, 上, 再创, 新的, 业绩]</code></pre><h4 id="13、同义标注"><a href="#13、同义标注" class="headerlink" title="13、同义标注"></a>13、同义标注</h4><pre><code>List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;楚离陌千方百计为无情找回记忆&quot;);System.out.println(words);结果如下：[楚离陌, 千方百计, 为, 无情, 找回, 记忆]做同义标注：SynonymTagging.process(words);System.out.println(words);结果如下：[楚离陌, 千方百计[久有存心, 化尽心血, 想方设法, 费尽心机], 为, 无情, 找回, 记忆[影象]]如果启用间接同义词：SynonymTagging.process(words, false);System.out.println(words);结果如下：[楚离陌, 千方百计[久有存心, 化尽心血, 想方设法, 费尽心机], 为, 无情, 找回, 记忆[影像, 影象]]List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;手劲大的老人往往更长寿&quot;);System.out.println(words);结果如下：[手劲, 大, 的, 老人, 往往, 更, 长寿]做同义标注：SynonymTagging.process(words);System.out.println(words);结果如下：[手劲, 大, 的, 老人[白叟], 往往[常常, 每每, 经常], 更, 长寿[长命, 龟龄]]如果启用间接同义词：SynonymTagging.process(words, false);System.out.println(words);结果如下：[手劲, 大, 的, 老人[白叟], 往往[一样平常, 一般, 凡是, 寻常, 常常, 常日, 平凡, 平居, 平常, 平日, 平时, 往常, 日常, 日常平凡, 时常, 普通, 每每, 泛泛, 素日, 经常, 通俗, 通常], 更, 长寿[长命, 龟龄]]以词“千方百计”为例：可以通过Word的getSynonym()方法获取同义词如：System.out.println(word.getSynonym());结果如下：[久有存心, 化尽心血, 想方设法, 费尽心机]注意：如果没有同义词，则getSynonym()返回空集合：Collections.emptyList()间接同义词和直接同义词的区别如下：假设：A和B是同义词，A和C是同义词，B和D是同义词，C和E是同义词则：对于A来说，A B C是直接同义词对于B来说，A B D是直接同义词对于C来说，A C E是直接同义词对于A B C来说，A B C D E是间接同义词</code></pre><h4 id="14、反义标注"><a href="#14、反义标注" class="headerlink" title="14、反义标注"></a>14、反义标注</h4><pre><code>List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;5月初有哪些电影值得观看&quot;);System.out.println(words);结果如下：[5, 月初, 有, 哪些, 电影, 值得, 观看]做反义标注：AntonymTagging.process(words);System.out.println(words);结果如下：[5, 月初[月底, 月末, 月终], 有, 哪些, 电影, 值得, 观看]List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;由于工作不到位、服务不完善导致顾客在用餐时发生不愉快的事情,餐厅方面应该向顾客作出真诚的道歉,而不是敷衍了事。&quot;);System.out.println(words);结果如下：[由于, 工作, 不到位, 服务, 不完善, 导致, 顾客, 在, 用餐, 时, 发生, 不愉快, 的, 事情, 餐厅, 方面, 应该, 向, 顾客, 作出, 真诚, 的, 道歉, 而不是, 敷衍了事]做反义标注：AntonymTagging.process(words);System.out.println(words);结果如下：[由于, 工作, 不到位, 服务, 不完善, 导致, 顾客, 在, 用餐, 时, 发生, 不愉快, 的, 事情, 餐厅, 方面, 应该, 向, 顾客, 作出, 真诚[糊弄, 虚伪, 虚假, 险诈], 的, 道歉, 而不是, 敷衍了事[一丝不苟, 兢兢业业, 尽心竭力, 竭尽全力, 精益求精, 诚心诚意]]以词“月初”为例：可以通过Word的getAntonym()方法获取反义词如：System.out.println(word.getAntonym());结果如下：[月底, 月末, 月终]注意：如果没有反义词，getAntonym()返回空集合：Collections.emptyList()</code></pre><h4 id="15、拼音标注"><a href="#15、拼音标注" class="headerlink" title="15、拼音标注"></a>15、拼音标注</h4><pre><code>List&lt;Word&gt; words = WordSegmenter.segWithStopWords(&quot;《速度与激情7》的中国内地票房自4月12日上映以来，在短短两周内突破20亿人民币&quot;);System.out.println(words);结果如下：[速度, 与, 激情, 7, 的, 中国, 内地, 票房, 自, 4月, 12日, 上映, 以来, 在, 短短, 两周, 内, 突破, 20亿, 人民币]执行拼音标注：PinyinTagging.process(words);System.out.println(words);结果如下：[速度 sd sudu, 与 y yu, 激情 jq jiqing, 7, 的 d de, 中国 zg zhongguo, 内地 nd neidi, 票房 pf piaofang, 自 z zi, 4月, 12日, 上映 sy shangying, 以来 yl yilai, 在 z zai, 短短 dd duanduan, 两周 lz liangzhou, 内 n nei, 突破 tp tupo, 20亿, 人民币 rmb renminbi]以词“速度”为例：可以通过Word的getFullPinYin()方法获取完整拼音如：sudu可以通过Word的getAcronymPinYin()方法获取首字母缩略拼音如：sd</code></pre><h4 id="16、Lucene插件："><a href="#16、Lucene插件：" class="headerlink" title="16、Lucene插件："></a>16、Lucene插件：</h4><pre><code>1、构造一个word分析器ChineseWordAnalyzerAnalyzer analyzer = new ChineseWordAnalyzer();如果需要使用特定的分词算法，可通过构造函数来指定：Analyzer analyzer = new ChineseWordAnalyzer(SegmentationAlgorithm.FullSegmentation);如不指定，默认使用双向最大匹配算法：SegmentationAlgorithm.BidirectionalMaximumMatching可用的分词算法参见枚举类：SegmentationAlgorithm2、利用word分析器切分文本TokenStream tokenStream = analyzer.tokenStream(&quot;text&quot;, &quot;杨尚川是APDPlat应用级产品开发平台的作者&quot;);//准备消费tokenStream.reset();//开始消费while(tokenStream.incrementToken()){    //词    CharTermAttribute charTermAttribute = tokenStream.getAttribute(CharTermAttribute.class);    //词在文本中的起始位置    OffsetAttribute offsetAttribute = tokenStream.getAttribute(OffsetAttribute.class);    //第几个词    PositionIncrementAttribute positionIncrementAttribute = tokenStream.getAttribute(PositionIncrementAttribute.class);    LOGGER.info(charTermAttribute.toString()+&quot; (&quot;+offsetAttribute.startOffset()+&quot; - &quot;+offsetAttribute.endOffset()+&quot;) &quot;+positionIncrementAttribute.getPositionIncrement());}//消费完毕tokenStream.close();3、利用word分析器建立Lucene索引Directory directory = new RAMDirectory();IndexWriterConfig config = new IndexWriterConfig(analyzer);IndexWriter indexWriter = new IndexWriter(directory, config);4、利用word分析器查询Lucene索引QueryParser queryParser = new QueryParser(&quot;text&quot;, analyzer);Query query = queryParser.parse(&quot;text:杨尚川&quot;);TopDocs docs = indexSearcher.search(query, Integer.MAX_VALUE);</code></pre><h4 id="17、Solr插件："><a href="#17、Solr插件：" class="headerlink" title="17、Solr插件："></a>17、Solr插件：</h4><pre><code>1、下载word-1.3.jar下载地址：http://search.maven.org/remotecontent?filepath=org/apdplat/word/1.3/word-1.3.jar2、创建目录solr-5.2.0/example/solr/lib，将word-1.3.jar复制到lib目录3、配置schema指定分词器将solr-5.2.0/example/solr/collection1/conf/schema.xml文件中所有的&lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt;和&lt;tokenizer class=&quot;solr.StandardTokenizerFactory&quot;/&gt;全部替换为&lt;tokenizer class=&quot;org.apdplat.word.solr.ChineseWordTokenizerFactory&quot;/&gt;并移除所有的filter标签4、如果需要使用特定的分词算法：&lt;tokenizer class=&quot;org.apdplat.word.solr.ChineseWordTokenizerFactory&quot; segAlgorithm=&quot;ReverseMinimumMatching&quot;/&gt;segAlgorithm可选值有：     正向最大匹配算法：MaximumMatching逆向最大匹配算法：ReverseMaximumMatching正向最小匹配算法：MinimumMatching逆向最小匹配算法：ReverseMinimumMatching双向最大匹配算法：BidirectionalMaximumMatching双向最小匹配算法：BidirectionalMinimumMatching双向最大最小匹配算法：BidirectionalMaximumMinimumMatching全切分算法：FullSegmentation最少词数算法：MinimalWordCount最大Ngram分值算法：MaxNgramScore如不指定，默认使用双向最大匹配算法：BidirectionalMaximumMatching5、如果需要指定特定的配置文件：&lt;tokenizer class=&quot;org.apdplat.word.solr.ChineseWordTokenizerFactory&quot; segAlgorithm=&quot;ReverseMinimumMatching&quot;        conf=&quot;solr-5.2.0/example/solr/nutch/conf/word.local.conf&quot;/&gt;word.local.conf文件中可配置的内容见 word-1.3.jar 中的word.conf文件如不指定，使用默认配置文件，位于 word-1.3.jar 中的word.conf文件</code></pre><h4 id="18、ElasticSearch插件："><a href="#18、ElasticSearch插件：" class="headerlink" title="18、ElasticSearch插件："></a>18、ElasticSearch插件：</h4><pre><code>1、打开命令行并切换到elasticsearch的bin目录cd elasticsearch-2.1.1/bin2、运行plugin脚本安装word分词插件：./plugin install http://apdplat.org/word/archive/v1.4.zip安装的时候注意：    如果提示：        ERROR: failed to download     或者         Failed to install word, reason: failed to download    或者         ERROR: incorrect hash (SHA1)    则重新再次运行命令，如果还是不行，多试两次如果是elasticsearch1.x系列版本，则使用如下命令：./plugin -u http://apdplat.org/word/archive/v1.3.1.zip -i word3、修改文件elasticsearch-2.1.1/config/elasticsearch.yml，新增如下配置：    index.analysis.analyzer.default.type : &quot;word&quot;index.analysis.tokenizer.default.type : &quot;word&quot;4、启动ElasticSearch测试效果，在Chrome浏览器中访问：    http://localhost:9200/_analyze?analyzer=word&amp;text=杨尚川是APDPlat应用级产品开发平台的作者5、自定义配置修改配置文件elasticsearch-2.1.1/plugins/word/word.local.conf6、指定分词算法修改文件elasticsearch-2.1.1/config/elasticsearch.yml，新增如下配置：index.analysis.analyzer.default.segAlgorithm : &quot;ReverseMinimumMatching&quot;index.analysis.tokenizer.default.segAlgorithm : &quot;ReverseMinimumMatching&quot;这里segAlgorithm可指定的值有：正向最大匹配算法：MaximumMatching逆向最大匹配算法：ReverseMaximumMatching正向最小匹配算法：MinimumMatching逆向最小匹配算法：ReverseMinimumMatching双向最大匹配算法：BidirectionalMaximumMatching双向最小匹配算法：BidirectionalMinimumMatching双向最大最小匹配算法：BidirectionalMaximumMinimumMatching全切分算法：FullSegmentation最少词数算法：MinimalWordCount最大Ngram分值算法：MaxNgramScore如不指定，默认使用双向最大匹配算法：BidirectionalMaximumMatching</code></pre><h4 id="19、Luke插件："><a href="#19、Luke插件：" class="headerlink" title="19、Luke插件："></a>19、Luke插件：</h4><pre><code>1、下载http://luke.googlecode.com/files/lukeall-4.0.0-ALPHA.jar（国内不能访问）2、下载并解压Java中文分词组件word-1.0-bin.zip：http://pan.baidu.com/s/1dDziDFz3、将解压后的 Java中文分词组件word-1.0-bin/word-1.0 文件夹里面的4个jar包解压到当前文件夹用压缩解压工具如winrar打开lukeall-4.0.0-ALPHA.jar，将当前文件夹里面除了META-INF文件夹、.jar、.bat、.html、word.local.conf文件外的其他所有文件拖到lukeall-4.0.0-ALPHA.jar里面4、执行命令 java -jar lukeall-4.0.0-ALPHA.jar 启动luke，在Search选项卡的Analysis里面就可以选择 org.apdplat.word.lucene.ChineseWordAnalyzer 分词器了 5、在Plugins选项卡的Available analyzers found on the current classpath里面也可以选择 org.apdplat.word.lucene.ChineseWordAnalyzer 分词器注意：如果你要自己集成word分词器的其他版本，在项目根目录下运行mvn install编译项目，然后运行命令mvn dependency:copy-dependencies复制依赖的jar包，接着在target/dependency/目录下就会有所有的依赖jar包。其中target/dependency/slf4j-api-1.6.4.jar是word分词器使用的日志框架，target/dependency/logback-classic-0.9.28.jar和target/dependency/logback-core-0.9.28.jar是word分词器推荐使用的日志实现，日志实现的配置文件路径位于target/classes/logback.xml，target/word-1.3.jar是word分词器的主jar包，如果需要自定义词典，则需要修改分词器配置文件target/classes/word.conf</code></pre><p>   已经集成好的Luke插件下载（适用于lucene4.0.0） ：<a href="http://pan.baidu.com/s/1bn52ooR" target="_blank" rel="noopener">lukeall-4.0.0-ALPHA-with-word-1.0.jar</a></p><p>   已经集成好的Luke插件下载（适用于lucene4.10.3）：<a href="http://pan.baidu.com/s/1mgFt7ZU" target="_blank" rel="noopener">lukeall-4.10.3-with-word-1.2.jar</a></p><h4 id="20、通过计算词的语境来获得相关词："><a href="#20、通过计算词的语境来获得相关词：" class="headerlink" title="20、通过计算词的语境来获得相关词："></a>20、通过计算词的语境来获得相关词：</h4><p>我们如何通过计算词的语境来获得相关词呢？</p><pre><code>语境的定义是：在一段文本中，任意一个词的语境由它的前N个词和后N个词组成。相关词的定义是：如果两个词的语境越相似，那么这两个词就越相似，也就越相关。</code></pre><p>算法由两个步骤组成：</p><pre><code>1、从大规模语料库中计算每一个词的语境，并使用词向量来表示语境。2、把求两个词的相似度的问题转换为求这两个词的语境的相似度的问题。通过计算语境的相似度，就可得到词的相似度，越相似的词就越相关。</code></pre><p>使用方法如下：</p><pre><code>1、使用word分词内置语料库：运行word分词项目根目录下的脚本 demo-word-vector-corpus.bat 或 demo-word-vector-corpus.sh2、使用自己的文本内容：运行word分词项目根目录下的脚本 demo-word-vector-file.bat 或 demo-word-vector-file.sh由于语料库很大，所以启动的时间会很长，请耐心等待，下面以例子来说明：比如我们想分析 兰州 这个词的相关词有哪些，我们运行脚本 demo-word-vector-corpus.sh ，启动成功之后命令行提示：开始初始化模型模型初始化完成可通过输入命令sa=cos来指定相似度算法，可用的算法有：   1、sa=cos，余弦相似度   2、sa=edi，编辑距离   3、sa=euc，欧几里得距离   4、sa=sim，简单共有词   5、sa=jac，Jaccard相似性系数   6、sa=man，曼哈顿距离   7、sa=shh，SimHash + 汉明距离   8、sa=ja，Jaro距离   9、sa=jaw，Jaro–Winkler距离   10、sa=sd，Sørensen–Dice系数可通过输入命令limit=15来指定显示结果条数可通过输入命令exit退出程序输入要查询的词或命令：我们输入 兰州 后回车，结果显示：兰州 的相关词（EditDistanceTextSimilarity）：----------------------------------------------------------    1、兰州 1.0    2、北京 0.21    3、福州 0.2    4、太原 0.19    5、成都 0.17    6、西安 0.17    7、哈尔滨 0.17    8、南宁 0.17    9、贵阳 0.16    10、庆阳 0.15    11、沈阳 0.14    12、合肥 0.14    13、大同 0.14    14、拉萨 0.13    15、西宁 0.13----------------------------------------------------------这里显示的结果就是 兰州 这个词的相关词，词后面跟的是相关度分值，兰州 和 兰州 是同一个词，相关度百分之百，自然是1分。从这个结果我们来分析，这些词凭什么相关呢？线索在哪里？首先这些词的词性都是名词；其次这些词都是地名而且是大城市名；从这里我们也可以看到一个有意思的现象，同一词性比如地名的用法往往保持一致。相关词是从语境推导得到的，语境中词后面跟的数字是权重，权重是1/N的累加值下面我们看看这些词的语境：兰州 : [军区 1.0, 甘肃 0.78205127, 新区 0.7692308, 大学 0.42307693, 甘肃兰州 0.41025642, 货车 0.3846154, 西安 0.32051283, 本报 0.2948718, 新华社 0.2820513, 兰州新区 0.26923078, 召开 0.23076923, 发往 0.21794872, 中国 0.20512821, 兰州 0.20512821, 火车站 0.20512821, 铁路 0.17948718, 参加 0.15384616, 西宁 0.15384616, 方向 0.15384616, 成都 0.14102565, 警察 0.14102565, 建设 0.12820514, 市委 0.12820514, 来到 0.12820514, 一家 0.12820514, 中心 0.115384616, 炼油厂 0.102564104, 进入 0.102564104, 来自 0.102564104, 举行 0.102564104]    北京 : [新华社 1.0, 本报 0.7119143, 举行 0.19384204, 上海 0.17831326, 时间 0.16385542, 铁路局 0.1394913, 西站 0.13226238, 青年报 0.12717536, 晨报 0.11700134, 市委 0.1145917, 地区 0.11218206, 召开 0.10200803, 城市 0.08299866, 目前 0.07951807, 来到 0.06961178, 军区 0.06827309, 国际 0.066398926, 中心 0.063453816, 北京时间 0.06184739, 人民 0.059973225, 工作 0.05863454, 地铁 0.057563588, 北京铁路局 0.056492638, 医院 0.055421688, 飞往 0.05381526, 首都 0.053547524, 中国 0.053547524, 其中 0.05274431, 今天 0.052208837, 卫视 0.05167336]福州 : [火车站 1.0, 新区 0.46666667, 福州火车站 0.45555556, 晚报 0.2962963, 记者 0.2777778, 打工 0.27407408, 来到 0.24814814, 市民 0.23333333, 本报 0.22222222, 大学 0.21851853, 市区 0.2074074, 市委 0.19259259, 举行 0.19259259, 鼓楼区 0.18518518, 网友 0.18148148, 到达 0.17037037, 开往 0.16296296, 目前 0.14074074, 分行 0.14074074, 一家 0.12962963, 全市 0.12962963, 东街口 0.12222222, 福州晚报 0.12222222, 新华社 0.11851852, 铁路 0.11851852, 召开 0.11481482, 前往 0.11481482, 发展 0.11481482, 推进 0.11111111, 福州 0.11111111]     太原 : [山西 1.0, 山西太原 0.6136364, 本报 0.39772728, 新华社 0.3409091, 火车站 0.26136363, 济南 0.25, 铁路 0.23863636, 北京 0.22727273, 推出 0.1590909, 国际 0.1590909, 返回 0.14772727, 刚玉 0.13636364, 来自 0.13636364, 发布 0.13636364, 打工 0.125, 中心 0.125, 市委 0.11363637, 银行 0.11363637, 铁路局 0.10227273, 西安 0.09090909, 集团 0.09090909, 公安 0.09090909, 开往 0.09090909, 比如 0.07954545, 金融 0.07954545, 火车票 0.07954545, 大同 0.06818182, 山西省 0.06818182, 军分区 0.06818182, 离开 0.06818182]成都 : [商报 1.0, 成都商报 0.4117647, 军区 0.1875, 铁路局 0.17830883, 北京 0.17463236, 本报 0.17095588, 重庆 0.15441176, 告诉 0.15441176, 交警 0.14338236, 方向 0.1360294, 记者 0.13419117, 平原 0.121323526, 四川 0.1194853, 长沙 0.11764706, 理工大学 0.0992647, 来自 0.09375, 新华社 0.09191176, 开往 0.090073526, 成都铁路局 0.08455882, 铁路 0.080882356, 召开 0.07904412, 市民 0.075367644, 市委 0.073529415, 公司 0.07169118, 广州 0.07169118, 西安 0.0680147, 郫县 0.060661763, 打工 0.060661763, 市区 0.05882353, 晚报 0.05882353]西安 : [火车站 1.0, 事变 0.75, 交通 0.7058824, 建设 0.5882353, 地铁 0.5882353, &gt;咸阳 0.5588235, 来到 0.5294118, 市民 0.50735295, 大学 0.5, 铁路 0.5, 代表团 0.5, 铁路局 0.49264705, 公司 0.4852941, 武汉 0.4632353, 曲江 0.44117647, 供电 0.42647058, 新华社 0.4117647, 西安火车站 0.4117647, 北京 0.3602941, 交大 0.3602941, 本报 0.34558824, 西安事变 0.3382353, 城市 0.31617647, 城区 0.31617647, 落户 0.30882353, 市委 0.29411766, 国际 0.2867647, 城东 0.2867647, 成都 0.2720588, 举行 0.25]    哈尔滨 : [理工大学 1.0, 火车站 0.41584158, 哈尔滨理工大学 0.36138615, 工业 0.25742576, 方向 0.23762377, 新华社 0.20792079, 开往 0.18811882, 哈尔滨火车站 0.18316832, 位于 0.17821783, 大学 0.17326732, 铁路局 0.15841584, 来自 0.15346535, 最低 0.14356436, 北京 0.12871288, 本报 0.12376238, 黑龙江省 0.12376238, 发布 0.11386139, 中国 0.10891089, 飞往 0.0990099, 黑龙&gt;江 0.08415841, 沈阳 0.07920792, 工程 0.07920792, 附近 0.074257426, 市委 0.06930693, 飞机 0.06930693, 上海 0.06930693, 考生 0.06930693, 进入 0.06930693, 停止 0.06930693, 经济 0.06435644]南宁 : [广西 1.0, 铁路局 0.8, 广西南宁 0.62222224, 本报 0.54444444, 新华社 0.36666667, 南宁铁路局 0.31111112, 市委 0.26666668, 柳州 0.18888889, 桂林 0.17777778, 铁路 0.15555556, 兴&gt;宁区 0.14444445, 来到 0.11111111, 开往 0.11111111, 前往 0.11111111, 公安 0.11111111, 工作 0.11111111, 运往 0.11111111, 城市 0.08888889, 美丽 0.08888889, 召开 0.08888889, 从事 0.08888889, 官塘 0.08888889, 楼市 0.08888889, 分局 0.07777778, 南宁市委 0.07777778, 动车 0.07777778, 发生 0.07777778, 举行 0.07777778, 西乡 0.06666667, 市长 0.06666667]贵阳 : [本报 1.0, 重庆 0.73333335, 新华社 0.46666667, 方向 0.43333334, 前往 0.4, 哥俩 0.4, 城区 0.4, 老家 0.33333334, 西安 0.26666668, 成都 0.26666668, 街头 0.26666668, 晚报 0.26666668, 无关 0.26666668, 杭州 0.23333333, 涉及 0.2, 以及 0.2, 市内 0.2, 网友 0.2, 郑州 0.16666667, 南宁 0.16666667, 长沙 0.16666667, 武汉 0.16666667, 摆摊 0.16666667, 市委 0.13333334, 昆明 0.13333334, 安顺 0.13333334, 来到 0.13333334, 争霸 0.13333334, 四强 0.13333334, 铁路 0.13333334]庆阳 : [甘肃 1.0, 甘肃庆阳 0.8, 甘肃省 0.4, 地区 0.4, 老区 0.3, 森林 0.2, 平凉 0.2, 镇远县 0.1, 革命 0.1, 韩凤廷 0.1, 交通处 0.1, 兰州森林大队 0.1, 大队 0.1, 兰州 0.1, 西峰 0.1, 发&gt;送 0.1, 一辆 0.1, 牌照 0.1, 来自 0.1]沈阳 : [军区 1.0, 晚报 0.5123967, 方向 0.3181818, 本报 0.27272728, 沈阳晚报 0.23553719, 新华社 0.20661157, 沈阳军区 0.18595041, 军区队 0.15289256, 海狮队 0.14876033, 自动化所 0.14049587, 此次 0.14049587, 经济区 0.1322314, 中国 0.12809917, &gt;大连 0.12809917, 大爷 0.12809917, 市委 0.12396694, 一家 0.11570248, 高速 0.11570248, 国际 0.11157025, 火车票 0.11157025, 法库 0.10743801, 大学 0.10330579, 长春 0.10330579, 直达 0.09917355, 深圳 0.09090909, 上海 0.08677686, 记者 0.08677686, 海狮 0.08264463, 大妈 0.08264463, 两位 0.08264463]    合肥 : [火车站 1.0, 市民 0.8181818, 市区 0.53333336, 楼市 0.4848485, 合肥火车站 0.4121212, 铁路 0.38787878, 安徽 0.36969697, 到达 0.36363637, 市场 0.34545454, 上周 0.3030303, 芜湖 0.2969697, 召开 0.28484848, 记者 0.27272728, 成为 0.27272728, 来到 0.26666668, 安徽合肥 0.24242425, 城市 0.24242425, 经济圈 0.24242425, 公交 0.24242425, 目前 0.23636363, 本报 0.21818182, 今年 0.21818182, 起飞 0.21818182, 汽车 0.21212122, 物质 0.2060606, 合肥楼市 0.2060606, 空港 0.2060606, 工业 0.19393939, 标题 0.18181819, 野生 0.16969697]大同 : [大学 1.0, 铁路 0.52380955, 山西 0.5, 证券 0.33333334, 大同大学 0.33333334, 山西省 0.23809524, 此次 0.23809524, 山西大同 0.1904762, 世界 0.1904762, 世界大同 0.1904762, 街道 0.16666667, 太原 0.14285715, 市委 0.14285715, 上海 0.14285715, 派出所 0.14285715, 公安处 0.14285715, 日方 0.14285715, 转发 0.14285715, 运城 0.11904762, 军分区 0.0952381, 矿务局 0.0952381, 小学 0.0952381, 参加 0.0952381, 项目 0.0952381, 中学 0.0952381, 水厂 0.0952381, 车辆段 0.0952381, 开往 0.0952381, 大同证券 0.0952381, 战役 0.071428575]拉萨 : [火车站 1.0, 新华社 0.91935486, 西藏 0.7580645, 市区 0.61290324, 本报 0.58064514, 召开 0.5645161, 海关 0.5483871, 城市 0.48387095, 拉萨火车站 0.4032258, 市委 0.38709676, 成都 0.37096775, 贡嘎 0.3548387, 开幕 0.32258064, 发布 0.30645162, 西藏拉萨 0.2580645, 会议 0.2580645, 机场 0.22580644, 闭幕 0.22580644, 隆重 0.22580644, 林芝 0.20967741, 举行 0.19354838, 开通 0.19354838, 营业部 0.19354838, 市民 0.17741935, 市场 0.17741935, 经济 0.17741935, 中心 0.17741935, 空气 0.17741935, 成为 0.17741935, 人民 0.16129032]西宁 : [新华社 1.0, 上海 0.8235294, 兰州 0.3529412, 辗转 0.3529412, 本报 0.29411766, 青海 0.29411766, 考察 0.23529412, 当街 0.23529412, 特钢 0.1764706, 方向 0.1764706, 分行 0.1764706, 索贿 0.1764706, 北京 0.14705883, 但是 0.14705883, 拉萨 0.11764706, 我们 0.11764706, 标题 0.11764706, 交警 0.11764706, 代表团 0.11764706, 处理 0.0882353, 银川 0.0882353, 车票 0.0882353, 筹建 0.0882353, 中转 0.0882353, 参加 0.0882353, 一月 0.05882353, 试验局 0.05882353, 二月 0.05882353, 地区 0.05882353, 严肃 0.05882353]    最后我们看一下分别使用7种相似度算法算出来的 兰州 的相关词：----------------------------------------------------------兰州 的相关词（CosineTextSimilarity）：    1、兰州 1.0    2、沈阳 0.5    3、北京军区 0.47    4、后勤部 0.46    5、沈阳军区 0.46    6、总医院 0.46    7、新疆军区 0.46    8、司令员 0.42    9、甘肃兰州 0.42    10、兰州新区 0.42    11、某师 0.39    12、郑蒲港 0.38    13、西咸 0.38    14、天水 0.37    15、郑东 0.37耗时：25秒,572毫秒----------------------------------------------------------兰州 的相关词（EditDistanceTextSimilarity）：    1、兰州 1.0    2、北京 0.21    3、福州 0.2    4、太原 0.19    5、成都 0.17    6、南宁 0.17    7、西安 0.17    8、哈尔滨 0.17    9、贵阳 0.16    10、庆阳 0.15    11、合肥 0.14    12、大同 0.14    13、沈阳 0.14    14、珀斯 0.13    15、拉萨 0.13耗时：44秒,253毫秒----------------------------------------------------------兰州 的相关词（EuclideanDistanceTextSimilarity）：    1、兰州 1.0    2、后勤部 0.37    3、北京军区 0.37    4、新疆军区 0.37    5、沈阳 0.37    6、沈阳军区 0.37    7、总医院 0.37    8、上海浦东新区 0.36    9、郑蒲港 0.36    10、浦东新区 0.36    11、甘肃兰州 0.36    12、西咸 0.36    13、西咸新区 0.36    14、正定新区 0.36    15、司令员 0.36耗时：24秒,710毫秒----------------------------------------------------------兰州 的相关词（SimpleTextSimilarity）：    1、兰州 1.0    2、福州 0.36    3、西安 0.33    4、李红旗 0.33    5、中国金融信息中心 0.33    6、南特 0.32    7、卡塔赫纳 0.32    8、哈尔滨 0.3    9、武汉 0.3    10、戴克瑞 0.3    11、楚雄州 0.29    12、朱梦魁 0.29    13、岳菲菲 0.29    14、长沙 0.28    15、吕国庆 0.28耗时：21秒,918毫秒----------------------------------------------------------兰州 的相关词（JaccardTextSimilarity）：    1、兰州 1.0    2、福州 0.22    3、西安 0.2    4、哈尔滨 0.18    5、北京 0.18    6、武汉 0.18    7、成都 0.18    8、长沙 0.15    9、太原 0.15    10、贵阳 0.15    11、沈阳 0.15    12、广州 0.15    13、拉萨 0.15    14、南昌 0.15    15、长春 0.13耗时：19秒,717毫秒----------------------------------------------------------兰州 的相关词（ManhattanDistanceTextSimilarity）：    1、兰州 1.0    2、上海浦东新区 0.11    3、陕西西咸新区 0.11    4、甘肃兰州 0.11    5、北京军区 0.11    6、新疆军区 0.11    7、西咸 0.11    8、正定新区 0.11    9、天府新区 0.11    10、沈阳军区 0.11    11、国家级新区 0.11    12、兰州新区 0.11    13、侠客 0.1    14、威胁论 0.1    15、一两个月 0.1耗时：23秒,857毫秒----------------------------------------------------------兰州 的相关词（SimHashPlusHammingDistanceTextSimilarity）：    1、兰州 1.0    2、鱼水 0.96    3、冯导 0.95    4、新闻稿 0.95    5、科学 0.95    6、物业公司 0.95    7、现役军人 0.95    8、何人 0.95    9、张轸 0.94    10、公告 0.94    11、信息发布 0.94    12、倡议 0.94    13、药液 0.94    14、考古发掘 0.94    15、公开发布 0.94耗时：5分钟,57秒,339毫秒----------------------------------------------------------兰州 的相关词（JaroDistanceTextSimilarity）：    1、兰州 1.0    2、长沙 0.49    3、哈尔滨 0.49    4、福州 0.48    5、太原 0.47    6、庆阳 0.46    7、济南 0.46    8、北京 0.45    9、成都 0.45    10、张家明 0.45    11、西安 0.45    12、孙勇 0.45    13、楚雄州 0.44    14、福州站 0.44    15、南宁 0.44耗时：12秒,718毫秒----------------------------------------------------------兰州 的相关词（JaroWinklerDistanceTextSimilarity）：    1、兰州 1.0    2、拉萨 0.56    3、南宁 0.55    4、朝廷 0.55    5、公判 0.54    6、萨蒙德 0.53    7、世界级 0.53    8、滨湖 0.53    9、大大小小 0.52    10、大选 0.52    11、七届 0.52    12、烘焙 0.51    13、武平县 0.51    14、莫斯科 0.51    15、复训 0.51耗时：16秒,723毫秒----------------------------------------------------------兰州 的相关词（SørensenDiceCoefficientTextSimilarity）：    1、兰州 1.0    2、福州 0.37    3、西安 0.33    4、哈尔滨 0.3    5、北京 0.3    6、武汉 0.3    7、成都 0.3    8、长沙 0.27    9、太原 0.27    10、贵阳 0.27    11、沈阳 0.27    12、广州 0.27    13、拉萨 0.27    14、南昌 0.27    15、长春 0.23耗时：19秒,852毫秒----------------------------------------------------------</code></pre><h4 id="21、词频统计："><a href="#21、词频统计：" class="headerlink" title="21、词频统计："></a>21、词频统计：</h4><p>org.apdplat.word.WordFrequencyStatistics 提供了词频统计的功能</p><p>命令行脚本的调用方法如下：</p><pre><code>将需要统计词频的文本写入文件：text.txtchmod +x wfs.sh &amp; wfs.sh -textFile=text.txt -statisticsResultFile=statistics-result.txt程序运行结束后打开文件statistics-result.txt查看词频统计结果</code></pre><p>在程序中的调用方法如下：</p><pre><code>//词频统计设置WordFrequencyStatistics wordFrequencyStatistics = new WordFrequencyStatistics();wordFrequencyStatistics.setRemoveStopWord(false);wordFrequencyStatistics.setResultPath(&quot;word-frequency-statistics.txt&quot;);wordFrequencyStatistics.setSegmentationAlgorithm(SegmentationAlgorithm.MaxNgramScore);//开始分词wordFrequencyStatistics.seg(&quot;明天下雨，结合成分子，明天有关于分子和原子的课程，下雨了也要去听课&quot;);//输出词频统计结果wordFrequencyStatistics.dump();//准备文件Files.write(Paths.get(&quot;text-to-seg.txt&quot;), Arrays.asList(&quot;word分词是一个Java实现的分布式中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。&quot;));//清除之前的统计结果wordFrequencyStatistics.reset();//对文件进行分词wordFrequencyStatistics.seg(new File(&quot;text-to-seg.txt&quot;), new File(&quot;text-seg-result.txt&quot;));//输出词频统计结果wordFrequencyStatistics.dump(&quot;file-seg-statistics-result.txt&quot;);</code></pre><p>第一句话的词频统计结果：</p><pre><code>1、下雨 22、明天 23、分子 24、课程 15、听课 16、结合 17、原子 18、去 19、成 110、关于 111、和 112、也要 113、有 114、的 115、了 1</code></pre><p>第二句话的词频统计结果：</p><pre><code>1、分词 22、的 23、基于 14、word 15、组件 16、词典 17、ngram 18、多种 19、实现 110、并 111、利用 112、消除歧义 113、中文分词 114、算法 115、是 116、分布式 117、了 118、提供 119、模型 120、来 121、一个 122、Java 1    </code></pre><h4 id="22、文本相似度："><a href="#22、文本相似度：" class="headerlink" title="22、文本相似度："></a>22、文本相似度：</h4><p>word分词提供了多种文本相似度计算方式：</p><p>方式一：余弦相似度，通过计算两个向量的夹角余弦值来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.CosineTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new CosineTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.67我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式二：简单共有词，通过计算两篇文档共有的词的总字符数除以最长文档字符数来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.SimpleTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new SimpleTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.5我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式三：编辑距离，通过计算两个字串之间由一个转成另一个所需的最少编辑操作次数来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.EditDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new EditDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.5我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式四：SimHash + 汉明距离，先使用SimHash把不同长度的文本映射为等长文本，然后再计算等长文本的汉明距离</p><p>实现类：org.apdplat.word.analysis.SimHashPlusHammingDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new SimHashPlusHammingDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.95我爱购物 和 他是黑客 的相似度分值：0.83我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.86他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式五：Jaccard相似性系数（Jaccard similarity coefficient），通过计算两个集合交集的大小除以并集的大小来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.JaccardTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new JaccardTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.5我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式六：欧几里得距离（Euclidean Distance），通过计算两点间的距离来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.EuclideanDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new EuclideanDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.41我爱购物 和 他是黑客 的相似度分值：0.29我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.29他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式七：曼哈顿距离（Manhattan Distance），通过计算两个点在标准坐标系上的绝对轴距总和来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.ManhattanDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new ManhattanDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.33我爱购物 和 他是黑客 的相似度分值：0.14我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.14他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式八：Jaro距离（Jaro Distance），编辑距离的一种类型</p><p>实现类：org.apdplat.word.analysis.JaroDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new JaroDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.67我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式九：Jaro–Winkler距离（Jaro–Winkler Distance），Jaro的扩展</p><p>实现类：org.apdplat.word.analysis.JaroWinklerDistanceTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new JaroWinklerDistanceTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.73我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><p>方式十：Sørensen–Dice系数（Sørensen–Dice coefficient），通过计算两个集合交集的大小的2倍除以两个集合的大小之和来评估他们的相似度</p><p>实现类：org.apdplat.word.analysis.SørensenDiceCoefficientTextSimilarity</p><p>用法如下：</p><pre><code>String text1 = &quot;我爱购物&quot;;String text2 = &quot;我爱读书&quot;;String text3 = &quot;他是黑客&quot;;TextSimilarity textSimilarity = new SørensenDiceCoefficientTextSimilarity();double score1pk1 = textSimilarity.similarScore(text1, text1);double score1pk2 = textSimilarity.similarScore(text1, text2);double score1pk3 = textSimilarity.similarScore(text1, text3);double score2pk2 = textSimilarity.similarScore(text2, text2);double score2pk3 = textSimilarity.similarScore(text2, text3);double score3pk3 = textSimilarity.similarScore(text3, text3);System.out.println(text1+&quot; 和 &quot;+text1+&quot; 的相似度分值：&quot;+score1pk1);System.out.println(text1+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score1pk2);System.out.println(text1+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score1pk3);System.out.println(text2+&quot; 和 &quot;+text2+&quot; 的相似度分值：&quot;+score2pk2);System.out.println(text2+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score2pk3);System.out.println(text3+&quot; 和 &quot;+text3+&quot; 的相似度分值：&quot;+score3pk3);</code></pre><p>运行结果如下：</p><pre><code>我爱购物 和 我爱购物 的相似度分值：1.0我爱购物 和 我爱读书 的相似度分值：0.67我爱购物 和 他是黑客 的相似度分值：0.0我爱读书 和 我爱读书 的相似度分值：1.0我爱读书 和 他是黑客 的相似度分值：0.0他是黑客 和 他是黑客 的相似度分值：1.0</code></pre><h4 id="23、判定句子是有意义的人话的可能性："><a href="#23、判定句子是有意义的人话的可能性：" class="headerlink" title="23、判定句子是有意义的人话的可能性："></a>23、判定句子是有意义的人话的可能性：</h4><pre><code>通过如下命令:unix-like:    chmod +x sentence-identify.sh &amp; ./sentence-identify.shwindows:    ./sentence-identify.bat运行 org.apdplat.word.analysis.SentenceIdentify 类的结果如下所示:1. 句子: 我是一个男人你是一个女人, 概率: 0.714285731. 句子: 我是一个人, 概率: 0.66666672. 句子: 我爱读书, 概率: 0.53. 句子: 我爱学习, 概率: 0.54. 句子: 法蒂小室汝辈武学大师改个入门处, 概率: 0.28571435. 句子: 显气孔率高压线塔总监督室波洛奈兹王毅陈刘玉荣, 概率: 0.28571436. 句子: 王捷俊汇报演出干草加韦拉一杠地垄墙未尝不可, 概率: 0.257. 句子: 八九点钟山光水色饱经世变普留申科淮河镇乐不极盘模拟飞行, 概率: 0.222222228. 句子: 物位任务区亡灵书巴纳尔没脑子揪人心肺复习功课林友力避风塘, 概率: 0.29.  句子: 参与方植物学报白善烨暗影狂奔骑白马痦子山城堡犹豫不定岳阳机场, 概率: 0.2接着可根据命令行提示输入句子并回车来获得句子的评分例如输入句子并回车:为中国崛起而努力奋斗程序返回结果如下:随机单词: [为, 中国, 崛起, 而, 努力, 奋斗]生成句子: 为中国崛起而努力奋斗句子概率: 1.0例如输入句子并回车:人脑的记忆是保存在生物电上还是在细胞里？程序返回结果如下:随机单词: [人脑, 的, 记忆, 是, 保存, 在, 生物, 电, 上, 还是, 在, 细胞, 里]生成句子: 人脑的记忆是保存在生物电上还是在细胞里？句子概率: 0.8333333</code></pre><h3 id="分词算法效果评估："><a href="#分词算法效果评估：" class="headerlink" title="分词算法效果评估："></a>分词算法效果评估：</h3><pre><code>1、word分词 最大Ngram分值算法：分词速度：370.9714 字符/毫秒行数完美率：66.55%  行数错误率：33.44%  总的行数：2533709  完美行数：1686210  错误行数：847499字数完美率：60.94% 字数错误率：39.05% 总的字数：28374490 完美字数：17293964 错误字数：110805262、word分词 最少词数算法：分词速度：330.1586 字符/毫秒行数完美率：65.67%  行数错误率：34.32%  总的行数：2533709  完美行数：1663958  错误行数：869751字数完美率：60.12% 字数错误率：39.87% 总的字数：28374490 完美字数：17059641 错误字数：113148493、word分词 全切分算法：分词速度：62.960262 字符/毫秒行数完美率：57.2%  行数错误率：42.79%  总的行数：2533709  完美行数：1449288  错误行数：1084421字数完美率：47.95% 字数错误率：52.04% 总的字数：28374490 完美字数：13605742 错误字数：147687484、word分词 双向最大最小匹配算法：分词速度：462.87158 字符/毫秒行数完美率：53.06%  行数错误率：46.93%  总的行数：2533709  完美行数：1344624  错误行数：1189085字数完美率：43.07% 字数错误率：56.92% 总的字数：28374490 完美字数：12221610 错误字数：161528805、word分词 双向最小匹配算法：分词速度：967.68604 字符/毫秒行数完美率：46.34%  行数错误率：53.65%  总的行数：2533709  完美行数：1174276  错误行数：1359433字数完美率：36.07% 字数错误率：63.92% 总的字数：28374490 完美字数：10236574 错误字数：181379166、word分词 双向最大匹配算法：分词速度：661.148 字符/毫秒行数完美率：46.18%  行数错误率：53.81%  总的行数：2533709  完美行数：1170075  错误行数：1363634字数完美率：35.65% 字数错误率：64.34% 总的字数：28374490 完美字数：10117122 错误字数：182573687、word分词 正向最大匹配算法：分词速度：1567.1318 字符/毫秒行数完美率：41.88%  行数错误率：58.11%  总的行数：2533709  完美行数：1061189  错误行数：1472520字数完美率：31.35% 字数错误率：68.64% 总的字数：28374490 完美字数：8896173 错误字数：194783178、word分词 逆向最大匹配算法：分词速度：1232.6017 字符/毫秒行数完美率：41.69%  行数错误率：58.3%  总的行数：2533709  完美行数：1056515  错误行数：1477194字数完美率：30.98% 字数错误率：69.01% 总的字数：28374490 完美字数：8792532 错误字数：195819589、word分词 逆向最小匹配算法：分词速度：1936.9575 字符/毫秒行数完美率：41.42%  行数错误率：58.57%  总的行数：2533709  完美行数：1049673  错误行数：1484036字数完美率：31.34% 字数错误率：68.65% 总的字数：28374490 完美字数：8893622 错误字数：1948086810、word分词 正向最小匹配算法：分词速度：2228.9465 字符/毫秒行数完美率：36.7%  行数错误率：63.29%  总的行数：2533709  完美行数：930069  错误行数：1603640字数完美率：26.72% 字数错误率：73.27% 总的字数：28374490 完美字数：7583741 错误字数：20790749</code></pre><h3 id="相关文章："><a href="#相关文章：" class="headerlink" title="相关文章："></a>相关文章：</h3><p>   <a href="http://yangshangchuan.iteye.com/blog/2031813" target="_blank" rel="noopener">1、中文分词算法 之 基于词典的正向最大匹配算法</a></p><p>   <a href="http://yangshangchuan.iteye.com/blog/2033843" target="_blank" rel="noopener">2、中文分词算法 之 基于词典的逆向最大匹配算法</a></p><p>   <a href="http://yangshangchuan.iteye.com/blog/2035007" target="_blank" rel="noopener">3、中文分词算法 之 词典机制性能优化与测试</a></p><p>   <a href="http://yangshangchuan.iteye.com/blog/2040423" target="_blank" rel="noopener">4、中文分词算法 之 基于词典的正向最小匹配算法</a></p><p>   <a href="http://yangshangchuan.iteye.com/blog/2040431" target="_blank" rel="noopener">5、中文分词算法 之 基于词典的逆向最小匹配算法</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/411112" target="_blank" rel="noopener">6、一种利用ngram模型来消除歧义的中文分词方法</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/411032" target="_blank" rel="noopener">7、一种基于词性序列的人名识别方法</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/412785" target="_blank" rel="noopener">8、中文分词算法 之 基于词典的全切分算法</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/412921" target="_blank" rel="noopener">9、9大Java开源中文分词器的使用方法和分词效果对比</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/408779" target="_blank" rel="noopener">10、中文分词之11946组同义词</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/411301" target="_blank" rel="noopener">11、中文分词之9271组反义词</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/414076" target="_blank" rel="noopener">12、如何利用多核提升分词速度</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/417047" target="_blank" rel="noopener">13、利用word分词来计算文本相似度</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/417641" target="_blank" rel="noopener">14、利用word分词来对文本进行词频统计</a></p><p>   <a href="http://my.oschina.net/apdplat/blog/417922" target="_blank" rel="noopener">15、利用word分词通过计算词的语境来获得相关词</a></p><h3 id="相关项目："><a href="#相关项目：" class="headerlink" title="相关项目："></a>相关项目：</h3><p><a href="https://github.com/ysc/cws_evaluation/" target="_blank" rel="noopener">Java开源项目cws_evaluation：中文分词器分词效果评估对比</a></p><p><a href="https://github.com/ysc/QuestionAnsweringSystem/" target="_blank" rel="noopener">Java开源项目QuestionAnsweringSystem：人机问答系统</a></p><p><a href="https://github.com/ysc/word_web/" target="_blank" rel="noopener">Java开源项目word_web：通过web服务器对word分词的资源进行集中统一管理</a></p><h3 id="相关文献："><a href="#相关文献：" class="headerlink" title="相关文献："></a>相关文献：</h3><p><a href="http://linux.thai.net/~thep/datrie/datrie.html" target="_blank" rel="noopener">An Implementation of Double-Array Trie</a></p><p><a href="http://technology.chtsai.org/mmseg/" target="_blank" rel="noopener">MMSEG: A Word Identification System for Mandarin Chinese Text Based on Two Variants of the Maximum Matching Algorithm</a></p><p><a href="https://books.google.com/ngrams" target="_blank" rel="noopener">With Google’s new tool Ngram Viewer, you can visualise the rise and fall of concepts across 5 million books and 500 years!</a></p><p><a href="https://code.google.com/p/word2vec/" target="_blank" rel="noopener">word2vec</a></p><p><a href="http://open.163.com/special/cuvocw/meilihanyu.html" target="_blank" rel="noopener">魅力汉语</a></p><p><a href="https://travis-ci.org/ysc/word" target="_blank" rel="noopener">https://travis-ci.org/ysc/word</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Java </tag>
            
            <tag> 分词 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>javaNLP-各种Java分词工具比较</title>
      <link href="/2018/06/29/javaNLP-%E5%90%84%E7%A7%8DJava%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E6%AF%94%E8%BE%83/"/>
      <url>/2018/06/29/javaNLP-%E5%90%84%E7%A7%8DJava%E5%88%86%E8%AF%8D%E5%B7%A5%E5%85%B7%E6%AF%94%E8%BE%83/</url>
      
        <content type="html"><![CDATA[<p>转载自：<a href="https://github.com/ysc/cws_evaluation" target="_blank" rel="noopener">Java开源项目cws_evaluation：中文分词器分词效果评估对比</a></p><h2 id="中文分词器分词效果评估对比"><a href="#中文分词器分词效果评估对比" class="headerlink" title="中文分词器分词效果评估对比"></a>中文分词器分词效果评估对比</h2><a id="more"></a><h3 id="捐赠致谢"><a href="#捐赠致谢" class="headerlink" title="捐赠致谢"></a><a href="https://github.com/ysc/QuestionAnsweringSystem/wiki/donation" target="_blank" rel="noopener">捐赠致谢</a></h3><h3 id="使用说明："><a href="#使用说明：" class="headerlink" title="使用说明："></a>使用说明：</h3><p>   如何建立开发环境？</p><pre><code>如果是使用Netbeans、IDEA，则直接打开项目如果是使用Eclipse、MyEclipse，则要执行导入操作推荐使用IDEA</code></pre><p>   评估采用的测试文本位于data目录下，253 3709行，共2837 4490个字符</p><p>   test-test.txt为未分词的文件，一行一个句子或短语，格式如下：</p><pre><code>迈向充满希望的新世纪一九九八年新年讲话附图片1张中共中央总书记国家主席江泽民一九九七年十二月三十一日12月31日总书记国家主席江泽民发表1998年新年讲话新华社记者兰红光摄</code></pre><p>   standard-text.txt为人工分好词的文件，用于判断参与评估的分词器的分词结果是否正确，词和词之间以空格分隔，格式如下：</p><pre><code>迈向 充满 希望 的 新 世纪一九九八年 新年 讲话附 图片 1 张中共中央 总书记国家 主席 江泽民一九九七年 十二月 三十一日12月 31日总书记国家 主席 江泽民 发表 1998年 新年 讲话新华社 记者 兰红光 摄</code></pre><p>   speed-test-text.txt用于纯粹的速度对比</p><p>   注意：由于每个分词器的词典格式不一致，除了词典之外使用的其他模型的格式也不一致，所以我们评估对比时没有让所有分词器使用统一的词典和模型，测试的是各个分词器的默认行为</p><p>   运行org.apdplat.evaluation.Evaluator类可获得评估结果</p><p>   运行org.apdplat.evaluation.WordSegmenter类可对比不同分词器结果</p><p>   windows:</p><pre><code>./contrast.bat./evaluation.bat</code></pre><p>   linux:</p><pre><code>chmod +x contrast.sh &amp; ./contrast.shchmod +x evaluation.sh &amp; ./evaluation.sh</code></pre><p>   最终评估结果文件位于report目录下：分词效果评估报告.txt</p><p>   注意：stanford分词器是吃内存的怪兽，运行的时候需要增加虚拟机参数 -Xms3000m -Xmx3000m</p><h3 id="评估报告："><a href="#评估报告：" class="headerlink" title="评估报告："></a>评估报告：</h3><pre><code>1、word分词 最大Ngram分值算法：分词速度：370.9714 字符/毫秒行数完美率：66.55%  行数错误率：33.44%  总的行数：2533709  完美行数：1686210  错误行数：847499字数完美率：60.94% 字数错误率：39.05% 总的字数：28374490 完美字数：17293964 错误字数：110805262、word分词 最少词数算法：分词速度：330.1586 字符/毫秒行数完美率：65.67%  行数错误率：34.32%  总的行数：2533709  完美行数：1663958  错误行数：869751字数完美率：60.12% 字数错误率：39.87% 总的字数：28374490 完美字数：17059641 错误字数：113148493、HanLP分词器 标准分词：分词速度：935.7724 字符/毫秒行数完美率：58.31%  行数错误率：41.68%  总的行数：2533709  完美行数：1477422  错误行数：1056287字数完美率：50.43% 字数错误率：49.56% 总的字数：28374490 完美字数：14311008 错误字数：140634824、word分词 全切分算法：分词速度：62.960262 字符/毫秒行数完美率：57.2%  行数错误率：42.79%  总的行数：2533709  完美行数：1449288  错误行数：1084421字数完美率：47.95% 字数错误率：52.04% 总的字数：28374490 完美字数：13605742 错误字数：147687485、Ansj BaseAnalysis 基本分词：分词速度：1295.5205 字符/毫秒行数完美率：55.36%  行数错误率：44.63%  总的行数：2533709  完美行数：1402905  错误行数：1130804字数完美率：48.18% 字数错误率：51.81% 总的字数：28374490 完美字数：13672441 错误字数：147020496、smartcn：分词速度：611.1504 字符/毫秒行数完美率：55.29%  行数错误率：44.7%  总的行数：2533690  完美行数：1401069  错误行数：1132621字数完美率：48.03% 字数错误率：51.96% 总的字数：28374433 完美字数：13628910 错误字数：147455237、Ansj ToAnalysis 精准分词：分词速度：759.40717 字符/毫秒行数完美率：54.72%  行数错误率：45.27%  总的行数：2533709  完美行数：1386683  错误行数：1147026字数完美率：44.99% 字数错误率：55.0% 总的字数：28374490 完美字数：12768426 错误字数：156060648、HanLP分词器 极速词典分词：分词速度：6015.3677 字符/毫秒行数完美率：54.25%  行数错误率：45.74%  总的行数：2533709  完美行数：1374736  错误行数：1158973字数完美率：46.12% 字数错误率：53.87% 总的字数：28374490 完美字数：13088320 错误字数：152861709、word分词 双向最大最小匹配算法：分词速度：462.87158 字符/毫秒行数完美率：53.06%  行数错误率：46.93%  总的行数：2533709  完美行数：1344624  错误行数：1189085字数完美率：43.07% 字数错误率：56.92% 总的字数：28374490 完美字数：12221610 错误字数：1615288010、HanLP分词器 N-最短路径分词：分词速度：77.89775 字符/毫秒行数完美率：53.01%  行数错误率：46.98%  总的行数：2533709  完美行数：1343252  错误行数：1190457字数完美率：44.42% 字数错误率：55.57% 总的字数：28374490 完美字数：12604878 错误字数：1576961211、HanLP分词器 最短路径分词：分词速度：384.70233 字符/毫秒行数完美率：52.94%  行数错误率：47.05%  总的行数：2533709  完美行数：1341450  错误行数：1192259字数完美率：43.76% 字数错误率：56.23% 总的字数：28374490 完美字数：12417741 错误字数：1595674912、Ansj NlpAnalysis NLP分词：分词速度：172.19516 字符/毫秒行数完美率：52.66%  行数错误率：47.33%  总的行数：2533709  完美行数：1334314  错误行数：1199395字数完美率：42.66% 字数错误率：57.33% 总的字数：28374490 完美字数：12105808 错误字数：1626868213、HanLP分词器 NLP分词：分词速度：408.2249 字符/毫秒行数完美率：52.18%  行数错误率：47.81%  总的行数：2533709  完美行数：1322216  错误行数：1211493字数完美率：43.03% 字数错误率：56.96% 总的字数：28374490 完美字数：12211399 错误字数：1616309114、FudanNLP：分词速度：123.456985 字符/毫秒行数完美率：51.48%  行数错误率：48.51%  总的行数：2533709  完美行数：1304371  错误行数：1229338字数完美率：43.22% 字数错误率：56.77% 总的字数：28374490 完美字数：12265742 错误字数：1610874815、Jieba SEARCH：分词速度：993.435 字符/毫秒行数完美率：50.84%  行数错误率：49.15%  总的行数：2533709  完美行数：1288237  错误行数：1245472字数完美率：41.54% 字数错误率：58.45% 总的字数：28374490 完美字数：11789036 错误字数：1658545416、Jcseg 复杂模式：分词速度：561.55975 字符/毫秒行数完美率：47.96%  行数错误率：52.03%  总的行数：2533709  完美行数：1215171  错误行数：1318538字数完美率：38.84% 字数错误率：61.15% 总的字数：28374490 完美字数：11021588 错误字数：1735290217、word分词 双向最小匹配算法：分词速度：967.68604 字符/毫秒行数完美率：46.34%  行数错误率：53.65%  总的行数：2533709  完美行数：1174276  错误行数：1359433字数完美率：36.07% 字数错误率：63.92% 总的字数：28374490 完美字数：10236574 错误字数：1813791618、word分词 双向最大匹配算法：分词速度：661.148 字符/毫秒行数完美率：46.18%  行数错误率：53.81%  总的行数：2533709  完美行数：1170075  错误行数：1363634字数完美率：35.65% 字数错误率：64.34% 总的字数：28374490 完美字数：10117122 错误字数：1825736819、HanLP分词器 索引分词：分词速度：942.4862 字符/毫秒行数完美率：45.44%  行数错误率：54.55%  总的行数：2533709  完美行数：1151473  错误行数：1382236字数完美率：35.48% 字数错误率：64.51% 总的字数：28374490 完美字数：10068062 错误字数：1830642820、Jcseg 简易模式：分词速度：1193.3085 字符/毫秒行数完美率：44.59%  行数错误率：55.4%  总的行数：2533709  完美行数：1130000  错误行数：1403709字数完美率：35.78% 字数错误率：64.21% 总的字数：28374490 完美字数：10155059 错误字数：1821943121、word分词 正向最大匹配算法：分词速度：1567.1318 字符/毫秒行数完美率：41.88%  行数错误率：58.11%  总的行数：2533709  完美行数：1061189  错误行数：1472520字数完美率：31.35% 字数错误率：68.64% 总的字数：28374490 完美字数：8896173 错误字数：1947831722、word分词 逆向最大匹配算法：分词速度：1232.6017 字符/毫秒行数完美率：41.69%  行数错误率：58.3%  总的行数：2533709  完美行数：1056515  错误行数：1477194字数完美率：30.98% 字数错误率：69.01% 总的字数：28374490 完美字数：8792532 错误字数：1958195823、word分词 逆向最小匹配算法：分词速度：1936.9575 字符/毫秒行数完美率：41.42%  行数错误率：58.57%  总的行数：2533709  完美行数：1049673  错误行数：1484036字数完美率：31.34% 字数错误率：68.65% 总的字数：28374490 完美字数：8893622 错误字数：1948086824、Ansj IndexAnalysis 面向索引的分词：分词速度：677.1308 字符/毫秒行数完美率：40.66%  行数错误率：59.33%  总的行数：2533709  完美行数：1030336  错误行数：1503373字数完美率：29.81% 字数错误率：70.18% 总的字数：28374490 完美字数：8459997 错误字数：1991449325、MMSeg4j ComplexSeg：分词速度：1699.5801 字符/毫秒行数完美率：38.81%  行数错误率：61.18%  总的行数：2533688  完美行数：983517  错误行数：1550171字数完美率：29.6% 字数错误率：70.39% 总的字数：28374428 完美字数：8400089 错误字数：1997433926、MMSeg4j SimpleSeg：分词速度：2355.5115 字符/毫秒行数完美率：37.57%  行数错误率：62.42%  总的行数：2533688  完美行数：951909  错误行数：1581779字数完美率：28.45% 字数错误率：71.54% 总的字数：28374428 完美字数：8074021 错误字数：2030040727、IKAnalyzer 智能切分：分词速度：319.28085 字符/毫秒行数完美率：37.55%  行数错误率：62.44%  总的行数：2533686  完美行数：951638  错误行数：1582048字数完美率：27.97% 字数错误率：72.02% 总的字数：28374416 完美字数：7938726 错误字数：2043569028、word分词 正向最小匹配算法：分词速度：2228.9465 字符/毫秒行数完美率：36.7%  行数错误率：63.29%  总的行数：2533709  完美行数：930069  错误行数：1603640字数完美率：26.72% 字数错误率：73.27% 总的字数：28374490 完美字数：7583741 错误字数：2079074929、Jieba INDEX：分词速度：861.55615 字符/毫秒行数完美率：36.02%  行数错误率：63.97%  总的行数：2533709  完美行数：912771  错误行数：1620938字数完美率：25.9% 字数错误率：74.09% 总的字数：28374490 完美字数：7351689 错误字数：2102280130、MMSeg4j MaxWordSeg：分词速度：1737.2491 字符/毫秒行数完美率：34.27%  行数错误率：65.72%  总的行数：2533688  完美行数：868440  错误行数：1665248字数完美率：25.2% 字数错误率：74.79% 总的字数：28374428 完美字数：7152898 错误字数：2122153031、IKAnalyzer 细粒度切分：分词速度：323.76926 字符/毫秒行数完美率：18.87%  行数错误率：81.12%  总的行数：2533686  完美行数：478176  错误行数：2055510字数完美率：10.93% 字数错误率：89.06% 总的字数：28374416 完美字数：3103178 错误字数：25271238评估耗时：41分钟,42秒,725毫秒重点说明：        关于分词速度，这个不是绝对的，每次测试都会有些差距，而完美率是固定的，所以按行数完美率排名        上面的评估报告中没有包括Stanford分词器和Paoding分词器        当前代码已经移除了Paoding分词器，因为Paoding分词器已经7年没有维护了        当前代码升级Stanford分词器到3.5.2，速度慢的无法等待评估完成，仅用于交互式效果对比        下面是之前代码对 Paoding分词器2.0.4-beta 和 Stanford分词器 3.3.1 的评估数据Stanford Beijing University segmentation：分词速度：14.4612055 字符/毫秒行数完美率：58.29%  行数错误率：41.7%  总的行数：2533709  完美行数：1477034  错误行数：1056675字数完美率：51.36% 字数错误率：48.63% 总的字数：28374490 完美字数：14574120 错误字数：13800370Stanford Chinese Treebank segmentation：分词速度：13.723294 字符/毫秒行数完美率：55.45%  行数错误率：44.54%  总的行数：2533709  完美行数：1404968  错误行数：1128741字数完美率：47.27% 字数错误率：52.72% 总的字数：28374490 完美字数：13414926 错误字数：14959564Paoding MAX_WORD_LENGTH_MODE：分词速度：1343.1075 字符/毫秒行数完美率：14.19%  行数错误率：85.8%  总的行数：2533158  完美行数：359637  错误行数：2173521字数完美率：7.72% 字数错误率：92.27% 总的字数：28373102 完美字数：2191349 错误字数：26181753Paoding MOST_WORDS_MODE：分词速度：1338.9246 字符/毫秒行数完美率：11.6%  行数错误率：88.39%  总的行数：2533158  完美行数：294011  错误行数：2239147字数完美率：5.92% 字数错误率：94.07% 总的字数：28373102 完美字数：1680261 错误字数：26692841</code></pre><h3 id="效果对比："><a href="#效果对比：" class="headerlink" title="效果对比："></a>效果对比：</h3><h4 id="1、以-我爱楚离陌-为例子："><a href="#1、以-我爱楚离陌-为例子：" class="headerlink" title="1、以 我爱楚离陌 为例子："></a>1、以 我爱楚离陌 为例子：</h4><pre><code>word分词器 的分词结果：    1 、【全切分算法】    我 爱 楚离陌     2 、【双向最大最小匹配算法】    我 爱 楚离陌     3 、【最大Ngram分值算法】    我 爱 楚离陌     4 、【正向最大匹配算法】    我 爱 楚离陌     5 、【双向最大匹配算法】    我 爱 楚离陌     6 、【最少词数算法】    我 爱 楚离陌     7 、【逆向最大匹配算法】    我 爱 楚离陌     8 、【正向最小匹配算法】    我 爱 楚离陌     9 、【双向最小匹配算法】    我 爱 楚离陌     10 、【逆向最小匹配算法】    我 爱 楚离陌 Stanford分词器 的分词结果：    1 、【Stanford Chinese Treebank segmentation】    我 爱 楚离陌     2 、【Stanford Beijing University segmentation】    我 爱 楚 离陌 Ansj分词器 的分词结果：    1 、【BaseAnalysis】    我 爱 楚 离 陌     2 、【IndexAnalysis】    我 爱 楚 离 陌     3 、【ToAnalysis】    我 爱 楚 离 陌     4 、【NlpAnalysis】    我 爱 楚离 陌 HanLP分词器 的分词结果：    1 、【NLP分词】 我 爱 楚 离 陌     2 、【标准分词】  我 爱 楚 离 陌     3 、【N-最短路径分词】  我 爱 楚 离 陌     4 、【索引分词】  我 爱 楚 离 陌     5 、【最短路径分词】    我 爱 楚 离 陌     6 、【极速词典分词】    我 爱 楚 离 陌 smartcn分词器 的分词结果：    1 、【smartcn】    我 爱 楚 离 陌 FudanNLP分词器 的分词结果：    1 、【FudanNLP】    我 爱楚离陌Jieba分词器 的分词结果：    1 、【SEARCH】    我爱楚 离 陌     2 、【INDEX】    我爱楚 离 陌 Jcseg分词器 的分词结果：    1 、【简易模式】    我 爱 楚 离 陌     2 、【复杂模式】    我 爱 楚 离 陌 MMSeg4j分词器 的分词结果：    1 、【SimpleSeg】    我爱 楚 离 陌     2 、【ComplexSeg】    我爱 楚 离 陌     3 、【MaxWordSeg】    我爱 楚 离 陌 IKAnalyzer分词器 的分词结果：    1 、【智能切分】    我 爱 楚 离 陌     2 、【细粒度切分】    我 爱 楚 离 陌 </code></pre><h4 id="2、以-结合成分子-为例子："><a href="#2、以-结合成分子-为例子：" class="headerlink" title="2、以 结合成分子 为例子："></a>2、以 结合成分子 为例子：</h4><pre><code>word分词器 的分词结果：    1 、【全切分算法】    结合 成 分子     2 、【双向最大最小匹配算法】    结 合成 分子     3 、【最大Ngram分值算法】    结合 成 分子     4 、【正向最大匹配算法】    结合 成分 子     5 、【双向最大匹配算法】    结 合成 分子     6 、【最少词数算法】    结合 成 分子     7 、【逆向最大匹配算法】    结 合成 分子     8 、【正向最小匹配算法】    结合 成分 子     9 、【双向最小匹配算法】    结 合成 分子     10 、【逆向最小匹配算法】    结 合成 分子 Stanford分词器 的分词结果：    1 、【Stanford Chinese Treebank segmentation】    结合 成 分子     2 、【Stanford Beijing University segmentation】    结合 成 分子 Ansj分词器 的分词结果：    1 、【BaseAnalysis】    结合 成 分子     2 、【IndexAnalysis】    结合 成 分子     3 、【ToAnalysis】    结合 成 分子     4 、【NlpAnalysis】    结合 成 分子 HanLP分词器 的分词结果：    1 、【NLP分词】    结合 成 分子     2 、【标准分词】    结合 成 分子     3 、【N-最短路径分词】    结合 成 分子     4 、【索引分词】    结合 成 分子     5 、【最短路径分词】    结合 成 分子     6 、【极速词典分词】    结合 成分 子 smartcn分词器 的分词结果：    1 、【smartcn】    结合 成 分子 FudanNLP分词器 的分词结果：    1 、【FudanNLP】    结合 成 分子Jieba分词器 的分词结果：    1 、【SEARCH】    结合 成 分子     2 、【INDEX】    结合 成 分子 Jcseg分词器 的分词结果：    1 、【简易模式】    结合 成分 子     2 、【复杂模式】    结合 成 分子 MMSeg4j分词器 的分词结果：    1 、【SimpleSeg】    结合 成分 子     2 、【ComplexSeg】    结合 成分 子     3 、【MaxWordSeg】    结合 成分 子 IKAnalyzer分词器 的分词结果：    1 、【智能切分】    结合 成 分子     2 、【细粒度切分】    结合 合成 成分 分子</code></pre><h3 id="速度对比："><a href="#速度对比：" class="headerlink" title="速度对比："></a>速度对比：</h3><pre><code>1、HanLP分词器 极速词典分词：分词速度：5030.1978 字符/毫秒2、MMSeg4j MaxWordSeg：分词速度：2454.494 字符/毫秒3、MMSeg4j SimpleSeg：分词速度：2184.697 字符/毫秒4、word分词 逆向最小匹配算法：分词速度：1407.4127 字符/毫秒5、word分词 正向最小匹配算法：分词速度：1234.6848 字符/毫秒6、MMSeg4j ComplexSeg：分词速度：1184.436 字符/毫秒7、Jcseg 简易模式：分词速度：1023.73364 字符/毫秒8、Ansj BaseAnalysis 基本分词：分词速度：906.4427 字符/毫秒9、word分词 双向最小匹配算法：分词速度：833.2229 字符/毫秒10、Jieba SEARCH：分词速度：831.52246 字符/毫秒11、word分词 逆向最大匹配算法：分词速度：808.4246 字符/毫秒12、IKAnalyzer 细粒度切分：分词速度：735.4621 字符/毫秒13、HanLP分词器 索引分词：分词速度：664.67535 字符/毫秒14、word分词 正向最大匹配算法：分词速度：573.46375 字符/毫秒15、word分词 双向最大匹配算法：分词速度：539.6636 字符/毫秒16、Jieba INDEX：分词速度：507.40472 字符/毫秒17、word分词 双向最大最小匹配算法：分词速度：505.20273 字符/毫秒18、IKAnalyzer 智能切分：分词速度：483.90262 字符/毫秒19、HanLP分词器 标准分词：分词速度：461.43375 字符/毫秒20、Ansj IndexAnalysis 面向索引的分词：分词速度：446.76096 字符/毫秒21、word分词 最少词数算法：分词速度：444.56738 字符/毫秒22、Ansj ToAnalysis 精准分词：分词速度：440.2442 字符/毫秒23、word分词 最大Ngram分值算法：分词速度：419.61484 字符/毫秒24、smartcn：分词速度：419.39886 字符/毫秒25、Jcseg 复杂模式：分词速度：391.21075 字符/毫秒26、HanLP分词器 最短路径分词：分词速度：288.55948 字符/毫秒27、HanLP分词器 NLP分词：分词速度：251.66522 字符/毫秒28、Ansj NlpAnalysis NLP分词：分词速度：174.01068 字符/毫秒29、word分词 全切分算法：分词速度：146.16898 字符/毫秒30、FudanNLP：分词速度：111.7975 字符/毫秒31、HanLP分词器 N-最短路径分词：分词速度：67.67644 字符/毫秒</code></pre><h3 id="支持的分词器有："><a href="#支持的分词器有：" class="headerlink" title="支持的分词器有："></a>支持的分词器有：</h3><p>   <a href="https://github.com/ysc/word" target="_blank" rel="noopener">1、word分词器</a></p><p>   <a href="https://github.com/ansjsun/ansj_seg" target="_blank" rel="noopener">2、ansj分词器</a></p><p>   <a href="http://code.google.com/p/mmseg4j/" target="_blank" rel="noopener">3、mmseg4j分词器</a></p><p>   <a href="http://code.google.com/p/ik-analyzer/" target="_blank" rel="noopener">4、ik-analyzer分词器</a></p><p>   <a href="https://code.google.com/p/jcseg/" target="_blank" rel="noopener">5、jcseg分词器</a></p><p>   <a href="https://code.google.com/p/fudannlp/" target="_blank" rel="noopener">6、fudannlp分词器</a></p><p>   <a href="http://lucene.apache.org/core/5_1_0/analyzers-smartcn/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.html" target="_blank" rel="noopener">7、smartcn分词器</a></p><p>   <a href="https://github.com/huaban/jieba-analysis" target="_blank" rel="noopener">8、jieba分词器</a></p><p>   <a href="http://nlp.stanford.edu/software/segmenter.shtml" target="_blank" rel="noopener">9、stanford分词器</a></p><p>   <a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">10、hanlp分词器</a></p><p><a href="https://travis-ci.org/ysc/cws_evaluation" target="_blank" rel="noopener">https://travis-ci.org/ysc/cws_evaluation</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博分析报告学习</title>
      <link href="/2018/06/29/%E5%BE%AE%E5%8D%9A%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/"/>
      <url>/2018/06/29/%E5%BE%AE%E5%8D%9A%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p><img src="/.io//001.png" alt="微博分析报告学习"></p><p>一份微博分析报告， 本文主要将网页内容截屏为图片，主要用于学习，有兴趣的同学可以到原文<a href="https://wfx.51wyq.cn/share/view/j3qLuwlKZ1mDoQBJa" target="_blank" rel="noopener">微博传播效果分析</a></p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EasyPR-Java新能源车牌识别</title>
      <link href="/2018/06/29/EasyPR-Java%E6%96%B0%E8%83%BD%E6%BA%90%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/"/>
      <url>/2018/06/29/EasyPR-Java%E6%96%B0%E8%83%BD%E6%BA%90%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;EasyPR中主要涉及到蓝色底牌与黄色底牌的车牌识别，随着新能源车辆的发展，目前已经出现绿色底牌的车牌，因此有必要增加绿色车牌的识别。</p><a id="more"></a><p>&emsp;&emsp;EasyPR中关于车牌的识别已经比较完善，这里主要涉及到三个地方的修改：颜色枚举类、颜色识别逻辑、增加字符限制。</p><h2 id="添加颜色"><a href="#添加颜色" class="headerlink" title="添加颜色"></a>添加颜色</h2><p>在自定义Color的枚举类中，添加 绿色，修改之后为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public enum Color &#123;</span><br><span class="line">UNKNOWN, BLUE, YELLOW, GREEN</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="添加绿色识别"><a href="#添加绿色识别" class="headerlink" title="添加绿色识别"></a>添加绿色识别</h2><p>&emsp;&emsp;在OpenCV或其他软件中，识别颜色主要通过RGB映射到HSV空间，通过判断H、S、V的相关值来判断颜色的，主要原理可以参考：<a href="http://blog.csdn.net/liuqz2009/article/details/47623399" target="_blank" rel="noopener">OpenCV颜色识别</a>。修改之后的部分代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">public static Mat colorMatch(final Mat src, final Color r,</span><br><span class="line">final boolean adaptive_minsv) &#123;</span><br><span class="line"></span><br><span class="line">final float max_sv &#x3D; 255;</span><br><span class="line">final float minref_sv &#x3D; 40;</span><br><span class="line">final float minabs_sv &#x3D; 60;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; blue的H范围75-130</span><br><span class="line">final int min_blue &#x3D; 100;</span><br><span class="line">final int max_blue &#x3D; 140;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; yellow的H范围22- 38</span><br><span class="line">final int min_yellow &#x3D; 10;</span><br><span class="line">final int max_yellow &#x3D; 35;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; green的H范围38-75&#x2F;&#x2F; -- 增加绿色判断范围 --</span><br><span class="line">final int min_green &#x3D; 35;</span><br><span class="line">final int max_green &#x3D; 80;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 转到HSV空间进行处理，颜色搜索主要使用的是H分量进行蓝色与黄色、绿色的匹配工作</span><br><span class="line">Mat src_hsv &#x3D; new Mat();</span><br><span class="line">cvtColor(src, src_hsv, CV_BGR2HSV);</span><br><span class="line">MatVector hsvSplit &#x3D; new MatVector();</span><br><span class="line">split(src_hsv, hsvSplit);</span><br><span class="line">equalizeHist(hsvSplit.get(2), hsvSplit.get(2));</span><br><span class="line">merge(hsvSplit, src_hsv);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 匹配模板基色,切换以查找想要的基色</span><br><span class="line">int min_h &#x3D; 0;</span><br><span class="line">int max_h &#x3D; 0;</span><br><span class="line">switch (r) &#123;</span><br><span class="line">case BLUE:</span><br><span class="line">min_h &#x3D; min_blue;</span><br><span class="line">max_h &#x3D; max_blue;</span><br><span class="line">break;</span><br><span class="line">case YELLOW:</span><br><span class="line">min_h &#x3D; min_yellow;</span><br><span class="line">max_h &#x3D; max_yellow;</span><br><span class="line">break;</span><br><span class="line">case GREEN:</span><br><span class="line">min_h &#x3D; min_green;</span><br><span class="line">max_h &#x3D; max_green;</span><br><span class="line">default:</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">float diff_h &#x3D; (float) ((max_h - min_h) &#x2F; 2);</span><br><span class="line">int avg_h &#x3D; (int) (min_h + diff_h);</span><br><span class="line"></span><br><span class="line">int channels &#x3D; src_hsv.channels();</span><br><span class="line">int nRows &#x3D; src_hsv.rows();</span><br><span class="line">&#x2F;&#x2F; 图像数据列需要考虑通道数的影响；</span><br><span class="line">int nCols &#x3D; src_hsv.cols() * channels;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 连续存储的数据，按一行处理</span><br><span class="line">if (src_hsv.isContinuous()) &#123;</span><br><span class="line">nCols *&#x3D; nRows;</span><br><span class="line">nRows &#x3D; 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for (int i &#x3D; 0; i &lt; nRows; ++i) &#123;</span><br><span class="line">BytePointer p &#x3D; src_hsv.ptr(i);</span><br><span class="line">for (int j &#x3D; 0; j &lt; nCols; j +&#x3D; 3) &#123;</span><br><span class="line">int H &#x3D; p.get(j) &amp; 0xFF;</span><br><span class="line">int S &#x3D; p.get(j + 1) &amp; 0xFF;</span><br><span class="line">int V &#x3D; p.get(j + 2) &amp; 0xFF;</span><br><span class="line"></span><br><span class="line">boolean colorMatched &#x3D; false;</span><br><span class="line"></span><br><span class="line">if (H &gt; min_h &amp;&amp; H &lt; max_h) &#123;</span><br><span class="line"></span><br><span class="line">int Hdiff &#x3D; 0;</span><br><span class="line">if (H &gt; avg_h)</span><br><span class="line">Hdiff &#x3D; H - avg_h;</span><br><span class="line">else</span><br><span class="line">Hdiff &#x3D; avg_h - H;</span><br><span class="line"></span><br><span class="line">float Hdiff_p &#x3D; Hdiff &#x2F; diff_h;</span><br><span class="line"></span><br><span class="line">float min_sv &#x3D; 0;</span><br><span class="line">if (true &#x3D;&#x3D; adaptive_minsv)</span><br><span class="line">min_sv &#x3D; minref_sv - minref_sv &#x2F; 2 * (1 - Hdiff_p);</span><br><span class="line">else</span><br><span class="line">min_sv &#x3D; minabs_sv;</span><br><span class="line"></span><br><span class="line">if ((S &gt; min_sv &amp;&amp; S &lt;&#x3D; max_sv)</span><br><span class="line">&amp;&amp; (V &gt; min_sv &amp;&amp; V &lt;&#x3D; max_sv))</span><br><span class="line">colorMatched &#x3D; true;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (colorMatched &#x3D;&#x3D; true) &#123;</span><br><span class="line">p.put(j, (byte) 0);</span><br><span class="line">p.put(j + 1, (byte) 0);</span><br><span class="line">p.put(j + 2, (byte) 255);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">p.put(j, (byte) 0);</span><br><span class="line">p.put(j + 1, (byte) 0);</span><br><span class="line">p.put(j + 2, (byte) 0);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 获取颜色匹配后的二值灰度图</span><br><span class="line">MatVector hsvSplit_done &#x3D; new MatVector();</span><br><span class="line">split(src_hsv, hsvSplit_done);</span><br><span class="line">Mat src_grey &#x3D; hsvSplit_done.get(2);</span><br><span class="line"></span><br><span class="line">return src_grey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中RGB与HSV颜色识别对应的关系，可以参考：<a href="http://www.cnblogs.com/wangyblzu/p/5710715.html" target="_blank" rel="noopener">OpenCV中HSV颜色模型及颜色分量范围</a></p><h2 id="增加字符限制"><a href="#增加字符限制" class="headerlink" title="增加字符限制"></a>增加字符限制</h2><p>&emsp;&emsp;以前的车牌主要是7位字符，包括省 <strong>[A-Z].[5位字符]</strong> 的方式。但新能源车牌，后面5为字符变为6位字符，因此之前的判断方法不能够获取全部车牌，最好的情况也只能获得前面的7位字符。因此需要修改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">private int RebuildRect(final Vector&lt;Rect&gt; vecRect, Vector&lt;Rect&gt; outRect,</span><br><span class="line">int specIndex) &#123;</span><br><span class="line">&#x2F;&#x2F; 最大只能有7个Rect,减去中文的就只有6个Rect</span><br><span class="line">int count &#x3D; 7;&#x2F;&#x2F; --这里将6修改为7即可--</span><br><span class="line">for (int i &#x3D; 0; i &lt; vecRect.size(); i++) &#123;</span><br><span class="line">&#x2F;&#x2F; 将特殊字符左边的Rect去掉，这个可能会去掉中文Rect，不过没关系，我们后面会重建。</span><br><span class="line">if (i &lt; specIndex)</span><br><span class="line">continue;</span><br><span class="line"></span><br><span class="line">outRect.add(vecRect.get(i));</span><br><span class="line">if (--count &#x3D;&#x3D; 0)</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，可以识别绿色车牌。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> EasyPR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>各种典型反爬虫套路</title>
      <link href="/2018/06/29/%E5%90%84%E7%A7%8D%E5%85%B8%E5%9E%8B%E5%8F%8D%E7%88%AC%E8%99%AB%E5%A5%97%E8%B7%AF/"/>
      <url>/2018/06/29/%E5%90%84%E7%A7%8D%E5%85%B8%E5%9E%8B%E5%8F%8D%E7%88%AC%E8%99%AB%E5%A5%97%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p>转载自：<a href="http://litten.me/2017/07/09/prevent-spiders/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io" target="_blank" rel="noopener">反击爬虫，前端工程师的脑洞可以有多大？</a></p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开源数据流处理</title>
      <link href="/2018/06/29/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E6%B5%81%E5%A4%84%E7%90%86/"/>
      <url>/2018/06/29/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E6%B5%81%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;随着公司规模增长，他们的工作流更加复杂，包含更多子处理过程以及带有复杂的依赖关系，这将导致更多监控、问题以及运维工作。如果没有一个清晰的数据血缘关系，可能会引起引用链问题和操作元数据丢失。这就是为什么DAGs、数据流和工作流管理器等产生的原因。</p><a id="more"></a><p>&emsp;&emsp;复杂的工作流可以通过DAGs来展现。DAGs就是信息沿着指定的方向在不通节点之间传递的一张图，但信息在图中流传不会回到原点。构建DAGs过程的就是数据流，或从一个进程作为输入并输出作为下一个进程输入的序列化进程。</p><p>&emsp;&emsp;构建这些管道流式复杂的。幸运的是，目前存在几款开源的流管理器来辅助处理这些问题，并允许开发者将注意力聚焦在单独的任务和任务依赖上来。为了帮助需求者从许多工作流管理器中选择合适的，下面我们进行了一些相关的讨论。</p><h2 id="Luigi"><a href="#Luigi" class="headerlink" title="Luigi"></a>Luigi</h2><p>&emsp;&emsp;Luigi是Spotify与2011开发的一个Python包，主要是用来构建–像产生推荐和排行榜任务–这样的需要多任务复杂管道。目前组件的主要使用者，包括 Foursquare, Stripe, the Wall Street Journal, Groupon，以及其他主要商业公司。它内嵌Hadoop支持，但不像其他类似产品OOZIE和Azkaban，它们都是为了支持Hadoop而开发的，Luigi的理念就是能够使任务事情尽可能普适性。Luigi可以扩展到其他类型的任务，如Hive查询，使用Scala或Python开发的SparkJob等等。它是面向编码控制的，而不是基于GUI或声明式的，能够完美兼容Python中的所有包（包括依赖路径）。Luigi的界面支持搜索、过滤或监控每个任务的状态信息。用户也可以查看工作流的依赖是否完成，或还没有运行等状态。</p><p><strong>特性：</strong></p><ul><li>允许有需要的任务并行运行</li><li>通用任务模版的工具箱</li><li>支持在Hadoop\Hive\Pig等的基于Python的MR任务</li><li>嵌入针对Hadoop分布式文件系统和本地文件系统的抽象文件系统，这样能够保证所有系统的原子性，防止任务崩困时数据缺失</li></ul><h2 id="Azkaban"><a href="#Azkaban" class="headerlink" title="Azkaban"></a>Azkaban</h2><p>&emsp;&emsp;Azkaban是另外一款开源工作流管理器，它是由LinkedIn给Hadoop的实时批处理而开发的。不像Luigi，它是基于Java、调度是通过WEB浏览器来完成的。它主要包括AzkabanWebServer–主要作为UI界面和处理工程管理、授权、调度和监控，MySQL数据库作为元数据存储，以及AzkabanExecutorServer（以前WEB服务和executor服务器是合并在一起，但随着Azkaban的发展，它分裂为两部分来帮助用户滚动更新信息）。当前最新为Azkaban3.0版本，包括三个模式：单服务器的使用模式，两服务器的生产环境，以及分布式多执行节点模式。Azkaban设计之初就将易用性作为首要目标。例如，它包括非常易用、极其优秀展示操作功能的UI界面。</p><p><strong>特点：</strong></p><ul><li>兼容任何Hadoop版本</li><li>简单的WEB界面和Http工作任务上传</li><li>每个Hadoop生态的模块与插件</li><li>用户行为、认证和授权追踪</li><li>提供每个工程的独立工作空间</li><li>提供SLAs、任务失败和成功的邮件提醒</li><li>运行用户重启失败任务</li></ul><h2 id="Oozie"><a href="#Oozie" class="headerlink" title="Oozie"></a>Oozie</h2><p>&emsp;&emsp;跟Azkaban一样，OOZIE也是一款Java开发、基于Hadoop系统的开源工作流调度系统。然后不同于Azkaban的易用性，OOZIE更偏向于灵活性和创建复杂工作流。然而，Azkaban只能通过WEB提供基于时间的调度系统。OOZIE的Coordinator提供基于通过时间、时间或在数据不可预测情境下数据有效性的触发器，并运行用户通过命令行、Java API，以及基于WEB浏览器的GUI界面。OOZIE同样支持基于XML属性文件配置，而Azkaban是基于Java的。最后，Azkaban将所有的工作流运行数据保存在内存中，而OOZIE使用SQL数据库保存，内存只用来保存状态事务。</p><p>&emsp;&emsp;OOZIE工作流是通过DAGs来优化运行的，分为三种节点：控制节点、关联节点和动作节点。控制节点定义了任务何时启动与停止、流向决策、任务分支等功能，关联节点依赖执行路径，动作节点触发任务运行。每个任务提供一个唯一的URL，任务结束时会响应该URL。如果URL没有被通知，OOZIE会判断任务是否已经完成。</p><p><strong>特点：</strong></p><ul><li>提供多种支持，包括MapReduce，Pig，Hive，Sqoop，和Distcp，以及系统特殊任务</li><li>可伸缩、可靠、可扩展</li><li>唯一标记工作任务，能够配置为并发运行</li><li>允许用户对任务的KILL、Suspend，或Resume</li><li>高可用</li><li>多任务和协调者[coordinator]能够通过OOZIE Bundle打包和管理</li></ul><h2 id="Airflow"><a href="#Airflow" class="headerlink" title="Airflow"></a>Airflow</h2><p>&emsp;&emsp;Airflow是Airbnb与2015年开发的工具，主要用来编辑、调度DAGs及监控工作流。它主要面向编程环境的基于编辑的工具，这方面与Luigi类似。它是基于Python的DAGs工作流编码的工具，能够保证尽量协调性与易于维护、版本控制与测试。它的主要架构包括源码控制的任务定义、命令行接口–用户可以测试、运行和描述DAGs的部分环节、查看依赖/进度/元数据和日志的WEB应用、元数据仓储、运行分布式任务实例的工作节点、调度进程–触发任务运行。</p><p><strong>特点：</strong></p><ul><li>丰富的CLI和UI接口：允许用户查看依赖、进度、日志、相关代码</li><li>模块化、可伸缩、高可扩展</li><li>参数化脚本：内嵌Jinja模版引擎</li><li>提供分析：基于搜索排序和session连接信息来追踪用户的点击流和时间花费</li><li>能够与Hive、Presto、MySQL、HDFS、Postres或S3交互</li></ul><h2 id="翻译文章"><a href="#翻译文章" class="headerlink" title="翻译文章"></a>翻译文章</h2><p><a href="https://www.bizety.com/2017/06/05/open-source-data-pipeline-luigi-vs-azkaban-vs-oozie-vs-airflow/" target="_blank" rel="noopener">Open Source Data Pipeline – Luigi vs Azkaban vs Oozie vs Airflow</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ganglia-Spark/Kafka编译与安装总结</title>
      <link href="/2018/06/29/Ganglia-Spark-Kafka%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%E6%80%BB%E7%BB%93/"/>
      <url>/2018/06/29/Ganglia-Spark-Kafka%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;Ganglia是一款优秀的监控软件，能够监控节点级别以及组件级别的监控，并且与Nagios配合可以做到监控提示的发送通知功能。</p><a id="more"></a><h3 id="Ganliga安装"><a href="#Ganliga安装" class="headerlink" title="Ganliga安装"></a>Ganliga安装</h3><h3 id="预先安装配置"><a href="#预先安装配置" class="headerlink" title="预先安装配置"></a>预先安装配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 服务器端</span><br><span class="line">yum install -y rrdtool epel-release ganglia-devel ganglia-gmetad ganglia-gmond ganglia-web httpd php</span><br><span class="line">## 客户端</span><br><span class="line">yum install -y ganglia-gmond epel-release</span><br></pre></td></tr></table></figure><h3 id="Ganglia配置"><a href="#Ganglia配置" class="headerlink" title="Ganglia配置"></a>Ganglia配置</h3><ol><li>Gmetad配置</li><li>Gmond配置</li><li>Httpd相关配置</li></ol><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Server端</span></span></span><br><span class="line">service gmond start</span><br><span class="line">service gmetad start </span><br><span class="line">service httpd start</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Client端</span></span></span><br><span class="line">service gmond start</span><br></pre></td></tr></table></figure><h3 id="Ganglia-Hadoop配置"><a href="#Ganglia-Hadoop配置" class="headerlink" title="Ganglia-Hadoop配置"></a>Ganglia-Hadoop配置</h3><p>&emsp;&emsp;默认Hadoop支持Ganglia元数据收集，所以只需要配置起来，即可使用Ganglia查看Hadoop集群的相关数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 在hadoop-metrics2.properties中添加一下配置</span><br><span class="line">*.sink.ganglia.class&#x3D;org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31</span><br><span class="line">*.sink.ganglia.period&#x3D;10</span><br><span class="line">datanode.sink.ganglia.servers&#x3D;ganglia-server:8649</span><br></pre></td></tr></table></figure><h2 id="Ganglia-Spark编译使用"><a href="#Ganglia-Spark编译使用" class="headerlink" title="Ganglia-Spark编译使用"></a>Ganglia-Spark编译使用</h2><p>&emsp;&emsp;因为需要通过Ganglia监控Spark的相关数据，而Spark的licence与Ganglia用到的组件不同，所以在原生的Spark中，不支持Ganglia监控的支持。所以好多公开资料，都是自行编译带有Ganglia的版本。<br>&emsp;&emsp;因此，本文作者自行编译Spark版本的Spark软件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;make-distribution.sh \</span><br><span class="line">--tgz \</span><br><span class="line">-Psparkr \</span><br><span class="line">-Pyarn \</span><br><span class="line">-Phadoop-2.6 \</span><br><span class="line">-Dhadoop.version&#x3D;2.6.0-cdh5.12.1 \</span><br><span class="line">-Phive \</span><br><span class="line">-DskipTests \</span><br><span class="line">-Phive-thriftserver \</span><br><span class="line">-Pspark-ganglia-lgpl \</span><br><span class="line">-Dscala-2.10.7 \</span><br><span class="line">clean package</span><br></pre></td></tr></table></figure><p>编译过程可能会遇到未预期错误，具体问题具体分析。</p><h2 id="Ganglia-Kafka安装使用"><a href="#Ganglia-Kafka安装使用" class="headerlink" title="Ganglia-Kafka安装使用"></a>Ganglia-Kafka安装使用</h2><p>&emsp;&emsp;Ganglia针对Kafka的支持是基于Ganglia API的实现：(<a href="https://github.com/Xinshiyou/kafka-ganglia)。" target="_blank" rel="noopener">https://github.com/Xinshiyou/kafka-ganglia)。</a></p><p>一般配置步骤如下</p><ol><li>编译开源软件kafka-ganglia</li><li>将JAR包：kafka-ganglia-1.0.0.jar， metrics-ganglia-2.2.0.jar复制到Kafka响应的kafka libs下</li><li>针对Kafka添加配置,在kafka.properties中<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka.metrics.reporters&#x3D;com.criteo.kafka.KafkaGangliaMetricsReporter,kafka.metrics.KafkaCSVMetricsReporter</span><br><span class="line">kafka.ganglia.metrics.reporter.enabled&#x3D;true</span><br></pre></td></tr></table></figure></li><li>重启Kafka服务，使之生效。</li></ol><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>&emsp;&emsp;这样操作可能会是CDH-Kafka中，失去controller角色引起其他问题[未做详细测试]。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译 </tag>
            
            <tag> Spark </tag>
            
            <tag> Kafka </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记一个Spark模块Hive-thriftserver编译报错</title>
      <link href="/2018/06/29/%E8%AE%B0%E4%B8%80%E4%B8%AASpark%E6%A8%A1%E5%9D%97Hive-thriftserver%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99/"/>
      <url>/2018/06/29/%E8%AE%B0%E4%B8%80%E4%B8%AASpark%E6%A8%A1%E5%9D%97Hive-thriftserver%E7%BC%96%E8%AF%91%E6%8A%A5%E9%94%99/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (scala-compile-first) on project spark-hive-thriftserver_2.10: Execution scala-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed.: CompileFailed -&gt; [Help 1]</span><br><span class="line">org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (scala-compile-first) on project spark-hive-thriftserver_2.10: Execution scala-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed.</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br><span class="line">Caused by: org.apache.maven.plugin.PluginExecutionException: Execution scala-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed.</span><br><span class="line">    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:145)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br><span class="line">Caused by: sbt.compiler.CompileFailed</span><br><span class="line">    at sbt_inc.SbtIncrementalCompiler.zincCompile (SbtIncrementalCompiler.java:136)</span><br><span class="line">    at sbt_inc.SbtIncrementalCompiler.compile (SbtIncrementalCompiler.java:86)</span><br><span class="line">    at scala_maven.ScalaCompilerSupport.incrementalCompile (ScalaCompilerSupport.java:303)</span><br><span class="line">    at scala_maven.ScalaCompilerSupport.compile (ScalaCompilerSupport.java:119)</span><br><span class="line">    at scala_maven.ScalaCompilerSupport.doExecute (ScalaCompilerSupport.java:99)</span><br><span class="line">    at scala_maven.ScalaMojoSupport.execute (ScalaMojoSupport.java:482)</span><br><span class="line">    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)</span><br><span class="line">    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)</span><br><span class="line">    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)</span><br><span class="line">    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)</span><br><span class="line">    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)</span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)</span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">    at java.lang.reflect.Method.invoke (Method.java:498)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)</span><br><span class="line">    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编译 </tag>
            
            <tag> Spark </tag>
            
            <tag> Hive </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apache-Kylin编译CDH5.12.X</title>
      <link href="/2018/06/29/Apache-Kylin%E7%BC%96%E8%AF%91CDH5-12-X/"/>
      <url>/2018/06/29/Apache-Kylin%E7%BC%96%E8%AF%91CDH5-12-X/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;基于业务自动化需求，搭建Apache Kylin用于实时OLAP场景。</p><a id="more"></a><h2 id="1-编译"><a href="#1-编译" class="headerlink" title="1. 编译"></a>1. 编译</h2><p>&emsp;&emsp;官方提供的Apache Kylin目前仅支持到CDH5.7，更高版本的没有发布，或测试。针对公司的CDH版本，需要进行相关设置与编译，才能适用于公司的环境。</p><h3 id="1-1-Github获取代码"><a href="#1-1-Github获取代码" class="headerlink" title="1.1. Github获取代码"></a>1.1. Github获取代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;kylin.git</span><br><span class="line">git checkout yang21-cdh5.7</span><br></pre></td></tr></table></figure><h3 id="1-2-进行配置"><a href="#1-2-进行配置" class="headerlink" title="1.2. 进行配置"></a>1.2. 进行配置</h3><p>主要进行一下几方面的更改：</p><ol><li>JDK版本：1.7→1.8</li><li>CDH版本：cdh5.7.0→cdh5.12.1</li><li>代码修改：涉及到的类<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A、engine-spark&#x2F;src&#x2F;main&#x2F;java&#x2F;org&#x2F;apache&#x2F;kylin&#x2F;engine&#x2F;spark&#x2F;SparkCubing.java </span><br><span class="line">B、server-base&#x2F;src&#x2F;main&#x2F;java&#x2F;org&#x2F;apache&#x2F;kylin&#x2F;rest&#x2F;security&#x2F;MockHTable.java</span><br></pre></td></tr></table></figure></li></ol><h3 id="1-3-进行编译"><a href="#1-3-进行编译" class="headerlink" title="1.3. 进行编译"></a>1.3. 进行编译</h3><p>./build/script/package.sh</p><h2 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h2><p>上述编译完成之后，安装相对简单，直接解压即可。</p><h2 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h2><p>&emsp;&emsp;原始信息存在差距，无法直接使用，因此需要针对出现问题的位置进行修改。主要涉及到的配置</p><h3 id="3-1-Hbase配置【数据存储位置，必须】"><a href="#3-1-Hbase配置【数据存储位置，必须】" class="headerlink" title="3.1. Hbase配置【数据存储位置，必须】"></a>3.1. Hbase配置【数据存储位置，必须】</h3><h3 id="3-2-Hive配置【数据来源，需要】"><a href="#3-2-Hive配置【数据来源，需要】" class="headerlink" title="3.2. Hive配置【数据来源，需要】"></a>3.2. Hive配置【数据来源，需要】</h3><h2 id="4-使用"><a href="#4-使用" class="headerlink" title="4. 使用"></a>4. 使用</h2><p>&emsp;&emsp;到这里，可以直接在浏览器中访问了。<br>&emsp;&emsp;本地浏览器访问：<a href="http://localhost:7070/kylin" target="_blank" rel="noopener">http://localhost:7070/kylin</a><br>&emsp;&emsp;默认用户名/密码：ADMIN/KYLIN</p><h2 id="5-参考"><a href="#5-参考" class="headerlink" title="5. 参考"></a>5. 参考</h2><ol><li><a href="https://github.com/Xinshiyou/kylin" target="_blank" rel="noopener">https://github.com/Xinshiyou/kylin</a></li><li><a href="https://www.kancloud.cn/cxfeel/cdh5_12_0/370970" target="_blank" rel="noopener">https://www.kancloud.cn/cxfeel/cdh5_12_0/370970</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kylin </tag>
            
            <tag> CDH </tag>
            
            <tag> 编译 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH-Manager开启alert功能</title>
      <link href="/2018/06/29/CDH-Manager%E5%BC%80%E5%90%AFalert%E5%8A%9F%E8%83%BD/"/>
      <url>/2018/06/29/CDH-Manager%E5%BC%80%E5%90%AFalert%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;使用CDH时，需要针对多个项目进行监控，但又不想太麻烦使用专业的监控工具，所以只使用CDH自带的CDH Manager来查看相关的监控参数，并开启邮件告警通知功能。</p><a id="more"></a><p>&emsp;&emsp;虽然最终搞定了但还是需要好好记录下来，以作备忘。</p><h1 id="网络端口确定"><a href="#网络端口确定" class="headerlink" title="网络端口确定"></a>网络端口确定</h1><p>&emsp;&emsp;默认邮件端口是<em>25</em>，所以在确认是否可以发送邮件之前，需要端口25开放，或能够正常访问外网。特殊的邮件服务器，比如Office365/Google等，他们使用特殊的端口，比如587/465/995等端口。</p><p>&emsp;&emsp;在确认使用之前，一般需要自己本地测试一下连通性配置是否准确等。本地发邮件的项目/代码有很多，可以百度/Google一下。</p><h1 id="使用QQ邮箱作为发件服务器"><a href="#使用QQ邮箱作为发件服务器" class="headerlink" title="使用QQ邮箱作为发件服务器"></a>使用QQ邮箱作为发件服务器</h1><p>&emsp;&emsp;使用QQ邮箱作为邮件发送服务器，基本上不存在问题，只需要配置起来即可。配置如下所示<br><img src="/.io//001.png" alt="CDH-manager-configure"></p><h1 id="使用office365邮箱"><a href="#使用office365邮箱" class="headerlink" title="使用office365邮箱"></a>使用office365邮箱</h1><p>&emsp;&emsp;office365邮箱与普通邮箱的一个不同在于，需要使用SSL传输，如果不是那么会报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">com.sun.mail.smtp.SMTPSendFailedException: 530 5.7.57 SMTP; Client was not authenticated to send anonymous mail during MAIL FROM [HK2PR0401CA0016.apcprd04.prod.outlook.com]</span><br><span class="line">at com.sun.mail.smtp.SMTPTransport.issueSendCommand(SMTPTransport.java:2202)</span><br><span class="line">at com.sun.mail.smtp.SMTPTransport.mailFrom(SMTPTransport.java:1693)</span><br><span class="line">at com.sun.mail.smtp.SMTPTransport.sendMessage(SMTPTransport.java:1194)</span><br><span class="line">at javax.mail.Transport.send0(Transport.java:254)</span><br><span class="line">at javax.mail.Transport.send(Transport.java:146)</span><br><span class="line">at com.hundun.java.email.SendMail.sendMessage(SendMail.java:57)</span><br><span class="line">at com.hundun.java.email.Main.main(Main.java:9)</span><br></pre></td></tr></table></figure><p>使用邮件客户端，或Java程序中， 可以配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(&quot;mail.smtp.starttls.enable&quot;, &quot;true&quot;);&#x2F;&#x2F; 使用 STARTTLS安全连接</span><br></pre></td></tr></table></figure><p>但在CDH中没有找到这个配置的位置，不知道是不是这个配置引起的。</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
            <tag> 调研 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>调度工具技术选型与开发参考</title>
      <link href="/2018/06/29/%E8%B0%83%E5%BA%A6%E5%B7%A5%E5%85%B7%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E4%B8%8E%E5%BC%80%E5%8F%91%E5%8F%82%E8%80%83/"/>
      <url>/2018/06/29/%E8%B0%83%E5%BA%A6%E5%B7%A5%E5%85%B7%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E4%B8%8E%E5%BC%80%E5%8F%91%E5%8F%82%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;无论是自研调度工具，还是技术选型，都需要实先确定自己的业务需求，今儿根据具体的业务需求进行相关的研究与开发工作。</p><a id="more"></a><p>&emsp;&emsp; 主要是个人记录日常事物，读者仅供参考。</p><h2 id="一、调度工具目标"><a href="#一、调度工具目标" class="headerlink" title="一、调度工具目标"></a>一、调度工具目标</h2><ol><li>支持依赖配置：任务间依赖</li><li>支持定时任务与临时任务，灵活配置与启动停止</li><li>支持分布式运行任务</li><li>支持触发式运行任务：存在依赖的任务，上游任务运行结束，可以触发下游任务的运行</li><li>软件要求：<br> A、稳定性<br> B、易用性<br> C、任务支持配置管理<br> D、尽量支持WEB任务状态管理【查看、更新、运行、结束等】等操作<br> E、任务管理【上传任务文件、生成任务、添加依赖、删除任务等】等操作<br> F、支持配置管理【配置运行参数、运行日期、手动运行等】等操作<br> G、支持线程数管理【同时并发数据、JVM配置、垃圾回收器等JAVA启动配置】<br> H、负载均衡</li></ol><h2 id="二、可选软件"><a href="#二、可选软件" class="headerlink" title="二、可选软件"></a>二、可选软件</h2><ol><li>Azkaban</li><li>Oozie</li><li>Airflow</li><li>Github任务调度参考：<br><img src="/.io//001.png" alt="这里写图片描述"></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HiveServer遇到一个问题</title>
      <link href="/2018/06/29/HiveServer%E9%81%87%E5%88%B0%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98/"/>
      <url>/2018/06/29/HiveServer%E9%81%87%E5%88%B0%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;基于给开发同学使用与BI用户使用的需求，打算开启HiveServer2服务，集群上面的Hive任务执行、调度，都走HiveServer2方式。之前只有调度任务与开发同学使用，所以使用的是Hive CLI方式，开发同学没有添加权限控制。</p><a id="more"></a><p>&emsp;&emsp;使用一段时间之后，发现HiveServer2存在各种问题。突出的问题就是不稳定、运行日志很难获取、任务ID需要解析等，最近遇到一个概率性出现的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">INFO  : Cleaning up the staging area file:&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;staging&#x2F;hive1294900272&#x2F;.staging&#x2F;job_local1294900272_0933</span><br><span class="line">ERROR : Job Submission failed with exception &#39;java.io.IOException(java.util.concurrent.ExecutionException: java.io.IOException: Unable to rename file: [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009</span><br><span class="line">296491_tmp&#x2F;tmp_hive-exec-1.1.0-cdh5.12.1-core.jar] to [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;hive-exec-1.1.0-cdh5.12.1-core.jar])&#39;</span><br><span class="line">java.io.IOException: java.util.concurrent.ExecutionException: java.io.IOException: Unable to rename file: [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;tmp_hive-exec-1.1.0-cdh5.12.1-core</span><br><span class="line">.jar] to [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;hive-exec-1.1.0-cdh5.12.1-core.jar]</span><br><span class="line">        at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:143)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalJobRunner$Job.&lt;init&gt;(LocalJobRunner.java:171)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:758)</span><br><span class="line">        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1307)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1304)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1304)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:578)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:573)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:573)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:564)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:436)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:142)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:99)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:79)</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: java.io.IOException: Unable to rename file: [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;tmp_hive-exec-1.1.0-cdh5.12.1-core.jar] to [</span><br><span class="line">&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;hive-exec-1.1.0-cdh5.12.1-core.jar]</span><br><span class="line">        at java.util.concurrent.FutureTask.report(FutureTask.java:122)</span><br><span class="line">        at java.util.concurrent.FutureTask.get(FutureTask.java:192)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:139)</span><br><span class="line">        ... 21 more</span><br><span class="line">Caused by: java.io.IOException: Unable to rename file: [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp&#x2F;tmp_hive-exec-1.1.0-cdh5.12.1-core.jar] to [&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;15260092964</span><br><span class="line">91_tmp&#x2F;hive-exec-1.1.0-cdh5.12.1-core.jar]</span><br><span class="line">        at org.apache.hadoop.yarn.util.FSDownload.unpack(FSDownload.java:327)</span><br><span class="line">        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:362)</span><br><span class="line">        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">INFO  : Cleaning up the staging area file:&#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;staging&#x2F;hive1101623315&#x2F;.staging&#x2F;job_local1101623315_0934</span><br><span class="line">ERROR : Job Submission failed with exception &#39;java.io.IOException(java.util.concurrent.ExecutionException: java.io.FileNotFoundException: File &#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tm</span><br><span class="line">p does not exist)&#39;</span><br><span class="line">java.io.IOException: java.util.concurrent.ExecutionException: java.io.FileNotFoundException: File &#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp does not exist</span><br><span class="line">        at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:143)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalJobRunner$Job.&lt;init&gt;(LocalJobRunner.java:171)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:758)</span><br><span class="line">        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1307)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1304)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1304)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:578)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:573)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:573)</span><br><span class="line">        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:564)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.ExecDriver.execute(ExecDriver.java:436)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.mr.MapRedTask.execute(MapRedTask.java:142)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:214)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:99)</span><br><span class="line">        at org.apache.hadoop.hive.ql.exec.TaskRunner.run(TaskRunner.java:79)</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: java.io.FileNotFoundException: File &#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp does not exist</span><br><span class="line">        at java.util.concurrent.FutureTask.report(FutureTask.java:122)</span><br><span class="line">        at java.util.concurrent.FutureTask.get(FutureTask.java:192)</span><br><span class="line">        at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:139)</span><br><span class="line">        ... 21 more</span><br><span class="line">Caused by: java.io.FileNotFoundException: File &#x2F;tmp&#x2F;hadoop-hive&#x2F;mapred&#x2F;local&#x2F;1526009296491_tmp does not exist</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:598)</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:811)</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:588)</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileLinkStatusInternal(RawLocalFileSystem.java:827)</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:813)</span><br><span class="line">        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatus(RawLocalFileSystem.java:784)</span><br><span class="line">        at org.apache.hadoop.fs.DelegateToFileSystem.getFileLinkStatus(DelegateToFileSystem.java:132)</span><br><span class="line">        at org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:701)</span><br><span class="line">        at org.apache.hadoop.fs.FilterFs.renameInternal(FilterFs.java:236)</span><br><span class="line">        at org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:674)</span><br><span class="line">        at org.apache.hadoop.fs.FileContext.rename(FileContext.java:932)</span><br><span class="line">        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:364)</span><br><span class="line">        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line"> </span><br><span class="line">ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask</span><br><span class="line">INFO  : Completed executing command(queryId&#x3D;hive_20180511112828_b253761f-a1ae-40bc-ae7e-650cfa4c7b79); Time taken: 9.506 seconds</span><br><span class="line"> </span><br><span class="line">Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask (state&#x3D;08S01,code&#x3D;1)</span><br><span class="line">Closing: 0:</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;想要排查问题，该问题又不会定期出现，在运行几百个JOB中，偶尔出现几个这样的报错信息。<br>&emsp;&emsp;最后还是找到了这样一篇文章：<a href="https://my.oschina.net/u/186712/blog/827949" target="_blank" rel="noopener">一台服务器同时起多个hive跑local mr很大机率会报 FileAlreadyExistsException</a>。根据该文中的报错信息，以及源代码的内容，可以看出我们这里的报错应该也是同类，或同一个出处。至此为我们的问题找打了一个合理的解释，因此可以对症下药解决问题。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java单例模式的几种写法</title>
      <link href="/2018/06/29/Java%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%87%A0%E7%A7%8D%E5%86%99%E6%B3%95/"/>
      <url>/2018/06/29/Java%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%87%A0%E7%A7%8D%E5%86%99%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>《Java并发编程 从入门到精通》读书笔记。</p><a id="more"></a><h2 id="错误模式"><a href="#错误模式" class="headerlink" title="错误模式"></a>错误模式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Test instance;</span><br><span class="line"><span class="function">privae <span class="title">Test</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Test <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)</span><br><span class="line">instance = <span class="keyword">new</span> Test();</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="低效模式：synchronized"><a href="#低效模式：synchronized" class="headerlink" title="低效模式：synchronized"></a>低效模式：synchronized</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Test instance;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Test</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Test <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)</span><br><span class="line">instance = <span class="keyword">new</span> Test();</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见模式：使用对象锁"><a href="#常见模式：使用对象锁" class="headerlink" title="常见模式：使用对象锁"></a>常见模式：使用对象锁</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Test instance;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] lock = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Test</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Test <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)</span><br><span class="line"><span class="keyword">synchronized</span>(lock)&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)</span><br><span class="line">instance = <span class="keyword">new</span> Test();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见模式：ReentranLock"><a href="#常见模式：ReentranLock" class="headerlink" title="常见模式：ReentranLock"></a>常见模式：ReentranLock</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Test instance;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> ReentranLock lock = <span class="keyword">new</span> ReentranLock();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Test</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Test <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)&#123;</span><br><span class="line">lock.lock();</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span>==instance)</span><br><span class="line">instance = <span class="keyword">new</span> Test();</span><br><span class="line">lock.unlock();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java安全集合类</title>
      <link href="/2018/06/29/Java%E5%AE%89%E5%85%A8%E9%9B%86%E5%90%88%E7%B1%BB/"/>
      <url>/2018/06/29/Java%E5%AE%89%E5%85%A8%E9%9B%86%E5%90%88%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>《Java并发编程 从入门到精通》读书笔记。</p><p>Java集合类非常方便，但适用于现成安全场景下的集合类平常使用的比较少一点，主要是ConcurrentHashMap。</p><a id="more"></a><p><img src="/.io//001.png" alt="Java集合类，安全集合类"></p><p>作图工具processon，注册链接：<a href="https://www.processon.com/i/59b27b8be4b0d3fbea26247c" target="_blank" rel="noopener">https://www.processon.com/i/59b27b8be4b0d3fbea26247c</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java同步辅助类总结</title>
      <link href="/2018/06/29/Java%E5%90%8C%E6%AD%A5%E8%BE%85%E5%8A%A9%E7%B1%BB%E6%80%BB%E7%BB%93/"/>
      <url>/2018/06/29/Java%E5%90%8C%E6%AD%A5%E8%BE%85%E5%8A%A9%E7%B1%BB%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>《Java并发编程 从入门到精通》读书笔记。</p><a id="more"></a><p><img src="/.io//001.png" alt="同步复制类"></p><p>作图工具processon，注册链接：<a href="https://www.processon.com/i/59b27b8be4b0d3fbea26247c" target="_blank" rel="noopener">https://www.processon.com/i/59b27b8be4b0d3fbea26247c</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-Queue整理</title>
      <link href="/2018/06/29/Java-Queue%E6%95%B4%E7%90%86/"/>
      <url>/2018/06/29/Java-Queue%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>《Java并发编程 从入门到精通》读书笔记。</p><a id="more"></a><p><img src="/.io//001.png" alt="Java_Queue"></p><p>作图工具processon，注册链接：<a href="https://www.processon.com/i/59b27b8be4b0d3fbea26247c" target="_blank" rel="noopener">https://www.processon.com/i/59b27b8be4b0d3fbea26247c</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git-CI/CD安装与使用【一】</title>
      <link href="/2018/06/29/Git-CI-CD%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E3%80%90%E4%B8%80%E3%80%91/"/>
      <url>/2018/06/29/Git-CI-CD%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E3%80%90%E4%B8%80%E3%80%91/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在使用Gitlab的公司，使用Gitlab提供的各项功能，实现公司代码的管理、自动化编译同步等，具有非常明显的优势。通Jenkins相比，使用CI/CD可以个性化定制自己的编译内容并触发执行，无需实现设置crontab配置。</p><a id="more"></a><p>&emsp;&emsp;本小节主要是Git-Runner的安装。</p><h2 id="更新repo"><a href="#更新repo" class="headerlink" title="更新repo"></a>更新repo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">## 打开配置文件</span><br><span class="line">vim &#x2F;etc&#x2F;yum.repos.d&#x2F;gitlab-ci-multi-runner.repo</span><br><span class="line"></span><br><span class="line">## 添加配置信息</span><br><span class="line">[gitlab-ci-multi-runner]</span><br><span class="line">name&#x3D;gitlab-ci-multi-runner</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ci-multi-runner&#x2F;yum&#x2F;el7</span><br><span class="line">repo_gpgcheck&#x3D;0</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;gpg.key</span><br><span class="line"></span><br><span class="line">## 刷新repo</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gitlab-ci-multi-runner</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 输入命令，根据提示输入配置信息</span><br><span class="line">gitlab-ci-multi-runner register</span><br></pre></td></tr></table></figure><p>注册关键信息，可以找到类似下面的位置获取<br><img src="/.io//001.png" alt="主要信息"></p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># start</span><br><span class="line">gitlab-ci-multi-runner start</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;至此，配置启动完成，在Git界面可以看到这个Runner了。</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> 使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git-CI/CD安装与使用【二】</title>
      <link href="/2018/06/29/Git-CI-CD%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E3%80%90%E4%BA%8C%E3%80%91/"/>
      <url>/2018/06/29/Git-CI-CD%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E3%80%90%E4%BA%8C%E3%80%91/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在使用Gitlab的公司，使用Gitlab提供的各项功能，实现公司代码的管理、自动化编译同步等，具有非常明显的优势。通Jenkins相比，使用CI/CD可以个性化定制自己的编译内容，并触发执行，无需实现设置crontab配置。</p><a id="more"></a><p>&emsp;&emsp;本小节主要是Git-CI/CD配置。</p><h2 id="样例配置"><a href="#样例配置" class="headerlink" title="样例配置"></a>样例配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">stages:</span><br><span class="line">  - build</span><br><span class="line"></span><br><span class="line">build_staging:</span><br><span class="line">  stage: build</span><br><span class="line">  environment:</span><br><span class="line">    name: staging</span><br><span class="line">  image: rastasheep&#x2F;ubuntu-sshd:16</span><br><span class="line">  script:</span><br><span class="line">    - bin&#x2F;build.sh</span><br><span class="line">  only:</span><br><span class="line">    - master</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://www.jianshu.com/p/c840632cef38" target="_blank" rel="noopener">https://www.jianshu.com/p/c840632cef38</a></li><li><a href="https://docs.gitlab.com/ee/ci/README.html" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/README.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> 使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka-&gt;SparkStreaming-&gt;Hbase【一】</title>
      <link href="/2018/06/29/Kafka-SparkStreaming-Hbase%E3%80%90%E4%B8%80%E3%80%91/"/>
      <url>/2018/06/29/Kafka-SparkStreaming-Hbase%E3%80%90%E4%B8%80%E3%80%91/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;根据业务需求，将Kafka中数据抽取插入到Hbase中。目前网上可以找到许多相关的文章，这里介绍Github上的一个开源工具。</p><a id="more"></a><h2 id="工具地址"><a href="#工具地址" class="headerlink" title="工具地址"></a>工具地址</h2><h3 id="Github上搜索结果"><a href="#Github上搜索结果" class="headerlink" title="Github上搜索结果"></a>Github上搜索结果</h3><p><img src="/.io//001.png" alt="这里写图片描述"></p><h3 id="选择工具"><a href="#选择工具" class="headerlink" title="选择工具"></a>选择工具</h3><p><a href="https://github.com/cloudera-labs/SparkOnHBase" target="_blank" rel="noopener">SparkOnHbase</a></p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ol><li>Hadoop: 2.6.0-cdh5.12.1</li><li>Spark:   1.6.0-2.10.5</li><li>Hbase:  1.2.0-cdh5.12.1</li><li>Hive:     1.1.0-cdh5.12.1</li><li>Kafka:   kafka_2.10-0.9.0</li><li>OS:       CentOS Linux release 7.4.1708 (Core)</li><li>JDK:      jdk1.8.0_151</li></ol><h2 id="场景需求"><a href="#场景需求" class="headerlink" title="场景需求"></a>场景需求</h2><ol><li>支持自定义接口解析Kafka对象</li><li>支持插入不同的Hbase表，即配置多个Hbase表名</li><li>Kafka偏移量，可以写入Zookeeper，自定义偏移量</li></ol><h2 id="工具研究"><a href="#工具研究" class="headerlink" title="工具研究"></a>工具研究</h2><h3 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h3><p>&emsp;&emsp;对于Scala用户，主要是以下源代码</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HBaseContext</span>(<span class="params">@transient sc: <span class="type">SparkContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                   @transient config: <span class="type">Configuration</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                    val tmpHdfsConfgFile: <span class="type">String</span> = null</span>) <span class="keyword">extends</span> <span class="title">Serializable</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> credentials = <span class="type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> tmpHdfsConfiguration:<span class="type">Configuration</span> = config</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> appliedCredentials = <span class="literal">false</span>;</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">Job</span>(config)</span><br><span class="line">  <span class="type">TableMapReduceUtil</span>.initCredentials(job)</span><br><span class="line">  <span class="keyword">val</span> broadcastedConf = sc.broadcast(<span class="keyword">new</span> <span class="type">SerializableWritable</span>(config))</span><br><span class="line">  <span class="keyword">val</span> credentialsConf = sc.broadcast(<span class="keyword">new</span> <span class="type">SerializableWritable</span>(job.getCredentials()))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tmpHdfsConfgFile != <span class="literal">null</span> &amp;&amp; config != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.newInstance(config)</span><br><span class="line">    <span class="keyword">val</span> tmpPath = <span class="keyword">new</span> <span class="type">Path</span>(tmpHdfsConfgFile)</span><br><span class="line">    <span class="keyword">if</span> (!fs.exists(tmpPath)) &#123;</span><br><span class="line">      <span class="keyword">val</span> outputStream = fs.create(tmpPath)</span><br><span class="line">      config.write(outputStream)</span><br><span class="line">      outputStream.close();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      logWarning(<span class="string">"tmpHdfsConfigDir "</span> + tmpHdfsConfgFile + <span class="string">" exist!!"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple enrichment of the traditional Spark RDD foreachPartition.</span></span><br><span class="line"><span class="comment">   * This function differs from the original in that it offers the</span></span><br><span class="line"><span class="comment">   * developer access to a already connected HConnection object</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Do not close the HConnection object.  All HConnection</span></span><br><span class="line"><span class="comment">   * management is handled outside this method</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd  Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param f    Function to be given a iterator to iterate through</span></span><br><span class="line"><span class="comment">   *             the RDD values and a HConnection object to interact</span></span><br><span class="line"><span class="comment">   *             with HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">foreachPartition</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">                          f: (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Unit</span>) = &#123;</span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; hbaseForeachPartition(broadcastedConf, it, f))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple enrichment of the traditional Spark Streaming dStream foreach</span></span><br><span class="line"><span class="comment">   * This function differs from the original in that it offers the</span></span><br><span class="line"><span class="comment">   * developer access to a already connected HConnection object</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Do not close the HConnection object.  All HConnection</span></span><br><span class="line"><span class="comment">   * management is handled outside this method</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream  Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param f        Function to be given a iterator to iterate through</span></span><br><span class="line"><span class="comment">   *                 the DStream values and a HConnection object to</span></span><br><span class="line"><span class="comment">   *                 interact with HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">foreachRDD</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                    f: (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Unit</span>) = &#123;</span><br><span class="line">    dstream.foreach((rdd, time) =&gt; &#123;</span><br><span class="line">      foreachPartition(rdd, f)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple enrichment of the traditional Spark RDD mapPartition.</span></span><br><span class="line"><span class="comment">   * This function differs from the original in that it offers the</span></span><br><span class="line"><span class="comment">   * developer access to a already connected HConnection object</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Do not close the HConnection object.  All HConnection</span></span><br><span class="line"><span class="comment">   * management is handled outside this method</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Make sure to partition correctly to avoid memory issue when</span></span><br><span class="line"><span class="comment">   *       getting data from HBase</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd  Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param mp   Function to be given a iterator to iterate through</span></span><br><span class="line"><span class="comment">   *             the RDD values and a HConnection object to interact</span></span><br><span class="line"><span class="comment">   *             with HBase</span></span><br><span class="line"><span class="comment">   * @return     Returns a new RDD generated by the user definition</span></span><br><span class="line"><span class="comment">   *             function just like normal mapPartition</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">mapPartition</span></span>[<span class="type">T</span>, <span class="type">R</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">                                   mp: (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Iterator</span>[<span class="type">R</span>]): <span class="type">RDD</span>[<span class="type">R</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    rdd.mapPartitions[<span class="type">R</span>](it =&gt; hbaseMapPartition[<span class="type">T</span>, <span class="type">R</span>](broadcastedConf,</span><br><span class="line">      it,</span><br><span class="line">      mp), <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple enrichment of the traditional Spark Streaming DStream</span></span><br><span class="line"><span class="comment">   * mapPartition.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * This function differs from the original in that it offers the</span></span><br><span class="line"><span class="comment">   * developer access to a already connected HConnection object</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Do not close the HConnection object.  All HConnection</span></span><br><span class="line"><span class="comment">   * management is handled outside this method</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: Make sure to partition correctly to avoid memory issue when</span></span><br><span class="line"><span class="comment">   *       getting data from HBase</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream  Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param mp       Function to be given a iterator to iterate through</span></span><br><span class="line"><span class="comment">   *                 the DStream values and a HConnection object to</span></span><br><span class="line"><span class="comment">   *                 interact with HBase</span></span><br><span class="line"><span class="comment">   * @return         Returns a new DStream generated by the user</span></span><br><span class="line"><span class="comment">   *                 definition function just like normal mapPartition</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamMap</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                                mp: (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>]): <span class="type">DStream</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    dstream.mapPartitions(it =&gt; hbaseMapPartition[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">      broadcastedConf,</span><br><span class="line">      it,</span><br><span class="line">      mp), <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.foreachPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take RDD</span></span><br><span class="line"><span class="comment">   * and generate puts and send them to HBase.</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd       Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to put into</span></span><br><span class="line"><span class="comment">   * @param f         Function to convert a value in the RDD to a HBase Put</span></span><br><span class="line"><span class="comment">   * @param autoFlush If autoFlush should be turned on</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkPut</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; <span class="type">Put</span>, autoFlush: <span class="type">Boolean</span>) &#123;</span><br><span class="line"></span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; hbaseForeachPartition[<span class="type">T</span>](</span><br><span class="line">        broadcastedConf,</span><br><span class="line">        it,</span><br><span class="line">        (iterator, hConnection) =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line">          htable.setAutoFlush(autoFlush, <span class="literal">true</span>)</span><br><span class="line">          iterator.foreach(<span class="type">T</span> =&gt; htable.put(f(<span class="type">T</span>)))</span><br><span class="line">          htable.flushCommits()</span><br><span class="line">          htable.close()</span><br><span class="line">        &#125;))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">applyCreds</span></span>[<span class="type">T</span>] (configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]])&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    credentials = <span class="type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()</span><br><span class="line"></span><br><span class="line">    logInfo(<span class="string">"appliedCredentials:"</span> + appliedCredentials + <span class="string">",credentials:"</span> + credentials);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (appliedCredentials == <span class="literal">false</span> &amp;&amp; credentials != <span class="literal">null</span>) &#123;</span><br><span class="line">      appliedCredentials = <span class="literal">true</span></span><br><span class="line">      logCredInformation(credentials)</span><br><span class="line"></span><br><span class="line">      <span class="meta">@transient</span> <span class="keyword">val</span> ugi = <span class="type">UserGroupInformation</span>.getCurrentUser();</span><br><span class="line">      ugi.addCredentials(credentials)</span><br><span class="line">      <span class="comment">// specify that this is a proxy user</span></span><br><span class="line">      ugi.setAuthenticationMethod(<span class="type">AuthenticationMethod</span>.<span class="type">PROXY</span>)</span><br><span class="line"></span><br><span class="line">      ugi.addCredentials(credentialsConf.value.value)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">logCredInformation</span></span>[<span class="type">T</span>] (credentials2:<span class="type">Credentials</span>) &#123;</span><br><span class="line">    logInfo(<span class="string">"credentials:"</span> + credentials2);</span><br><span class="line">    <span class="keyword">for</span> (a &lt;- <span class="number">0</span> until credentials2.getAllSecretKeys.size()) &#123;</span><br><span class="line">      logInfo(<span class="string">"getAllSecretKeys:"</span> + a + <span class="string">":"</span> + credentials2.getAllSecretKeys.get(a));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> it = credentials2.getAllTokens.iterator();</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext) &#123;</span><br><span class="line">      logInfo(<span class="string">"getAllTokens:"</span> + it.next());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.streamMapPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generate puts and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream    Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName  The name of the table to put into</span></span><br><span class="line"><span class="comment">   * @param f          Function to convert a value in</span></span><br><span class="line"><span class="comment">   *                   the DStream to a HBase Put</span></span><br><span class="line"><span class="comment">   * @param autoFlush        If autoFlush should be turned on</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkPut</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                       tableName: <span class="type">String</span>,</span><br><span class="line">                       f: (<span class="type">T</span>) =&gt; <span class="type">Put</span>,</span><br><span class="line">                       autoFlush: <span class="type">Boolean</span>) = &#123;</span><br><span class="line">    dstream.foreach((rdd, time) =&gt; &#123;</span><br><span class="line">      bulkPut(rdd, tableName, f, autoFlush)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.foreachPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take RDD</span></span><br><span class="line"><span class="comment">   * and generate checkAndPuts and send them to HBase.</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd       Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to put into</span></span><br><span class="line"><span class="comment">   * @param f         Function to convert a value in the RDD to</span></span><br><span class="line"><span class="comment">   *                  a HBase checkAndPut</span></span><br><span class="line"><span class="comment">   * @param autoFlush If autoFlush should be turned on</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkCheckAndPut</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; (<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Put</span>), autoFlush: <span class="type">Boolean</span>) &#123;</span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; hbaseForeachPartition[<span class="type">T</span>](</span><br><span class="line">        broadcastedConf,</span><br><span class="line">        it,</span><br><span class="line">        (iterator, hConnection) =&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">          <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line">          htable.setAutoFlush(autoFlush, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">          iterator.foreach(<span class="type">T</span> =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> checkPut = f(<span class="type">T</span>)</span><br><span class="line">            htable.checkAndPut(checkPut._1, checkPut._2, checkPut._3, checkPut._4, checkPut._5)</span><br><span class="line">          &#125;)</span><br><span class="line">          htable.flushCommits()</span><br><span class="line">          htable.close()</span><br><span class="line">        &#125;))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.streamMapPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generate checkAndPuts and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream    Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName  The name of the table to checkAndPut into</span></span><br><span class="line"><span class="comment">   * @param f          function to convert a value in the RDD to</span></span><br><span class="line"><span class="comment">   *                   a HBase checkAndPut</span></span><br><span class="line"><span class="comment">   * @param autoFlush        If autoFlush should be turned on</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkCheckAndPut</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; (<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Put</span>), autoFlush: <span class="type">Boolean</span>) &#123;</span><br><span class="line">    dstream.foreach((rdd, time) =&gt; &#123;</span><br><span class="line">      bulkCheckAndPut(rdd, tableName, f, autoFlush)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.foreachPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a RDD and</span></span><br><span class="line"><span class="comment">   * generate increments and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd       Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to increment to</span></span><br><span class="line"><span class="comment">   * @param f         function to convert a value in the RDD to a</span></span><br><span class="line"><span class="comment">   *                  HBase Increments</span></span><br><span class="line"><span class="comment">   * @param batchSize       The number of increments to batch before sending to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkIncrement</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; <span class="type">Increment</span>, batchSize: <span class="type">Integer</span>) &#123;</span><br><span class="line">    bulkMutation(rdd, tableName, f, batchSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.foreachPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a RDD and generate delete</span></span><br><span class="line"><span class="comment">   * and send them to HBase.  The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd       Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to delete from</span></span><br><span class="line"><span class="comment">   * @param f         Function to convert a value in the RDD to a</span></span><br><span class="line"><span class="comment">   *                  HBase Deletes</span></span><br><span class="line"><span class="comment">   * @param batchSize       The number of delete to batch before sending to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkDelete</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; <span class="type">Delete</span>, batchSize: <span class="type">Integer</span>) &#123;</span><br><span class="line">    bulkMutation(rdd, tableName, f, batchSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.foreachPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a RDD and generate</span></span><br><span class="line"><span class="comment">   * checkAndDelete and send them to HBase.  The complexity of managing the</span></span><br><span class="line"><span class="comment">   * HConnection is removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd       Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to delete from</span></span><br><span class="line"><span class="comment">   * @param f         Function to convert a value in the RDD to a</span></span><br><span class="line"><span class="comment">   *                  HBase Deletes</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkCheckDelete</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">                         tableName: <span class="type">String</span>,</span><br><span class="line">                         f: (<span class="type">T</span>) =&gt; (<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Delete</span>)) &#123;</span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; hbaseForeachPartition[<span class="type">T</span>](</span><br><span class="line">        broadcastedConf,</span><br><span class="line">        it,</span><br><span class="line">        (iterator, hConnection) =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line"></span><br><span class="line">          iterator.foreach(<span class="type">T</span> =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> checkDelete = f(<span class="type">T</span>)</span><br><span class="line">            htable.checkAndDelete(checkDelete._1, checkDelete._2, checkDelete._3, checkDelete._4, checkDelete._5)</span><br><span class="line">          &#125;)</span><br><span class="line">          htable.flushCommits()</span><br><span class="line">          htable.close()</span><br><span class="line">        &#125;))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.streamBulkMutation method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generate Increments and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream   Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to increments into</span></span><br><span class="line"><span class="comment">   * @param f         Function to convert a value in the DStream to a</span></span><br><span class="line"><span class="comment">   *                  HBase Increments</span></span><br><span class="line"><span class="comment">   * @param batchSize       The number of increments to batch before sending to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkIncrement</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                             tableName: <span class="type">String</span>,</span><br><span class="line">                             f: (<span class="type">T</span>) =&gt; <span class="type">Increment</span>,</span><br><span class="line">                             batchSize: <span class="type">Int</span>) = &#123;</span><br><span class="line">    streamBulkMutation(dstream, tableName, f, batchSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.streamBulkMutation method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generate Delete and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream    Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName  The name of the table to delete from</span></span><br><span class="line"><span class="comment">   * @param f          function to convert a value in the DStream to a</span></span><br><span class="line"><span class="comment">   *                   HBase Delete</span></span><br><span class="line"><span class="comment">   * @param batchSize        The number of deletes to batch before sending to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkDelete</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                          tableName: <span class="type">String</span>,</span><br><span class="line">                          f: (<span class="type">T</span>) =&gt; <span class="type">Delete</span>,</span><br><span class="line">                          batchSize: <span class="type">Integer</span>) = &#123;</span><br><span class="line">    streamBulkMutation(dstream, tableName, f, batchSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the bulkCheckDelete method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generate CheckAndDelete and send them to HBase.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The complexity of managing the HConnection is</span></span><br><span class="line"><span class="comment">   * removed from the developer</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream    Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName  The name of the table to delete from</span></span><br><span class="line"><span class="comment">   * @param f          function to convert a value in the DStream to a</span></span><br><span class="line"><span class="comment">   *                   HBase Delete</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkCheckAndDelete</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                                  tableName: <span class="type">String</span>,</span><br><span class="line">                                  f: (<span class="type">T</span>) =&gt; (<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Delete</span>)) &#123;</span><br><span class="line">    dstream.foreach((rdd, time) =&gt; &#123;</span><br><span class="line">      bulkCheckDelete(rdd, tableName, f)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  Under lining function to support all bulk mutations</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *  May be opened up if requested</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">bulkMutation</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], tableName: <span class="type">String</span>, f: (<span class="type">T</span>) =&gt; <span class="type">Mutation</span>, batchSize: <span class="type">Integer</span>) &#123;</span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; hbaseForeachPartition[<span class="type">T</span>](</span><br><span class="line">        broadcastedConf,</span><br><span class="line">        it,</span><br><span class="line">        (iterator, hConnection) =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line">          <span class="keyword">val</span> mutationList = <span class="keyword">new</span> <span class="type">ArrayList</span>[<span class="type">Mutation</span>]</span><br><span class="line">          iterator.foreach(<span class="type">T</span> =&gt; &#123;</span><br><span class="line">            mutationList.add(f(<span class="type">T</span>))</span><br><span class="line">            <span class="keyword">if</span> (mutationList.size &gt;= batchSize) &#123;</span><br><span class="line">              htable.batch(mutationList)</span><br><span class="line">              mutationList.clear()</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;)</span><br><span class="line">          <span class="keyword">if</span> (mutationList.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            htable.batch(mutationList)</span><br><span class="line">            mutationList.clear()</span><br><span class="line">          &#125;</span><br><span class="line">          htable.close()</span><br><span class="line">        &#125;))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  Under lining function to support all bulk streaming mutations</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *  May be opened up if requested</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">streamBulkMutation</span></span>[<span class="type">T</span>](dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                                    tableName: <span class="type">String</span>,</span><br><span class="line">                                    f: (<span class="type">T</span>) =&gt; <span class="type">Mutation</span>,</span><br><span class="line">                                    batchSize: <span class="type">Integer</span>) = &#123;</span><br><span class="line">    dstream.foreach((rdd, time) =&gt; &#123;</span><br><span class="line">      bulkMutation(rdd, tableName, f, batchSize)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.mapPartition method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a RDD and generates a</span></span><br><span class="line"><span class="comment">   * new RDD based on Gets and the results they bring back from HBase</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param rdd     Original RDD with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName        The name of the table to get from</span></span><br><span class="line"><span class="comment">   * @param makeGet    function to convert a value in the RDD to a</span></span><br><span class="line"><span class="comment">   *                   HBase Get</span></span><br><span class="line"><span class="comment">   * @param convertResult This will convert the HBase Result object to</span></span><br><span class="line"><span class="comment">   *                   what ever the user wants to put in the resulting</span></span><br><span class="line"><span class="comment">   *                   RDD</span></span><br><span class="line"><span class="comment">   * return            new RDD that is created by the Get to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkGet</span></span>[<span class="type">T</span>, <span class="type">U</span>](tableName: <span class="type">String</span>,</span><br><span class="line">                    batchSize: <span class="type">Integer</span>,</span><br><span class="line">                    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">                    makeGet: (<span class="type">T</span>) =&gt; <span class="type">Get</span>,</span><br><span class="line">                    convertResult: (<span class="type">Result</span>) =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> getMapPartition = <span class="keyword">new</span> <span class="type">GetMapPartition</span>(tableName,</span><br><span class="line">      batchSize,</span><br><span class="line">      makeGet,</span><br><span class="line">      convertResult)</span><br><span class="line"></span><br><span class="line">    rdd.mapPartitions[<span class="type">U</span>](it =&gt;</span><br><span class="line">      hbaseMapPartition[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">        broadcastedConf,</span><br><span class="line">        it,</span><br><span class="line">        getMapPartition.run), <span class="literal">true</span>)(fakeClassTag[<span class="type">U</span>])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A simple abstraction over the HBaseContext.streamMap method.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * It allow addition support for a user to take a DStream and</span></span><br><span class="line"><span class="comment">   * generates a new DStream based on Gets and the results</span></span><br><span class="line"><span class="comment">   * they bring back from HBase</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @param dstream   Original DStream with data to iterate over</span></span><br><span class="line"><span class="comment">   * @param tableName The name of the table to get from</span></span><br><span class="line"><span class="comment">   * @param makeGet   function to convert a value in the DStream to a</span></span><br><span class="line"><span class="comment">   *                  HBase Get</span></span><br><span class="line"><span class="comment">   * @param convertResult This will convert the HBase Result object to</span></span><br><span class="line"><span class="comment">   *                      what ever the user wants to put in the resulting</span></span><br><span class="line"><span class="comment">   *                      DStream</span></span><br><span class="line"><span class="comment">   * return            new DStream that is created by the Get to HBase</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">streamBulkGet</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](tableName: <span class="type">String</span>,</span><br><span class="line">                                    batchSize: <span class="type">Integer</span>,</span><br><span class="line">                                    dstream: <span class="type">DStream</span>[<span class="type">T</span>],</span><br><span class="line">                                    makeGet: (<span class="type">T</span>) =&gt; <span class="type">Get</span>,</span><br><span class="line">                                    convertResult: (<span class="type">Result</span>) =&gt; <span class="type">U</span>): <span class="type">DStream</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> getMapPartition = <span class="keyword">new</span> <span class="type">GetMapPartition</span>(tableName,</span><br><span class="line">      batchSize,</span><br><span class="line">      makeGet,</span><br><span class="line">      convertResult)</span><br><span class="line"></span><br><span class="line">    dstream.mapPartitions[<span class="type">U</span>](it =&gt; hbaseMapPartition[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">      broadcastedConf,</span><br><span class="line">      it,</span><br><span class="line">      getMapPartition.run), <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * This function will use the native HBase TableInputFormat with the</span></span><br><span class="line"><span class="comment">   * given scan object to generate a new RDD</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *  @param tableName the name of the table to scan</span></span><br><span class="line"><span class="comment">   *  @param scan      the HBase scan object to use to read data from HBase</span></span><br><span class="line"><span class="comment">   *  @param f         function to convert a Result object from HBase into</span></span><br><span class="line"><span class="comment">   *                   what the user wants in the final generated RDD</span></span><br><span class="line"><span class="comment">   *  @return          new RDD with results from scan</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hbaseRDD</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](tableName: <span class="type">String</span>, scan: <span class="type">Scan</span>, f: ((<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)) =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> job: <span class="type">Job</span> = <span class="keyword">new</span> <span class="type">Job</span>(getConf(broadcastedConf))</span><br><span class="line"></span><br><span class="line">    <span class="type">TableMapReduceUtil</span>.initCredentials(job)</span><br><span class="line">    <span class="type">TableMapReduceUtil</span>.initTableMapperJob(tableName, scan, classOf[<span class="type">IdentityTableMapper</span>], <span class="literal">null</span>, <span class="literal">null</span>, job)</span><br><span class="line"></span><br><span class="line">    sc.newAPIHadoopRDD(job.getConfiguration(),</span><br><span class="line">      classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">      classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">      classOf[<span class="type">Result</span>]).map(f)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A overloaded version of HBaseContext hbaseRDD that predefines the</span></span><br><span class="line"><span class="comment">   * type of the outputing RDD</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *  @param tableName the name of the table to scan</span></span><br><span class="line"><span class="comment">   *  @param scans      the HBase scan object to use to read data from HBase</span></span><br><span class="line"><span class="comment">   *  @return New RDD with results from scan</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hbaseRDD</span></span>(tableName: <span class="type">String</span>, scans: <span class="type">Scan</span>):</span><br><span class="line">  <span class="type">RDD</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], java.util.<span class="type">List</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])])] = &#123;</span><br><span class="line"></span><br><span class="line">    hbaseRDD[(<span class="type">Array</span>[<span class="type">Byte</span>], java.util.<span class="type">List</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])])](</span><br><span class="line">      tableName,</span><br><span class="line">      scans,</span><br><span class="line">      (r: (<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)) =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> it = r._2.list().iterator()</span><br><span class="line">        <span class="keyword">val</span> list = <span class="keyword">new</span> <span class="type">ArrayList</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])]()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">          <span class="keyword">val</span> kv = it.next()</span><br><span class="line">          list.add((kv.getFamily(), kv.getQualifier(), kv.getValue()))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        (r._1.copyBytes(), list)</span><br><span class="line">      &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hbaseScanRDD</span></span>(tableName: <span class="type">String</span>, scan: <span class="type">Scan</span>):</span><br><span class="line">  <span class="type">RDD</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], java.util.<span class="type">List</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])])] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">new</span> <span class="type">HBaseScanRDD</span>(sc, tableName, scan,</span><br><span class="line">      broadcastedConf)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  Under lining wrapper all foreach functions in HBaseContext</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">hbaseForeachPartition</span></span>[<span class="type">T</span>](</span><br><span class="line">                                        configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]],</span><br><span class="line">                                        it: <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">                                        f: (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Unit</span>) = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> config = getConf(configBroadcast)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    applyCreds(configBroadcast)</span><br><span class="line">    <span class="comment">// specify that this is a proxy user</span></span><br><span class="line">    <span class="keyword">val</span> hConnection = <span class="type">HConnectionManager</span>.createConnection(config)</span><br><span class="line">    f(it, hConnection)</span><br><span class="line">    hConnection.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getConf</span></span>(configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]]): <span class="type">Configuration</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tmpHdfsConfiguration != <span class="literal">null</span>) &#123;</span><br><span class="line">      tmpHdfsConfiguration</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tmpHdfsConfgFile != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.newInstance(<span class="type">SparkHadoopUtil</span>.get.conf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> inputStream = fs.open(<span class="keyword">new</span> <span class="type">Path</span>(tmpHdfsConfgFile))</span><br><span class="line">      tmpHdfsConfiguration = <span class="keyword">new</span> <span class="type">Configuration</span>(<span class="literal">false</span>)</span><br><span class="line">      tmpHdfsConfiguration.readFields(inputStream)</span><br><span class="line">      inputStream.close()</span><br><span class="line"></span><br><span class="line">      tmpHdfsConfiguration</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tmpHdfsConfiguration == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        tmpHdfsConfiguration = configBroadcast.value.value</span><br><span class="line">        tmpHdfsConfiguration</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> ex: <span class="type">Exception</span> =&gt;&#123;</span><br><span class="line">          println(<span class="string">"Unable to getConfig from broadcast"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    tmpHdfsConfiguration</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  Under lining wrapper all mapPartition functions in HBaseContext</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">hbaseMapPartition</span></span>[<span class="type">K</span>, <span class="type">U</span>](</span><br><span class="line">                                       configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]],</span><br><span class="line">                                       it: <span class="type">Iterator</span>[<span class="type">K</span>],</span><br><span class="line">                                       mp: (<span class="type">Iterator</span>[<span class="type">K</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>]): <span class="type">Iterator</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> config = getConf(configBroadcast)</span><br><span class="line">    applyCreds(configBroadcast)</span><br><span class="line">    <span class="keyword">val</span> hConnection = <span class="type">HConnectionManager</span>.createConnection(config)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> res = mp(it, hConnection)</span><br><span class="line">    hConnection.close()</span><br><span class="line">    res</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *  Under lining wrapper all get mapPartition functions in HBaseContext</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">GetMapPartition</span>[<span class="type">T</span>, <span class="type">U</span>](<span class="params">tableName: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                                      batchSize: <span class="type">Integer</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                                      makeGet: (<span class="type">T</span></span>) <span class="title">=&gt;</span> <span class="title">Get</span>,</span></span><br><span class="line"><span class="class">                                      <span class="title">convertResult</span></span>: (<span class="type">Result</span>) =&gt; <span class="type">U</span>) <span class="keyword">extends</span> <span class="type">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(iterator: <span class="type">Iterator</span>[<span class="type">T</span>], hConnection: <span class="type">HConnection</span>): <span class="type">Iterator</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">      <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> gets = <span class="keyword">new</span> <span class="type">ArrayList</span>[<span class="type">Get</span>]()</span><br><span class="line">      <span class="keyword">var</span> res = <span class="type">List</span>[<span class="type">U</span>]()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (iterator.hasNext) &#123;</span><br><span class="line">        gets.add(makeGet(iterator.next))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (gets.size() == batchSize) &#123;</span><br><span class="line">          <span class="keyword">var</span> results = htable.get(gets)</span><br><span class="line">          res = res ++ results.map(convertResult)</span><br><span class="line">          gets.clear()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (gets.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> results = htable.get(gets)</span><br><span class="line">        res = res ++ results.map(convertResult)</span><br><span class="line">        gets.clear()</span><br><span class="line">      &#125;</span><br><span class="line">      htable.close()</span><br><span class="line">      res.iterator</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Produces a ClassTag[T], which is actually just a casted ClassTag[AnyRef].</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * This method is used to keep ClassTags out of the external Java API, as the Java compiler</span></span><br><span class="line"><span class="comment">   * cannot produce them automatically. While this ClassTag-faking does please the compiler,</span></span><br><span class="line"><span class="comment">   * it can cause problems at runtime if the Scala API relies on ClassTags for correctness.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Often, though, a ClassTag[AnyRef] will not lead to incorrect behavior, just worse performance</span></span><br><span class="line"><span class="comment">   * or security issues. For instance, an Array[AnyRef] can hold any type T, but may lose primitive</span></span><br><span class="line"><span class="comment">   * specialization.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span>[spark]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fakeClassTag</span></span>[<span class="type">T</span>]: <span class="type">ClassTag</span>[<span class="type">T</span>] = <span class="type">ClassTag</span>.<span class="type">AnyRef</span>.asInstanceOf[<span class="type">ClassTag</span>[<span class="type">T</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h3><p><em>优点</em>：</p><ol><li>使用方便，直接套用工具即可</li><li>不需要考虑不必要的序列化等问题</li><li>Cloudera出品，质量有保证</li></ol><p><em>缺点</em>：</p><ol><li>适合只写一张表的场景</li><li>应用场景收限，特别是需要自己保存Kafka的Offsets到Zookeeper时</li><li>定制化程度较高，不适合博主的需求</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Spark </tag>
            
            <tag> Kafka </tag>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka-&gt;SparkStreaming-&gt;Hbase【二】</title>
      <link href="/2018/06/29/Kafka-SparkStreaming-Hbase%E3%80%90%E4%BA%8C%E3%80%91/"/>
      <url>/2018/06/29/Kafka-SparkStreaming-Hbase%E3%80%90%E4%BA%8C%E3%80%91/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;根据业务需求，将Kafka中数据抽取插入到Hbase中。目前网上可以找到许多相关的文章，这里介绍Github上的一个开源工具。</p><a id="more"></a><p>&emsp;&emsp;上一章节讲到选择SparkOnHbase为主要原型，将之修改为我们需要的源代码。这里给出修改之后的源代码，修改之后符合我们的业务需求，并尽量避免引起其他不必要的问题。同时，后期优化程序执行效率问题。</p><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HBaseContext</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  @transient sc:        <span class="type">SparkContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  @transient config:    <span class="type">Configuration</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  metas:                java.util.<span class="type">HashMap</span>[<span class="type">String</span>, java.util.<span class="type">HashMap</span>[<span class="type">String</span>, java.util.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]],</span></span></span><br><span class="line"><span class="class"><span class="params">  val tmpHdfsConfgFile: <span class="type">String</span>                                                                                      = null</span>) <span class="keyword">extends</span> <span class="title">Serializable</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> credentials = <span class="type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> tmpHdfsConfiguration: <span class="type">Configuration</span> = config</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> appliedCredentials = <span class="literal">false</span>;</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">var</span> metasLocal = metas</span><br><span class="line">  <span class="meta">@transient</span> <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">Job</span>(config)</span><br><span class="line">  <span class="type">TableMapReduceUtil</span>.initCredentials(job)</span><br><span class="line">  <span class="keyword">val</span> broadcastedConf = sc.broadcast(<span class="keyword">new</span> <span class="type">SerializableWritable</span>(config))</span><br><span class="line">  <span class="keyword">val</span> credentialsConf = sc.broadcast(<span class="keyword">new</span> <span class="type">SerializableWritable</span>(job.getCredentials()))</span><br><span class="line">  <span class="keyword">val</span> broadcastMetas = sc.broadcast(metas)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tmpHdfsConfgFile != <span class="literal">null</span> &amp;&amp; config != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.newInstance(config)</span><br><span class="line">    <span class="keyword">val</span> tmpPath = <span class="keyword">new</span> <span class="type">Path</span>(tmpHdfsConfgFile)</span><br><span class="line">    <span class="keyword">if</span> (!fs.exists(tmpPath)) &#123;</span><br><span class="line">      <span class="keyword">val</span> outputStream = fs.create(tmpPath)</span><br><span class="line">      config.write(outputStream)</span><br><span class="line">      outputStream.close();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      logWarning(<span class="string">"tmpHdfsConfigDir "</span> + tmpHdfsConfgFile + <span class="string">" exist!!"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">mapPartition</span></span>[<span class="type">T</span>, <span class="type">R</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    mp:  (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Iterator</span>[<span class="type">R</span>]): <span class="type">RDD</span>[<span class="type">R</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    rdd.mapPartitions[<span class="type">R</span>](it =&gt; hbaseMapPartition[<span class="type">T</span>, <span class="type">R</span>](</span><br><span class="line">      broadcastedConf,</span><br><span class="line">      it,</span><br><span class="line">      mp), <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">applyCreds</span></span>[<span class="type">T</span>](configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]]) &#123;</span><br><span class="line"></span><br><span class="line">    credentials = <span class="type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()</span><br><span class="line"></span><br><span class="line">    logInfo(<span class="string">"appliedCredentials:"</span> + appliedCredentials + <span class="string">",credentials:"</span> + credentials);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (appliedCredentials == <span class="literal">false</span> &amp;&amp; credentials != <span class="literal">null</span>) &#123;</span><br><span class="line">      appliedCredentials = <span class="literal">true</span></span><br><span class="line">      logCredInformation(credentials)</span><br><span class="line"></span><br><span class="line">      <span class="meta">@transient</span> <span class="keyword">val</span> ugi = <span class="type">UserGroupInformation</span>.getCurrentUser();</span><br><span class="line">      ugi.addCredentials(credentials)</span><br><span class="line">      ugi.setAuthenticationMethod(<span class="type">AuthenticationMethod</span>.<span class="type">PROXY</span>)</span><br><span class="line">      ugi.addCredentials(credentialsConf.value.value)</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">logCredInformation</span></span>[<span class="type">T</span>](credentials2: <span class="type">Credentials</span>) &#123;</span><br><span class="line">    logInfo(<span class="string">"credentials:"</span> + credentials2);</span><br><span class="line">    <span class="keyword">for</span> (a &lt;- <span class="number">0</span> until credentials2.getAllSecretKeys.size()) &#123;</span><br><span class="line">      logInfo(<span class="string">"getAllSecretKeys:"</span> + a + <span class="string">":"</span> + credentials2.getAllSecretKeys.get(a));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> it = credentials2.getAllTokens.iterator();</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext) &#123;</span><br><span class="line">      logInfo(<span class="string">"getAllTokens:"</span> + it.next());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bulkMutation</span></span>[<span class="type">T</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], fun: (<span class="type">T</span>) =&gt; (<span class="type">DataEntity</span>), autoFlush: <span class="type">Boolean</span>) &#123;</span><br><span class="line">    </span><br><span class="line">    rdd.foreachPartition(</span><br><span class="line">      it =&gt; &#123;</span><br><span class="line">        hbaseForeachPartition[<span class="type">T</span>](</span><br><span class="line">          broadcastedConf, broadcastMetas,</span><br><span class="line">          it,</span><br><span class="line">          (iter, hConnection, metas) =&gt; &#123;</span><br><span class="line"></span><br><span class="line">            iter.foreach(item =&gt; &#123;</span><br><span class="line"></span><br><span class="line">              <span class="keyword">val</span> entity = fun(item)</span><br><span class="line">              <span class="keyword">val</span> dbName = entity.dbName</span><br><span class="line">              <span class="keyword">val</span> tabName = entity.tabName</span><br><span class="line">              <span class="keyword">if</span> (metas.containsKey(dbName) &amp;&amp; metas.get(dbName).containsKey(tabName)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">val</span> htable = hConnection.getTable(entity.dbName + <span class="string">":"</span> + entity.tabName)</span><br><span class="line">                htable.setAutoFlush(autoFlush, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">                entity.`<span class="class"><span class="keyword">type</span>` <span class="title">match</span> </span>&#123;</span><br><span class="line">                  <span class="keyword">case</span> <span class="string">"INSERT"</span> | <span class="string">"insert"</span> =&gt; &#123;</span><br><span class="line">                    <span class="keyword">val</span> insertPuts = <span class="type">Instance</span>.insert(entity, metas)</span><br><span class="line">                    <span class="keyword">if</span> (<span class="literal">null</span> != insertPuts &amp;&amp; insertPuts.size() &gt; <span class="number">0</span>)</span><br><span class="line">                      htable.batch(insertPuts)</span><br><span class="line">                  &#125;</span><br><span class="line"></span><br><span class="line">                  <span class="keyword">case</span> <span class="string">"UPDATE"</span> | <span class="string">"update"</span> =&gt; &#123;</span><br><span class="line">                    <span class="keyword">val</span> updatePuts = <span class="type">Instance</span>.update(entity, metas)</span><br><span class="line">                    <span class="keyword">if</span> (<span class="literal">null</span> != updatePuts &amp;&amp; updatePuts.size() &gt; <span class="number">0</span>)</span><br><span class="line">                      htable.batch(updatePuts)</span><br><span class="line">                  &#125;</span><br><span class="line"></span><br><span class="line">                  <span class="keyword">case</span> <span class="string">"DELETE"</span> | <span class="string">"delete"</span> =&gt; &#123;</span><br><span class="line">                    <span class="keyword">val</span> deleteDels = <span class="type">Instance</span>.delete(entity)</span><br><span class="line">                    <span class="keyword">if</span> (<span class="literal">null</span> != deleteDels &amp;&amp; deleteDels.size() &gt; <span class="number">0</span>)</span><br><span class="line">                      htable.batch(deleteDels)</span><br><span class="line">                  &#125;</span><br><span class="line">                  </span><br><span class="line">                  <span class="keyword">case</span> all: <span class="type">Any</span> =&gt; &#123;</span><br><span class="line">                    logInfo(<span class="string">"其他操作："</span> + all)</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                htable.flushCommits()</span><br><span class="line">                htable.close()</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;)</span><br><span class="line">          &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hbaseRDD</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](tableName: <span class="type">String</span>, scan: <span class="type">Scan</span>, f: ((<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)) =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> job: <span class="type">Job</span> = <span class="keyword">new</span> <span class="type">Job</span>(getConf(broadcastedConf))</span><br><span class="line"></span><br><span class="line">    <span class="type">TableMapReduceUtil</span>.initCredentials(job)</span><br><span class="line">    <span class="type">TableMapReduceUtil</span>.initTableMapperJob(tableName, scan, classOf[<span class="type">IdentityTableMapper</span>], <span class="literal">null</span>, <span class="literal">null</span>, job)</span><br><span class="line"></span><br><span class="line">    sc.newAPIHadoopRDD(</span><br><span class="line">      job.getConfiguration(),</span><br><span class="line">      classOf[<span class="type">TableInputFormat</span>],</span><br><span class="line">      classOf[<span class="type">ImmutableBytesWritable</span>],</span><br><span class="line">      classOf[<span class="type">Result</span>]).map(f)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hbaseRDD</span></span>(tableName: <span class="type">String</span>, scans: <span class="type">Scan</span>): <span class="type">RDD</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], java.util.<span class="type">List</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])])] = &#123;</span><br><span class="line"></span><br><span class="line">    hbaseRDD[(<span class="type">Array</span>[<span class="type">Byte</span>], java.util.<span class="type">List</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])])](</span><br><span class="line">      tableName,</span><br><span class="line">      scans,</span><br><span class="line">      (r: (<span class="type">ImmutableBytesWritable</span>, <span class="type">Result</span>)) =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> it = r._2.list().iterator()</span><br><span class="line">        <span class="keyword">val</span> list = <span class="keyword">new</span> <span class="type">ArrayList</span>[(<span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>], <span class="type">Array</span>[<span class="type">Byte</span>])]()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">          <span class="keyword">val</span> kv = it.next()</span><br><span class="line">          list.add((kv.getFamily(), kv.getQualifier(), kv.getValue()))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        (r._1.copyBytes(), list)</span><br><span class="line">      &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">hbaseForeachPartition</span></span>[<span class="type">T</span>](</span><br><span class="line">    configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]],</span><br><span class="line">    metasBroadcast:  <span class="type">Broadcast</span>[<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]]],</span><br><span class="line">    it:              <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">    fun:               (<span class="type">Iterator</span>[<span class="type">T</span>], <span class="type">HConnection</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]]) =&gt; <span class="type">Unit</span>) = &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> config = getConf(configBroadcast)</span><br><span class="line">    <span class="keyword">val</span> metas = getMetas(metasBroadcast)</span><br><span class="line">    applyCreds(configBroadcast)</span><br><span class="line">    <span class="keyword">val</span> hConnection = <span class="type">HConnectionManager</span>.createConnection(config)</span><br><span class="line">    fun(it, hConnection, metas)</span><br><span class="line">    hConnection.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * @desc get METAS from broadcast or driver's configure</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMetas</span></span>(metasBroadcast: <span class="type">Broadcast</span>[<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]]]): <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> != metasLocal) &#123;</span><br><span class="line">      <span class="keyword">return</span> metasLocal</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        metasLocal = metasBroadcast.value</span><br><span class="line">        metasLocal</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> ex: <span class="type">Exception</span> =&gt; &#123;</span><br><span class="line">          logInfo(<span class="string">"Unable to getConfig from broadcast"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    metasLocal</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getConf</span></span>(configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]]): <span class="type">Configuration</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tmpHdfsConfiguration != <span class="literal">null</span>) &#123;</span><br><span class="line">      tmpHdfsConfiguration</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tmpHdfsConfgFile != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.newInstance(<span class="type">SparkHadoopUtil</span>.get.conf)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> inputStream = fs.open(<span class="keyword">new</span> <span class="type">Path</span>(tmpHdfsConfgFile))</span><br><span class="line">      tmpHdfsConfiguration = <span class="keyword">new</span> <span class="type">Configuration</span>(<span class="literal">false</span>)</span><br><span class="line">      tmpHdfsConfiguration.readFields(inputStream)</span><br><span class="line">      inputStream.close()</span><br><span class="line"></span><br><span class="line">      tmpHdfsConfiguration</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tmpHdfsConfiguration == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        tmpHdfsConfiguration = configBroadcast.value.value</span><br><span class="line">        tmpHdfsConfiguration</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> ex: <span class="type">Exception</span> =&gt; &#123;</span><br><span class="line">          println(<span class="string">"Unable to getConfig from broadcast"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tmpHdfsConfiguration</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">hbaseMapPartition</span></span>[<span class="type">K</span>, <span class="type">U</span>](</span><br><span class="line">    configBroadcast: <span class="type">Broadcast</span>[<span class="type">SerializableWritable</span>[<span class="type">Configuration</span>]],</span><br><span class="line">    it:              <span class="type">Iterator</span>[<span class="type">K</span>],</span><br><span class="line">    mp:              (<span class="type">Iterator</span>[<span class="type">K</span>], <span class="type">HConnection</span>) =&gt; <span class="type">Iterator</span>[<span class="type">U</span>]): <span class="type">Iterator</span>[<span class="type">U</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> config = getConf(configBroadcast)</span><br><span class="line">    applyCreds(configBroadcast)</span><br><span class="line">    <span class="keyword">val</span> hConnection = <span class="type">HConnectionManager</span>.createConnection(config)</span><br><span class="line">    <span class="keyword">val</span> res = mp(it, hConnection)</span><br><span class="line">    hConnection.close()</span><br><span class="line">    res</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">GetMapPartition</span>[<span class="type">T</span>, <span class="type">U</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    tableName:     <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    batchSize:     <span class="type">Integer</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    makeGet:       (<span class="type">T</span></span>) <span class="title">=&gt;</span> <span class="title">Get</span>,</span></span><br><span class="line"><span class="class">    <span class="title">convertResult</span></span>: (<span class="type">Result</span>) =&gt; <span class="type">U</span>) <span class="keyword">extends</span> <span class="type">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(iterator: <span class="type">Iterator</span>[<span class="type">T</span>], hConnection: <span class="type">HConnection</span>): <span class="type">Iterator</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">      <span class="keyword">val</span> htable = hConnection.getTable(tableName)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> gets = <span class="keyword">new</span> <span class="type">ArrayList</span>[<span class="type">Get</span>]()</span><br><span class="line">      <span class="keyword">var</span> res = <span class="type">List</span>[<span class="type">U</span>]()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (iterator.hasNext) &#123;</span><br><span class="line">        gets.add(makeGet(iterator.next))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (gets.size() == batchSize) &#123;</span><br><span class="line">          <span class="keyword">var</span> results = htable.get(gets)</span><br><span class="line">          res = res ++ results.map(convertResult)</span><br><span class="line">          gets.clear()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (gets.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> results = htable.get(gets)</span><br><span class="line">        res = res ++ results.map(convertResult)</span><br><span class="line">        gets.clear()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      htable.close()</span><br><span class="line">      res.iterator</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">fakeClassTag</span></span>[<span class="type">T</span>]: <span class="type">ClassTag</span>[<span class="type">T</span>] = <span class="type">ClassTag</span>.<span class="type">AnyRef</span>.asInstanceOf[<span class="type">ClassTag</span>[<span class="type">T</span>]]</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;根据我们的需求，重构了HbaseContext的源代码，删除了不必要的程序代码，从源头上保证了程序适用于我们的应用场景。</p><h2 id="SparkSteaming代码"><a href="#SparkSteaming代码" class="headerlink" title="SparkSteaming代码"></a>SparkSteaming代码</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment">/** initialize ZK UTIL */</span></span><br><span class="line">   <span class="meta">@transient</span> <span class="keyword">val</span> zkUtil = <span class="keyword">new</span> <span class="type">CuratorUtil</span>()</span><br><span class="line"></span><br><span class="line">   <span class="comment">/** get initialize parameters */</span></span><br><span class="line">   <span class="keyword">val</span> offsetPath = <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">ZOOKEEPER_SPARK_PATH</span>)</span><br><span class="line">   zkUtil.createZKNodePer(offsetPath, <span class="literal">null</span>)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> topic = <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">KAFKA_TOPIC_NAME</span>)</span><br><span class="line">   <span class="keyword">val</span> recTime = <span class="type">Integer</span>.parseInt(<span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">STREAMING_RECTCKE_TIME</span>))</span><br><span class="line">   <span class="keyword">val</span> <span class="type">ZK_MYSQL_PATH</span> = <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">ZOOKEEPER_NAMESPACE_MYSQL_TABLES</span>);</span><br><span class="line">   <span class="keyword">val</span> brokerList = <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">KAFKA_BROKER_LIST</span>);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">     <span class="string">"metadata.broker.list"</span> -&gt; brokerList,</span><br><span class="line">     <span class="string">"zookeeper.connect"</span> -&gt; <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">ZOOKEEPER_SERVER_LIST</span>),</span><br><span class="line">     <span class="string">"group.id"</span> -&gt; <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">KAFKA_CONSUMER_GROUPID</span>))</span><br><span class="line"></span><br><span class="line">   <span class="comment">/** initialize HBASE METAS for filter */</span></span><br><span class="line">   <span class="meta">@transient</span> <span class="meta">@volatile</span> <span class="keyword">var</span> metas: java.util.<span class="type">HashMap</span>[<span class="type">String</span>, java.util.<span class="type">HashMap</span>[<span class="type">String</span>, java.util.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ColumnInfo</span>]]] = <span class="type">Instance</span>.paserMetas(zkUtil, <span class="type">ZK_MYSQL_PATH</span>)</span><br><span class="line">   <span class="keyword">if</span> (metas.size() &lt; <span class="number">1</span>) &#123;</span><br><span class="line">     println(<span class="string">"load hbase tablem metas failed!"</span>)</span><br><span class="line">     <span class="keyword">return</span> ;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**  initialize Context */</span></span><br><span class="line">   <span class="comment">// configure</span></span><br><span class="line">   <span class="meta">@transient</span> <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">     .set(<span class="string">"spark.streaming.backpressure.enabled"</span>, <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">STREAMING_BACK_ENABLED</span>)) <span class="comment">// 设置可以限制</span></span><br><span class="line">     .set(<span class="string">"spark.streaming.kafka.maxRatePerPartition"</span>, <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">STREAMING_KAFKA_MAXRATE</span>)) <span class="comment">// 设置具体限制数量：records/SEC</span></span><br><span class="line">     .set(<span class="string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="type">PropertiesUtil</span>.getProperty(<span class="type">ConstantUtil</span>.<span class="type">STREAMING_SHUTDOWN_GRACEFULLLY</span>)) <span class="comment">// 设置Gracefully stop</span></span><br><span class="line">     .set(<span class="string">"serializer.class"</span>, <span class="string">"kafka.serializer.StringEncoder"</span>)</span><br><span class="line">   <span class="meta">@transient</span> <span class="keyword">val</span> hbaseConf = <span class="type">HBaseConfiguration</span>.create();</span><br><span class="line">   hbaseConf.addResource(<span class="string">"/etc/hbase/conf.cloudera.hbase/hbase-site.xml"</span>)</span><br><span class="line">   hbaseConf.addResource(<span class="string">"/etc/hbase/conf.cloudera.hbase/core-site.xml"</span>)</span><br><span class="line">   <span class="meta">@transient</span> <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br><span class="line">   <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(recTime));</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> fromOffsets = readOffsetData(zkUtil, offsetPath, topic, brokerList, <span class="number">9092</span>)</span><br><span class="line">   <span class="keyword">val</span> stream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>, (<span class="type">String</span>, <span class="type">String</span>)](ssc, kafkaParams, fromOffsets, (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">String</span>, <span class="type">String</span>]) =&gt; (mmd.key(), mmd.message()))</span><br><span class="line"></span><br><span class="line">   stream.foreachRDD(rdd =&gt; &#123;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">val</span> offsets = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges.map &#123; offset =&gt; (offset.partition, offset.fromOffset) &#125;</span><br><span class="line">     writeOffsetData(zkUtil, offsetPath, offsets)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">val</span> hbaseContext = <span class="keyword">new</span> <span class="type">HBaseContext</span>(sc, hbaseConf, metas)</span><br><span class="line">     hbaseContext.bulkMutation(rdd.map(item =&gt; item._2), (<span class="type">KV</span>: <span class="type">String</span>) =&gt; &#123;</span><br><span class="line">       <span class="type">Instance</span>.parse(<span class="type">KV</span>)</span><br><span class="line">     &#125;, <span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">   &#125;)</span><br><span class="line"></span><br><span class="line">   <span class="comment">/** add gracefully stop control */</span></span><br><span class="line">   <span class="type">Runtime</span>.getRuntime.addShutdownHook(<span class="keyword">new</span> <span class="type">Thread</span> &#123;</span><br><span class="line">     <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         zkUtil.close()</span><br><span class="line">       &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">         <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; &#123;</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       ssc.stop(<span class="literal">true</span>, <span class="literal">true</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;)</span><br><span class="line"></span><br><span class="line">   <span class="comment">/** spark streaming start and wait termination */</span></span><br><span class="line">   ssc.start()</span><br><span class="line">   ssc.awaitTermination()</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * @desc read data from Zookeeper</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">readOffsetData</span></span>(zkUtil: <span class="type">CuratorUtil</span>, offsetPath: <span class="type">String</span>, topic: <span class="type">String</span>, brokerList: <span class="type">String</span>, kafkaPort: <span class="type">Integer</span>): <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = &#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> orgData = zkUtil.readDataForPath(offsetPath)</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">null</span> == orgData) &#123;</span><br><span class="line">     <span class="keyword">val</span> util = <span class="type">KafkaUtil</span>.getInstance();</span><br><span class="line">     util.init(brokerList, kafkaPort, topic);</span><br><span class="line">     <span class="keyword">val</span> offsets = util.getLeastOffsets</span><br><span class="line">     <span class="keyword">val</span> fromOffsets = <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to offsets.size() - <span class="number">1</span>)</span><br><span class="line">       <span class="keyword">yield</span> <span class="type">TopicAndPartition</span>.apply(topic, i) -&gt; offsets.get(i).toLong</span><br><span class="line">     <span class="keyword">return</span> fromOffsets.toMap</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> data = <span class="type">JSON</span>.parseFull(orgData).get.asInstanceOf[<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]]</span><br><span class="line">   <span class="keyword">val</span> fromOffsets = data.map(item =&gt; &#123;</span><br><span class="line">     <span class="type">TopicAndPartition</span>.apply(topic, item._1.toInt) -&gt; item._2.toLong</span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="keyword">return</span> fromOffsets</span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * @desc write offset data to Zookeeper</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">writeOffsetData</span></span>(zkUtil: <span class="type">CuratorUtil</span>, offsetPath: <span class="type">String</span>, data: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">val</span> map = data.toMap[<span class="type">Int</span>, <span class="type">Long</span>].map(item =&gt; &#123;</span><br><span class="line">     item._1.toString() -&gt; item._2.toString()</span><br><span class="line">   &#125;)</span><br><span class="line">   zkUtil.setDataForPath(offsetPath, <span class="type">JSONObject</span>(map).toString)</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> Spark </tag>
            
            <tag> Kafka </tag>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven使用各种问题汇总</title>
      <link href="/2018/06/29/Maven%E4%BD%BF%E7%94%A8%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
      <url>/2018/06/29/Maven%E4%BD%BF%E7%94%A8%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="查找损坏Jar"><a href="#查找损坏Jar" class="headerlink" title="查找损坏Jar"></a>查找损坏Jar</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find  ~/.m2/repository/ -name "*jar" | xargs -L 1 zip -T | grep error | grep invalid</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Maven-plugin备忘"><a href="#Maven-plugin备忘" class="headerlink" title="Maven plugin备忘"></a>Maven plugin备忘</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- maven-jar-plugin:设置JDK版本 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">&lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">&lt;archive&gt;</span><br><span class="line">&lt;manifest&gt;</span><br><span class="line">&lt;mainClass&gt;com.cetc.di.hellocetc.App&lt;/mainClass&gt;</span><br><span class="line">&lt;addClasspath&gt;true&lt;/addClasspath&gt;</span><br><span class="line">&lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;</span><br><span class="line">&lt;/manifest&gt;</span><br><span class="line">&lt;/archive&gt;</span><br><span class="line">&lt;classesDirectory&gt;</span><br><span class="line">&lt;/classesDirectory&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- maven-compiler-plugin:设置JDK版本 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;3.1&lt;/version&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">&lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- maven-shade-plugin:可执行jar包 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;3.1.1&lt;/version&gt;</span><br><span class="line">&lt;executions&gt;</span><br><span class="line">&lt;execution&gt;</span><br><span class="line">&lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">&lt;goals&gt;</span><br><span class="line">&lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">&lt;/goals&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;</span><br><span class="line">&lt;shadedClassifierName&gt;exe&lt;/shadedClassifierName&gt; &lt;!-- Any name that makes sense --&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;/execution&gt;</span><br><span class="line">&lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;!-- maven-assembly-plugin:将依赖打入Jar包 --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;2.4.1&lt;/version&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;descriptorRefs&gt;</span><br><span class="line">&lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;</span><br><span class="line">&lt;/descriptorRefs&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;executions&gt;</span><br><span class="line">&lt;execution&gt;</span><br><span class="line">&lt;id&gt;make-assembly&lt;/id&gt;</span><br><span class="line">&lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">&lt;goals&gt;</span><br><span class="line">&lt;goal&gt;single&lt;/goal&gt;</span><br><span class="line">&lt;/goals&gt;</span><br><span class="line">&lt;/execution&gt;</span><br><span class="line">&lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><h2 id="Maven将test类打入jar包"><a href="#Maven将test类打入jar包" class="headerlink" title="Maven将test类打入jar包"></a>Maven将test类打入jar包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--  maven plugin --&gt;</span><br><span class="line">&lt;plugin&gt;</span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;2.4.1&lt;/version&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;descriptor&gt;src/main/java/assembly/assembly.xml&lt;/descriptor&gt;</span><br><span class="line">&lt;!--&lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; </span><br><span class="line">&lt;/descriptorRefs&gt; --&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;executions&gt;</span><br><span class="line">&lt;execution&gt;</span><br><span class="line">&lt;id&gt;make-assembly&lt;/id&gt;</span><br><span class="line">&lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">&lt;goals&gt;</span><br><span class="line">&lt;goal&gt;single&lt;/goal&gt;</span><br><span class="line">&lt;/goals&gt;</span><br><span class="line">&lt;/execution&gt;</span><br><span class="line">&lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- assembly.xml --&gt;</span><br><span class="line">&lt;assembly</span><br><span class="line">xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3"</span><br><span class="line">xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"</span><br><span class="line">xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt;</span><br><span class="line">&lt;id&gt;fat-tests&lt;/id&gt;</span><br><span class="line">&lt;formats&gt;</span><br><span class="line">&lt;format&gt;jar&lt;/format&gt;</span><br><span class="line">&lt;/formats&gt;</span><br><span class="line">&lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt;</span><br><span class="line">&lt;dependencySets&gt;</span><br><span class="line">&lt;dependencySet&gt;</span><br><span class="line">&lt;outputDirectory&gt;/&lt;/outputDirectory&gt;</span><br><span class="line">&lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt;</span><br><span class="line">&lt;unpack&gt;true&lt;/unpack&gt;</span><br><span class="line">&lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">&lt;/dependencySet&gt;</span><br><span class="line">&lt;/dependencySets&gt;</span><br><span class="line">&lt;fileSets&gt;</span><br><span class="line">&lt;fileSet&gt;</span><br><span class="line">&lt;directory&gt;$&#123;project.build.directory&#125;/test-classes&lt;/directory&gt;</span><br><span class="line">&lt;outputDirectory&gt;/&lt;/outputDirectory&gt;</span><br><span class="line">&lt;includes&gt;</span><br><span class="line">&lt;include&gt;**/*.class&lt;/include&gt;</span><br><span class="line">&lt;/includes&gt;</span><br><span class="line">&lt;useDefaultExcludes&gt;true&lt;/useDefaultExcludes&gt;</span><br><span class="line">&lt;/fileSet&gt;</span><br><span class="line">&lt;/fileSets&gt;</span><br><span class="line">&lt;/assembly&gt;</span><br></pre></td></tr></table></figure><h2 id="向仓库中发布Jar包"><a href="#向仓库中发布Jar包" class="headerlink" title="向仓库中发布Jar包"></a>向仓库中发布Jar包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn deploy:deploy-file -DgroupId=[GroupID] -DartifactId=[ArtifactID] -Dversion=[Jar Version] -Dpackaging=jar -Dfile=[Local Jar path]  -DrepositoryId=[Repository ID, define in POM] -Durl=[Remote Repository URL] -s [default setting.xml or special one]</span><br></pre></td></tr></table></figure><h2 id="Maven依赖冲突相关"><a href="#Maven依赖冲突相关" class="headerlink" title="Maven依赖冲突相关"></a>Maven依赖冲突相关</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看依赖树</span></span></span><br><span class="line">mvn dependency:tree [-Dverbose -D...]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看有效pom</span></span></span><br><span class="line">mvn help:effiective-pom</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> 问题 </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS之我遇到的各种问题</title>
      <link href="/2018/06/29/HDFS%E4%B9%8B%E6%88%91%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98/"/>
      <url>/2018/06/29/HDFS%E4%B9%8B%E6%88%91%E9%81%87%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Hostname问题"><a href="#Hostname问题" class="headerlink" title="Hostname问题"></a>Hostname问题</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Datanode denied communication with namenode because hostname cannot be resolved (ip&#x3D;xx.xx.xx.xx, hostname&#x3D;xx.xx.xx.xx)</span><br><span class="line">    at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:876)</span><br><span class="line">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerDatanode(FSNamesystem.java:5269)</span><br><span class="line">    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.registerDatanode(NameNodeRpcServer.java:1178)</span><br><span class="line">    at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.registerDatanode(DatanodeProtocolServerSideTranslatorPB.java:100)</span><br><span class="line">    at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:29184)</span><br><span class="line">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)</span><br><span class="line">    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)</span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2281)</span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2277)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)</span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2275)</span><br></pre></td></tr></table></figure><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>A. 在/etc/hosts中添加映射关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IPhostname</span><br><span class="line">IPhostname</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>B. 设置取消hostname检查</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfs.namenode.datanode.registratin.io-hostname-check: false</span><br></pre></td></tr></table></figure><h2 id="安装问题"><a href="#安装问题" class="headerlink" title="安装问题"></a>安装问题</h2><h3 id="deltarpm"><a href="#deltarpm" class="headerlink" title="deltarpm"></a>deltarpm</h3><p>A. 问题描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Delta RPMs disabled because &#x2F;usr&#x2F;bin&#x2F;applydeltarpm not installed</span><br></pre></td></tr></table></figure><p>B. 解决方案</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install deltarpm</span><br></pre></td></tr></table></figure><h3 id="SASL"><a href="#SASL" class="headerlink" title="SASL"></a>SASL</h3><p>A. 问题描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Could not start SASL: Error in sasl_client_start (-4) SASL(-4): no mechanism available: No worthy mechs found (code THRIFTTRANSPORT): TTransportException(&#39;Could not start SASL: Error in sasl_client_start (-4) SASL(-4): no mechanism available: No worthy mechs found&#39;,)</span><br></pre></td></tr></table></figure><p>B. 解决方案</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install cyrus-sasl-plain cyrus-sasl-devel cyrus-sasl-gssapi</span><br></pre></td></tr></table></figure><h3 id="libxslt-so"><a href="#libxslt-so" class="headerlink" title="libxslt.so"></a>libxslt.so</h3><p>A. 问题描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> Couldn&#39;t import snappy. Support for snappy compression disabled.</span><br><span class="line">File &quot;&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH-5.12.1-1.cdh5.12.1.p0.3&#x2F;lib&#x2F;hue&#x2F;build&#x2F;env&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;lxml-3.3.6-py2.7-linux-x86_64.egg&#x2F;lxml&#x2F;html&#x2F;__init__.py&quot;, line 42, in &lt;module&gt; from lxml import etree</span><br><span class="line">ImportError: libxslt.so.1: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure><p>B. 解决方案</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install httpd -y</span><br></pre></td></tr></table></figure><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="注释中文乱码问题"><a href="#注释中文乱码问题" class="headerlink" title="注释中文乱码问题"></a>注释中文乱码问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8; </span><br><span class="line">alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8; </span><br><span class="line">alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8; （分区表）</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
            <tag> HDFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux使用命令备忘</title>
      <link href="/2018/06/29/Linux%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98/"/>
      <url>/2018/06/29/Linux%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;在使用Centos或Ubuntu时，遇到各种Linux的命令，用到的时候回去查一下语法、参数、使用等内容，但使用过后基本上就忘记了。后面再使用的话，还的继续查找相关文档。</p><a id="more"></a><h2 id="ls命令"><a href="#ls命令" class="headerlink" title="ls命令"></a>ls命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br><span class="line">ls -l</span><br><span class="line">ls -ltr</span><br></pre></td></tr></table></figure><h2 id="du-df命令"><a href="#du-df命令" class="headerlink" title="du/df命令"></a>du/df命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">du -h --max-depth&#x3D;1 &#x2F;</span><br><span class="line">df</span><br><span class="line">df -lh</span><br></pre></td></tr></table></figure><h2 id="top命令"><a href="#top命令" class="headerlink" title="top命令"></a>top命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">top</span><br><span class="line">top -U</span><br><span class="line">top -p PID</span><br></pre></td></tr></table></figure><h2 id="find命令"><a href="#find命令" class="headerlink" title="find命令"></a>find命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find &#x2F; -name XXX</span><br><span class="line">find &#x2F; -size [+&#x2F;-]XXX</span><br></pre></td></tr></table></figure><h2 id="grep命令"><a href="#grep命令" class="headerlink" title="grep命令"></a>grep命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep agent | grep -v grep | awk &#39;&#123;print $2&#125;&#39; | xargs kill -9 </span><br><span class="line">ps -ef | grep agent | grep -v grep | awk &#39;&#123;print \$2&#125;&#39; | xargs kill -9</span><br></pre></td></tr></table></figure><h2 id="cp命令"><a href="#cp命令" class="headerlink" title="cp命令"></a>cp命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 保持权限状态</span><br><span class="line">cp -p XXX XXX</span><br></pre></td></tr></table></figure><h2 id="netstat命令"><a href="#netstat命令" class="headerlink" title="netstat命令"></a>netstat命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -nltp</span><br></pre></td></tr></table></figure><h2 id="trace命令"><a href="#trace命令" class="headerlink" title="trace命令"></a>trace命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strace -p PID  -f -e trace&#x3D;network -s 10000</span><br></pre></td></tr></table></figure><h2 id="tcpdump命令"><a href="#tcpdump命令" class="headerlink" title="tcpdump命令"></a>tcpdump命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 \) </span><br><span class="line">tcpdump -i eth0 src host IPAddress</span><br></pre></td></tr></table></figure><h2 id="Java命令"><a href="#Java命令" class="headerlink" title="Java命令"></a>Java命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br><span class="line">java</span><br><span class="line">javac</span><br><span class="line">javah</span><br></pre></td></tr></table></figure><h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jmap -heap [PID]</span><br><span class="line">jmap -histo [PID]</span><br><span class="line">jmap -dump:file&#x3D;文件名.dump [pid]</span><br></pre></td></tr></table></figure><h3 id="jhat"><a href="#jhat" class="headerlink" title="jhat"></a>jhat</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap [Dump File]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 备忘 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装Chrome-Headless遇到的问题</title>
      <link href="/2018/06/29/%E5%AE%89%E8%A3%85Chrome-Headless%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/2018/06/29/%E5%AE%89%E8%A3%85Chrome-Headless%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h2><p><a href="https://dl.lancdn.com/landian/software/chrome/m" target="_blank" rel="noopener">https://dl.lancdn.com/landian/software/chrome/m</a><br><a href="https://sites.google.com/a/chromium.org/chromedriver/downloads" target="_blank" rel="noopener">https://sites.google.com/a/chromium.org/chromedriver/downloads</a></p><a id="more"></a><h2 id="缺少依赖"><a href="#缺少依赖" class="headerlink" title="缺少依赖"></a>缺少依赖</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">warning: 67.0.3396.79_x86_64.rpm: Header V4 DSA&#x2F;SHA1 Signature, key ID 7fac5991: NOKEY</span><br><span class="line">error: Failed dependencies:</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;lsb_release is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libX11-xcb.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libX11.so.6()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXcomposite.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXcursor.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXdamage.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXext.so.6()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXfixes.so.3()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXi.so.6()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXrandr.so.2()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXrender.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXss.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libXtst.so.6()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libappindicator3.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libasound.so.2()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libatk-1.0.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libatk-bridge-2.0.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libc.so.6(GLIBC_2.14)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libc.so.6(GLIBC_2.15)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libcairo.so.2()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libcups.so.2()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libgdk-3.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libgdk_pixbuf-2.0.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libgtk-3.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libnss3.so(NSS_3.22)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libpango-1.0.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libpangocairo-1.0.so.0()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libssl3.so(NSS_3.28)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libstdc++.so.6(GLIBCXX_3.4.14)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libstdc++.so.6(GLIBCXX_3.4.15)(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">libxcb.so.1()(64bit) is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br><span class="line">xdg-utils is needed by google-chrome-stable-67.0.3396.79-1.x86_64</span><br></pre></td></tr></table></figure><p>由于依赖组件太多，只能逐步排查：安装缺少的依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum install -y redhat-lsb-core-4.0-7.el6.centos.x86_64 </span><br><span class="line">yum install -y libX11-devel --nogpg  </span><br><span class="line">yum install -y cmake gcc gcc-c++ gtk+-devel gimp-devel gimp-devel-tools gimp-help-browser zlib-devel libtiff-devel libjpeg-devel libpng-devel gstreamer-devel libavc1394-devel libraw1394-devel libdc1394-devel jasper-devel jasper-utils swig python libtool nasm </span><br><span class="line">yum install -y gtk2 gtk2-devel gtk2-devel-docs</span><br><span class="line">yum install -y libgtk*</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;最终发现，这种安装方式存在缺陷且依赖的组件相对较多，任务介入安装比较麻烦。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Alibaba-DataX调研使用</title>
      <link href="/2018/06/29/Alibaba-DataX%E8%B0%83%E7%A0%94%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/06/29/Alibaba-DataX%E8%B0%83%E7%A0%94%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;接触DataX是基于公司离线数据同步需求，从而开始接触到DataX的使用。前异构数据之间开源同步工具，主要有</p><a id="more"></a><h2 id="同步工具调研"><a href="#同步工具调研" class="headerlink" title="同步工具调研"></a>同步工具调研</h2><ol><li><p>Sqoop<br>&emsp;&emsp;Sqoop是一款开源的工具，主要用于Hadoop与传统RDBMS之间的数据同步，可以将RDBMS中的数据同步到HDFS中，也可以进行逆向操作。主要是基于MR任务的进行同步，具有支持并发、增量更新、支持海量数据同步等优点。<br>&emsp;&emsp;<a href="https://github.com/cloudera/sqoop/wiki" target="_blank" rel="noopener">Sqoop Wiki</a><br>&emsp;&emsp;<a href="https://github.com/cloudera/sqoop/wiki" target="_blank" rel="noopener">Sqoop官网</a></p></li><li><p>OGG<br>&emsp;&emsp;Oracle Golden Gate，缩写为OGG，可见其是Oralce“冠名”的同步工具。主要是RDBMS之间的数据同步，常见的关系型数据，例如Oracle/DB2/Sybase/MySQL/MsSQL等均支持。<br>&emsp;&emsp;<a href="http://www.oracle.com/technetwork/cn/middleware/goldengate/overview/index.html" target="_blank" rel="noopener">OGG介绍</a></p></li><li><p>Kettle<br>&emsp;&emsp;Kettle是一款开源的ETL工具，具有集群模式。Kettle主要用来做ETL数据处理，具有方便快捷、可视化等优点，适合于一般中小业务的使用。</p></li><li><p>DataX<br>&emsp;&emsp;DataX是由Alibaba开源的一款异构数据同步工具，可以在常见的各种数据源之间进行同步，并仅依赖Java环境，具有轻量、插件式、方便等优点，可以快速完成同步任务。一般公司的数据同步任务，基本可以满足。</p></li><li><p>canal+otter<br>&emsp;&emsp;canal+otter数据同步方案，同样是Alibaba开源的同步工具。该方案适用于大规模、扩机房、跨区域等重量级数据同步任务，并具有监控、近实时同步等优点。</p></li><li><p>SymmetricDS<br>&emsp;&emsp;同样是一款基于Java开发的分布式开源同步软件，基于复制原理，源于Java的特性，SymmetricDS具有跨平台、多线程、可监控等优点。</p></li></ol><p>&emsp;&emsp;博主公司具有实时同步数据与离线同步数据的需求，因此需要调研数据同步工具。其中实时同步主要是从MySQL同步数据到Hive，这里我们选择的是MySQL Binlog方式进行实时同步；离线同步，主要是从各种数据源–如MySQL、ODPS、HIVE等–之间的数据同步。</p><p>&emsp;&emsp;经过调研发现，DataX具有以下优点</p><ol><li>社区活跃，虽然Alibaba没有开源集群模式，仍有许多用户群体；</li><li>Alibaba出品，有大公司维护；</li><li>使用方便，只需要配置JSON即可使用;无需安装，直接解压即可使用；</li><li>完善的文档，很快可以上手，学习成本近乎于零。</li></ol><h2 id="DataX介绍"><a href="#DataX介绍" class="headerlink" title="DataX介绍"></a>DataX介绍</h2><p>&emsp;&emsp;<em>DataX</em>是Alibaba推出的异构数据通过方案，通过插件式组合，可以完成不同数据源之间的数据同步任务。DataX可以通过的数据包括目前所见的绝大数，包括关系型数据库[MySQL、Oracle、SQLServer、PostgreSQL等]、阿里云数据仓数据存储[ODPS、ADS、OSS、OCS等]、NoSQL数据库[OTS、Hbase、MongoDB、Hive等]、无结构化数据[TextFile、FTP、HDFS、ES等]。另外DataX提供了方便的扩展实现，可以方便的个性化定制自己的数据源，方便扩展。</p><p>&emsp;&emsp;目前开源出来的DataX已经发布了3.0版本，增加了许多新的特性，包括</p><ol><li>可靠地数据质量监控</li><li>丰富的数据转换功能</li><li>精准的速度控制</li><li>强劲的同步性能</li><li>健壮的容错机制</li><li>极简的使用体验</li></ol><p>&emsp;&emsp;更加详细的介绍，可以参考DataX的官方说明：<br>&emsp;&emsp;<a href="https://github.com/alibaba/DataX/blob/master/userGuid.md" target="_blank" rel="noopener">User Guide</a><br>&emsp;&emsp;<a href="https://github.com/alibaba/DataX/blob/master/introduction.md" target="_blank" rel="noopener">DataX-Introduction</a><br>&emsp;&emsp;<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md" target="_blank" rel="noopener">插件开发宝典</a></p><h2 id="目前使用场景"><a href="#目前使用场景" class="headerlink" title="目前使用场景"></a>目前使用场景</h2><p>&emsp;&emsp;目前我们使用到的场景如下所示<br><img src="/.io//001.png" alt="插件使用场景"><br>&emsp;&emsp;同步的路径为：</p><ol><li>MySQL-&gt;Hive</li><li>Hive-&gt;MySQL</li><li>ODPS-&gt;Hive</li><li>ODPS-&gt;MySQL</li><li>RDS-&gt;Hive<br>&emsp;&emsp;选择DataX还有一个重要的特性就是，DataX是Alibaba提供的数据同步方案，天然的支持阿里云的数据源，不需要我们重新从API开始开发，节省开发成本。</li></ol><h2 id="使用体会"><a href="#使用体会" class="headerlink" title="使用体会"></a>使用体会</h2><p>&emsp;&emsp;在使用DataX的过程中，总体而言遇到的问题较少。目前DataX的主要缺点在于开源出来的DataX，缺少分布式支持，是单机版本，无法充分发挥集群的里面。因此，会存在单机节点存在的各种问题，内存、CPU、网络等问题。</p><p>使用一段时间，有一些思考</p><ol><li>DataX集群模式的实现方式，如何实现？如果集群之后，如何监控？</li><li>DataX单节点状态时，任务运行性能参数的收集。DataX提供了Hook，可以回调打印一些参数，另外可以加入最后打印的数据，例如<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, Number&gt; preLogStatics &#x3D; communication.getCounter();</span><br><span class="line">preLogStatics.put(&quot;任务启动时刻&quot;, startTimeStamp);</span><br><span class="line">preLogStatics.put(&quot;任务结束时刻&quot;, endTimeStamp);</span><br><span class="line">preLogStatics.put(&quot;任务总计耗时&quot;, totalCosts);</span><br><span class="line">preLogStatics.put(&quot;任务平均流量&quot;, byteSpeedPerSecond);</span><br><span class="line">preLogStatics.put(&quot;记录写入速度&quot;, recordSpeedPerSecond);</span><br><span class="line">preLogStatics.put(&quot;读出记录总数&quot;, CommunicationTool.getTotalReadRecords(communication));</span><br><span class="line">preLogStatics.put(&quot;读写失败总数&quot;, CommunicationTool.getTotalErrorRecords(communication));</span><br><span class="line"></span><br><span class="line">HookInvoker invoker &#x3D; new HookInvoker(CoreConstant.DATAX_HOME + &quot;&#x2F;hook&quot;, configuration, preLogStatics);</span><br></pre></td></tr></table></figure>&emsp;&emsp;这样我们收集到更多的运行参数，方便后期对任务的运行作分析，便于改进优化任务的运行参数。</li><li>DataX.py本质上运行的是Java程序，如果直接调用Engine.entry，如何统计任务运行日志？是否存在一种方式，可以按照线程打印单独一个文件的日志？</li></ol><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><ol><li><a href="https://github.com/alibaba/DataX" target="_blank" rel="noopener">https://github.com/alibaba/DataX</a></li><li><a href="https://blog.csdn.net/gamer_gyt/article/details/55225700" target="_blank" rel="noopener">https://blog.csdn.net/gamer_gyt/article/details/55225700</a></li><li><a href="https://www.cnblogs.com/qiumingcheng/p/5435907.html" target="_blank" rel="noopener">https://www.cnblogs.com/qiumingcheng/p/5435907.html</a></li><li><a href="https://www.cnblogs.com/majinju/p/5739820.html" target="_blank" rel="noopener">https://www.cnblogs.com/majinju/p/5739820.html</a></li><li><a href="http://www.oracle.com/technetwork/cn/middleware/goldengate/overview/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/cn/middleware/goldengate/overview/index.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 调研 </tag>
            
            <tag> DataX </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
