<!DOCTYPE html><html lang="zh-CN"><head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="xinshiyou">
  <meta name="keywords" content="">
  <title>Kafka-&gt;SparkStreaming-&gt;Hbase【二】 - 星空捞月：找寻心中的安宁</title>

  


  
  

  
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->










<!-- 自定义样式保持在最底部 -->


  
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="星空捞月：找寻心中的安宁" type="application/atom+xml">
<script>function loadCss(l){var d=document,h=d.head,s=d.createElement('link');s.rel='stylesheet';s.href=l;!function e(f){if (d.body)return f();setTimeout(function(){e(f)})}(function(){h.appendChild(s);});}loadCss('/style.css');loadCss('https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css');loadCss('https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css');loadCss('https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css');loadCss('//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css');loadCss('//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css');loadCss('https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css');</script><noscript><link rel="stylesheet" href="/style.css"><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css"><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"></noscript></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">&nbsp;<strong>星空捞月：找寻心中的安宁</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax="true" style="background: url('/img/top.jpeg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2018-06-29 16:52">
      2018年6月29日 下午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      26
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>  根据业务需求，将Kafka中数据抽取插入到Hbase中。目前网上可以找到许多相关的文章，这里介绍Github上的一个开源工具。</p>
<a id="more"></a>

<p>  上一章节讲到选择SparkOnHbase为主要原型，将之修改为我们需要的源代码。这里给出修改之后的源代码，修改之后符合我们的业务需求，并尽量避免引起其他不必要的问题。同时，后期优化程序执行效率问题。</p>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><pre class=" language-hljs scala"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HBaseContext</span>(<span class="hljs-params"><code class="language-hljs scala"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HBaseContext</span>(<span class="hljs-params"></span></span>
<span class="hljs-class"><span class="hljs-params">  @transient sc:        <span class="hljs-type">SparkContext</span>,</span></span>
<span class="hljs-class"><span class="hljs-params">  @transient config:    <span class="hljs-type">Configuration</span>,</span></span>
<span class="hljs-class"><span class="hljs-params">  metas:                java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]],</span></span>
<span class="hljs-class"><span class="hljs-params">  val tmpHdfsConfgFile: <span class="hljs-type">String</span>                                                                                      = null</span>) <span class="hljs-keyword">extends</span> <span class="hljs-title">Serializable</span> <span class="hljs-keyword">with</span> <span class="hljs-title">Logging</span> </span>{

  <span class="hljs-meta">@transient</span> <span class="hljs-keyword">var</span> credentials = <span class="hljs-type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()
  <span class="hljs-meta">@transient</span> <span class="hljs-keyword">var</span> tmpHdfsConfiguration: <span class="hljs-type">Configuration</span> = config
  <span class="hljs-meta">@transient</span> <span class="hljs-keyword">var</span> appliedCredentials = <span class="hljs-literal">false</span>;
  <span class="hljs-meta">@transient</span> <span class="hljs-keyword">var</span> metasLocal = metas
  <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> job = <span class="hljs-keyword">new</span> <span class="hljs-type">Job</span>(config)
  <span class="hljs-type">TableMapReduceUtil</span>.initCredentials(job)
  <span class="hljs-keyword">val</span> broadcastedConf = sc.broadcast(<span class="hljs-keyword">new</span> <span class="hljs-type">SerializableWritable</span>(config))
  <span class="hljs-keyword">val</span> credentialsConf = sc.broadcast(<span class="hljs-keyword">new</span> <span class="hljs-type">SerializableWritable</span>(job.getCredentials()))
  <span class="hljs-keyword">val</span> broadcastMetas = sc.broadcast(metas)

  <span class="hljs-keyword">if</span> (tmpHdfsConfgFile != <span class="hljs-literal">null</span> &amp;&amp; config != <span class="hljs-literal">null</span>) {
    <span class="hljs-keyword">val</span> fs = <span class="hljs-type">FileSystem</span>.newInstance(config)
    <span class="hljs-keyword">val</span> tmpPath = <span class="hljs-keyword">new</span> <span class="hljs-type">Path</span>(tmpHdfsConfgFile)
    <span class="hljs-keyword">if</span> (!fs.exists(tmpPath)) {
      <span class="hljs-keyword">val</span> outputStream = fs.create(tmpPath)
      config.write(outputStream)
      outputStream.close();
    } <span class="hljs-keyword">else</span> {
      logWarning(<span class="hljs-string">"tmpHdfsConfigDir "</span> + tmpHdfsConfgFile + <span class="hljs-string">" exist!!"</span>)
    }
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mapPartition</span></span>[<span class="hljs-type">T</span>, <span class="hljs-type">R</span>: <span class="hljs-type">ClassTag</span>](
    rdd: <span class="hljs-type">RDD</span>[<span class="hljs-type">T</span>],
    mp:  (<span class="hljs-type">Iterator</span>[<span class="hljs-type">T</span>], <span class="hljs-type">HConnection</span>) =&gt; <span class="hljs-type">Iterator</span>[<span class="hljs-type">R</span>]): <span class="hljs-type">RDD</span>[<span class="hljs-type">R</span>] = {

    rdd.mapPartitions[<span class="hljs-type">R</span>](it =&gt; hbaseMapPartition[<span class="hljs-type">T</span>, <span class="hljs-type">R</span>](
      broadcastedConf,
      it,
      mp), <span class="hljs-literal">true</span>)
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">applyCreds</span></span>[<span class="hljs-type">T</span>](configBroadcast: <span class="hljs-type">Broadcast</span>[<span class="hljs-type">SerializableWritable</span>[<span class="hljs-type">Configuration</span>]]) {

    credentials = <span class="hljs-type">SparkHadoopUtil</span>.get.getCurrentUserCredentials()

    logInfo(<span class="hljs-string">"appliedCredentials:"</span> + appliedCredentials + <span class="hljs-string">",credentials:"</span> + credentials);

    <span class="hljs-keyword">if</span> (appliedCredentials == <span class="hljs-literal">false</span> &amp;&amp; credentials != <span class="hljs-literal">null</span>) {
      appliedCredentials = <span class="hljs-literal">true</span>
      logCredInformation(credentials)

      <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> ugi = <span class="hljs-type">UserGroupInformation</span>.getCurrentUser();
      ugi.addCredentials(credentials)
      ugi.setAuthenticationMethod(<span class="hljs-type">AuthenticationMethod</span>.<span class="hljs-type">PROXY</span>)
      ugi.addCredentials(credentialsConf.value.value)

    }
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logCredInformation</span></span>[<span class="hljs-type">T</span>](credentials2: <span class="hljs-type">Credentials</span>) {
    logInfo(<span class="hljs-string">"credentials:"</span> + credentials2);
    <span class="hljs-keyword">for</span> (a &lt;- <span class="hljs-number">0</span> until credentials2.getAllSecretKeys.size()) {
      logInfo(<span class="hljs-string">"getAllSecretKeys:"</span> + a + <span class="hljs-string">":"</span> + credentials2.getAllSecretKeys.get(a));
    }
    <span class="hljs-keyword">val</span> it = credentials2.getAllTokens.iterator();
    <span class="hljs-keyword">while</span> (it.hasNext) {
      logInfo(<span class="hljs-string">"getAllTokens:"</span> + it.next());
    }
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bulkMutation</span></span>[<span class="hljs-type">T</span>](rdd: <span class="hljs-type">RDD</span>[<span class="hljs-type">T</span>], fun: (<span class="hljs-type">T</span>) =&gt; (<span class="hljs-type">DataEntity</span>), autoFlush: <span class="hljs-type">Boolean</span>) {
    
    rdd.foreachPartition(
      it =&gt; {
        hbaseForeachPartition[<span class="hljs-type">T</span>](
          broadcastedConf, broadcastMetas,
          it,
          (iter, hConnection, metas) =&gt; {

            iter.foreach(item =&gt; {

              <span class="hljs-keyword">val</span> entity = fun(item)
              <span class="hljs-keyword">val</span> dbName = entity.dbName
              <span class="hljs-keyword">val</span> tabName = entity.tabName
              <span class="hljs-keyword">if</span> (metas.containsKey(dbName) &amp;&amp; metas.get(dbName).containsKey(tabName)) {

                <span class="hljs-keyword">val</span> htable = hConnection.getTable(entity.dbName + <span class="hljs-string">":"</span> + entity.tabName)
                htable.setAutoFlush(autoFlush, <span class="hljs-literal">true</span>)

                entity.`<span class="hljs-class"><span class="hljs-keyword">type</span>` <span class="hljs-title">match</span> </span>{
                  <span class="hljs-keyword">case</span> <span class="hljs-string">"INSERT"</span> | <span class="hljs-string">"insert"</span> =&gt; {
                    <span class="hljs-keyword">val</span> insertPuts = <span class="hljs-type">Instance</span>.insert(entity, metas)
                    <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> != insertPuts &amp;&amp; insertPuts.size() &gt; <span class="hljs-number">0</span>)
                      htable.batch(insertPuts)
                  }

                  <span class="hljs-keyword">case</span> <span class="hljs-string">"UPDATE"</span> | <span class="hljs-string">"update"</span> =&gt; {
                    <span class="hljs-keyword">val</span> updatePuts = <span class="hljs-type">Instance</span>.update(entity, metas)
                    <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> != updatePuts &amp;&amp; updatePuts.size() &gt; <span class="hljs-number">0</span>)
                      htable.batch(updatePuts)
                  }

                  <span class="hljs-keyword">case</span> <span class="hljs-string">"DELETE"</span> | <span class="hljs-string">"delete"</span> =&gt; {
                    <span class="hljs-keyword">val</span> deleteDels = <span class="hljs-type">Instance</span>.delete(entity)
                    <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> != deleteDels &amp;&amp; deleteDels.size() &gt; <span class="hljs-number">0</span>)
                      htable.batch(deleteDels)
                  }
                  
                  <span class="hljs-keyword">case</span> all: <span class="hljs-type">Any</span> =&gt; {
                    logInfo(<span class="hljs-string">"其他操作："</span> + all)
                  }
                }
                
                htable.flushCommits()
                htable.close()
              }
            })
          })
      })
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hbaseRDD</span></span>[<span class="hljs-type">U</span>: <span class="hljs-type">ClassTag</span>](tableName: <span class="hljs-type">String</span>, scan: <span class="hljs-type">Scan</span>, f: ((<span class="hljs-type">ImmutableBytesWritable</span>, <span class="hljs-type">Result</span>)) =&gt; <span class="hljs-type">U</span>): <span class="hljs-type">RDD</span>[<span class="hljs-type">U</span>] = {

    <span class="hljs-keyword">var</span> job: <span class="hljs-type">Job</span> = <span class="hljs-keyword">new</span> <span class="hljs-type">Job</span>(getConf(broadcastedConf))

    <span class="hljs-type">TableMapReduceUtil</span>.initCredentials(job)
    <span class="hljs-type">TableMapReduceUtil</span>.initTableMapperJob(tableName, scan, classOf[<span class="hljs-type">IdentityTableMapper</span>], <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, job)

    sc.newAPIHadoopRDD(
      job.getConfiguration(),
      classOf[<span class="hljs-type">TableInputFormat</span>],
      classOf[<span class="hljs-type">ImmutableBytesWritable</span>],
      classOf[<span class="hljs-type">Result</span>]).map(f)
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hbaseRDD</span></span>(tableName: <span class="hljs-type">String</span>, scans: <span class="hljs-type">Scan</span>): <span class="hljs-type">RDD</span>[(<span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], java.util.<span class="hljs-type">List</span>[(<span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>])])] = {

    hbaseRDD[(<span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], java.util.<span class="hljs-type">List</span>[(<span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>])])](
      tableName,
      scans,
      (r: (<span class="hljs-type">ImmutableBytesWritable</span>, <span class="hljs-type">Result</span>)) =&gt; {
        <span class="hljs-keyword">val</span> it = r._2.list().iterator()
        <span class="hljs-keyword">val</span> list = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayList</span>[(<span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>], <span class="hljs-type">Array</span>[<span class="hljs-type">Byte</span>])]()

        <span class="hljs-keyword">while</span> (it.hasNext()) {
          <span class="hljs-keyword">val</span> kv = it.next()
          list.add((kv.getFamily(), kv.getQualifier(), kv.getValue()))
        }

        (r._1.copyBytes(), list)
      })
  }

  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hbaseForeachPartition</span></span>[<span class="hljs-type">T</span>](
    configBroadcast: <span class="hljs-type">Broadcast</span>[<span class="hljs-type">SerializableWritable</span>[<span class="hljs-type">Configuration</span>]],
    metasBroadcast:  <span class="hljs-type">Broadcast</span>[<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]]],
    it:              <span class="hljs-type">Iterator</span>[<span class="hljs-type">T</span>],
    fun:               (<span class="hljs-type">Iterator</span>[<span class="hljs-type">T</span>], <span class="hljs-type">HConnection</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]]) =&gt; <span class="hljs-type">Unit</span>) = {
    
    <span class="hljs-keyword">val</span> config = getConf(configBroadcast)
    <span class="hljs-keyword">val</span> metas = getMetas(metasBroadcast)
    applyCreds(configBroadcast)
    <span class="hljs-keyword">val</span> hConnection = <span class="hljs-type">HConnectionManager</span>.createConnection(config)
    fun(it, hConnection, metas)
    hConnection.close()

  }

  <span class="hljs-comment">/**</span>
<span class="hljs-comment">   * @desc get METAS from broadcast or driver's configure</span>
<span class="hljs-comment">   */</span>
  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getMetas</span></span>(metasBroadcast: <span class="hljs-type">Broadcast</span>[<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]]]): <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]] = {

    <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> != metasLocal) {
      <span class="hljs-keyword">return</span> metasLocal
    } <span class="hljs-keyword">else</span> {
      <span class="hljs-keyword">try</span> {
        metasLocal = metasBroadcast.value
        metasLocal
      } <span class="hljs-keyword">catch</span> {
        <span class="hljs-keyword">case</span> ex: <span class="hljs-type">Exception</span> =&gt; {
          logInfo(<span class="hljs-string">"Unable to getConfig from broadcast"</span>)
        }
      }
    }
    metasLocal
  }

  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getConf</span></span>(configBroadcast: <span class="hljs-type">Broadcast</span>[<span class="hljs-type">SerializableWritable</span>[<span class="hljs-type">Configuration</span>]]): <span class="hljs-type">Configuration</span> = {

    <span class="hljs-keyword">if</span> (tmpHdfsConfiguration != <span class="hljs-literal">null</span>) {
      tmpHdfsConfiguration
    } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (tmpHdfsConfgFile != <span class="hljs-literal">null</span>) {

      <span class="hljs-keyword">val</span> fs = <span class="hljs-type">FileSystem</span>.newInstance(<span class="hljs-type">SparkHadoopUtil</span>.get.conf)

      <span class="hljs-keyword">val</span> inputStream = fs.open(<span class="hljs-keyword">new</span> <span class="hljs-type">Path</span>(tmpHdfsConfgFile))
      tmpHdfsConfiguration = <span class="hljs-keyword">new</span> <span class="hljs-type">Configuration</span>(<span class="hljs-literal">false</span>)
      tmpHdfsConfiguration.readFields(inputStream)
      inputStream.close()

      tmpHdfsConfiguration
    }

    <span class="hljs-keyword">if</span> (tmpHdfsConfiguration == <span class="hljs-literal">null</span>) {
      <span class="hljs-keyword">try</span> {
        tmpHdfsConfiguration = configBroadcast.value.value
        tmpHdfsConfiguration
      } <span class="hljs-keyword">catch</span> {
        <span class="hljs-keyword">case</span> ex: <span class="hljs-type">Exception</span> =&gt; {
          println(<span class="hljs-string">"Unable to getConfig from broadcast"</span>)
        }
      }
    }

    tmpHdfsConfiguration
  }

  <span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hbaseMapPartition</span></span>[<span class="hljs-type">K</span>, <span class="hljs-type">U</span>](
    configBroadcast: <span class="hljs-type">Broadcast</span>[<span class="hljs-type">SerializableWritable</span>[<span class="hljs-type">Configuration</span>]],
    it:              <span class="hljs-type">Iterator</span>[<span class="hljs-type">K</span>],
    mp:              (<span class="hljs-type">Iterator</span>[<span class="hljs-type">K</span>], <span class="hljs-type">HConnection</span>) =&gt; <span class="hljs-type">Iterator</span>[<span class="hljs-type">U</span>]): <span class="hljs-type">Iterator</span>[<span class="hljs-type">U</span>] = {

    <span class="hljs-keyword">val</span> config = getConf(configBroadcast)
    applyCreds(configBroadcast)
    <span class="hljs-keyword">val</span> hConnection = <span class="hljs-type">HConnectionManager</span>.createConnection(config)
    <span class="hljs-keyword">val</span> res = mp(it, hConnection)
    hConnection.close()
    res

  }

  <span class="hljs-keyword">private</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">GetMapPartition</span>[<span class="hljs-type">T</span>, <span class="hljs-type">U</span>](<span class="hljs-params"></span></span>
<span class="hljs-class"><span class="hljs-params">    tableName:     <span class="hljs-type">String</span>,</span></span>
<span class="hljs-class"><span class="hljs-params">    batchSize:     <span class="hljs-type">Integer</span>,</span></span>
<span class="hljs-class"><span class="hljs-params">    makeGet:       (<span class="hljs-type">T</span></span>) <span class="hljs-title">=&gt;</span> <span class="hljs-title">Get</span>,</span>
<span class="hljs-class">    <span class="hljs-title">convertResult</span></span>: (<span class="hljs-type">Result</span>) =&gt; <span class="hljs-type">U</span>) <span class="hljs-keyword">extends</span> <span class="hljs-type">Serializable</span> {

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span></span>(iterator: <span class="hljs-type">Iterator</span>[<span class="hljs-type">T</span>], hConnection: <span class="hljs-type">HConnection</span>): <span class="hljs-type">Iterator</span>[<span class="hljs-type">U</span>] = {
      <span class="hljs-keyword">val</span> htable = hConnection.getTable(tableName)

      <span class="hljs-keyword">val</span> gets = <span class="hljs-keyword">new</span> <span class="hljs-type">ArrayList</span>[<span class="hljs-type">Get</span>]()
      <span class="hljs-keyword">var</span> res = <span class="hljs-type">List</span>[<span class="hljs-type">U</span>]()

      <span class="hljs-keyword">while</span> (iterator.hasNext) {
        gets.add(makeGet(iterator.next))

        <span class="hljs-keyword">if</span> (gets.size() == batchSize) {
          <span class="hljs-keyword">var</span> results = htable.get(gets)
          res = res ++ results.map(convertResult)
          gets.clear()
        }
      }

      <span class="hljs-keyword">if</span> (gets.size() &gt; <span class="hljs-number">0</span>) {
        <span class="hljs-keyword">val</span> results = htable.get(gets)
        res = res ++ results.map(convertResult)
        gets.clear()
      }

      htable.close()
      res.iterator
    }
  }

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fakeClassTag</span></span>[<span class="hljs-type">T</span>]: <span class="hljs-type">ClassTag</span>[<span class="hljs-type">T</span>] = <span class="hljs-type">ClassTag</span>.<span class="hljs-type">AnyRef</span>.asInstanceOf[<span class="hljs-type">ClassTag</span>[<span class="hljs-type">T</span>]]

}</code></span></span></pre>
<p>  根据我们的需求，重构了HbaseContext的源代码，删除了不必要的程序代码，从源头上保证了程序适用于我们的应用场景。</p>
<h2 id="SparkSteaming代码"><a href="#SparkSteaming代码" class="headerlink" title="SparkSteaming代码"></a>SparkSteaming代码</h2><pre class=" language-hljs scala">   <span class="hljs-comment"><code class="language-hljs scala">   <span class="hljs-comment">/** initialize ZK UTIL */</span>
   <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> zkUtil = <span class="hljs-keyword">new</span> <span class="hljs-type">CuratorUtil</span>()

   <span class="hljs-comment">/** get initialize parameters */</span>
   <span class="hljs-keyword">val</span> offsetPath = <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">ZOOKEEPER_SPARK_PATH</span>)
   zkUtil.createZKNodePer(offsetPath, <span class="hljs-literal">null</span>)

   <span class="hljs-keyword">val</span> topic = <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">KAFKA_TOPIC_NAME</span>)
   <span class="hljs-keyword">val</span> recTime = <span class="hljs-type">Integer</span>.parseInt(<span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">STREAMING_RECTCKE_TIME</span>))
   <span class="hljs-keyword">val</span> <span class="hljs-type">ZK_MYSQL_PATH</span> = <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">ZOOKEEPER_NAMESPACE_MYSQL_TABLES</span>);
   <span class="hljs-keyword">val</span> brokerList = <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">KAFKA_BROKER_LIST</span>);

   <span class="hljs-keyword">val</span> kafkaParams = <span class="hljs-type">Map</span>[<span class="hljs-type">String</span>, <span class="hljs-type">String</span>](
     <span class="hljs-string">"metadata.broker.list"</span> -&gt; brokerList,
     <span class="hljs-string">"zookeeper.connect"</span> -&gt; <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">ZOOKEEPER_SERVER_LIST</span>),
     <span class="hljs-string">"group.id"</span> -&gt; <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">KAFKA_CONSUMER_GROUPID</span>))

   <span class="hljs-comment">/** initialize HBASE METAS for filter */</span>
   <span class="hljs-meta">@transient</span> <span class="hljs-meta">@volatile</span> <span class="hljs-keyword">var</span> metas: java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, java.util.<span class="hljs-type">HashMap</span>[<span class="hljs-type">String</span>, <span class="hljs-type">ColumnInfo</span>]]] = <span class="hljs-type">Instance</span>.paserMetas(zkUtil, <span class="hljs-type">ZK_MYSQL_PATH</span>)
   <span class="hljs-keyword">if</span> (metas.size() &lt; <span class="hljs-number">1</span>) {
     println(<span class="hljs-string">"load hbase tablem metas failed!"</span>)
     <span class="hljs-keyword">return</span> ;
   }

   <span class="hljs-comment">/**  initialize Context */</span>
   <span class="hljs-comment">// configure</span>
   <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> sparkConf = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkConf</span>()
     .set(<span class="hljs-string">"spark.streaming.backpressure.enabled"</span>, <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">STREAMING_BACK_ENABLED</span>)) <span class="hljs-comment">// 设置可以限制</span>
     .set(<span class="hljs-string">"spark.streaming.kafka.maxRatePerPartition"</span>, <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">STREAMING_KAFKA_MAXRATE</span>)) <span class="hljs-comment">// 设置具体限制数量：records/SEC</span>
     .set(<span class="hljs-string">"spark.streaming.stopGracefullyOnShutdown"</span>, <span class="hljs-type">PropertiesUtil</span>.getProperty(<span class="hljs-type">ConstantUtil</span>.<span class="hljs-type">STREAMING_SHUTDOWN_GRACEFULLLY</span>)) <span class="hljs-comment">// 设置Gracefully stop</span>
     .set(<span class="hljs-string">"serializer.class"</span>, <span class="hljs-string">"kafka.serializer.StringEncoder"</span>)
   <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> hbaseConf = <span class="hljs-type">HBaseConfiguration</span>.create();
   hbaseConf.addResource(<span class="hljs-string">"/etc/hbase/conf.cloudera.hbase/hbase-site.xml"</span>)
   hbaseConf.addResource(<span class="hljs-string">"/etc/hbase/conf.cloudera.hbase/core-site.xml"</span>)
   <span class="hljs-meta">@transient</span> <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkContext</span>(sparkConf)
   <span class="hljs-keyword">val</span> ssc = <span class="hljs-keyword">new</span> <span class="hljs-type">StreamingContext</span>(sc, <span class="hljs-type">Seconds</span>(recTime));

   <span class="hljs-keyword">val</span> fromOffsets = readOffsetData(zkUtil, offsetPath, topic, brokerList, <span class="hljs-number">9092</span>)
   <span class="hljs-keyword">val</span> stream = <span class="hljs-type">KafkaUtils</span>.createDirectStream[<span class="hljs-type">String</span>, <span class="hljs-type">String</span>, <span class="hljs-type">StringDecoder</span>, <span class="hljs-type">StringDecoder</span>, (<span class="hljs-type">String</span>, <span class="hljs-type">String</span>)](ssc, kafkaParams, fromOffsets, (mmd: <span class="hljs-type">MessageAndMetadata</span>[<span class="hljs-type">String</span>, <span class="hljs-type">String</span>]) =&gt; (mmd.key(), mmd.message()))

   stream.foreachRDD(rdd =&gt; {

     <span class="hljs-keyword">val</span> offsets = rdd.asInstanceOf[<span class="hljs-type">HasOffsetRanges</span>].offsetRanges.map { offset =&gt; (offset.partition, offset.fromOffset) }
     writeOffsetData(zkUtil, offsetPath, offsets)

     <span class="hljs-keyword">val</span> hbaseContext = <span class="hljs-keyword">new</span> <span class="hljs-type">HBaseContext</span>(sc, hbaseConf, metas)
     hbaseContext.bulkMutation(rdd.map(item =&gt; item._2), (<span class="hljs-type">KV</span>: <span class="hljs-type">String</span>) =&gt; {
       <span class="hljs-type">Instance</span>.parse(<span class="hljs-type">KV</span>)
     }, <span class="hljs-literal">false</span>)

   })

   <span class="hljs-comment">/** add gracefully stop control */</span>
   <span class="hljs-type">Runtime</span>.getRuntime.addShutdownHook(<span class="hljs-keyword">new</span> <span class="hljs-type">Thread</span> {
     <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span></span>(): <span class="hljs-type">Unit</span> = {
       <span class="hljs-keyword">try</span> {
         zkUtil.close()
       } <span class="hljs-keyword">catch</span> {
         <span class="hljs-keyword">case</span> e: <span class="hljs-type">Exception</span> =&gt; {
         }
       }
       ssc.stop(<span class="hljs-literal">true</span>, <span class="hljs-literal">true</span>)
     }
   })

   <span class="hljs-comment">/** spark streaming start and wait termination */</span>
   ssc.start()
   ssc.awaitTermination()

 }

<span class="hljs-comment">/**</span>
<span class="hljs-comment">  * @desc read data from Zookeeper</span>
<span class="hljs-comment">  */</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">readOffsetData</span></span>(zkUtil: <span class="hljs-type">CuratorUtil</span>, offsetPath: <span class="hljs-type">String</span>, topic: <span class="hljs-type">String</span>, brokerList: <span class="hljs-type">String</span>, kafkaPort: <span class="hljs-type">Integer</span>): <span class="hljs-type">Map</span>[<span class="hljs-type">TopicAndPartition</span>, <span class="hljs-type">Long</span>] = {

   <span class="hljs-keyword">val</span> orgData = zkUtil.readDataForPath(offsetPath)
   <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> == orgData) {
     <span class="hljs-keyword">val</span> util = <span class="hljs-type">KafkaUtil</span>.getInstance();
     util.init(brokerList, kafkaPort, topic);
     <span class="hljs-keyword">val</span> offsets = util.getLeastOffsets
     <span class="hljs-keyword">val</span> fromOffsets = <span class="hljs-keyword">for</span> (i &lt;- <span class="hljs-number">0</span> to offsets.size() - <span class="hljs-number">1</span>)
       <span class="hljs-keyword">yield</span> <span class="hljs-type">TopicAndPartition</span>.apply(topic, i) -&gt; offsets.get(i).toLong
     <span class="hljs-keyword">return</span> fromOffsets.toMap
   }

   <span class="hljs-keyword">val</span> data = <span class="hljs-type">JSON</span>.parseFull(orgData).get.asInstanceOf[<span class="hljs-type">Map</span>[<span class="hljs-type">String</span>, <span class="hljs-type">String</span>]]
   <span class="hljs-keyword">val</span> fromOffsets = data.map(item =&gt; {
     <span class="hljs-type">TopicAndPartition</span>.apply(topic, item._1.toInt) -&gt; item._2.toLong
   })
   <span class="hljs-keyword">return</span> fromOffsets

 }

 <span class="hljs-comment">/**</span>
<span class="hljs-comment">  * @desc write offset data to Zookeeper</span>
<span class="hljs-comment">  */</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">writeOffsetData</span></span>(zkUtil: <span class="hljs-type">CuratorUtil</span>, offsetPath: <span class="hljs-type">String</span>, data: <span class="hljs-type">Array</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Long</span>)]): <span class="hljs-type">Unit</span> = {

   <span class="hljs-keyword">val</span> map = data.toMap[<span class="hljs-type">Int</span>, <span class="hljs-type">Long</span>].map(item =&gt; {
     item._1.toString() -&gt; item._2.toString()
   })
   zkUtil.setDataForPath(offsetPath, <span class="hljs-type">JSONObject</span>(map).toString)

 }</code></span></pre>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E8%B0%83%E7%A0%94/">调研</a>
                    
                      <a class="hover-with-bg" href="/tags/Hbase/">Hbase</a>
                    
                      <a class="hover-with-bg" href="/tags/Kafka/">Kafka</a>
                    
                      <a class="hover-with-bg" href="/tags/Spark/">Spark</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2018/06/29/Kafka-SparkStreaming-Hbase%E3%80%90%E4%B8%80%E3%80%91/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kafka-&gt;SparkStreaming-&gt;Hbase【一】</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2018/06/29/Maven%E4%BD%BF%E7%94%A8%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/">
                        <span class="hidden-mobile">Maven使用各种问题汇总</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">×</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script>
<script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script>



<!-- Plugins -->


  
    
  



  <script defer="" src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script>
  







  <script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script>
  



  <script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script>
  



  <script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script>
  



  
  



  <script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script>
  

  






















<script src="/bundle.js"></script><script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  ;

    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Kafka->SparkStreaming->Hbase【二】&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  ;

    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  ;

    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  ;

    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script></body></html>