<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>星空捞月：找寻心中的安宁</title>
  
  <subtitle>日常运维、心中火花、总结排错</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xinshiyou.github.io/"/>
  <updated>2020-06-13T11:20:34.627Z</updated>
  <id>https://xinshiyou.github.io/</id>
  
  <author>
    <name>xinshiyou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>部署CDH6.2组件</title>
    <link href="https://xinshiyou.github.io/2020/06/13/%E9%83%A8%E7%BD%B2CDH6-2%E7%BB%84%E4%BB%B6/"/>
    <id>https://xinshiyou.github.io/2020/06/13/%E9%83%A8%E7%BD%B2CDH6-2%E7%BB%84%E4%BB%B6/</id>
    <published>2020-06-13T10:22:18.000Z</published>
    <updated>2020-06-13T11:20:34.627Z</updated>
    
    <content type="html"><![CDATA[<!-- TOC --><ul><li><a href="#1-下载组件">.1. 下载组件</a></li><li><a href="#2-部署安装">.2. 部署安装</a><ul><li><a href="#21-配置文件----configini--cloudera-scm-agent需要">.2.1. 配置文件 – config.ini : cloudera-scm-agent需要</a></li><li><a href="#22-dbproperties--cloudera-scm-server-需要">.2.2. db.properties : cloudera-scm-server 需要</a></li></ul></li><li><a href="#3-部署编排">.3. 部署编排</a></li><li><a href="#4-其他补充">.4. 其他补充</a><ul><li><a href="#41-创建mysql数据库">.4.1. 创建MySQL数据库</a></li><li><a href="#42-初始化scm数据库">.4.2. 初始化SCM数据库</a></li></ul></li></ul><!-- /TOC --><h2 id="1-下载组件"><a href="#1-下载组件" class="headerlink" title=".1. 下载组件"></a>.1. 下载组件</h2><div class="hljs"><pre class=" language-hljs bash"><span class="hljs-comment"><code class="language-hljs bash"><span class="hljs-comment">## 必须下载</span><span class="hljs-comment">### Cloudera Manager</span>cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpmcloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpmcloudera-manager-server-6.2.0-968826.el7.x86_64.rpmcloudera-manager-server-db-2-6.2.0-968826.el7.x86_64.rpm<span class="hljs-comment">### CDH</span>manifest.jsonCDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcelCDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.shaCDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha256<span class="hljs-comment">## 按需下载</span>oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm<span class="hljs-comment">## 部署MySQL需要</span>mysql57-community-release-el7-7.noarch.rpmmysql-connector-java.jar</code></pre></div><h2 id="2-部署安装"><a href="#2-部署安装" class="headerlink" title=".2. 部署安装"></a>.2. 部署安装</h2><h3 id="2-1-配置文件-–-config-ini-cloudera-scm-agent需要"><a href="#2-1-配置文件-–-config-ini-cloudera-scm-agent需要" class="headerlink" title=".2.1. 配置文件 – config.ini : cloudera-scm-agent需要"></a>.2.1. 配置文件 – config.ini : cloudera-scm-agent需要</h3><div class="hljs"><pre class=" language-hljs XML"><code class="language-hljs XML"># Configuration file for cloudera-scm-agent.# Please note that this file supports multi-line values.  Multi-line# values are indicated by indenting following lines with a space.## If you have whitespace in front of a parameter name, it will be# read as a continuation of the previous parameter value.  Please# be careful not to leave spaces in front of parameter names.## To check if this file has spaces in front of parameters names# you can do a grep like this:#  grep '^[[:blank:]]' /etc/cloudera-scm-agent/config.ini[General]# Hostname of the CM server.server_host=&#123;&#123; groups['CDM'][0] &#125;&#125;# Port that the CM server is listening on.server_port=7182## It should not normally be necessary to modify these.# Port that the CM agent should listen on.# listening_port=9000# IP Address that the CM agent should listen on.# listening_ip=# Hostname that the CM agent reports as its hostname. If unset, will be# obtained in code through something like this:##   python -c 'import socket; \#              print socket.getfqdn(), \#                    socket.gethostbyname(socket.getfqdn())'## listening_hostname=# An alternate hostname to report as the hostname for this host in CM.# Useful when this agent is behind a load balancer or proxy and all# inbound communication must connect through that proxy.# reported_hostname=# Port that supervisord should listen on.# NB: This only takes effect if supervisord is restarted.# supervisord_port=19001# Log file.  The supervisord log file will be placed into# the same directory.  Note that if the agent is being started via the# init.d script, /var/log/cloudera-scm-agent/cloudera-scm-agent.out will# also have a small amount of output (from before logging is initialized).# log_file=/var/log/cloudera-scm-agent/cloudera-scm-agent.log# Persistent state directory.  Directory to store CM agent state that# persists across instances of the agent process and system reboots.# Particularly, the agent's UUID is stored here.# lib_dir=/var/lib/cloudera-scm-agent# Parcel directory.  Unpacked parcels will be stored in this directory.# Downloaded parcels will be stored in <span class="hljs-tag"><<span class="hljs-name">parcel_dir</span>></span>/../parcel-cache# parcel_dir=/opt/cloudera/parcels# Enable supervisord event monitoring.  Used in eager heartbeating, amongst# other things.# enable_supervisord_events=true# Maximum time to wait (in seconds) for all metric collectors to finish# collecting data.max_collection_wait_seconds=10.0# Maximum time to wait (in seconds) when connecting to a local role's# webserver to fetch metrics.metrics_url_timeout_seconds=30.0# Maximum time to wait (in seconds) when connecting to a local TaskTracker# to fetch task attempt data.task_metrics_timeout_seconds=5.0# The list of non-device (nodev) filesystem types which will be monitored.monitored_nodev_filesystem_types=nfs,nfs4,tmpfs# The list of filesystem types which are considered local for monitoring purposes.# These filesystems are combined with the other local filesystem types found in# /proc/filesystemslocal_filesystem_whitelist=ext2,ext3,ext4,xfs# The largest size impala profile log bundle that this agent will serve to the# CM server. If the CM server requests more than this amount, the bundle will# be limited to this size. All instances of this limit being hit are logged to# the agent log.impala_profile_bundle_max_bytes=1073741824# The largest size stacks log bundle that this agent will serve to the CM# server. If the CM server requests more than this amount, the bundle will be# limited to this size. All instances of this limit being hit are logged to the# agent log.stacks_log_bundle_max_bytes=1073741824# The size to which the uncompressed portion of a stacks log can grow before it# is rotated. The log will then be compressed during rotation.stacks_log_max_uncompressed_file_size_bytes=5242880# The orphan process directory staleness threshold. If a diretory is more stale# than this amount of seconds, CM agent will remove it.orphan_process_dir_staleness_threshold=5184000# The orphan process directory refresh interval. The CM agent will check the# staleness of the orphan processes config directory every this amount of# seconds.orphan_process_dir_refresh_interval=3600# A knob to control the agent logging level. The options are listed as follows:# 1) DEBUG (set the agent logging level to 'logging.DEBUG')# 2) INFO (set the agent logging level to 'logging.INFO')scm_debug=INFO# The DNS resolution collecion interval in seconds. A java base test program# will be executed with at most this frequency to collect java DNS resolution# metrics. The test program is only executed if the associated health test,# Host DNS Resolution, is enabled.dns_resolution_collection_interval_seconds=60# The maximum time to wait (in seconds) for the java test program to collect# java DNS resolution metrics.dns_resolution_collection_timeout_seconds=30# The directory location in which the agent-wide kerberos credential cache# will be created.# agent_wide_credential_cache_location=/var/run/cloudera-scm-agent[Security]# Use TLS and certificate validation when connecting to the CM server.use_tls=0# The maximum allowed depth of the certificate chain returned by the peer.# The default value of 9 matches the default specified in openssl's# SSL_CTX_set_verify.max_cert_depth=9# A file of CA certificates in PEM format. The file can contain several CA# certificates identified by## -----BEGIN CERTIFICATE-----# ... (CA certificate in base64 encoding) ...# -----END CERTIFICATE-----## sequences. Before, between, and after the certificates text is allowed which# can be used e.g. for descriptions of the certificates.## The file is loaded once, the first time an HTTPS connection is attempted. A# restart of the agent is required to pick up changes to the file.## Note that if neither verify_cert_file or verify_cert_dir is set, certificate# verification will not be performed.# verify_cert_file=# Directory containing CA certificates in PEM format. The files each contain one# CA certificate. The files are looked up by the CA subject name hash value,# which must hence be available. If more than one CA certificate with the same# name hash value exist, the extension must be different (e.g. 9d66eef0.0,# 9d66eef0.1 etc). The search is performed in the ordering of the extension# number, regardless of other properties of the certificates. Use the c_rehash# utility to create the necessary links.## The certificates in the directory are only looked up when required, e.g. when# building the certificate chain or when actually performing the verification# of a peer certificate. The contents of the directory can thus be changed# without an agent restart.## When looking up CA certificates, the verify_cert_file is first searched, then# those in the directory. Certificate matching is done based on the subject name,# the key identifier (if present), and the serial number as taken from the# certificate to be verified. If these data do not match, the next certificate# will be tried. If a first certificate matching the parameters is found, the# verification process will be performed; no other certificates for the same# parameters will be searched in case of failure.## Note that if neither verify_cert_file or verify_cert_dir is set, certificate# verification will not be performed.# verify_cert_dir=# PEM file containing client private key.# client_key_file=# A command to run which returns the client private key password on stdout# client_keypw_cmd=# If client_keypw_cmd isn't specified, instead a text file containing# the client private key password can be used.# client_keypw_file=# PEM file containing client certificate.# client_cert_file=## Location of Hadoop files.  These are the CDH locations when installed by## packages.  Unused when CDH is installed by parcels.[Hadoop]#cdh_crunch_home=/usr/lib/crunch#cdh_flume_home=/usr/lib/flume-ng#cdh_hadoop_bin=/usr/bin/hadoop#cdh_hadoop_home=/usr/lib/hadoop#cdh_hbase_home=/usr/lib/hbase#cdh_hbase_indexer_home=/usr/lib/hbase-solr#cdh_hcat_home=/usr/lib/hive-hcatalog#cdh_hdfs_home=/usr/lib/hadoop-hdfs#cdh_hive_home=/usr/lib/hive#cdh_httpfs_home=/usr/lib/hadoop-httpfs#cdh_hue_home=/usr/share/hue#cdh_hue_plugins_home=/usr/lib/hadoop#cdh_impala_home=/usr/lib/impala#cdh_kudu_home=/usr/lib/kudu#cdh_llama_home=/usr/lib/llama#cdh_mr1_home=/usr/lib/hadoop-0.20-mapreduce#cdh_mr2_home=/usr/lib/hadoop-mapreduce#cdh_oozie_home=/usr/lib/oozie#cdh_parquet_home=/usr/lib/parquet#cdh_pig_home=/usr/lib/pig#cdh_solr_home=/usr/lib/solr#cdh_spark_home=/usr/lib/spark#cdh_sqoop_home=/usr/lib/sqoop#cdh_sqoop2_home=/usr/lib/sqoop2#cdh_yarn_home=/usr/lib/hadoop-yarn#cdh_zookeeper_home=/usr/lib/zookeeper#hive_default_xml=/etc/hive/conf.dist/hive-default.xml#webhcat_default_xml=/etc/hive-webhcat/conf.dist/webhcat-default.xml#jsvc_home=/usr/libexec/bigtop-utils#tomcat_home=/usr/lib/bigtop-tomcat#oracle_home=/usr/share/oracle/instantclient## Location of Cloudera Management Services files.[Cloudera]#mgmt_home=/usr/share/cmf## Location of JDBC Drivers.[JDBC]#cloudera_mysql_connector_jar=/usr/share/java/mysql-connector-java.jar#cloudera_oracle_connector_jar=/usr/share/java/oracle-connector-java.jar#By default, postgres jar is found dynamically in $MGMT_HOME/lib#cloudera_postgresql_jdbc_jar=[Cgroup_Paths]# This section lists paths that agent will use to figure out resource allocation# If not specified then agent will use the cgroup that agent process is part of## Note: do not add /sys/fs/cgroup in the path. cgroups mounted inside container will# be used to figure out the subsystems.#cpu_cgroup_path=/#cpuacct_cgroup_path=/#blkio_cgroup_path=/#memory_cgroup_path=/</code></pre></div><h3 id="2-2-db-properties-cloudera-scm-server-需要"><a href="#2-2-db-properties-cloudera-scm-server-需要" class="headerlink" title=".2.2. db.properties : cloudera-scm-server 需要"></a>.2.2. db.properties : cloudera-scm-server 需要</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain"># Copyright (c) 2012 Cloudera, Inc. All rights reserved.## This file describes the database connection.## The database type# Currently 'mysql', 'postgresql' and 'oracle' are valid databases.com.cloudera.cmf.db.type&#x3D;mysql# The database host# If a non standard port is needed, use 'hostname:port'com.cloudera.cmf.db.host&#x3D;&#123;&#123; groups['MySQL'][0] &#125;&#125;# The database namecom.cloudera.cmf.db.name&#x3D;&#123;&#123; cmd_db_name &#125;&#125;# The database usercom.cloudera.cmf.db.user&#x3D;&#123;&#123; root_user &#125;&#125;# The database user's passwordcom.cloudera.cmf.db.password&#x3D;&#123;&#123; root_password &#125;&#125;# The db setup type# After fresh install it is set to INIT# and will be changed post config.# If scm-server uses Embedded DB then it is set to EMBEDDED# If scm-server uses External DB then it is set to EXTERNALcom.cloudera.cmf.db.setupType&#x3D;EXTERNAL ## external with mysql</code></pre></div><h2 id="3-部署编排"><a href="#3-部署编排" class="headerlink" title=".3. 部署编排"></a>.3. 部署编排</h2><div class="hljs"><pre class=" language-hljs bash"><code class="language-hljs bash">---- hosts: CDM:Common  tasks:  - name: copy hosts    copy:        src: confs/hosts        dest: /etc/hosts  - name: <span class="hljs-built_in">set</span> hostname    hostname: name=&#123;&#123; inventory_hostname &#125;&#125;  - name: copy oracle-jdk1.8    copy:        src: confs/oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm         dest: /tmp/oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm   - name: install oracle-jdk1.8    shell: rpm -Uvh --replacepkgs  /tmp/oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm   - name: install rpcbind    shell: yum install -y rpcbind    ignore_errors: <span class="hljs-literal">true</span>  - name: <span class="hljs-built_in">set</span> java_home    lineinfile:        path: /etc/profile        line: <span class="hljs-built_in">export</span> JAVA_HOME=/usr/lib/jvm/java        state: absent   - name: install needed packages    shell: yum install cyrus-sasl-gssapi fuse fuse-libs httpd mod_ssl openssl-devel python-psycopg2 MySQL-python -y  - name: configure each-cred    shell: <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"y\ny\n"</span> | ssh-keygen -q -t rsa -f /root/.ssh/id_rsa -C <span class="hljs-string">""</span> -N <span class="hljs-string">""</span>  - name: cat ssh-key auths    shell: cat /root/.ssh/id_rsa.pub    register: id_rsa  - name: touch authorized_keys    shell: |        <span class="hljs-built_in">echo</span> <span class="hljs-string">"ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEArk0cjBbDgdke86pN9962BjcsyxUNhvtW8rkzmykqCPu2QlQxwCg5OikQxmcJUakCkkGhww88U9gx+gPgoJZ9UtClRqHbJKbyqu5XXYFfxjjjRa4N60d5wXXgga2UB6RVIgA+snPxBKi6oFlvH5jV7h3lHxRo3JRQt51/NmcbkyZyUIF7bOJztB9C85jw7dk4dXG52M9bN+FtVlGiVCVKZRWHHoEUVt7y1ZUaao5Ceqw0nAL9JZfQK1zQhrq7YI8pN3ssI35ZKL7EkVKy+qs9GplJFfTBvXO5Q0btFMtM6cY1fMEv9PIt3n0uZF1kGjAHyrAPYnQPcb3H6sDCLQJQ+Q== tp_cloud_hadoop@qiyi.com"</span> > /root/.ssh/authorized_keys        chmod 600 /root/.ssh/authorized_keys  - name: <span class="hljs-built_in">set</span> public-keys to each nodes    lineinfile:        path: /root/.ssh/authorized_keys        line: <span class="hljs-string">"&#123;&#123; hostvars[item].id_rsa.stdout &#125;&#125;"</span>        state: present    with_items:        - <span class="hljs-string">"&#123;&#123; groups['Common'] | union(groups['CDM']) | unique &#125;&#125;"</span>- hosts: CDM  tasks:  - name: make sure mysql-connector exists    shell: mkdir -p /usr/share/java  - name: copy mysql-connector    copy:        src: confs/mysql-connector-java.jar        dest: /usr/share/java/mysql-connector-java.jar  - name: copy files    copy:         src: <span class="hljs-string">"confs/&#123;&#123; item &#125;&#125;"</span>        dest: <span class="hljs-string">"/tmp/&#123;&#123; item &#125;&#125;"</span>    with_items:        - cloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-server-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-server-db-2-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpm  - name: install rpm    shell: rpm -Uvh --replacepkgs /tmp/&#123;&#123; item &#125;&#125;    with_items:        - cloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-server-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-server-db-2-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpm  - name: create target directory    file:        path: /opt/cloudera/parcels        state: directory        owner: cloudera-scm  - name: copy parcells file    copy:        src: <span class="hljs-string">"confs/cdh/&#123;&#123; item &#125;&#125;"</span>        dest: <span class="hljs-string">"/opt/cloudera/parcels/&#123;&#123; item &#125;&#125;"</span>    with_items:        - CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha        - CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha256        - manifest.json        - CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel  - name: copy template files    template:        src: confs/db.properties        dest: /etc/cloudera-scm-server/db.properties- hosts: Common  tasks:  - name: copy files    copy:         src: <span class="hljs-string">"confs/&#123;&#123; item &#125;&#125;"</span>        dest: <span class="hljs-string">"/tmp/&#123;&#123; item &#125;&#125;"</span>    with_items:        - cloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpm  - name: install rpm    shell: rpm -Uvh --replacepkgs /tmp/&#123;&#123; item &#125;&#125;    with_items:        - cloudera-manager-daemons-6.2.0-968826.el7.x86_64.rpm        - cloudera-manager-agent-6.2.0-968826.el7.x86_64.rpm- hosts: CDM:Common  tasks:  - name: configure client conf    template:        src: confs/config.ini        dest: /etc/cloudera-scm-agent/config.ini  - name: configure ntpd service    include: ntpd.yml <span class="hljs-comment">## 公网或公司服务</span></code></pre></div><h2 id="4-其他补充"><a href="#4-其他补充" class="headerlink" title=".4. 其他补充"></a>.4. 其他补充</h2><h3 id="4-1-创建MySQL数据库"><a href="#4-1-创建MySQL数据库" class="headerlink" title=".4.1. 创建MySQL数据库"></a>.4.1. 创建MySQL数据库</h3><div class="hljs"><pre class=" language-hljs bash"><code class="language-hljs bash">CREATE DATABASE mydatabase CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;</code></pre></div><h3 id="4-2-初始化SCM数据库"><a href="#4-2-初始化SCM数据库" class="headerlink" title=".4.2. 初始化SCM数据库"></a>.4.2. 初始化SCM数据库</h3><div class="hljs"><pre class=" language-hljs bash">/opt/cloudera/cm/schema/scm_prepare_database.sh -h[MySQL Host/IP ] -P 3306 -u [Admin User Name] -p[Admin User Password]  mysql scm scm <span class="hljs-string"><code class="language-hljs bash">/opt/cloudera/cm/schema/scm_prepare_database.sh -h[MySQL Host/IP ] -P 3306 -u [Admin User Name] -p[Admin User Password]  mysql scm scm <span class="hljs-string">"Scm@123456"</span>  -f</code></pre></div>]]></content>
    
    <summary type="html">
    
      部署操作步骤固化，方便重复部署，快速搭建测试集群。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="CDH" scheme="https://xinshiyou.github.io/tags/CDH/"/>
    
  </entry>
  
  <entry>
    <title>工具知识总结</title>
    <link href="https://xinshiyou.github.io/2020/06/13/Hadoop%E5%B7%A5%E5%85%B7%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    <id>https://xinshiyou.github.io/2020/06/13/Hadoop%E5%B7%A5%E5%85%B7%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/</id>
    <published>2020-06-13T01:17:15.000Z</published>
    <updated>2020-06-13T02:10:16.323Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HDFS-大数据"><a href="#HDFS-大数据" class="headerlink" title="HDFS(大数据)"></a>HDFS(大数据)</h1><p>&emsp;&emsp;在大数据生态圈中，针对HDFS服务的各种缺陷或适用场景，发展了许许多多的开源解决方案。我们在这里总结一下，方便后期针对应用场景筛选使用。</p><h2 id="NameNode性能测试"><a href="#NameNode性能测试" class="headerlink" title="NameNode性能测试"></a>NameNode性能测试</h2><ol><li><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/SLGUserGuide.html" target="_blank" rel="noopener">Synthetic Load Generator Guide</a>: The synthetic load generator (SLG) is a tool for testing NameNode behavior under different client loads. The user can generate different mixes of read, write, and list requests by specifying the probabilities of read and write. The user controls the intensity of the load by adjusting parameters for the number of worker threads and the delay between operations. While load generators are running, the user can profile and monitor the running of the NameNode. When a load generator exits, it prints some NameNode statistics like the average execution time of each kind of operation and the NameNode throughput.</li><li><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/Benchmarking.html" target="_blank" rel="noopener">Hadoop Benchmarking</a>: NNThroughputBenchmark</li></ol><h2 id="NameNode性能模拟"><a href="#NameNode性能模拟" class="headerlink" title="NameNode性能模拟"></a>NameNode性能模拟</h2><ol><li><a href="https://github.com/linkedin/dynamometer" target="_blank" rel="noopener">Dynamometer</a>: A tool for scale and performance testing of HDFS with a specific focus on the NameNode.</li></ol><h2 id="HDFS文件分析"><a href="#HDFS文件分析" class="headerlink" title="HDFS文件分析"></a>HDFS文件分析</h2><ol><li><a href="https://github.com/paypal/NNAnalytics" target="_blank" rel="noopener">NNAnalytics</a>: NameNodeAnalytics is a self-help utility for scouting and maintaining the namespace of an HDFS instance.</li></ol><h2 id="HDFS冷热管理"><a href="#HDFS冷热管理" class="headerlink" title="HDFS冷热管理"></a>HDFS冷热管理</h2><ol><li><a href="https://github.com/Intel-bigdata/SSM" target="_blank" rel="noopener">SSM</a>: Smart Storage Management for Big Data, a comprehensive hot/cold data optimized solution</li></ol><h1 id="Java通用"><a href="#Java通用" class="headerlink" title="Java通用"></a>Java通用</h1><h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><ol><li>JVM: Jstack：jstack通常用来定位Java进程的异常线程，或异常代码</li><li>CPU: 火焰图: perf 命令。关于火焰图解读，可以参考文献：<a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">如何读懂火焰图？</a></li><li>磁盘问题排查：<img src="%E7%9F%A5%E8%AF%86%E6%A0%88.png" srcset="/img/loading.gif" alt="磁盘问题排查"></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HDFS-大数据&quot;&gt;&lt;a href=&quot;#HDFS-大数据&quot; class=&quot;headerlink&quot; title=&quot;HDFS(大数据)&quot;&gt;&lt;/a&gt;HDFS(大数据)&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;在大数据生态圈中，针对HDFS服务的各种缺陷或适用场景，发展了许
      
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="总结" scheme="https://xinshiyou.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="HDFS" scheme="https://xinshiyou.github.io/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>ETCD集群部署</title>
    <link href="https://xinshiyou.github.io/2020/06/12/ETCD%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://xinshiyou.github.io/2020/06/12/ETCD%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</id>
    <published>2020-06-12T07:13:14.000Z</published>
    <updated>2020-06-12T11:12:04.889Z</updated>
    
    <content type="html"><![CDATA[<!-- TOC --><ul><li><a href="#1-etcd介绍">.1. ETCD介绍</a></li><li><a href="#2-部署etcd集群">.2. 部署ETCD集群</a><ul><li><a href="#21-编译cfssl组件">.2.1. 编译cfssl组件</a></li><li><a href="#22-创建ca证书">.2.2. 创建CA证书</a><ul><li><a href="#221-创建ca证书">.2.2.1. 创建CA证书</a></li><li><a href="#222-创建业务key">.2.2.2. 创建业务Key</a></li></ul></li><li><a href="#23-集群配置部署">.2.3. 集群配置部署</a><ul><li><a href="#231-etcdservicej2">.2.3.1. etcd.service.j2</a></li><li><a href="#232-etcdconfj2">.2.3.2. etcd.conf.j2</a></li><li><a href="#233-分发部署playbook">.2.3.3. 分发部署Playbook</a></li></ul></li></ul></li><li><a href="#3-集群状态检查及基本使用">.3. 集群状态检查及基本使用</a></li></ul><!-- /TOC --><h2 id="1-ETCD介绍"><a href="#1-ETCD介绍" class="headerlink" title=".1. ETCD介绍"></a>.1. ETCD介绍</h2><p>&emsp;&emsp;ETCD是一个K-V分布式数据存储库，为分布式系统提供关键数据的存储服务。主要特点</p><ol><li>简单：设计简单、部署简单，API简单</li><li>安全：可部署为自认证系统</li><li>快速：写入性能测试达到了10k/s</li><li>可靠：基于Raft算法</li></ol><p>&emsp;&emsp;Raft算法的介绍，可以参考：<a href="https://raft.github.io/" target="_blank" rel="noopener">The Raft Consensus Algorithm</a>。Raft的提出，主要是为了解决Paxos算法的如下短板</p><ol><li>晦涩难懂</li><li>落地困难</li></ol><p>因此，Raft设计之初就是为了易与理解而设计。在上述参考文献中，详细介绍了Raft算的机制/原理等内容。</p><h2 id="2-部署ETCD集群"><a href="#2-部署ETCD集群" class="headerlink" title=".2. 部署ETCD集群"></a>.2. 部署ETCD集群</h2><p>&emsp;&emsp;<strong>ETCD</strong>集群的部署，也较为简单。不安全的集群部署，这里不再讨论。这里的部署，主要是指自认证的<strong>ETCD</strong>集群。</p><p>&emsp;&emsp;ETCD集群部署配置，可以参考：<a href="https://www.jianshu.com/p/85803026a9a1" target="_blank" rel="noopener">ETCD集群部署</a>、<a href="https://www.jianshu.com/p/33b5f47ababc" target="_blank" rel="noopener">etcd多台部署:启用https以及ca自签名</a>。参考上述两篇博文的配置、操作步骤，但配置过程中略微存在差异。</p><h3 id="2-1-编译cfssl组件"><a href="#2-1-编译cfssl组件" class="headerlink" title=".2.1. 编译cfssl组件"></a>.2.1. 编译cfssl组件</h3><p>&emsp;&emsp;CFSSL主要是为了实现自认证配置，生成CA证书、公钥、私钥等内容。<br>最新版本cfssl已经不再提供通过官方网站下载，可以直接通过Github下载编译或直接安装</p><div class="hljs"><pre class=" language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"><code class="language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 直接下载某个版本</span></span>wget https://github.com/cloudflare/cfssl/archive/1.3.4.tar.gz<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 下载Master分支，切换为某个tag的代码</span></span>1. Download：https://github.com/cloudflare/cfssl.git2. 安装依赖组件：    go get -u github.com/cloudflare/cfssl/cli \              github.com/go-sql-driver/mysql \              github.com/lib/pq github.com/mattn/go-sqlite3 \              github.com/cloudflare/go-metrics3. 编译安装：make ## 会在bin目录下面创建常用命令<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 切换分支命令：参考</span></span>git checkout tags/v1.0 -b v1.0-branch</code></pre></div><h3 id="2-2-创建CA证书"><a href="#2-2-创建CA证书" class="headerlink" title=".2.2. 创建CA证书"></a>.2.2. 创建CA证书</h3><p>&emsp;&emsp;创建CA证书，主要涉及到两个操作步骤。通过CFSSL来创建证书，一般只需要编辑JSON配置文件即可。</p><h4 id="2-2-1-创建CA证书"><a href="#2-2-1-创建CA证书" class="headerlink" title=".2.2.1. 创建CA证书"></a>.2.2.1. 创建CA证书</h4><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### 创建CA，配置文件如下#### ca-config.json&#123;    <span class="hljs-attr">"signing"</span>: &#123;        <span class="hljs-attr">"default"</span>: &#123;            <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"86400h"</span>        &#125;,        <span class="hljs-attr">"profiles"</span>: &#123;            <span class="hljs-attr">"server"</span>: &#123;                <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"86400h"</span>,                <span class="hljs-attr">"usages"</span>: [                    <span class="hljs-string">"signing"</span>,                    <span class="hljs-string">"key encipherment"</span>,                    <span class="hljs-string">"server auth"</span>,                    <span class="hljs-string">"client auth"</span>                ]            &#125;,            <span class="hljs-attr">"client"</span>: &#123;                <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"86400h"</span>,                <span class="hljs-attr">"usages"</span>: [                    <span class="hljs-string">"signing"</span>,                    <span class="hljs-string">"key encipherment"</span>,                    <span class="hljs-string">"client auth"</span>                ]            &#125;,            <span class="hljs-attr">"peer"</span>: &#123;                <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"86400h"</span>,                <span class="hljs-attr">"usages"</span>: [                    <span class="hljs-string">"signing"</span>,                    <span class="hljs-string">"key encipherment"</span>,                    <span class="hljs-string">"server auth"</span>,                    <span class="hljs-string">"client auth"</span>                ]            &#125;        &#125;    &#125;&#125;#### 创建CA相关文件cfssl gencert -initca ca-csr.json | cfssljson -bare ca</code></pre></div><h4 id="2-2-2-创建业务Key"><a href="#2-2-2-创建业务Key" class="headerlink" title=".2.2.2. 创建业务Key"></a>.2.2.2. 创建业务Key</h4><p>&emsp;&emsp;创建业务需求的公钥\私钥，需要明确业务是那种情况：server(peer)、client，这里配置了两种不同的适应场景。另外一点，需要定义一下业务的配置JSON文件。</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### 配置业务JSON文件：etcd-csr.json&#123;    <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"etcd"</span>,    <span class="hljs-attr">"hosts"</span>: [        <span class="hljs-string">"127.0.0.1"</span>,        <span class="hljs-string">"host1_ip"</span>,        <span class="hljs-string">"host2_ip"</span>,        <span class="hljs-string">"host3_ip"</span>    ],    <span class="hljs-attr">"key"</span>: &#123;        <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,        <span class="hljs-attr">"size"</span>: <span class="hljs-number">2048</span>    &#125;,    <span class="hljs-attr">"names"</span>: [        &#123;            <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>,            <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"Shanghai"</span>,            <span class="hljs-attr">"L"</span>: <span class="hljs-string">"Shanghai"</span>,            <span class="hljs-attr">"O"</span>: <span class="hljs-string">"test.com"</span>,            <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"System"</span>        &#125;    ]&#125;### 创建业务场景的公钥/私钥cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server etcd-csr.json | cfssljson -bare etcd</code></pre></div><p>&emsp;&emsp;至此，CA配置以及业务需要的配置的自认证配置已获取到。</p><h3 id="2-3-集群配置部署"><a href="#2-3-集群配置部署" class="headerlink" title=".2.3. 集群配置部署"></a>.2.3. 集群配置部署</h3><p>&emsp;&emsp;这里配置为service的形式，并使用ansible部署集群：主要涉及到配置文件(etcd.conf)、服务配置(etcd.service)，以及ansible部署脚本。</p><h4 id="2-3-1-etcd-service-j2"><a href="#2-3-1-etcd-service-j2" class="headerlink" title=".2.3.1. etcd.service.j2"></a>.2.3.1. etcd.service.j2</h4><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### 配置路径：/usr/lib/systemd/system/etcd.service&#123;%- set hosts = []  -%&#125;&#123;%- for host in groups['ETCD'] | sort -%&#125; &#123;&#123; hosts.append( hostvars[host]['etcd_name'] + '=https://' + host + ':' + cluster_port|string ) &#125;&#125;&#123;%- endfor -%&#125;[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=-/etc/etcd/etcd.confUser=etcd# set GOMAXPROCS to number of processorsExecStart=/usr/bin/etcd \  --name=$&#123;ETCD_NAME&#125; \  --cert-file=/etc/etcd/ssl/cfssl/ssl/etcd.pem \  --key-file=/etc/etcd/ssl/cfssl/ssl/etcd-key.pem \  --peer-cert-file=/etc/etcd/ssl/cfssl/ssl/etcd.pem \  --peer-key-file=/etc/etcd/ssl/cfssl/ssl/etcd-key.pem \  --trusted-ca-file=/etc/etcd/ssl/cfssl/ssl/ca.pem \  --peer-trusted-ca-file=/etc/etcd/ssl/cfssl/ssl/ca.pem \  --initial-advertise-peer-urls=$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \  --listen-peer-urls=$&#123;ETCD_LISTEN_PEER_URLS&#125; \  --listen-client-urls=$&#123;ETCD_LISTEN_CLIENT_URLS&#125; \  --advertise-client-urls=$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \  --initial-cluster-token=$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \  --initial-cluster=&#123;&#123; hosts | join(',') &#125;&#125;  --initial-cluster-state=new \  --data-dir=$&#123;ETCD_DATA_DIR&#125;Restart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target</code></pre></div><h4 id="2-3-2-etcd-conf-j2"><a href="#2-3-2-etcd-conf-j2" class="headerlink" title=".2.3.2. etcd.conf.j2"></a>.2.3.2. etcd.conf.j2</h4><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">#### 配置文件路径：/etc/etcd/etcd.conf[member]ETCD_NAME=&#123;&#123; etcd_name &#125;&#125;ETCD_DATA_DIR="/var/lib/etcd"ETCD_LISTEN_PEER_URLS="https://&#123;&#123; inventory_hostname &#125;&#125;:&#123;&#123; cluster_port &#125;&#125;"ETCD_LISTEN_CLIENT_URLS="https://&#123;&#123; inventory_hostname &#125;&#125;:&#123;&#123; client_port &#125;&#125;,https://127.0.0.1:&#123;&#123; client_port &#125;&#125;"[cluster]ETCD_INITIAL_ADVERTISE_PEER_URLS="https://&#123;&#123; inventory_hostname &#125;&#125;:&#123;&#123; cluster_port &#125;&#125;"ETCD_INITIAL_CLUSTER_TOKEN="&#123;&#123; cluster_token &#125;&#125;"ETCD_ADVERTISE_CLIENT_URLS="https://&#123;&#123; inventory_hostname &#125;&#125;:&#123;&#123; client_port &#125;&#125;"</code></pre></div><p>编译好的脚本，可以在这里下载：<a href="cfssl.tar.gz">cfssl.tar.gz</a></p><h4 id="2-3-3-分发部署Playbook"><a href="#2-3-3-分发部署Playbook" class="headerlink" title=".2.3.3. 分发部署Playbook"></a>.2.3.3. 分发部署Playbook</h4><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">---- hosts: ETCD  tasks:  - name: install etcd    yum:        name: etcd        state: installed  - name: mkdir target dir    shell: mkdir -p /etc/etcd/ssl  - name: copy ssl files    copy:        src: cfssl.tar.gz        dest: /tmp/cfssl.tar.gz  - name: untar ssl files    shell: tar xvf /tmp/cfssl.tar.gz -C /etc/etcd/ssl  - name: set privileges for ca files    shell: chmod -R 755 /etc/etcd/ssl  - name: copy template configure - conf    template:        src: etcd.service.j2        dest: /usr/lib/systemd/system/etcd.service  - name: copy template configure - service    template:        src: etcd.conf.j2        dest: /etc/etcd/etcd.conf  - name: systemctl reload before start service    shell: systemctl daemon-reload  - name: start etcd service    service:        name: etcd        state: restarted  - name: etcdctl with ssl    template:        src: etcdctls.j2        dest: /usr/bin/etcdctls        mode: "0755"</code></pre></div><h2 id="3-集群状态检查及基本使用"><a href="#3-集群状态检查及基本使用" class="headerlink" title=".3. 集群状态检查及基本使用"></a>.3. 集群状态检查及基本使用</h2><div class="hljs"><pre class=" language-hljs Json"><code class="language-hljs Json">### 健康状态检查: etcdctl 命令行访问etcdctl   \    --ca-file=/etc/etcd/ssl/cfssl/ssl/ca.pem   \    --cert-file=/etc/etcd/ssl/cfssl/ssl/etcd.pem   \    --key-file=/etc/etcd/ssl/cfssl/ssl/etcd-key.pem   \    --endpoint https://127.0.0.1:2379   \    cluster-health#### 输出member c3ca8ce4516450a is healthy: got healthy result from https://host1:2379member 22c833e1835a442d is healthy: got healthy result from https://host2:2379member 3254807a1a7e65ac is healthy: got healthy result from https://host3:2379cluster is healthy### 查看集群成员信息: rest api 访问curl -k --cert /etc/etcd/ssl/cfssl/ssl/etcd.pem  --key /etc/etcd/ssl/cfssl/ssl/etcd-key.pem  https://host1:2379/v2/members#### 输出&#123;    <span class="hljs-attr">"members"</span>: [        &#123;            <span class="hljs-attr">"id"</span>: <span class="hljs-string">"c3ca8ce4516450a"</span>,            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"infra01"</span>,            <span class="hljs-attr">"peerURLs"</span>: [                <span class="hljs-string">"https://host1:2380"</span>            ],            <span class="hljs-attr">"clientURLs"</span>: [                <span class="hljs-string">"https://host1:2379"</span>            ]        &#125;,        &#123;            <span class="hljs-attr">"id"</span>: <span class="hljs-string">"22c833e1835a442d"</span>,            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"infra03"</span>,            <span class="hljs-attr">"peerURLs"</span>: [                <span class="hljs-string">"https://host2:2380"</span>            ],            <span class="hljs-attr">"clientURLs"</span>: [                <span class="hljs-string">"https://host2:2379"</span>            ]        &#125;,        &#123;            <span class="hljs-attr">"id"</span>: <span class="hljs-string">"3254807a1a7e65ac"</span>,            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"infra02"</span>,            <span class="hljs-attr">"peerURLs"</span>: [                <span class="hljs-string">"https://host3:2380"</span>            ],            <span class="hljs-attr">"clientURLs"</span>: [                <span class="hljs-string">"https://host3:2379"</span>            ]        &#125;    ]&#125;</code></pre></div><p>如果新搭建的集群可以正常返回，那么基本可以表明搭建了一个健康、可用的<strong>ETCD</strong>集群。</p>]]></content>
    
    <summary type="html">
    
      准备调研学习一下Minio，以及Kube相关知识。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="云原生" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="ETCD" scheme="https://xinshiyou.github.io/tags/ETCD/"/>
    
  </entry>
  
  <entry>
    <title>Python2日期时间操作</title>
    <link href="https://xinshiyou.github.io/2020/06/08/Python2%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%93%8D%E4%BD%9C/"/>
    <id>https://xinshiyou.github.io/2020/06/08/Python2%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%93%8D%E4%BD%9C/</id>
    <published>2020-06-08T14:39:33.000Z</published>
    <updated>2020-06-08T14:40:54.293Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在日常工作中，经常遇到一下日期时间格式转化。例如时间比较、时间格式化、从字符串转化为日期等操作，本文将日常要的这些操作进行汇总备忘。</p><h2 id="一、时间日期"><a href="#一、时间日期" class="headerlink" title="一、时间日期"></a>一、时间日期</h2><p>想要时间格式比较，需要转化为统一的数据类型，例如转化为统一的Date类型，或Time类型，或DateTime类型。</p><h3 id="1-1-Date操作"><a href="#1-1-Date操作" class="headerlink" title="1.1 Date操作"></a>1.1 Date操作</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">#!&#x2F;bin&#x2F;python# -*- coding: UTF-8 -*-import timeimport datetime## 获取当前的日期today &#x3D; date.today()## 获取当前的时间戳now &#x3D; time.time()## 时间戳日期相互转化date &#x3D; date.fromtimestamp(1585138687)time &#x3D; time.mktime(date.timetuple())## 判断操作生成昨天的日期：yestoday &#x3D; date.today() - datetime.timedelta(1)生成明天的日期：tom &#x3D; date.today() _ datetime.timedelta(1)</code></pre></div><h2 id="二、时间格式化"><a href="#二、时间格式化" class="headerlink" title="二、时间格式化"></a>二、时间格式化</h2><p>工具包有强大的格式化输出功能，例如isoformat、strftime等输出方法。主要总结一下常见的日期格式输出</p><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">#!&#x2F;bin&#x2F;python# -*- coding: UTF-8 -*-from dateutil import parserimport datetimeimport pytz## 普通格式化### 生成时间对象dt &#x3D; datetime.datetime([year],[month],[day])dt &#x3D; datetime.strptime('2020&#x2F;03&#x2F;25',"%Y&#x2F;%m&#x2F;%d")### 格式化输出dt_str &#x3D; dt.strftime("%Y&#x2F;%m&#x2F;%d")dt_stt &#x3D; dt.strftime("%Y-%m-%d")## 带有时间格式化### 生成时间日期对象dt &#x3D; datetime.datetime([year],[month],[day],[hour],[minute],[seconds])dt &#x3D; dattime.datetime.strptime('2020-03-25 10:10:10','%Y-%m-%d %H:%M:%S')### 格式化输出dt_str &#x3D; dt.strftime('%Y-%m-%d %H:%M:%S')dt_str &#x3D; dt..isoformat() ## 2020-03-25T10:10:10## 包含毫秒format_string: %Y-%m-%d %H:%M:%S.%f## 带有时区格式化### 格式化datetime.datetime.now(pytz.timezone('Asia&#x2F;Shanghai')).strftime('%Y-%m-%dT%H:%M:%S.%f%z')### 从字符串转化为datetimedatetime &#x3D; parser.parser('2020-03-25T20:46:24.511426+0800')</code></pre></div><h2 id="三、引文"><a href="#三、引文" class="headerlink" title="三、引文"></a>三、引文</h2><ol><li><a href="https://docs.python.org/2/library/datetime.html" target="_blank" rel="noopener">Basic date and time types</a></li></ol>]]></content>
    
    <summary type="html">
    
      软件操作技巧
    
    </summary>
    
    
      <category term="软件" scheme="https://xinshiyou.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    
      <category term="python" scheme="https://xinshiyou.github.io/tags/python/"/>
    
      <category term="实践" scheme="https://xinshiyou.github.io/tags/%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>Ozone调研</title>
    <link href="https://xinshiyou.github.io/2020/06/07/Ozone%E8%B0%83%E7%A0%94/"/>
    <id>https://xinshiyou.github.io/2020/06/07/Ozone%E8%B0%83%E7%A0%94/</id>
    <published>2020-06-07T07:21:24.000Z</published>
    <updated>2020-06-13T04:02:39.203Z</updated>
    
    <content type="html"><![CDATA[<p>主要研究目标：</p><ol><li>独立Ozone集群部署：特性、功能、安全</li><li>Ozone with HDFS部署：特性、功能、安全</li></ol><!-- TOC --><ul><li><a href="#1-ozone架构">1. Ozone架构</a><ul><li><a href="#11-架构图">1.1. 架构图</a><ul><li><a href="#111-block管理角度">1.1.1. Block管理角度</a></li><li><a href="#112-功能分级角度">1.1.2. 功能分级角度</a></li><li><a href="#113-基本概念">1.1.3. 基本概念</a></li></ul></li><li><a href="#12-亮点特性">1.2. 亮点特性</a><ul><li><a href="#121-安全机制">1.2.1. 安全机制</a></li><li><a href="#122-单独的">1.2.2. 单独的</a></li></ul></li></ul></li><li><a href="#2-部署测试">2. 部署测试</a><ul><li><a href="#21-源码编译">2.1. 源码编译</a><ul><li><a href="#211-下载源码">2.1.1. 下载源码</a></li><li><a href="#212-编译问题">2.1.2. 编译问题</a></li></ul></li><li><a href="#22-部署ozone独立集群">2.2. 部署Ozone独立集群</a></li></ul></li><li><a href="#3-总结">3. 总结</a></li><li><a href="#4-参考文献">4. 参考文献</a></li></ul><!-- /TOC --><p>&emsp;&emsp;当前各种开源的对象存储组件，基本上是对标<strong>Amazon</strong>的<strong>S3</strong>。在特性、功能上面，基本上都支持<strong>S3服务</strong>的访问。毕竟当前<strong>Amazon</strong>的<strong>S3</strong>在对象存储领域，具有广泛的影响力。各类公司在上云时，也会基于<strong>S3</strong>进行基准测试，对比各家云厂商的对象存储服务能力，从而考虑上云的性价比。</p><p>&emsp;&emsp;上云时需要考虑的一个点是本地机房与云商对象存储的一体化访问能力。而<strong>Apache Ozone</strong>具有原生优势</p><ol><li><strong>Hadoop</strong>项目中分离而来：为解决<strong>HDFS</strong>自身缺陷而生</li><li>原生支持<strong>HDFS</strong>协议，以及安全机制(Kerberos+Token)</li><li>支持<strong>S3</strong>协议。大部分对象存储服务都兼容<strong>S3</strong>协议</li><li>原生支持云服务：<strong>Yarn</strong>、<strong>Kubernetes</strong></li><li>可伸缩、可扩展、强一致性</li></ol><p>&emsp;&emsp;当前<strong>Apache Ozone</strong>具有的不足之处，可能有几点</p><ol><li>尚未完全成熟：虽然已从Apache毕业，成为顶级项目，但尚未发型稳定版。当前各种主流的版本，都处理alpha、beta版，且版本号基本上处于0.X版</li><li>存在性能与稳定性瓶颈：当前<strong>Apache Ozone</strong>的已知版本中，在稳定性、性能访问还存在一定的瓶颈。特别是随着Ozone规模增长到一定程度之后，写入方面会存在较为严重的瓶颈。</li></ol><p>&emsp;&emsp;虽然<strong>Apache Ozone</strong>尚未经过大规模集群的验证，但这并不妨碍我们进行调研测试，毕竟未来云原生的对象存储可能会成为趋势。</p><h1 id="1-Ozone架构"><a href="#1-Ozone架构" class="headerlink" title="1. Ozone架构"></a>1. Ozone架构</h1><p>&emsp;&emsp;本小结我们先引入Ozone的架构图，然后分别介绍各个组件的功能，以及Ozone的基本概念。</p><h2 id="1-1-架构图"><a href="#1-1-架构图" class="headerlink" title="1.1. 架构图"></a>1.1. 架构图</h2><p>&emsp;&emsp;这里的架构图主要是引用hadoop-ozone官方文档介绍的结构图，主要有两个：Block管理角度、功能分层角度。</p><h3 id="1-1-1-Block管理角度"><a href="#1-1-1-Block管理角度" class="headerlink" title="1.1.1. Block管理角度"></a>1.1.1. Block管理角度</h3><p><img src="ozoneBlockDiagram.png" srcset="/img/loading.gif" alt="Block管理角度"><br>Block角度主要包括几大组件</p><ol><li>Ozone Manager(OM)：om在hadoop-ozone中具有命名空间管理的职能。</li><li>Storage Container Manager(SCM)：管理物理数据与数据层</li><li>Recon：接口管理</li></ol><p>&emsp;&emsp;在Ozone的Road Map中介绍，当前已经实现了针对SCM的HA架构，后期版本中逐渐实现对OM的HA架构，从而实现整体的HA架构部署。</p><h3 id="1-1-2-功能分级角度"><a href="#1-1-2-功能分级角度" class="headerlink" title="1.1.2. 功能分级角度"></a>1.1.2. 功能分级角度</h3><p><img src="FunctionalOzone.png" srcset="/img/loading.gif" alt="Ozone功能分层角度"><br>从功能上来看，hadoop-ozone主要分为</p><ol><li>Data Layer：数据存储层</li><li>Metadata Layer：元数据管理层</li><li>Repication Lay：数据复制与一致性管理</li><li>Protocol Bus：数据扩展访问</li><li>Recon Server：与Ozone的所有组件通信，提供统一的API</li></ol><h3 id="1-1-3-基本概念"><a href="#1-1-3-基本概念" class="headerlink" title="1.1.3. 基本概念"></a>1.1.3. 基本概念</h3><p>&emsp;&emsp;初识Apache Ozone的架构之后，我们需要了解涉及到的几个关键概念。主要涉及到对象存储相关的基本概念：卷、桶、Key。</p><ol><li>卷：Volume。卷的概念类似账户，只有管理员工可以创建删除</li><li>桶：Bucket。桶的概念类似目录，桶可以包含任意数量的Key，但不能不含其它桶</li><li>Key：Key类似与文件的概念。</li></ol><p>感觉官方文档的概念介绍，基本可以理解为：<img src="ozone_cengji.png" srcset="/img/loading.gif" alt="Hadoop-Ozone层级介绍"><br>其中粗粒度、细粒度可以理解为权限访问。且在对象存储模型中，没有目录的概念只有Key的概念，Key指向的就是具体的存储对象。</p><h2 id="1-2-亮点特性"><a href="#1-2-亮点特性" class="headerlink" title="1.2. 亮点特性"></a>1.2. 亮点特性</h2><h3 id="1-2-1-安全机制"><a href="#1-2-1-安全机制" class="headerlink" title="1.2.1. 安全机制"></a>1.2.1. 安全机制</h3><p>认证体系</p><h3 id="1-2-2-单独的"><a href="#1-2-2-单独的" class="headerlink" title="1.2.2. 单独的"></a>1.2.2. 单独的</h3><h1 id="2-部署测试"><a href="#2-部署测试" class="headerlink" title="2. 部署测试"></a>2. 部署测试</h1><h2 id="2-1-源码编译"><a href="#2-1-源码编译" class="headerlink" title="2.1. 源码编译"></a>2.1. 源码编译</h2><h3 id="2-1-1-下载源码"><a href="#2-1-1-下载源码" class="headerlink" title="2.1.1. 下载源码"></a>2.1.1. 下载源码</h3><h3 id="2-1-2-编译问题"><a href="#2-1-2-编译问题" class="headerlink" title="2.1.2. 编译问题"></a>2.1.2. 编译问题</h3><h2 id="2-2-部署Ozone独立集群"><a href="#2-2-部署Ozone独立集群" class="headerlink" title="2.2. 部署Ozone独立集群"></a>2.2. 部署Ozone独立集群</h2><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><h1 id="4-参考文献"><a href="#4-参考文献" class="headerlink" title="4. 参考文献"></a>4. 参考文献</h1><ol><li><a href="https://cwiki.apache.org/confluence/display/HADOOP/Ozone+Road+Map" target="_blank" rel="noopener">Ozone Road Map</a></li></ol>]]></content>
    
    <summary type="html">
    
      针对私有云与公有云的融合，调研一下当下流行的HDFS扩展组件 -- Ozone。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="云原生" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Ozone" scheme="https://xinshiyou.github.io/tags/Ozone/"/>
    
  </entry>
  
  <entry>
    <title>Minio初探</title>
    <link href="https://xinshiyou.github.io/2020/06/01/Minio%E5%88%9D%E6%8E%A2/"/>
    <id>https://xinshiyou.github.io/2020/06/01/Minio%E5%88%9D%E6%8E%A2/</id>
    <published>2020-06-01T10:00:00.000Z</published>
    <updated>2020-06-12T10:44:51.590Z</updated>
    
    <content type="html"><![CDATA[<!-- TOC --><ul><li><a href="#1-部署调研">1. 部署调研</a><ul><li><a href="#11-环境准备">1.1. 环境准备</a><ul><li><a href="#111-资源下载">1.1.1. 资源下载</a></li><li><a href="#112-添加执行权限">1.1.2. 添加执行权限</a></li></ul></li><li><a href="#12-部署模式">1.2. 部署模式</a><ul><li><a href="#121-单机部署">1.2.1. 单机部署</a><ul><li><a href="#1211-单机单租户">1.2.1.1. 单机单租户</a></li><li><a href="#1212-单机多租户">1.2.1.2. 单机多租户</a></li></ul></li><li><a href="#122-分布式部署">1.2.2. 分布式部署</a></li></ul></li><li><a href="#13-特性调研">1.3. 特性调研</a><ul><li><a href="#131-使用erase-code">1.3.1. 使用Erase Code</a></li><li><a href="#132-压缩compression">1.3.2. 压缩(compression)</a></li><li><a href="#133-缓存cache">1.3.3. 缓存(cache)</a></li></ul></li><li><a href="#14-界面功能">1.4. 界面功能</a></li><li><a href="#15-mc命令行操作">1.5. MC命令行操作</a><ul><li><a href="#151-配置与操作s3">1.5.1. 配置与操作S3</a></li><li><a href="#152-配置与操作minio">1.5.2. 配置与操作Minio</a></li></ul></li><li><a href="#16-压测">1.6. 压测</a><ul><li><a href="#161-压测命令">1.6.1. 压测命令</a></li><li><a href="#162-压测结果">1.6.2. 压测结果</a></li></ul></li></ul></li><li><a href="#2-minio架构">2. Minio架构</a><ul><li><a href="#21-部署">2.1. 部署</a><ul><li><a href="#211-准备配置文件">2.1.1. 准备配置文件</a></li><li><a href="#212-部署集群">2.1.2. 部署集群</a></li></ul></li><li><a href="#22-客户端配置">2.2. 客户端配置</a></li><li><a href="#23-测试">2.3. 测试</a></li></ul></li><li><a href="#3-问题汇总">3. 问题汇总</a></li><li><a href="#4-参考文献">4. 参考文献</a></li></ul><!-- /TOC --><h1 id="1-部署调研"><a href="#1-部署调研" class="headerlink" title="1. 部署调研"></a>1. 部署调研</h1><h2 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1. 环境准备"></a>1.1. 环境准备</h2><p>环境准备，主要是指环境配置、资源包下载/安装部署等内容。</p><h3 id="1-1-1-资源下载"><a href="#1-1-1-资源下载" class="headerlink" title="1.1.1. 资源下载"></a>1.1.1. 资源下载</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### Minio下载：RELEASE.2020-06-01T17-28-03Z  wget https://dl.min.io/server/minio/release/linux-amd64/minio  ### MC下载: RELEASE.2020-05-28T23-43-36Z  wget https://dl.min.io/client/mc/release/linux-amd64/mc</code></pre></div><p><strong>资源下载(更新于2020-06-02)</strong>：<br><a href="minio" target="_blank">Minio(Server)</a>    &emsp; &emsp; <a href="mc" target="_blank">MC(Client)</a></p><h3 id="1-1-2-添加执行权限"><a href="#1-1-2-添加执行权限" class="headerlink" title="1.1.2. 添加执行权限"></a>1.1.2. 添加执行权限</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### 最好存放在统一的位置，比如：/opt/soft/minio/ 等  chmod +x mc  chmod +x minio</code></pre></div><h2 id="1-2-部署模式"><a href="#1-2-部署模式" class="headerlink" title="1.2. 部署模式"></a>1.2. 部署模式</h2><p>这里主要介绍实战部署：参考官方文档，进行部署搭建。</p><h3 id="1-2-1-单机部署"><a href="#1-2-1-单机部署" class="headerlink" title="1.2.1. 单机部署"></a>1.2.1. 单机部署</h3><p>单机部署主要包括两种模式：单机单租户、单机多租户。</p><h4 id="1-2-1-1-单机单租户"><a href="#1-2-1-1-单机单租户" class="headerlink" title="1.2.1.1. 单机单租户"></a>1.2.1.1. 单机单租户</h4><p>单机部署非常简单</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">1. 启动服务：./minio server /data1 /data2 ...  2. 查看服务：http://host1:9000/</code></pre></div><p>主要架构如下所示：<br><img src="one_ten_one_host.png" srcset="/img/loading.gif" alt="单租户非EC模式"></p><h4 id="1-2-1-2-单机多租户"><a href="#1-2-1-2-单机多租户" class="headerlink" title="1.2.1.2. 单机多租户"></a>1.2.1.2. 单机多租户</h4><p>单机多租户，可以配置为多租户多次盘、多租户单磁盘等模式。</p><p><img src="multi_ten_one_host.jpg" srcset="/img/loading.gif" alt="单机多租户"></p><h3 id="1-2-2-分布式部署"><a href="#1-2-2-分布式部署" class="headerlink" title="1.2.2. 分布式部署"></a>1.2.2. 分布式部署</h3><p>分布式部署可以部署为单租户多机、多租户多机等情形，主要架构如下所示<br><img src="multi_ten_multi_host.jpg" srcset="/img/loading.gif" alt="分布式部署"></p><p>部署测试</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## host1 ~ host4 : 配置启动  echo "" > nohup.out  export MINIO_ACCESS_KEY=minioadmin  export MINIO_SECRET_KEY=minioadmin  nohup /root/minio server --address :9002 http://host1/data5 http://host2/data5 http://host3/data5 http://host4/data5   &</code></pre></div><p>使用s3-benchmark压测结果</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 压测命令  ./s3-benchmark -a minioadmin -s minioadmin -b test -t 10 -u http://host1:9002 -l 5 -z "1MB"  ## 压测结果  Parameters: url=http://host1:9002, bucket=test, duration=60, threads=10, loops=5, size=1MBFri, 05 Jun 2020 20:01:13 GMT Loop 1: PUT time 61.6 secs, objects = 213, speed = 3.5MB/sec, 3.5 operations/sec.Fri, 05 Jun 2020 20:02:14 GMT Loop 1: GET time 61.0 secs, objects = 395, speed = 6.5MB/sec, 6.5 operations/sec.Fri, 05 Jun 2020 20:02:15 GMT Loop 1: DELETE time 0.9 secs, 225.1 operations/sec.Fri, 05 Jun 2020 20:03:16 GMT Loop 2: PUT time 61.7 secs, objects = 215, speed = 3.5MB/sec, 3.5 operations/sec.Fri, 05 Jun 2020 20:04:17 GMT Loop 2: GET time 60.8 secs, objects = 346, speed = 5.7MB/sec, 5.7 operations/sec.Fri, 05 Jun 2020 20:04:18 GMT Loop 2: DELETE time 0.8 secs, 277.0 operations/sec.Fri, 05 Jun 2020 20:05:20 GMT Loop 3: PUT time 61.6 secs, objects = 209, speed = 3.4MB/sec, 3.4 operations/sec.Fri, 05 Jun 2020 20:06:21 GMT Loop 3: GET time 60.8 secs, objects = 403, speed = 6.6MB/sec, 6.6 operations/sec.Fri, 05 Jun 2020 20:06:21 GMT Loop 3: DELETE time 0.8 secs, 270.2 operations/sec.Fri, 05 Jun 2020 20:07:24 GMT Loop 4: PUT time 62.6 secs, objects = 214, speed = 3.4MB/sec, 3.4 operations/sec.Fri, 05 Jun 2020 20:08:25 GMT Loop 4: GET time 60.8 secs, objects = 399, speed = 6.6MB/sec, 6.6 operations/sec.Fri, 05 Jun 2020 20:08:25 GMT Loop 4: DELETE time 0.8 secs, 277.8 operations/sec.Fri, 05 Jun 2020 20:09:27 GMT Loop 5: PUT time 61.6 secs, objects = 206, speed = 3.3MB/sec, 3.3 operations/sec.Fri, 05 Jun 2020 20:10:28 GMT Loop 5: GET time 60.9 secs, objects = 395, speed = 6.5MB/sec, 6.5 operations/sec.Fri, 05 Jun 2020 20:10:29 GMT Loop 5: DELETE time 0.8 secs, 260.4 operations/sec.Benchmark completed.</code></pre></div><p><strong>注:</strong><br>如果使用本机多磁盘，意味着开启了Erase Code模式。在测试情境下，开启了EC模式，性能下降明显。</p><h2 id="1-3-特性调研"><a href="#1-3-特性调研" class="headerlink" title="1.3. 特性调研"></a>1.3. 特性调研</h2><p>主要调研了Minio的擦除码、缓存、压缩等特性。以下特性调研，使用<strong>单机单租户单磁盘模式，且磁盘为HDD硬盘</strong>。</p><h3 id="1-3-1-使用Erase-Code"><a href="#1-3-1-使用Erase-Code" class="headerlink" title="1.3.1. 使用Erase Code"></a>1.3.1. 使用Erase Code</h3><p>当前Minio在体验方面还不是非常友好，默认情况下的EC是Data跟parity是1:1分布的。如果需要修改配比，那么需要使用环境变量或使用MC进行设置。</p><p>下面简单调研一下Minio如何配置EC，以及配置EC的效果。主要配置项为</p><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">export MINIO_STORAGE_CLASS_STANDARD&#x3D;EC:3  export MINIO_STORAGE_CLASS_RRS&#x3D;EC:2</code></pre></div><p>通过命令操作单机实例</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 启动之前：随便设置(可以不设置)  export MINIO_STORAGE_CLASS_STANDARD=EC:3  export MINIO_STORAGE_CLASS_RRS=EC:2  ## 通过命令查看配置  mc admin config get myminio storage_class  ## 通过命令设置配置  mc admin config set myminio storage_class "standard=EC:2 rrs="     ## 重启生效  mc admin service restart myminio</code></pre></div><p>在配置了EC之后，查看目录文件夹中的数据，可以看到存在part.[num]块以及元数据描述信息</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">&#123;    <span class="hljs-attr">"version"</span>: <span class="hljs-string">"1.0.1"</span>,    <span class="hljs-attr">"format"</span>: <span class="hljs-string">"xl"</span>,    <span class="hljs-attr">"stat"</span>: &#123;        <span class="hljs-attr">"size"</span>: <span class="hljs-number">1048576</span>,        <span class="hljs-attr">"modTime"</span>: <span class="hljs-string">"2020-06-04T05:49:45.838591001Z"</span>    &#125;,    <span class="hljs-attr">"erasure"</span>: &#123;        <span class="hljs-attr">"algorithm"</span>: <span class="hljs-string">"klauspost/reedsolomon/vandermonde"</span>,        <span class="hljs-attr">"data"</span>: <span class="hljs-number">6</span>,        <span class="hljs-attr">"parity"</span>: <span class="hljs-number">3</span>,        <span class="hljs-attr">"blockSize"</span>: <span class="hljs-number">10485760</span>,        <span class="hljs-attr">"index"</span>: <span class="hljs-number">4</span>,        <span class="hljs-attr">"distribution"</span>: [            <span class="hljs-number">3</span>,            <span class="hljs-number">4</span>,            <span class="hljs-number">5</span>,            <span class="hljs-number">6</span>,            <span class="hljs-number">7</span>,            <span class="hljs-number">8</span>,            <span class="hljs-number">9</span>,            <span class="hljs-number">1</span>,            <span class="hljs-number">2</span>        ],        <span class="hljs-attr">"checksum"</span>: [            &#123;                <span class="hljs-attr">"name"</span>: <span class="hljs-string">"part.1"</span>,                <span class="hljs-attr">"algorithm"</span>: <span class="hljs-string">"highwayhash256S"</span>            &#125;        ]    &#125;,    <span class="hljs-attr">"minio"</span>: &#123;        <span class="hljs-attr">"release"</span>: <span class="hljs-string">"RELEASE.2020-06-01T17-28-03Z"</span>    &#125;,    <span class="hljs-attr">"meta"</span>: &#123;        <span class="hljs-attr">"content-type"</span>: <span class="hljs-string">"application/octet-stream"</span>,        <span class="hljs-attr">"etag"</span>: <span class="hljs-string">"7ede4e128789a6b6d51b834d77e00c92"</span>    &#125;,    <span class="hljs-attr">"parts"</span>: [        &#123;            <span class="hljs-attr">"number"</span>: <span class="hljs-number">1</span>,            <span class="hljs-attr">"size"</span>: <span class="hljs-number">1048576</span>,            <span class="hljs-attr">"actualSize"</span>: <span class="hljs-number">1048576</span>        &#125;    ]&#125;</code></pre></div><p>配置EC为 <strong>Standard(storage_class standard=EC:2 rrs= )</strong> 之后，压测如下</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">Parameters: url=http://host1:9001, bucket=test, duration=60, threads=10, loops=5, size=1MThu, 04 Jun 2020 13:48:12 GMT Loop 1: PUT time 62.5 secs, objects = 159, speed = 2.5MB/sec, 2.5 operations/sec.Thu, 04 Jun 2020 13:49:13 GMT Loop 1: GET time 61.0 secs, objects = 365, speed = 6MB/sec, 6.0 operations/sec.Thu, 04 Jun 2020 13:49:14 GMT Loop 1: DELETE time 0.6 secs, 277.4 operations/sec.Thu, 04 Jun 2020 13:50:15 GMT Loop 2: PUT time 61.5 secs, objects = 182, speed = 3MB/sec, 3.0 operations/sec.Thu, 04 Jun 2020 13:51:16 GMT Loop 2: GET time 60.8 secs, objects = 358, speed = 5.9MB/sec, 5.9 operations/sec.Thu, 04 Jun 2020 13:51:17 GMT Loop 2: DELETE time 0.6 secs, 288.5 operations/sec.Thu, 04 Jun 2020 13:52:19 GMT Loop 3: PUT time 62.2 secs, objects = 177, speed = 2.8MB/sec, 2.8 operations/sec.Thu, 04 Jun 2020 13:53:20 GMT Loop 3: GET time 61.0 secs, objects = 349, speed = 5.7MB/sec, 5.7 operations/sec.Thu, 04 Jun 2020 13:53:20 GMT Loop 3: DELETE time 0.7 secs, 263.1 operations/sec.Thu, 04 Jun 2020 13:54:22 GMT Loop 4: PUT time 61.5 secs, objects = 171, speed = 2.8MB/sec, 2.8 operations/sec.Thu, 04 Jun 2020 13:55:23 GMT Loop 4: GET time 61.1 secs, objects = 356, speed = 5.8MB/sec, 5.8 operations/sec.Thu, 04 Jun 2020 13:55:24 GMT Loop 4: DELETE time 0.6 secs, 302.4 operations/sec.Thu, 04 Jun 2020 13:56:27 GMT Loop 5: PUT time 62.8 secs, objects = 163, speed = 2.6MB/sec, 2.6 operations/sec.Thu, 04 Jun 2020 13:57:28 GMT Loop 5: GET time 61.1 secs, objects = 318, speed = 5.2MB/sec, 5.2 operations/sec.Thu, 04 Jun 2020 13:57:28 GMT Loop 5: DELETE time 0.7 secs, 246.7 operations/sec.</code></pre></div><p>具体EC的说明可以参考：<a href="https://github.com/minio/minio/tree/master/docs/erasure/storage-class" target="_blank" rel="noopener" title="6">MinIO Storage Class Quickstart Guide</a>。</p><h3 id="1-3-2-压缩-compression"><a href="#1-3-2-压缩-compression" class="headerlink" title="1.3.2. 压缩(compression)"></a>1.3.2. 压缩(compression)</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 查看压缩配置mc admin config get myminio compression## 默认压缩是不启用的，启用默认设置mc admin config set myminio compression## 设置压缩格式mc admin config set myminio compression extensions=".pdf" mime_types="application/pdf"</code></pre></div><p>启用压缩之后，可以看到大小不一致</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">"parts": [    &#123;        <span class="hljs-attr">"number"</span>: <span class="hljs-number">1</span>,        <span class="hljs-attr">"size"</span>: <span class="hljs-number">5505321</span>,        <span class="hljs-attr">"actualSize"</span>: <span class="hljs-number">7464298</span>    &#125;]</code></pre></div><p>启用压缩之后的压测结果</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">Parameters: url=http://host1:9001, bucket=test, duration=60, threads=10, loops=5, size=1MThu, 04 Jun 2020 14:21:14 GMT Loop 1: PUT time 62.8 secs, objects = 157, speed = 2.5MB/sec, 2.5 operations/sec.Thu, 04 Jun 2020 14:22:16 GMT Loop 1: GET time 61.2 secs, objects = 334, speed = 5.5MB/sec, 5.5 operations/sec.Thu, 04 Jun 2020 14:22:16 GMT Loop 1: DELETE time 0.6 secs, 281.2 operations/sec.Thu, 04 Jun 2020 14:23:17 GMT Loop 2: PUT time 61.3 secs, objects = 162, speed = 2.6MB/sec, 2.6 operations/sec.Thu, 04 Jun 2020 14:24:19 GMT Loop 2: GET time 61.3 secs, objects = 312, speed = 5.1MB/sec, 5.1 operations/sec.Thu, 04 Jun 2020 14:24:19 GMT Loop 2: DELETE time 0.7 secs, 243.1 operations/sec.Thu, 04 Jun 2020 14:25:21 GMT Loop 3: PUT time 62.0 secs, objects = 180, speed = 2.9MB/sec, 2.9 operations/sec.Thu, 04 Jun 2020 14:26:23 GMT Loop 3: GET time 61.4 secs, objects = 335, speed = 5.5MB/sec, 5.5 operations/sec.Thu, 04 Jun 2020 14:26:24 GMT Loop 3: DELETE time 0.8 secs, 237.2 operations/sec.Thu, 04 Jun 2020 14:27:25 GMT Loop 4: PUT time 61.8 secs, objects = 185, speed = 3MB/sec, 3.0 operations/sec.Thu, 04 Jun 2020 14:28:26 GMT Loop 4: GET time 60.6 secs, objects = 300, speed = 4.9MB/sec, 4.9 operations/sec.Thu, 04 Jun 2020 14:28:27 GMT Loop 4: DELETE time 0.7 secs, 266.4 operations/sec.Thu, 04 Jun 2020 14:29:29 GMT Loop 5: PUT time 61.9 secs, objects = 180, speed = 2.9MB/sec, 2.9 operations/sec.Thu, 04 Jun 2020 14:30:30 GMT Loop 5: GET time 61.4 secs, objects = 275, speed = 4.5MB/sec, 4.5 operations/sec.Thu, 04 Jun 2020 14:30:31 GMT Loop 5: DELETE time 0.6 secs, 297.0 operations/sec.Benchmark completed.</code></pre></div><p>具体Compression的说明可以参考：<a href="https://github.com/minio/minio/tree/master/docs/compression" target="_blank" rel="noopener" title="7">Compression Guide</a>。</p><h3 id="1-3-3-缓存-cache"><a href="#1-3-3-缓存-cache" class="headerlink" title="1.3.3. 缓存(cache)"></a>1.3.3. 缓存(cache)</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 设置缓存mc admin config set myminio cache drives=/data4/cache,/data5/cache,/data6/cache,/data7/cache,/data8/cache## 开启atime### 异常报错Unable to initialize disk caching: Atime support required for disk caching### 问题根因如果需要开启缓存，那么需要磁盘截至启用atime。当前我司为了提升磁盘性能，全面禁止使用atime。主要是挂载磁盘的时候，添加的属性参数。</code></pre></div><p>未单独配置，未进行测试。</p><h2 id="1-4-界面功能"><a href="#1-4-界面功能" class="headerlink" title="1.4. 界面功能"></a>1.4. 界面功能</h2><p>界面可以实现的基本功能：</p><ol><li>创建Bucket：这里的bucket，对应到本地为文件夹的概念</li><li>创建目录：映射到单机本地文件夹的概念：lazy加载。只有目录下面实际存在文件时，才会实际创建</li><li>上传与下载文件：上传文件，直接上传到单机存储目录本地。</li><li>删除目录与删除文件：删除文件，对应到删除本地文件。可以从界面上天删除，也可以直接删除本地文件</li></ol><h2 id="1-5-MC命令行操作"><a href="#1-5-MC命令行操作" class="headerlink" title="1.5. MC命令行操作"></a>1.5. MC命令行操作</h2><h3 id="1-5-1-配置与操作S3"><a href="#1-5-1-配置与操作S3" class="headerlink" title="1.5.1. 配置与操作S3"></a>1.5.1. 配置与操作S3</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 配置：会写入到本地配置文件mc config host add s3_bj s3.[region].amazonaws.com "[access key id]" "[ secret key id]"## 命令行操作(基本操作)mc ls s3_bj/test-bj/tmpmc stat s3_bj/test-bj/tmpmc du s3_bj/test-bj/tmp</code></pre></div><h3 id="1-5-2-配置与操作Minio"><a href="#1-5-2-配置与操作Minio" class="headerlink" title="1.5.2. 配置与操作Minio"></a>1.5.2. 配置与操作Minio</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">## 添加配置mc config host add local_single_minio  http://host1:9001 minioadmin minioadmin</code></pre></div><h2 id="1-6-压测"><a href="#1-6-压测" class="headerlink" title="1.6. 压测"></a>1.6. 压测</h2><h3 id="1-6-1-压测命令"><a href="#1-6-1-压测命令" class="headerlink" title="1.6.1. 压测命令"></a>1.6.1. 压测命令</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json"># 单机单磁盘## 压测命令./s3-benchmark -a minioadmin -s minioadmin -b test -t 10 -u http://host1:9001## 压测结果for threads in 10 20 30 40 50;  for size in "100K" "200K" "300K" "400K" "500K" "1M" "2M" "3M" "4M" "5M" ;    ./s3-benchmark -a minioadmin -s minioadmin -b test -t "$&#123;threads&#125;" -u http://host1:9001 -l 5 -z "$&#123;size&#125;" > logs_$&#123;threads&#125;_$&#123;size&#125;  done;done;</code></pre></div><h3 id="1-6-2-压测结果"><a href="#1-6-2-压测结果" class="headerlink" title="1.6.2. 压测结果"></a>1.6.2. 压测结果</h3><p>(待整理：画图)</p><h1 id="2-Minio架构"><a href="#2-Minio架构" class="headerlink" title="2. Minio架构"></a>2. Minio架构</h1><p>&emsp;&emsp;Minio的架构部署非常简单，主要可以分为两类：简单部署、Federation部署。简单部署如上所示，可以分为单机/多机、单磁盘/多次盘(EC)部署模式。Federation部署，这里主要是指DNS域名自动发现、存储桶存放在不同的Minio集群上面，依赖coredns、etcd等组件。本小结主要介绍与部署测试一下Federation模式的Minio集群。</p><h2 id="2-1-部署"><a href="#2-1-部署" class="headerlink" title="2.1. 部署"></a>2.1. 部署</h2><p>&emsp;&emsp;首先需要准备一下基础条件：搭建安全的ETCD集群。可以参考：<a href="/2020/06/12/ETCD%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/" title="ETCD集群部署">ETCD集群部署</a>。这里我们已经搭建部署了安全的ETCD集群(3个节点)。</p><p>&emsp;&emsp;针对Minio而言的Federation集群，主要是指不同的Bucket可以存放在不同的Minio集群中，使用自动化的CoreDNS或其他方式，自动化调度访问路由。我们仅搭建一个集群，来演示配置使用ETCD管理相关配置。</p><h3 id="2-1-1-准备配置文件"><a href="#2-1-1-准备配置文件" class="headerlink" title="2.1.1. 准备配置文件"></a>2.1.1. 准备配置文件</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### minio.service文件[Unit]Description=Minio serviceDocumentation=https://docs.minio.io/[Service]WorkingDirectory=/usr/local/minio/ExecStart=/usr/local/minio/bin/run.shRestart=on-failureRestartSec=[Install]WantedBy=multi-user.target### run.sh脚本&#123;%- set data_paths = [] -%&#125;&#123;%- set minio_ips = [] -%&#125;&#123;%- for host in groups['MINIO'] -%&#125; &#123;&#123; data_paths.append( 'https://' + host +':' + port|string + '/' + hostvars[host]['paths'] ) &#125;&#125;&#123;%- endfor -%&#125;&#123;%- for host in groups['MINIO'] -%&#125; &#123;&#123; minio_ips.append( hostvars[host]['ansible_host'] ) &#125;&#125;&#123;%- endfor -%&#125;#!/bin/bashexport MINIO_ACCESS_KEY=&#123;&#123; minio_admin_name &#125;&#125;export MINIO_SECRET_KEY=&#123;&#123; minio_admin_pwd &#125;&#125;export MINIO_ETCD_ENDPOINTS=&#123;&#123; etcd_endpoints &#125;&#125;export MINIO_DOMAIN=&#123;&#123; minio_domain &#125;&#125;export MINIO_PUBLIC_IPS=&#123;&#123; minio_ips | sort | join(',') &#125;&#125;/opt/minio/bin/minio server \--certs-dir /usr/local/minio/config/ \--address :&#123;&#123; port &#125;&#125; \&#123;&#123; data_paths | join(' ') &#125;&#125;</code></pre></div><h3 id="2-1-2-部署集群"><a href="#2-1-2-部署集群" class="headerlink" title="2.1.2. 部署集群"></a>2.1.2. 部署集群</h3><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">### ansible主机文件：hosts[all:vars]port=9002minio_admin_name=minioadminminio_admin_pwd=minioadminetcd_endpoints=https://host1_ip:2379,https://host2_ip:2379,https://host2_ip:2379minio_domain=iqiyi.minio.com[MINIO]host1 paths="data&#123;7...12&#125;" ansible_host=host1_iphost2 paths="data&#123;7...12&#125;" ansible_host=host2_iphost3 paths="data&#123;7...12&#125;" ansible_host=host3_iphost4 paths="data&#123;7...12&#125;" ansible_host=host4_ip</code></pre></div><h2 id="2-2-客户端配置"><a href="#2-2-客户端配置" class="headerlink" title="2.2. 客户端配置"></a>2.2. 客户端配置</h2><p>&emsp;&emsp;这里的客户端，主要是指mc工具(minio client)。在客户端侧，主要的配置文件目录如下所示</p><div class="hljs"><pre class=" language-hljs json"><code class="language-hljs json">.mc├── certs│   ├── CAs│   │   └── ca.pem│   ├── private.key│   └── public.crt├── config.json├── config.json.old├── session└── share    ├── downloads.json    └── uploads.json</code></pre></div><ol><li>使用客户端工具扩展配置时，主要是写入到：/config.json配置文件中</li><li>如果存在HTTPS的相关配置，不止需要输入用户名\密码等信息，还要配置认证信息。即：/certs/private.key、/certs/public.crt、/certs/CAs/ca.pem。</li></ol><h2 id="2-3-测试"><a href="#2-3-测试" class="headerlink" title="2.3. 测试"></a>2.3. 测试</h2><p>(这里不再展示)</p><h1 id="3-问题汇总"><a href="#3-问题汇总" class="headerlink" title="3. 问题汇总"></a>3. 问题汇总</h1><ol><li>配置之后，容量不对：界面不显示总的磁盘容量，只显示使用量</li><li>擦除码配置存在缺陷：一个文件只能保存到一台主机，当该主机异常下线时会丢失数据</li></ol><h1 id="4-参考文献"><a href="#4-参考文献" class="headerlink" title="4. 参考文献"></a>4. 参考文献</h1><ol><li><a href="https://github.com/minio/minio" target="_blank" rel="noopener">Github: Minio/minio</a></li><li><a href="https://docs.min.io" target="_blank" rel="noopener">Minio QuickStart</a></li><li><a href="https://github.com/minio/s3-benchmark" target="_blank" rel="noopener">S3-benchmark</a></li><li><a href="https://blog.min.io/s3-benchmark-using-hdd/" target="_blank" rel="noopener">S3 Benchmark: MinIO on HDDs</a></li><li><a href="https://docs.min.io/docs/multi-tenant-minio-deployment-guide.html" target="_blank" rel="noopener">MinIO Multi-Tenant Deployment Guide</a></li><li><a href="https://github.com/minio/minio/tree/master/docs/erasure/storage-class" target="_blank" rel="noopener">MinIO Storage Class Quickstart Guide</a></li><li><a href="https://github.com/minio/minio/tree/master/docs/compression" target="_blank" rel="noopener">Compression Guide</a></li></ol>]]></content>
    
    <summary type="html">
    
      Minio初步学习与探索。包括初步搭建、性能测试，以及Minio基本架构的调研。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="云原生" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Minio" scheme="https://xinshiyou.github.io/tags/Minio/"/>
    
  </entry>
  
  <entry>
    <title>编译CDH-6.beta-hive</title>
    <link href="https://xinshiyou.github.io/2020/06/01/%E7%BC%96%E8%AF%91Hive-CDH6/"/>
    <id>https://xinshiyou.github.io/2020/06/01/%E7%BC%96%E8%AF%91Hive-CDH6/</id>
    <published>2020-06-01T08:53:05.000Z</published>
    <updated>2020-06-03T11:10:21.380Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hbase-handler-llap-server"><a href="#hbase-handler-llap-server" class="headerlink" title="hbase-handler/llap-server"></a>hbase-handler/llap-server</h2><h3 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) on project hive-llap-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.3.1:enforce (enforce-no-snapshots) on project hive-llap-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke (Method.java:498)    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)Caused by: org.apache.maven.plugin.MojoExecutionException: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.    at org.apache.maven.plugins.enforcer.EnforceMojo.execute (EnforceMojo.java:209)    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke (Method.java:498)    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</code></pre></div><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain"><!-- https:&#x2F;&#x2F;mvnrepository.com&#x2F;artifact&#x2F;org.glassfish&#x2F;javax.el --><dependency>    <groupId>org.glassfish<&#x2F;groupId>    <artifactId>javax.el<&#x2F;artifactId>    <version>3.0.0<&#x2F;version><&#x2F;dependency></code></pre></div><h2 id="hive-webhcat"><a href="#hive-webhcat" class="headerlink" title="hive-webhcat"></a>hive-webhcat</h2><h3 id="报错信息-1"><a href="#报错信息-1" class="headerlink" title="报错信息"></a>报错信息</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) on project hive-webhcat: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip file[ERROR] [ERROR] Command line was:"cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs && &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc" @options @packages[ERROR] -> [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.4:javadoc (resourcesdoc.xml) on project hive-webhcat: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip fileCommand line was:"cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs && &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc" @options @packages    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:213)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke (Method.java:498)    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)Caused by: org.apache.maven.plugin.MojoExecutionException: An error has occurred in JavaDocs report generation:Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip fileCommand line was:"cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs && &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc" @options @packages    at org.apache.maven.plugin.javadoc.JavadocReport.execute (JavadocReport.java:238)    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke (Method.java:498)    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)Caused by: org.apache.maven.reporting.MavenReportException: Exit code: 1 - 错误: 读取&#x2F;Users&#x2F;xinshiyou&#x2F;.m2&#x2F;repository&#x2F;javax&#x2F;servlet&#x2F;jsp&#x2F;javax.servlet.jsp-api&#x2F;2.3.1&#x2F;javax.servlet.jsp-api-2.3.1.jar时出错; error in opening zip fileCommand line was:"cd &#x2F;Users&#x2F;xinshiyou&#x2F;git&#x2F;hive_cdh&#x2F;hive&#x2F;hcatalog&#x2F;webhcat&#x2F;svr&#x2F;target&#x2F;site&#x2F;apidocs && &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_151.jdk&#x2F;Contents&#x2F;Home&#x2F;bin&#x2F;javadoc" @options @packages    at org.apache.maven.plugin.javadoc.AbstractJavadocMojo.executeReport (AbstractJavadocMojo.java:1580)    at org.apache.maven.plugin.javadoc.JavadocReport.generate (JavadocReport.java:136)    at org.apache.maven.plugin.javadoc.JavadocReport.execute (JavadocReport.java:224)    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:134)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:208)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:154)    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:146)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:51)    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:309)    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:194)    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:107)    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:955)    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:290)    at org.apache.maven.cli.MavenCli.main (MavenCli.java:194)    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)    at java.lang.reflect.Method.invoke (Method.java:498)    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:415)    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:356)</code></pre></div><h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">## 一删除无法打开的文件，maven重新下载## 二mvn clean install package -DskipTests   -Dmaven.javadoc.skip&#x3D;true  -X -rf :hive-webhcat</code></pre></div>]]></content>
    
    <summary type="html">
    
      编译CDH-6.beta-hive
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="CDH" scheme="https://xinshiyou.github.io/tags/CDH/"/>
    
      <category term="编译" scheme="https://xinshiyou.github.io/tags/%E7%BC%96%E8%AF%91/"/>
    
      <category term="部署" scheme="https://xinshiyou.github.io/tags/%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>《道德经的人生智慧》读书笔记</title>
    <link href="https://xinshiyou.github.io/2020/06/01/%E9%81%93%E5%BE%B7%E7%BB%8F%E7%9A%84%E4%BA%BA%E7%94%9F%E6%99%BA%E6%85%A7/"/>
    <id>https://xinshiyou.github.io/2020/06/01/%E9%81%93%E5%BE%B7%E7%BB%8F%E7%9A%84%E4%BA%BA%E7%94%9F%E6%99%BA%E6%85%A7/</id>
    <published>2020-06-01T03:39:53.272Z</published>
    <updated>2020-06-03T11:10:30.340Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;最近有时间读了一本书：《道德经的智慧》。在干工作忙碌的闲暇之余，有空看看“鸡汤”书，喝喝鸡汤，也是非常不错的。本文取原文中的文段节选。</p><a id="more"></a><h2 id="1-道可道非常道，名可名非常名：道法自然的智慧"><a href="#1-道可道非常道，名可名非常名：道法自然的智慧" class="headerlink" title="1. 道可道非常道，名可名非常名：道法自然的智慧"></a>1. 道可道非常道，名可名非常名：道法自然的智慧</h2><h3 id="1-1-道可道非常道，名可名非常名"><a href="#1-1-道可道非常道，名可名非常名" class="headerlink" title="1.1. 道可道非常道，名可名非常名"></a>1.1. 道可道非常道，名可名非常名</h3><div class="hljs"><pre><code>“道”是无法用言语清晰表达出来的，如果可以，那就不是我们所说的“大道”；“道”的形态和概念如果可以为其定名，那就不可能是“道”永恒的形态与概念。</code></pre></div><p>&emsp;&emsp;“道”可以归纳为三个层次：理之道、物之道和人事之道。</p><h3 id="1-2-人法地，地法天，天法道，道法自然"><a href="#1-2-人法地，地法天，天法道，道法自然" class="headerlink" title="1.2. 人法地，地法天，天法道，道法自然"></a>1.2. 人法地，地法天，天法道，道法自然</h3><div class="hljs"><pre><code>人向天地取法，学习它的朴实厚德，地向天空取法，学习它的高明宽广，天向道取法，学习它的本院创生，道则向自然取法，遵从自然地规律而行事。</code></pre></div><p>&emsp;&emsp;”到法自然”，而这“自然”要怎理解？这里的自然其实就是我们所说的规律。老子认为，万物是按照它自身规律、发展的规律运行的。</p><h3 id="1-3-曲则全，枉则直，注则盈，敝则新，少则的，多则惑"><a href="#1-3-曲则全，枉则直，注则盈，敝则新，少则的，多则惑" class="headerlink" title="1.3. 曲则全，枉则直，注则盈，敝则新，少则的，多则惑"></a>1.3. 曲则全，枉则直，注则盈，敝则新，少则的，多则惑</h3><div class="hljs"><pre><code>遇到强大的外力压迫时，始终保持硬质容易损毁，而选择弯曲才能保全自己，委屈自己后才能再次伸展；低洼的地方反而能够积攒慢慢的水，东西过于陈旧则会被人翻新或更新；想要完成的目标少一点，反而容易完成和收获更多；而追求太多的人最终往往被自己选定的多个目标所迷惑，不清楚自己正正想要的，不清楚真正能够得到的，最终一无所获。</code></pre></div><h3 id="1-4-万物背阴而向阳，充气以为和"><a href="#1-4-万物背阴而向阳，充气以为和" class="headerlink" title="1.4. 万物背阴而向阳，充气以为和"></a>1.4. 万物背阴而向阳，充气以为和</h3><div class="hljs"><pre><code>万物背阴而向阳，阴阳二气相互冲融产生和气</code></pre></div><h3 id="1-5-故令有所属：见素抱朴，少私寡欲，绝学无忧"><a href="#1-5-故令有所属：见素抱朴，少私寡欲，绝学无忧" class="headerlink" title="1.5. 故令有所属：见素抱朴，少私寡欲，绝学无忧"></a>1.5. 故令有所属：见素抱朴，少私寡欲，绝学无忧</h3><div class="hljs"><pre><code>所以，要让人民的思想有所归属：保持纯洁朴实的本性，减少心中不该有的杂念和欲望，摒弃看似聪明的智慧、大度的仁义和浮于表面的文化，这样就能避免心生忧患。</code></pre></div><h3 id="1-6-天地所以能长且久者，以其不自生，故能长生"><a href="#1-6-天地所以能长且久者，以其不自生，故能长生" class="headerlink" title="1.6. 天地所以能长且久者，以其不自生，故能长生"></a>1.6. 天地所以能长且久者，以其不自生，故能长生</h3><div class="hljs"><pre><code>天和地能够长久地存在的原因，在于它们不求自己的生存，所以反而能够获得更长久的生存。</code></pre></div><h3 id="1-7-是以圣人去甚，去奢，去泰"><a href="#1-7-是以圣人去甚，去奢，去泰" class="headerlink" title="1.7. 是以圣人去甚，去奢，去泰"></a>1.7. 是以圣人去甚，去奢，去泰</h3><div class="hljs"><pre><code>因此，圣人要除去哪种极端的、奢侈的、过度的措施和法度。</code></pre></div><h2 id="2-善利万物而不争：上善若水的智慧"><a href="#2-善利万物而不争：上善若水的智慧" class="headerlink" title="2. 善利万物而不争：上善若水的智慧"></a>2. 善利万物而不争：上善若水的智慧</h2><h3 id="2-1-上善若水。水善利万物而不争，处众人之所恶，故几于道"><a href="#2-1-上善若水。水善利万物而不争，处众人之所恶，故几于道" class="headerlink" title="2.1. 上善若水。水善利万物而不争，处众人之所恶，故几于道"></a>2.1. 上善若水。水善利万物而不争，处众人之所恶，故几于道</h3><div class="hljs"><pre><code>最高的品德和修养(亦指拥有最高品德和修养的人)就如同水一样。水善于滋养、利于万物而不予万物相争，身处众人都不愿意居住生活的地方，所以水的这种境界已经很接近于“道”了。</code></pre></div><h3 id="2-2-企者不立，跨着不行"><a href="#2-2-企者不立，跨着不行" class="headerlink" title="2.2. 企者不立，跨着不行"></a>2.2. 企者不立，跨着不行</h3><div class="hljs"><pre><code>想要踮起脚尖站的更高的人，反而会站不稳；不想稳步前进，而想着跳跃式前进的人，反而无法走得又快又远。</code></pre></div><p>&emsp;&emsp;老子的这句话是说：浮躁之心不可有。做事要踏踏实实，一步一个脚印，更要如水般陈静，不疾不徐，这样才能有所成就。在这个充满诱惑的时代，人人渴望成功。所有人都梦想一觉醒来成为世界首富，都认为自己注定会成为人上之人，理应享受香车豪宅。如果说在物质贫乏的时代，阻碍人们走向成功的首要原因是外在条件不允许，桎梏使得人们㞏做梦，那么心在，阻碍人们成长和成功的正是如上种种不切实际的梦想以及由此积累的浮躁心态。</p><h3 id="2-3-上善若水"><a href="#2-3-上善若水" class="headerlink" title="2.3. 上善若水"></a>2.3. 上善若水</h3><div class="hljs"><pre><code>最高的品德和修养就如同水一样。</code></pre></div><h3 id="2-4-天下大事，必作于细"><a href="#2-4-天下大事，必作于细" class="headerlink" title="2.4. 天下大事，必作于细"></a>2.4. 天下大事，必作于细</h3><div class="hljs"><pre><code>天下的大事，必须从细微之处入手。</code></pre></div><p>&emsp;&emsp;老子认为，做事情不能仰头望天，而应脚踏实地。那些真正伟大的人物从来都不蔑视生活中的小时，既是常人认为很卑微很细小的事情，他们也都满怀热情地去做好。这就如同水一般，所过之处，填满每一个细微的缝隙，丝毫不会因为其细微而忽略情诗，人生亦是如此。</p><h3 id="2-5-高下相倾"><a href="#2-5-高下相倾" class="headerlink" title="2.5. 高下相倾"></a>2.5. 高下相倾</h3><div class="hljs"><pre><code>高与低相互依靠而存在。</code></pre></div><h2 id="3-见素抱朴，少私寡欲：修心养性的智慧"><a href="#3-见素抱朴，少私寡欲：修心养性的智慧" class="headerlink" title="3. 见素抱朴，少私寡欲：修心养性的智慧"></a>3. 见素抱朴，少私寡欲：修心养性的智慧</h2><h3 id="3-1-挫其锐，解其纷，和其光，同其尘，是谓“玄同”"><a href="#3-1-挫其锐，解其纷，和其光，同其尘，是谓“玄同”" class="headerlink" title="3.1. 挫其锐，解其纷，和其光，同其尘，是谓“玄同”"></a>3.1. 挫其锐，解其纷，和其光，同其尘，是谓“玄同”</h3><div class="hljs"><pre><code>将自己的锐气完美手链，却又能解开虫虫纷杂；将自己的光芒调和隐藏，又能与俗尘混同，这就是“玄同”。</code></pre></div><p>&emsp;&emsp;认为了生存，必须生活在社会之中。可是，在这复杂的社会中，总有着太多的纷繁俗世，让人常常回想，如果能隐居山林该多好。</p><h3 id="3-2-俗人昭昭，我独昏昏；俗人察察，我独闷闷"><a href="#3-2-俗人昭昭，我独昏昏；俗人察察，我独闷闷" class="headerlink" title="3.2. 俗人昭昭，我独昏昏；俗人察察，我独闷闷"></a>3.2. 俗人昭昭，我独昏昏；俗人察察，我独闷闷</h3><div class="hljs"><pre><code>众人都光辉炫目，唯独我好像迷迷糊糊；众人都获得明明白白，唯独我好像浑浑噩噩。我就想是在这个世界的无边海洋之中四处漂泊，没有找到可以停靠安歇的地方。世人仿佛都很灵巧，有自己的本领，同时又在发挥自己的作用，只有我玉梅笨拙仿佛一无是处。</code></pre></div><p>&emsp;&emsp;胸襟如海，容纳百川，境界高原，仿佛清风徐吹，回荡于山谷中的天籁之音。用出世的心做入世的事，不是每个人都能做到的。</p><h3 id="3-3-报怨以德"><a href="#3-3-报怨以德" class="headerlink" title="3.3. 报怨以德"></a>3.3. 报怨以德</h3><div class="hljs"><pre><code>用德兴去回报怨恨。</code></pre></div><p>&emsp;&emsp;人们常说：“比海洋宽阔的是天空，比天空更宽阔的是人的心灵。”心灵，拥有包纳世间一切事物的容量。唯宽可以容忍，唯厚可以载物。宽容，则是一种心性的修养，不仅是保持身心监控的良方，也是事业成功的重要条件。</p><h3 id="3-4-众人皆有余，而我独若遗"><a href="#3-4-众人皆有余，而我独若遗" class="headerlink" title="3.4. 众人皆有余，而我独若遗"></a>3.4. 众人皆有余，而我独若遗</h3><div class="hljs"><pre><code>众人都为自己预谋打算留下余财，只有我看似毫无智慧经常穷苦潦倒。</code></pre></div><p>&emsp;&emsp;不同的人对于贫穷的看法不同，标准不同，忍受贫穷的能力也不同。对于贫穷，有些人是不得不局于贫困，苦熬贫困，所以觉得贫困是可怕的，这是找艳遇物质生活的贫困。还有一些人是甘居贫困，是借贫困的环境来磨练自己的意志，这是自觉地忍受贫困。不仅注重自己的物质享受，还看中自己的精神修养，这才是积极地忍受贫困。</p><h3 id="3-5-功遂身退，天之道也"><a href="#3-5-功遂身退，天之道也" class="headerlink" title="3.5. 功遂身退，天之道也"></a>3.5. 功遂身退，天之道也</h3><div class="hljs"><pre><code>当自己功成名就的时候，就应该学会和懂得急流勇退的道理，因为这样做才符合天地自然地大道，才能让自己更加长久。</code></pre></div><p>&emsp;&emsp;花开果生，果结花谢，自然之道。</p><h2 id="4-无为而无不为：无为而治的智慧"><a href="#4-无为而无不为：无为而治的智慧" class="headerlink" title="4. 无为而无不为：无为而治的智慧"></a>4. 无为而无不为：无为而治的智慧</h2><h3 id="4-1-万物并作，吾以观复"><a href="#4-1-万物并作，吾以观复" class="headerlink" title="4.1. 万物并作，吾以观复"></a>4.1. 万物并作，吾以观复</h3><div class="hljs"><pre><code>世间万物共同蓬勃生长，我从万物的发展和变化中观察其循环往复的声明和运动规律。</code></pre></div><p>&emsp;&emsp;老子认为，天地万物，都在永远不息的动态循环旋转，在动态生生不息，并无真正的静止。一切人事的作为、思想、言语，都同此理。是非、善恶、祸福、主观与可观，都没有绝对的标准。无论是历史，还是人生，一切事物都是无穷无尽、相生相克的，没有了结之时。</p><p>&emsp;&emsp;既然生命无常，且生生不息，那么，对待生命的态度，就成为千古圣贤时常讨论的一个话题。</p><h3 id="4-2-无为而无不为"><a href="#4-2-无为而无不为" class="headerlink" title="4.2. 无为而无不为"></a>4.2. 无为而无不为</h3><div class="hljs"><pre><code>领悟“道”的道理不要妄为，就能做到无所不为。</code></pre></div><h3 id="4-3-故有之以为利，无之以为用"><a href="#4-3-故有之以为利，无之以为用" class="headerlink" title="4.3. 故有之以为利，无之以为用"></a>4.3. 故有之以为利，无之以为用</h3><div class="hljs"><pre><code>由此可见，如果对实实在在、看得见摸得着的材料进行改造，这样的材料本省提供了作用，而改造材料时出现了许多看不见摸不着的元素，这些元素也在为人们提供者作用。</code></pre></div><h3 id="4-4-我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先"><a href="#4-4-我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先" class="headerlink" title="4.4. 我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先"></a>4.4. 我有三宝，持而保之：一曰慈，二曰俭，三曰不敢为天下先</h3><div class="hljs"><pre><code>我有三种宝物，长久以来一直持有着、守护着、用心保存着。第一种是慈爱，第二种是俭蔷，第三种是不于天下人的前面。</code></pre></div><h3 id="4-5-有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母"><a href="#4-5-有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母" class="headerlink" title="4.5. 有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母"></a>4.5. 有物混成，先天地生。寂兮廖兮，独立而不改，周行而不殆，可以为天地母</h3><div class="hljs"><pre><code>有种东西浑然而成，它在天地形成出现之前就已经存在了。它没有声音也没有具体的形象，它不依靠任何外力而独立长存，周而复始地循环运行从不停息，它甚至可以作为天地万物的母体。</code></pre></div><p>&emsp;&emsp;自古以来，坚持的头号大敌就是诱惑，就是耐不住寂寞。有这么一句话：“我什么都能抵制，除了诱惑。”因为耐不住寂寞和诱惑，我们丧失了志向，偏离了方向，始终登不上成功之船。</p><p>&emsp;&emsp;我们的生命是有限的，但人生却是无限精彩的。只有耐住寂寞，才是更能收获成功的人。</p><h3 id="4-6-为者败之，执者失之。是以圣人无为，故无败；无执，故无失"><a href="#4-6-为者败之，执者失之。是以圣人无为，故无败；无执，故无失" class="headerlink" title="4.6. 为者败之，执者失之。是以圣人无为，故无败；无执，故无失"></a>4.6. 为者败之，执者失之。是以圣人无为，故无败；无执，故无失</h3><div class="hljs"><pre><code>任意妄为的人会招致失败，执着强求的人会使希望落空。因此，圣人无所作为，也就不会招致失败；不曾执着，也就不会希望落空了。</code></pre></div><p>&emsp;&emsp;从某种意义上来讲， 成功学也是一门放弃的哲学。老子告诉我们，对有些事情是没有必要执着的，必须学会选择，学会放弃。</p><p>&emsp;&emsp;在人生中，必要的放弃不是失败，而是智慧；必要的放弃不是削减，而是升华。放弃才是一种非常正确的思维方式。</p><h3 id="4-7-五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此"><a href="#4-7-五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此" class="headerlink" title="4.7. 五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此"></a>4.7. 五色令人目盲，五音令人耳聋，五味令人口爽。驰骋畋略令人心发狂，难得之货令人行妨。是以圣人为腹不为目。故去彼取此</h3><div class="hljs"><pre><code>缤纷的五色让人眼瞎，烦乱的五音让人耳聋，混杂的无味让人口伤，从马驰骋围猎让人内存发狂，金银财宝让人德行败坏。所以，圣人只求温饱，不妨从自己，放弃物欲，只求生存。</code></pre></div><p>&emsp;&emsp;以声色犬马困住你，让你无暇顾及其他，只知道，此间乐，不思蜀，自己却慢慢沦为别人的傀儡。</p><h3 id="4-8-是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居"><a href="#4-8-是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居" class="headerlink" title="4.8. 是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居"></a>4.8. 是以圣人处无为之事，行不言之教；万物作为佛始，生而弗有，为而弗恃，功成而弗居</h3><div class="hljs"><pre><code>正是这样，圣人在处事方面采用“无为而治”的做法，实施无言的教化方针，任凭万物自然生长而不首倡。给万物生命而不因为这一点将其据为己有，养育万物也不因为这一点而自恃能力甚高，帮助万物成就自己也不会居功自傲。</code></pre></div><h2 id="5-大直若屈，大巧若拙：大智若愚的智慧"><a href="#5-大直若屈，大巧若拙：大智若愚的智慧" class="headerlink" title="5. 大直若屈，大巧若拙：大智若愚的智慧"></a>5. 大直若屈，大巧若拙：大智若愚的智慧</h2><h3 id="5-1-绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧-利，盗贼无杈。此三者，以力文，不足"><a href="#5-1-绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧-利，盗贼无杈。此三者，以力文，不足" class="headerlink" title="5.1. 绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧#利，盗贼无杈。此三者，以力文，不足"></a>5.1. 绝圣弃智，民利百倍；绝仁弃义，民复孝慈；绝巧#利，盗贼无杈。此三者，以力文，不足</h3><p>   统治者不能自作聪明，而应丢弃那些智巧，这样人民就可以得到百倍的福利。而统治者抛弃那些虚伪的仁义，人民就能够重新变得孝敬和慈爱。抛弃巧诈和趋利的思想，盗贼也就不会出现了。“圣智”“仁义”“巧利”这三个方面，以它们作为治世的法则是远远不够的，这些并非人民的内心和根本的思想，所以它们不足以拿来治理天下。</p><p>&emsp;&emsp;过于聪明的人，常是别人猜忌的对象，因为任何有所图谋的人，都担心从事情刚开始筹划时便被识破。一旦发现有人独具慧眼，那么为了保全自己的一切，必回遣返白鸡、不择手段地加以掩盖，散布留言，捏造罪名。人须抛弃自己引以为傲的聪明技巧，才能保护好自己，才能从容地生活。</p><h3 id="5-2-自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长"><a href="#5-2-自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长" class="headerlink" title="5.2. 自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长"></a>5.2. 自己者，不明；自是者，不彰；不讨者，无功；自矜者，不长</h3><div class="hljs"><pre><code>常常炫耀自己高明的人，反而让别人无法看到他的高明所在；总是自以为是的人，他的有点反而无法真正地得到彰显；自吹自擂鞠躬自傲的人，反而没有人会承认他的功绩；自我膨胀的人，也难以成为领袖人物。</code></pre></div><p>&emsp;&emsp;道家主张逍遥任性，但是在道家看来，真正的个性与众不同不是一味地炫耀自己，彰显不同，而是一种智慧的人格气质与行为方式，所以一个人学习道家的做人之道，就须知道在这个社会上为人处世，我们必须学会收敛自己，不要不看时机与环境地彰显自己的个性。因为人的优势往往会成为他致命的弱点，学会收敛锋芒才是保护自己的最佳方法。</p><h3 id="5-3-绝圣弃慧，民利百倍"><a href="#5-3-绝圣弃慧，民利百倍" class="headerlink" title="5.3. 绝圣弃慧，民利百倍"></a>5.3. 绝圣弃慧，民利百倍</h3><div class="hljs"><pre><code>统治者不能自作聪明，而应丢弃那些智巧，这样人民就可以得到百倍的福利</code></pre></div><h3 id="5-4-大巧若拙，大辩若讷"><a href="#5-4-大巧若拙，大辩若讷" class="headerlink" title="5.4. 大巧若拙，大辩若讷"></a>5.4. 大巧若拙，大辩若讷</h3><div class="hljs"><pre><code>最精巧的东西反而显得有点笨拙，最善于辩论的人似乎有些不善言辞。</code></pre></div><p>&emsp;&emsp;到家认为做认真正的大智慧便是“无知”。大智若愚的人，从来不会张扬自己拥有多少智识，而是心中空空，外表看上去痴傻呆憨，内里却是绝顶的聪明。</p><p>&emsp;&emsp;刘备深明用人不疑的道理，对手下人推心置腹，对其尽心竭力，看似毫无主见，实则成竹在胸。刘备深明韬光养晦之道，大智若愚，一是骗尽天下英雄。</p><h3 id="5-5-合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下"><a href="#5-5-合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下" class="headerlink" title="5.5. 合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下"></a>5.5. 合抱之木，生于毫末；九层之台，起于累土；千里之行，始于足下</h3><div class="hljs"><pre><code>合抱粗细的大树，是从细小的萌芽生长而来；多层高的楼台，也是从平地的泥土一点点积累而来；行使千里之远的地方，也是从脚下一步一步走出来的。</code></pre></div><p>&emsp;&emsp;成功绝不是一蹴而就的，只有静下心来日积月累地积累蓄力量，才能够“绳锯木断，水滴石穿”。所谓“不积跬步，无以至千里”，一切成功都是通过点点滴滴的积淀最终实现的。</p><p>&emsp;&emsp;成功就是简单的事情重复着去做。每天进步一点点是简单的，之所以有人不成功，不是他做不到，而是他不愿意做哪些简单而重复的事情。因为越简单、越容易的事情，人们也越容易不去做它。</p><h3 id="5-6-夫物芸芸，各归其根"><a href="#5-6-夫物芸芸，各归其根" class="headerlink" title="5.6. 夫物芸芸，各归其根"></a>5.6. 夫物芸芸，各归其根</h3><div class="hljs"><pre><code>万物纷纷芸芸，各自循归其本源。</code></pre></div><p>&emsp;&emsp;我们的态度就是别人的态度，我们以什么样的态度对待人生，人生就反过来以什么样的汇报给我们。所以说生命其实很简单，我们老老实实地做好本分，其实就已经足够。</p><h3 id="5-7-揣而锐之，不可长保"><a href="#5-7-揣而锐之，不可长保" class="headerlink" title="5.7. 揣而锐之，不可长保"></a>5.7. 揣而锐之，不可长保</h3><div class="hljs"><pre><code>如果将铁骑打磨得非常锐利，这种锋利通常难以保存很长时间。</code></pre></div><p>&emsp;&emsp;聪明一表财富，真正聪明的人会正确使用，他们深藏不露，不到火候不会贸然使用。一昧地急与表现自己，时时处处显露精明，不仅无益于成功，还往往招来祸患。</p><p>&emsp;&emsp;很多朋友都认为，刚工作时一定要尽力表现自己的能力，只有这样才能坐稳自己的位置，因此在工作中就处处争强好胜，挑战强者，把自己的能耐表现出来。</p><h2 id="6-知人者智，自知者明：知人自知的智慧"><a href="#6-知人者智，自知者明：知人自知的智慧" class="headerlink" title="6. 知人者智，自知者明：知人自知的智慧"></a>6. 知人者智，自知者明：知人自知的智慧</h2><h3 id="6-1-知人者智，自知者明"><a href="#6-1-知人者智，自知者明" class="headerlink" title="6.1. 知人者智，自知者明"></a>6.1. 知人者智，自知者明</h3><div class="hljs"><pre><code>能够了解他人的人是智慧的，能够了解自己的人是明智的。</code></pre></div><p>&emsp;&emsp;老子说“自知者明”，中国有句经典经验叫做“人贵有自知之明”。在古希腊一座智慧神庙大门上，也写着这样一句箴言———“认识你自己”，古希腊人还把它奉为“神谕”，是最高智慧的象征。</p><p>&emsp;&emsp;所谓“自知之明”，就是自己了解自己，自己能够认识自己。</p><p>&emsp;&emsp;一个人应当正确地判断自己，自觉地为自己的能力、学识、容貌、背景打分，从而得到一个清晰地判断，那些事情自己应该做，那些事情自己做不了，这样才会选择幸福的生活、快乐的职业，才有平和的心态。</p><h3 id="6-2-故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。"><a href="#6-2-故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。" class="headerlink" title="6.2. 故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。"></a>6.2. 故贵以贱为本，高以下为基。是以侯王自称孤、寡、不毂。此非以贱为本邪？非乎？故至誉无誉。是故不欲渌渌如玉，珞珞如石。</h3><div class="hljs"><pre><code>所以，贵以贱作为根本，高一下作为基础。因此，侯王自称“孤、寡人、不毂”。这难道是不是以低贱作为根本？不是吗？所以至高的荣誉是不需要赞誉的。所以，得“道”的人不愿做光彩的美玉，而愿意成为坚硬普通的石头。</code></pre></div><p>&emsp;&emsp;老子在人际关系中讲究“处下”，也就是要自己处在“下方”“下位”“下层”，高要以下为根据，贵以贱为根本。这是一种智慧的定位。老子教导人们一切遵循道而行动，而道就是处下的，所以交往中也要选择“处下”。</p><p>&emsp;&emsp;很多人喜欢搞搞在上的感觉，尤其一些管理者，他们处在管理的位置上，给人的感觉经常是高高在上、颐指气使。</p><h3 id="6-3-豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客"><a href="#6-3-豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客" class="headerlink" title="6.3. 豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客"></a>6.3. 豫兮，若冬涉川；犹兮，若畏四邻；俨兮，其若客</h3><div class="hljs"><pre><code>（善于行使“道”得人）他们总是小心谨慎，仿佛在冬天涉水过河，怕踏破冰层掉进寒水之中；他们总是警觉戒备，仿佛一个国王害怕邻国的军队随时来进攻自己的国家；他们总是恭敬郑重，仿佛要去远方赴一场重要的宴会，作为上宾的客人一样。</code></pre></div><p>&emsp;&emsp;从容应对万事，是大智慧，举手投足之间，早已考虑周祥，运筹违章之中，决胜千里之外，正如苏轼在《念奴娇.赤壁怀古》中所写的“谈笑间樯橹灰飞烟灭”。此外，平时待人接物，洞若观火，毫不含糊，这种修养和态度，便是“豫立不老”的形象。</p><h3 id="6-4-不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱"><a href="#6-4-不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱" class="headerlink" title="6.4. 不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱"></a>6.4. 不尚贤，使民不争；不贵难得之货，使民不为盗；不见不欲，使民心不乱</h3><div class="hljs"><pre><code>不去推崇德行优秀的人才，这样可以使民众不去争名夺利；不要把稀有的珍宝看得异常珍贵，这样可以使民众不会因为想要占有而沦为强盗；不要将能够诱发贪欲的事物展示出来给民众看，这样民众的心思不会被扰乱。</code></pre></div><p>&emsp;&emsp;事实上，原本人心纯真无私、政治光明，随着年龄与阅历的增长，渐渐发现周围的许多人都是心有城府、勾心斗角，便不由自主地随波逐流，放弃了自己的之心道场。世风日下，人心不古，社会上风气不正，人们有失淳朴善良而流于谲诈虚伪，心底不再像古人那么淳朴，让许多老人不由感叹“今不如昔”。</p><p>&emsp;&emsp;古代贤人都推崇三代以上的圣帝明王，以之来阐场上古传统文化君道的精神。</p><h3 id="6-5-不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长"><a href="#6-5-不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长" class="headerlink" title="6.5. 不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长"></a>6.5. 不自见，故明；不自是，故彰；不自伐，故有功；不自矜，故长</h3><div class="hljs"><pre><code>不自我炫耀的人，反而更加容易被人看到；不自以为是的人，反而更容易显得名声显赫；不自吹自擂的人，反而更加功勋卓越；不自高自大自满的人，反而最终能达到更高的层次和地位，并且更加长久。</code></pre></div><p>&emsp;&emsp;人生难得四种病，也就是老子前后所说的四“自”————自见、自是、自伐、自矜。从正面来讲，人需要随时反省，使自己能够看见自己才对，而“不自见，故明”是说，人不可固执于自己主观的成见，如果过于执着，便会“一叶障目，不见泰山”，因此而说“不自间见，故明”。</p><h3 id="6-6-不贵其师，不爱其资，虽智大迷，是谓“要妙”"><a href="#6-6-不贵其师，不爱其资，虽智大迷，是谓“要妙”" class="headerlink" title="6.6. 不贵其师，不爱其资，虽智大迷，是谓“要妙”"></a>6.6. 不贵其师，不爱其资，虽智大迷，是谓“要妙”</h3><div class="hljs"><pre><code>常人如果不重视那些善人，不将其动作自己的老师，也不珍惜那些不善的人，不将其作为自己的借鉴，即使本人非常聪慧，也会便糊涂。这就是精深微妙的道理所在。</code></pre></div><p>&emsp;&emsp;我们常常会夸赞说某人聪明，也会鄙弃某人愚笨，一直以来都有聪明人和愚笨人之分，那么他们的区别是什么呢？是天生的智慧，还是情商，亦或是其他？在老子看来，聪明人和愚钝人的唯一区别是善不善于向他人学习。</p><h3 id="6-7-故或下以取，或下而取"><a href="#6-7-故或下以取，或下而取" class="headerlink" title="6.7. 故或下以取，或下而取"></a>6.7. 故或下以取，或下而取</h3><div class="hljs"><pre><code>所以，有时候谦下能够汇聚众多，有时候谦下能够获得融入。</code></pre></div><p>&emsp;&emsp;老子的这句话本事用来总结大国该用什么样的态度来对待小国的，他认为大国要有谦虚的态度来对待小的国家，这样才能汇聚更多的小国，而是自己壮大。其实人生又何尝不是如此，一个人要有谦虚的态度，虚心求知，只有这样才能让自己不断地进步，不断地强大。</p><p>&emsp;&emsp;一个人如果去求知，就一定要虚心，切记骄傲，否则很容易得了点皮毛自以为是起来，那只能是白费时间，浪费生命。这就是到家所说的虚怀若谷的道理。</p><h2 id="7-以其无私，故能成其私：利人利己的智慧"><a href="#7-以其无私，故能成其私：利人利己的智慧" class="headerlink" title="7. 以其无私，故能成其私：利人利己的智慧"></a>7. 以其无私，故能成其私：利人利己的智慧</h2><h3 id="7-1-知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴"><a href="#7-1-知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴" class="headerlink" title="7.1. 知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴"></a>7.1. 知其雄，守其雌，为天溪。为天下溪，常德不离，复归于婴儿。知其白，守其黑，为天下式。为天下式，常德不忒，复归于无极。知其荣，守其辱，为天下谷。为天下谷，常德乃足，复归于朴</h3><div class="hljs"><pre><code>了解强盛的道理，却能安然处于柔弱的位置，昨天下的溪谷容纳万物；做天下的溪谷，自身就能具备常理与正德，归回婴儿般纯洁的状态。懂得清明的德行，却能安然处于幽暗的地方，昨天下的榜样，如此就能长久保持美德而没有过失，回归宇宙最原始之处的状态。深知荣耀的道理，却能安然处于卑屈的地位，做天下的深谷；做天下的深谷，就能将常理与德行修葺完全，返璞归真。</code></pre></div><p>&emsp;&emsp;我们从婴儿长大成人后，历经了许多事情，遭受了众多打击，也感受了无数乐趣，在社会这个大染膏中摸爬滚打几十年，成就而各种各种的心态和思想，表现得多知多懂，经验丰富了，物质富足了。可以审多人揣着钱却患得患失，常常感慨“长大了一点都不好，烦恼多了”，其实，这主要是他们离婴儿哪种至柔至顺的样子太远了，失去了自己的初心，拥有的是一颗机心。<br>&emsp;&emsp;很多人都自认为聪明，可以骗了天下人，其实，人的智慧相差无几，一个人的那点小小的伎俩怎么可能瞒得了其他人呢？</p><p>&emsp;&emsp;所以说，做认要学习道家，保持一颗初心就是保留一个真实的自我，保留一种真实的态度。视初心为生命中的至宝，怀着一颗初心生活，应该是人生追求的最高境界。</p><h3 id="7-2-夫轻诺必寡信"><a href="#7-2-夫轻诺必寡信" class="headerlink" title="7.2. 夫轻诺必寡信"></a>7.2. 夫轻诺必寡信</h3><div class="hljs"><pre><code>轻易承诺必然很少能够守信。</code></pre></div><p>&emsp;&emsp;中华民族是一个礼仪之邦，热情、助人为乐是中华民族的优秀文化传统之一，自古以来，中国人就十分重视人与人之间的情谊。一个篱笆三个桩，一个好汉三个帮。</p><p>&emsp;&emsp;可是老子的大智慧，在于对人性有深刻的洞察，所以他一针见血地指出，轻易许诺的人必定信用不足。老子所说这句话的目的一方面是告诫我们不要上花言巧语之人的当，另一方面让我们不要轻易许诺，不做言而无信之徒。</p><h3 id="7-3-善者，吾善之；不善者，吾亦善之，德善"><a href="#7-3-善者，吾善之；不善者，吾亦善之，德善" class="headerlink" title="7.3. 善者，吾善之；不善者，吾亦善之，德善"></a>7.3. 善者，吾善之；不善者，吾亦善之，德善</h3><div class="hljs"><pre><code>对于善良的人，我会善待他；对不不善良的人，我同样会善待他，如果用来彼此也就都得到了真正的善良之心。</code></pre></div><p>&emsp;&emsp;宽容是一种美德。宽容是壁立千仞的泰山，是容纳百川的江河湖海。深邃的天空容忍了雷电风暴一时的肆虐，才有风和日丽；辽阔的大海容纳了惊涛骇浪一时的猖獗，才有浩渺无垠；苍莽的森林忍耐了弱肉强食的规律，才有郁郁葱葱。</p><p>&emsp;&emsp;与爱人交往，宽容是争吵后的主动修好，是对于爱人性格缺陷的循循善诱，而不是猜测、嫉妒、中伤甚至大动干戈。</p><p>&emsp;&emsp;与朋友交往，宽容是鲍叔牙多分给管仲的黄金。他不计较管仲的自私，也能理解管仲的贪生怕死，还想齐桓公推荐管仲做自己的上司。</p><p>&emsp;&emsp;最后还需要提示一点，宽容，并非说让你对错误不闻不问，而是说，你要学会宽容的方法，这样既不会让犯了错误的人觉得尴尬、羞愧，同时又可以达到教育的目的。</p><h3 id="7-4-以其无私，故能成其私"><a href="#7-4-以其无私，故能成其私" class="headerlink" title="7.4. 以其无私，故能成其私"></a>7.4. 以其无私，故能成其私</h3><div class="hljs"><pre><code>正是因为不求自己的私信，反而能够成就自己的私心。</code></pre></div><p>&emsp;&emsp;现代社会争名夺利之事常见，人与人之间的竞争很激烈，利益冲突是常态。如何在竞争中取胜呢？老子告诉你要“不争”“无私”之类的话。可能对于这些话急功近利的你肯定听不下去，稍安勿躁。</p><h3 id="7-5-同于道者，道亦乐得之"><a href="#7-5-同于道者，道亦乐得之" class="headerlink" title="7.5. 同于道者，道亦乐得之"></a>7.5. 同于道者，道亦乐得之</h3><div class="hljs"><pre><code>与大道和唯一的人，大道也同样愿意帮助其成功。</code></pre></div><p>&emsp;&emsp;无论你做什么事，都不要做表明功夫，坚持自己的理想，不要被外在的事物所影响。因为，真正为道德做学问的人，要“富贵不能淫，贫贱不能移，威武不能屈”，节操不移，才能出世入世，志在礼他。</p><h3 id="7-6-含德之厚，比于赤子"><a href="#7-6-含德之厚，比于赤子" class="headerlink" title="7.6. 含德之厚，比于赤子"></a>7.6. 含德之厚，比于赤子</h3><div class="hljs"><pre><code>道德涵养浑厚得人，就好比出生的婴孩。</code></pre></div><h3 id="7-7-善为士者，不武；善战者，不怒"><a href="#7-7-善为士者，不武；善战者，不怒" class="headerlink" title="7.7. 善为士者，不武；善战者，不怒"></a>7.7. 善为士者，不武；善战者，不怒</h3><div class="hljs"><pre><code>善于当统帅的人，不会轻易使用自己的武力；善于作战的人，不会随便逞强恼怒。</code></pre></div><h3 id="7-8-故不得而亲，可不得而疏；不可得而利，不可得而害"><a href="#7-8-故不得而亲，可不得而疏；不可得而利，不可得而害" class="headerlink" title="7.8. 故不得而亲，可不得而疏；不可得而利，不可得而害"></a>7.8. 故不得而亲，可不得而疏；不可得而利，不可得而害</h3><div class="hljs"><pre><code>因此，既不能因为了解他而投其所好与之亲近，也不能因为了解对方而故意和他书院；不能因为了解而利用对方，也不能因为了解而伤害对方</code></pre></div><p>&emsp;&emsp;老子的这句话告诉了我们，朋友之间要注重感情的真挚和心灵的纯净，而不可注重表面上的亲近和喧嚣，也就是我们通常所说的“君子之交谈入水”。</p><h2 id="8-祸莫大于不知足，咎莫大于欲得：知足常乐的智慧"><a href="#8-祸莫大于不知足，咎莫大于欲得：知足常乐的智慧" class="headerlink" title="8. 祸莫大于不知足，咎莫大于欲得：知足常乐的智慧"></a>8. 祸莫大于不知足，咎莫大于欲得：知足常乐的智慧</h2><h2 id="9-祸兮福之所倚，福兮祸之所伏：福祸相依的智慧"><a href="#9-祸兮福之所倚，福兮祸之所伏：福祸相依的智慧" class="headerlink" title="9. 祸兮福之所倚，福兮祸之所伏：福祸相依的智慧"></a>9. 祸兮福之所倚，福兮祸之所伏：福祸相依的智慧</h2><h2 id="1-死者天地之理，物质自然：出生入死的智慧"><a href="#1-死者天地之理，物质自然：出生入死的智慧" class="headerlink" title="1 死者天地之理，物质自然：出生入死的智慧"></a>1 死者天地之理，物质自然：出生入死的智慧</h2>]]></content>
    
    <summary type="html">
    
      《道德经的人生智慧》读书摘录
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="闲趣" scheme="https://xinshiyou.github.io/tags/%E9%97%B2%E8%B6%A3/"/>
    
  </entry>
  
  <entry>
    <title>Canal上手指南：mysql到kafka</title>
    <link href="https://xinshiyou.github.io/2018/11/22/canal_start/"/>
    <id>https://xinshiyou.github.io/2018/11/22/canal_start/</id>
    <published>2018-11-22T02:10:10.000Z</published>
    <updated>2020-06-01T04:15:01.883Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><h3 id="1-1-MySQL账号"><a href="#1-1-MySQL账号" class="headerlink" title="1.1. MySQL账号"></a>1.1. MySQL账号</h3><p>根据Canal官方说明，需要申请一个MySQL数据库的账号，该账号具有如下权限</p><div class="hljs"><pre class=" language-hljs shell"><code class="language-hljs shell">CREATE USER canal IDENTIFIED BY 'canal';  -- 至少具有如下权限GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ; -- 需要具有SHOW VIEW 权限FLUSH PRIVILEGES;</code></pre></div><p>并保证目标主机与MySQL数据库之间<strong>3306</strong>端口的连通性。</p><a id="more"></a><h3 id="1-2-安装Java"><a href="#1-2-安装Java" class="headerlink" title="1.2. 安装Java"></a>1.2. 安装Java</h3><p>由于是一个Java程序，因此需要在目标机上事先安装JDK。</p><h3 id="1-3-Kafka"><a href="#1-3-Kafka" class="headerlink" title="1.3. Kafka"></a>1.3. Kafka</h3><p>本项目目的是将Binlog数据发往Kafka，因此需要一个Kafka集群或单机节点，并保证<strong>9092</strong>端口的连通性。</p><h3 id="1-4-Zookeeper"><a href="#1-4-Zookeeper" class="headerlink" title="1.4. Zookeeper"></a>1.4. Zookeeper</h3><p>如果启用高可用，或将元数据保存在Zookeeper上，那么需要保证目标主机与ZK集群之间<strong>2181</strong>端口的连通性。</p><h2 id="2-配置工作"><a href="#2-配置工作" class="headerlink" title="2. 配置工作"></a>2. 配置工作</h2><p>&emsp;&emsp;配置Canal是一个不断摸索的过程，根据Git上面的文档，以及项目源码，如果有问题出现，基本上可以定位到问题出处。虽然Git上面有比较详尽的说明，但在测试时，还是会遇到各种各样的问题。这就需要充分理解相关配置参数的含义，以及参数之间的搭配，才能更好地使用这个工具。</p><h3 id="2-1-canal说明"><a href="#2-1-canal说明" class="headerlink" title="2.1. canal说明"></a>2.1. canal说明</h3><p>需要特别注意以下几个配置内容</p><div class="hljs"><pre class=" language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"><code class="language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 配置ZK地址：如果需要启用高可用，目前高可用仅支持同时一个节点工作</span></span>canal.zkServers=<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 配置sink方式：目前支持以下三种</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## tcp, kafka, RocketMQ</span></span>canal.serverMode=<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 并发配置：这里是二选一</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 1. 单线程处理</span></span>canal.instance.parser.parallel = false<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 2. 处理过程如下[源代码]</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##  * 1. 网络接收 (单线程)</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##  * 2. 事件基本解析 (单线程，事件类型、DDL解析构造TableMeta、维护位点信息)</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##  * 3. 事件深度解析 (多线程, DML事件数据的完整解析)</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##  * 4. 投递到store (单线程)</span></span>canal.instance.parser.parallel = truecanal.instance.parser.parallelThreadSize = 6canal.instance.parser.parallelBufferSize = 4096<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># MQ配置：配置Kafka的服务器: “IP1:9092,IP2:9092,,,”</span></span>canal.mq.servers=<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># MQ配置：设置消息序列化方式，true--json, false--protobuf</span></span>canal.mq.flatMessage=true<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># MQ设置</span></span>canal.mq.acks=canal.mq.lingerMs=</code></pre></div><h3 id="2-2-instance说明"><a href="#2-2-instance说明" class="headerlink" title="2.2. instance说明"></a>2.2. instance说明</h3><p>Instance中需要注意的配置项目如下</p><div class="hljs"><pre class=" language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"><code class="language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># GTID设置：如果配置为true，那么需要给出：canal.instance.master.gtid=</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 一般设置为false，小的项目就够了：自动寻找，以及记忆Binlog位置</span></span>canal.instance.gtidon=false<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 设置源数据库：用户名、密码、默认数据库</span></span>canal.instance.dbUsername=canal.instance.dbPassword=canal.instance.defaultDatabaseName = <span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># Kafka设置</span></span>canal.mq.topic=<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 二选一</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 1. 配置partition数量，并配合映射规则：实际代码中，优先判断该种情况</span></span>canal.mq.partitionsNum=3canal.mq.partitionHash=mytest.person:id,mytest.role:id<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 2. 配置为0，或不配置</span></span>canal.mq.partition=</code></pre></div><h2 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h2><h3 id="3-1-默认数据库"><a href="#3-1-默认数据库" class="headerlink" title="3.1. 默认数据库"></a>3.1. 默认数据库</h3><p>在实际测试中，这个默认数据库的设置不知道起到了什么作用</p><div class="hljs"><pre class=" language-hljs shell"><code class="language-hljs shell">canal.instance.defaultDatabaseName =</code></pre></div><p>在获取MySQL Binlog时，这个MySQL实例的Binlog都获取到了，并传输到了Kafka中。</p><h3 id="3-2-配置错误"><a href="#3-2-配置错误" class="headerlink" title="3.2. 配置错误"></a>3.2. 配置错误</h3><p>在配置mq.yml文件时，遇到了一个基本常识错误</p><div class="hljs"><pre class=" language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"><code class="language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 错误配置</span></span>canalDestinations:  - canalDestination: example    topic:example    partition:0<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 正确配置</span></span>canalDestinations:  - canalDestination: example    topic: example    partition: 0</code></pre></div><p>即在YML配置中，基本上是这种模式的[Key: value]。</p><p>&emsp;&emsp;<strong>博主在使用的时候，场景比较简单，配置也较为简单，目标仅是让整个流程跑起来，对于其他的参数未做详细的了解以及探究，其中不免有错误之处，欢迎留言指正。</strong></p>]]></content>
    
    <summary type="html">
    
      大数据实时处理的一部分：Binlog实时入Kafka
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Kafka" scheme="https://xinshiyou.github.io/tags/Kafka/"/>
    
      <category term="MySQL" scheme="https://xinshiyou.github.io/tags/MySQL/"/>
    
      <category term="Canal" scheme="https://xinshiyou.github.io/tags/Canal/"/>
    
  </entry>
  
  <entry>
    <title>Apache Spark vs. Apache Flink</title>
    <link href="https://xinshiyou.github.io/2018/10/22/flink.vs.spark/"/>
    <id>https://xinshiyou.github.io/2018/10/22/flink.vs.spark/</id>
    <published>2018-10-22T02:10:10.000Z</published>
    <updated>2020-06-08T04:56:29.994Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>&emsp;&emsp;Apache Flink，这个高性能大数据流处理框架，走到了成熟的一个阶段。通过与Apache Spark的测试比较，我们发现他们是竞对的技术，且是被推荐的实时分析框架。</p><p>&emsp;&emsp;从之前的Hadoop MR框架，大数据流处理框架在逐渐演进。在某种意义上，Spark不经大规模提升了计算性能，更重要的是允许快速、简单的构建数据分析框架，从而推广了Hadoop。</p><p>&emsp;&emsp;讨论到Flinke，与其竞争对手相比，其不仅是一些新兴技术，而且正在加速获得动力，并迅速向企业化推进。Flink支持流处理、批处理数据，同时集成对机器学习和图处理的支持。</p><p>&emsp;&emsp;<strong>但在当技术泛滥的当下，我们是否真的需要一项新的流处理技术?</strong> 目前，当下的Apache Spark已经提供了相似的特征与功能，并且最近几年已经成为一种非常流行的工具。Curt Monash对讨论的观点是：Flink基本上是德国的Spark，我认为是不必要的。因此，我们对比一下Flink与Spark的一些特点，来判断Flink是否与Spark竞争，或Flink仅仅是另一个大数据生态的泛滥工具？首先，我们比较了一下两种技术。</p><h2 id="相同之处"><a href="#相同之处" class="headerlink" title="相同之处"></a>相同之处</h2><p>&emsp;&emsp;它们都是Apache组织内的开源工具。每一个都是独立的解决方案，但他们通常集成到大数据环境中，例如Hadoop(YARN,HDFS,以及Kafka)。Spark和Flink都提供了相似的特征与API，例如支持SQL查询，图处理，以及批处理和流处理。</p><table><thead><tr><th>Spark vs. Flink</th><th>Apache Flink</th><th>Apache Spark</th></tr></thead><tbody><tr><td>SQL查询</td><td>MRQL</td><td>Spark SQL</td></tr><tr><td>图处理</td><td>Spargel(base)，Gelly(library)</td><td>GraphX</td></tr><tr><td>流处理</td><td>Flink Streaming</td><td>Spark Streaming</td></tr><tr><td>APIs</td><td>Scala,Java,Python</td><td>Scala,Java,Python,R</td></tr><tr><td>机器学习</td><td>Flink ML</td><td>MLib, ML</td></tr><tr><td>Stable Version</td><td>1.3.2</td><td>2.2.0</td></tr><tr><td>吞吐量</td><td>高</td><td>高</td></tr><tr><td>容错性</td><td>Exactly-once</td><td>Exactly-once</td></tr><tr><td>部署</td><td>Standalone,Mesos,EC2,YARN</td><td>Standalone,Mesos,EC2,YARN</td></tr><tr><td>数据源</td><td>Kafka, Amazon S3, ES, Twitter, etc</td><td>Kafka, Amazon S3, ES, Twitter, etc</td></tr></tbody></table><p>&emsp;&emsp;下面的代码说明了他们的相似性，但不尽相同。每段代码包含了固定的元素，以及计算最高分布频次的产品。一撇就可以看出每个技术方法的高度相似性，优劣与劣势也具有平衡性。只有深入挖掘不同框架的特征，才能够识别出不同姓。在这个特殊的案例中，可以看出在Flink中的maxBy函数在Spark中没有受到支持，并且Spark需要使用窗口函数，但这类API通常具有相同的数据处理构建方式。</p><p><img src="./code_flink_spark.png" srcset="/img/loading.gif" alt="Flink vs. Spark编码对比: Java中的代码比较"></p><h2 id="批处理-vs-水龙头"><a href="#批处理-vs-水龙头" class="headerlink" title="批处理 vs 水龙头"></a>批处理 vs 水龙头</h2><p>&emsp;&emsp;Flink与Spark的最大不同之处在于不同框架的计算理念不同。Spark针对批处理和流处理使用“批”的概念，而Flink是基于单纯的流方式。想想一下收集与运输水的过程： Spark处理的方式为混合大小的桶，Flink是直接按照水龙头的方式直接处理。Flink与Spark的不同之处列列举如下<br>| Spark vs. Flink | Apache Spark | Apache Flink |<br>| - | - | - |<br>| Steaming | 微“批”流 | 基于事件的流 |<br>| Batch Processing | 内存处理，DAG组织算子 | 流悠闲方式：”批”是有限的流 |<br>| 语言 | Scala | Java |<br>| 优化|全阶段代码生成与优化，DataSet查询优化执行计划。手动内存调优非常重要 | 自动化优化：根据输入、输出、算子，主动选择合适方法。C++风格的内存管理 |<br>| 数据重用与迭代 | DAG执行计划：每一个迭代需要调度与运行相同的数据。内存缓存与重用 | 执行引擎中迭代处理，基于圆形数据流(一个迭代，一个计划)。另外，提供了Delta迭代来处理改变部分数据 |<br>| 延迟性 | 批处理导致高延迟，秒级别的延迟 | 微妙级别的低延迟 |<br>| 有序流 | 新版本中，提供了基于事件处理的基本方式 | 基于时间线，有序流可以被很好的处理 |<br>| 支持 | 支持所有的hadoop分布：Cloudera, Hortonworks, etc. Databricks提供了晕平台和支持包 | 使用邮件列表或论坛 |</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>&emsp;&emsp;批处理的表现性能，依赖于不同的负载。有些Benchmark的测试，显示Flink0.9.1快于Spark1.5.1。关于机器学习库这一方面，Spark的测试显示其性能更优(Flink 1.0.3 vs. Spark1.6.0)。在2016年9月份，Flink和Spark分析了一些批处理和迭代处理的测试，这些测试表明Spark在图处理方面1.7倍快于Flink,而Flink在批处理和小规模图负载方面1.5倍快于SPark，且使用更少的资源。这表明，工具直接的性能与功能大同小异。</p><p>&emsp;&emsp;从这些性能比较中可以得出的结论是，要选择更快的框架，必须对特定的工作负载进行基准测试。针对这些主题，几乎没有最近版本的比较(Spark 2.2 vs. Flink1.3)。这很麻烦，因为这两个平台甚至在过去一年里都取得了令人印象深刻的性能提升。在我们博客的第2部分中，我们将提供我们自己的详细性能比较，请继续关注!</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>&emsp;&emsp;大数据作为不断增加的容量、对质量的高要求以及对更快的业务洞察力的需求的三重挑战，继续要求技术在任何规模的延迟和吞吐量方面保持高性能，同时允许快速开发和高质量的代码。</p><p>&emsp;&emsp;如果高吞吐量、低延迟和良好的容错性的数据流处理需求是开发的驱动因素，那么Flink提供了一个优秀的应用程序框架[1]。如果应用程序应该嵌入到Hadoop发行版中，比如Hortonworks或Cloudera，那么Spark将是一个更好的选择，因为它已经很好地集成到各自的平台中，并得到了供应商的支持。Flink和Spark都在不断改进，以提供更简单、更快和更智能的数据处理特性。</p><p>&emsp;&emsp;最终，最佳框架的决定取决于这样一个问题:“哪一个更适合我的需求?”即使是开发团队最喜欢的编程语言也可能是一个关键因素——Spark的Java API源自Scala API:这有时会导致不吸引人的Java代码。数据工程师通常更喜欢Python或Scala, Spark支持更成熟、功能更完备、速度更快的api。Spark与R的紧密集成——“数据科学的黄金之子”——在R中提供了Spark，从而很好地集成到现有的数据科学工具箱中。</p><p>&emsp;&emsp;引发最推崇的特性之一是速度可以，运行程序比Hadoop MapReduce快100倍在内存中,或磁盘上的快10倍。Flink在批处理方面提供了强大的竞争优势，通常具有相似的性能，并且显著降低了流处理的延迟。尽管Spark社区的“炒作”似乎转移到了Flink，但只有未来才能说明这对实际市场份额有多大影响。</p>]]></content>
    
    <summary type="html">
    
      技术选型时，选择Spark还是选择Flink，这是一个问题。本文翻译自一篇博文，博文最后的结论：最终的选择还是根据客观的需求。
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Spark" scheme="https://xinshiyou.github.io/tags/Spark/"/>
    
      <category term="Flink" scheme="https://xinshiyou.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Oracle JDBC为什么不能在Maven中直接配置？</title>
    <link href="https://xinshiyou.github.io/2018/09/12/ODBC%E5%AD%A6%E4%B9%A0/"/>
    <id>https://xinshiyou.github.io/2018/09/12/ODBC%E5%AD%A6%E4%B9%A0/</id>
    <published>2018-09-12T02:10:10.000Z</published>
    <updated>2020-06-01T05:22:48.919Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在实际项目中，我们通常使用这样的方式：首先，下载ODBC的Jar到本地；然后，通过Maven安装在本地库中。这样在项目中就可以使用ODBC的Jar包了，而大部分的jar是可以通过Maven中直接引用的。这是为什么呢？</p><h2 id="项目报错"><a href="#项目报错" class="headerlink" title="项目报错"></a>项目报错</h2><p>&emsp;&emsp;项目直接编译，报错如下</p><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">Failed to execute goal on project sql2o-oracle: Could not resolve dependencies for project org.sql2o.extensions: sql2o-oracle:jar:1.6.0-RC4-SNAPSHOT: Could not find artifact com.oracle.jdbc:ojdbc8:jar:12.2.0.1 in central (https:&#x2F;&#x2F;repo.maven.apache.org&#x2F;maven2)</code></pre></div><p>很明显项目中的引用：com.oracle.jdbc:ojdbc8:jar:12.2.0.1，无法在公共仓库中找到。</p><h2 id="常用做法"><a href="#常用做法" class="headerlink" title="常用做法"></a>常用做法</h2><p>&emsp;&emsp;一般的做法就是下载Jar包，然后存放在本地仓库中，这样就可以直接在项目中引用。但通常这样略显麻烦，也不具有通用性。之前这样做的原因主要是涉及到许可的原因，Oracle不开放ODBC的Jar不会开放到公共仓库中。<br>&emsp;&emsp;关于ODBC方面的讨论可以参考：<a href="https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository" target="_blank" rel="noopener">Find Oracle JDBC driver in Maven repository</a> .</p><h2 id="目前实现"><a href="#目前实现" class="headerlink" title="目前实现"></a>目前实现</h2><p>&emsp;&emsp;目前可以通过POM中的配置来直接使用Oracle仓库中的Jar，环境可以参考：<a href="https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9010" target="_blank" rel="noopener">6 Configuring the Oracle Maven Repository</a> .</p><p>&emsp;&emsp;博主主要分为三步实现本地Oracle库的配置：</p><ol><li>注册账号：<a href="https://www.oracle.com/webapps/maven/register/license.html" target="_blank" rel="noopener">https://www.oracle.com/webapps/maven/register/license.html</a> 。如果已经注册过OTN(Oracle Technology Network)的账号，所以直接跳过；</li><li>配置本地Settings.xml<div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain"><server><id>maven.oracle.com<&#x2F;id><username>[OTN username]<&#x2F;username><password>[OTN password]<&#x2F;password><configuration><basicAuthScope><host>ANY<&#x2F;host><port>ANY<&#x2F;port><realm>OAM 11g<&#x2F;realm><&#x2F;basicAuthScope><httpConfiguration><all><params><property><name>http.protocol.allow-circular-redirects<&#x2F;name><value>%b,true<&#x2F;value><&#x2F;property><&#x2F;params><&#x2F;all><&#x2F;httpConfiguration><&#x2F;configuration><&#x2F;server></code></pre></div></li><li>Maven中配置<div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain"><repositories><repository><id>maven.oracle.com<&#x2F;id><releases><enabled>true<&#x2F;enabled><&#x2F;releases><snapshots><enabled>false<&#x2F;enabled><&#x2F;snapshots><url>https:&#x2F;&#x2F;maven.oracle.com<&#x2F;url><layout>default<&#x2F;layout><&#x2F;repository><&#x2F;repositories><pluginRepositories><pluginRepository><id>maven.oracle.com<&#x2F;id><url>https:&#x2F;&#x2F;maven.oracle.com<&#x2F;url><&#x2F;pluginRepository><&#x2F;pluginRepositories></code></pre></div></li></ol><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><ol><li>虽然通过这种方式，可以直接获取相应的Jar。但实现需要知道Jar的相关信息，例如groupId、artifactId、version等。这些信息在哪里知道？</li><li>通过权限访问这种方式，略显复杂。如果是公司的本地库，可以配置统一的Jar管理，例如artifactory软件等。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://blogs.oracle.com/dev2dev/get-oracle-jdbc-drivers-and-ucp-from-oracle-maven-repository-without-ides" target="_blank" rel="noopener">Get Oracle JDBC drivers and UCP from Oracle Maven Repository (without IDEs)</a></li><li><a href="https://stackoverflow.com/questions/1074869/find-oracle-jdbc-driver-in-maven-repository/27943380#27943380" target="_blank" rel="noopener">Find Oracle JDBC driver in Maven repository</a></li><li><a href="https://docs.oracle.com/middleware/1213/core/MAVEN/config_maven_repo.htm#MAVEN9010" target="_blank" rel="noopener">6 Configuring the Oracle Maven Repository</a></li></ol>]]></content>
    
    <summary type="html">
    
      最近在研究一个开源项目Sql2o，项目介绍性能优越。其中在ODBC子模块中，直接编译无法通过，本地没有ODBC的Jar包。
    
    </summary>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/categories/Java/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="问题" scheme="https://xinshiyou.github.io/tags/%E9%97%AE%E9%A2%98/"/>
    
      <category term="JDBC" scheme="https://xinshiyou.github.io/tags/JDBC/"/>
    
  </entry>
  
  <entry>
    <title>Hive复杂类型的导入</title>
    <link href="https://xinshiyou.github.io/2018/08/10/Hive%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%BC%E5%85%A5/"/>
    <id>https://xinshiyou.github.io/2018/08/10/Hive%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%BC%E5%85%A5/</id>
    <published>2018-08-10T02:10:01.000Z</published>
    <updated>2020-06-01T05:26:38.276Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Hive是大数据体系下ETL、数据预处理、数仓等领域比较重要的组件，应用广泛。博主空闲时间研究一下Hive的数据类型。</p><h2 id="1-Hive数据类型组成"><a href="#1-Hive数据类型组成" class="headerlink" title="1. Hive数据类型组成"></a>1. Hive数据类型组成</h2><p>&emsp;&emsp;关于Hive的数据类型，官方文档展示的比较全面，关于数据类型的详细说明<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types" target="_blank" rel="noopener">Hive数据类型</a>，这里总结如下<br>| 大类 | 类型 | 具体类型 |<br>| – | – | - |<br>| 基本类型| 数值型 |tinyint,smallint,int,bigint,float,double,decimal,numeric  |<br>| 基本类型 | 字符型 | string,varchar,char  |<br>| 基本类型 | 日期型 | timestamp,date,interval  |<br>| 基本类型 | 其他 | boolean,binary  |<br>| 复杂类型 | 数组 | array  |<br>| 复杂类型 | 映射 | map  |<br>| 复杂类型 | 结构 | struct  |<br>| 复杂类型 | 联合 | uniontype  |</p><h2 id="2-数据导入举例"><a href="#2-数据导入举例" class="headerlink" title="2. 数据导入举例"></a>2. 数据导入举例</h2><p>&emsp;&emsp;这里主要研究具体建表、产生测试数据、导入数据等内容。</p><h3 id="2-1-建表语句"><a href="#2-1-建表语句" class="headerlink" title="2.1. 建表语句"></a>2.1. 建表语句</h3><div class="hljs"><pre class=" language-hljs hive"><code class="language-hljs hive">create table test_hive_meta(    name string,    age int,    score float,    insert_time string,-- 刚开始定义的是date类型，后面修改为string或timestamp    students struct<sname:string,sage:int>,    infos map<int,string>,    scores array<float>)  comment "测试数据表"ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t'  COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':'STORED as TEXTFILE ;</code></pre></div><h3 id="2-2-产生测试数据"><a href="#2-2-产生测试数据" class="headerlink" title="2.2. 产生测试数据"></a>2.2. 产生测试数据</h3><div class="hljs"><pre class=" language-hljs java"><span class="hljs-keyword"><code class="language-hljs java"><span class="hljs-keyword">import</span> java.io.BufferedWriter;<span class="hljs-keyword">import</span> java.io.File;<span class="hljs-keyword">import</span> java.io.FileWriter;<span class="hljs-keyword">import</span> java.io.IOException;<span class="hljs-keyword">import</span> java.text.SimpleDateFormat;<span class="hljs-keyword">import</span> java.util.Date;<span class="hljs-keyword">import</span> java.util.Random;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TestMain</span> </span>&#123;<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String[] names = <span class="hljs-keyword">new</span> String[] &#123; <span class="hljs-string">"Laird"</span>, <span class="hljs-string">"莱尔德"</span>, <span class="hljs-string">"Lambert"</span>, <span class="hljs-string">"兰伯特"</span>, <span class="hljs-string">"Lamont"</span>, <span class="hljs-string">"拉蒙特"</span>, <span class="hljs-string">"Lance"</span>,<span class="hljs-string">"兰斯"</span>, <span class="hljs-string">"Lang"</span>, <span class="hljs-string">"兰格"</span>, <span class="hljs-string">"Lange"</span>, <span class="hljs-string">"兰格"</span>, <span class="hljs-string">"Langston"</span>, <span class="hljs-string">"兰斯顿"</span>, <span class="hljs-string">"Lanny"</span>, <span class="hljs-string">"兰尼"</span>, <span class="hljs-string">"Larkin"</span>, <span class="hljs-string">"拉金"</span>, <span class="hljs-string">"Larry"</span>, <span class="hljs-string">"拉里"</span>,<span class="hljs-string">"Clementina"</span>, <span class="hljs-string">"克莱门蒂娜"</span>, <span class="hljs-string">"Clementine"</span>, <span class="hljs-string">"克莱门廷"</span>, <span class="hljs-string">"Clemmie"</span>, <span class="hljs-string">"克莱米"</span>, <span class="hljs-string">"Cleo"</span>, <span class="hljs-string">"克利奥"</span>, <span class="hljs-string">"Cleopatra"</span>, <span class="hljs-string">"克利奥帕特拉"</span>,<span class="hljs-string">"Colette"</span>, <span class="hljs-string">"科莱特"</span>, <span class="hljs-string">"Colleen"</span>, <span class="hljs-string">"科琳"</span>, <span class="hljs-string">"Conchita"</span>, <span class="hljs-string">"康奇塔"</span>, <span class="hljs-string">"Connie"</span>, <span class="hljs-string">"康妮，康尼"</span>, <span class="hljs-string">"Constance"</span>, <span class="hljs-string">"康斯坦斯"</span>, <span class="hljs-string">"Alvina"</span>,<span class="hljs-string">"阿尔文娜"</span>, <span class="hljs-string">"Alvira"</span>, <span class="hljs-string">"阿尔薇拉"</span>, <span class="hljs-string">"Amabel"</span>, <span class="hljs-string">"阿玛贝尔"</span>, <span class="hljs-string">"Amanda"</span>, <span class="hljs-string">"阿曼达"</span>, <span class="hljs-string">"Amber"</span>, <span class="hljs-string">"安伯"</span>, <span class="hljs-string">"Amelia"</span>, <span class="hljs-string">"阿米莉亚"</span>, <span class="hljs-string">"Amity"</span>,<span class="hljs-string">"阿米蒂"</span>, <span class="hljs-string">"Amor"</span>, <span class="hljs-string">"埃默"</span>, <span class="hljs-string">"Amy"</span>, <span class="hljs-string">"艾米"</span>, <span class="hljs-string">"Ana"</span>, <span class="hljs-string">"安娜"</span>, <span class="hljs-string">"Ware"</span>, <span class="hljs-string">"韦尔"</span>, <span class="hljs-string">"Warner"</span>, <span class="hljs-string">"沃纳"</span>, <span class="hljs-string">"Warren"</span>, <span class="hljs-string">"沃伦"</span>, <span class="hljs-string">"Washburn"</span>,<span class="hljs-string">"沃什伯恩"</span>, <span class="hljs-string">"Washington"</span>, <span class="hljs-string">"华盛顿"</span>, <span class="hljs-string">"Watkins"</span>, <span class="hljs-string">"沃特金斯"</span>, <span class="hljs-string">"Watt"</span>, <span class="hljs-string">"瓦特"</span>, <span class="hljs-string">"Watts"</span>, <span class="hljs-string">"沃茨"</span>, <span class="hljs-string">"Wayne"</span>, <span class="hljs-string">"韦恩"</span>, <span class="hljs-string">"Webb"</span>, <span class="hljs-string">"韦布"</span>,<span class="hljs-string">"Lina"</span>, <span class="hljs-string">"莉娜"</span>, <span class="hljs-string">"Linda"</span>, <span class="hljs-string">"琳达"</span>, <span class="hljs-string">"Lindy"</span>, <span class="hljs-string">"琳迪"</span>, <span class="hljs-string">"Linn"</span>, <span class="hljs-string">"林"</span>, <span class="hljs-string">"Linsey"</span>, <span class="hljs-string">"林赛"</span>, <span class="hljs-string">"Lisa"</span>, <span class="hljs-string">"莉萨"</span>, <span class="hljs-string">"Lisbeth"</span>, <span class="hljs-string">"莉斯贝思"</span>,<span class="hljs-string">"Lise"</span>, <span class="hljs-string">"莉萨"</span>, <span class="hljs-string">"Lisette"</span>, <span class="hljs-string">"莉塞特"</span>, <span class="hljs-string">"Liz"</span>, <span class="hljs-string">"莉兹"</span> &#125;;<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Random random = <span class="hljs-keyword">new</span> Random();<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> SimpleDateFormat sdf = <span class="hljs-keyword">new</span> SimpleDateFormat(<span class="hljs-string">"yyyy-mm-dd HH:MM:ss"</span>);<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> size = names.length;<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">char</span>[] a = &#123; <span class="hljs-string">','</span> &#125;;<span class="hljs-comment">// fields termination</span><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">char</span>[] b = &#123; <span class="hljs-string">'-'</span> &#125;;<span class="hljs-comment">// collection item termination</span><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">char</span>[] c = &#123; <span class="hljs-string">':'</span> &#125;;<span class="hljs-comment">// map key termination</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<span class="hljs-keyword">try</span> &#123;File file = <span class="hljs-keyword">new</span> File(<span class="hljs-string">"./data.txt"</span>);<span class="hljs-keyword">if</span> (!file.exists()) &#123;file.createNewFile();&#125;FileWriter fw = <span class="hljs-keyword">new</span> FileWriter(file.getAbsoluteFile());BufferedWriter bw = <span class="hljs-keyword">new</span> BufferedWriter(fw);<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i < <span class="hljs-number">100</span>; i++) &#123;bw.write(gen1Line());&#125;bw.close();System.out.println(<span class="hljs-string">"Done"</span>);&#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;e.printStackTrace();&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> String <span class="hljs-title">gen1Line</span><span class="hljs-params">()</span> </span>&#123;StringBuffer line = <span class="hljs-keyword">new</span> StringBuffer();line.append(names[random.nextInt(size)]);line.append(a);line.append(random.nextInt(<span class="hljs-number">100</span>));line.append(a);line.append(random.nextDouble() * <span class="hljs-number">10</span>);line.append(a);line.append(sdf.format(<span class="hljs-keyword">new</span> Date()));line.append(a);line.append(names[random.nextInt(size)]);line.append(b);line.append(random.nextInt(<span class="hljs-number">100</span>));line.append(a);<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i < <span class="hljs-number">10</span>; i++) &#123;line.append(random.nextInt(<span class="hljs-number">100</span>));line.append(c);line.append(names[random.nextInt(size)]);line.append(b);&#125;line.append(random.nextInt(<span class="hljs-number">100</span>));line.append(c);line.append(names[random.nextInt(size)]);line.append(a);<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i < <span class="hljs-number">10</span>; i++) &#123;line.append(random.nextDouble() * <span class="hljs-number">10</span>);line.append(b);&#125;line.append(random.nextDouble() * <span class="hljs-number">10</span>);line.append(<span class="hljs-string">"\n"</span>);<span class="hljs-keyword">return</span> line.toString();&#125;&#125;</code></pre></div><h3 id="2-3-导入数据测试"><a href="#2-3-导入数据测试" class="headerlink" title="2.3. 导入数据测试"></a>2.3. 导入数据测试</h3><div class="hljs"><pre class=" language-hljs shell"><code class="language-hljs shell">-- 导入数据load data local inpath "/home/data.txt" into table test_hive_meta;-- 为了便于查看导入数据结果，打开列显示set hive.cli.print.header=true;set hive.cli.print.row.to.vertical=true;set hive.cli.print.row.to.vertical.num=1;</code></pre></div><h3 id="2-4-查看导入结果"><a href="#2-4-查看导入结果" class="headerlink" title="2.4. 查看导入结果"></a>2.4. 查看导入结果</h3><div class="hljs"><pre class=" language-hljs shell"><code class="language-hljs shell">-- 查询select * from test_hive_meta limit 1 ;-- 结果nameagescoreinsert_timestudentsinfosscoresCleopatra110.282060652018-14-11 17:08:15&#123;"sname":"阿玛贝尔","sage":15&#125;&#123;41:"Linda",82:"康斯坦斯",94:"艾米",81:"Washington",23:"兰尼",93:"Lise",36:"沃纳",70:"Lise",39:"克利奥帕特拉",35:"Lambert",67:"Colleen"&#125;[1.8265022,6.058134,7.794176,4.096524,8.195735,5.866253,0.75852406,6.835354,2.7134678,8.078223,6.275408]</code></pre></div><h2 id="3-采坑"><a href="#3-采坑" class="headerlink" title="3. 采坑"></a>3. 采坑</h2><ol><li>关于date数据类型<br>发现使用date数据类型在导入的时候存在问题，刚开始使用date类型，导入类型为long，结果显示为null；后面导入数据修改为”yyyy-MM-dd HH:mm:ss”之后，结果仍为null。后面修改为string类型，导入数据为格式化的日期类型，或者修改为timestamp类型，导入类型为long。</li></ol><h2 id="4-参考文章"><a href="#4-参考文章" class="headerlink" title="4. 参考文章"></a>4. 参考文章</h2><ol><li><a href="https://cwiki.apache.org/confluence/display/hive" target="_blank" rel="noopener">Apache Hive Document</a></li><li><a href="https://blog.csdn.net/kellyzly/article/details/30267557" target="_blank" rel="noopener">hive collection data type</a></li><li><a href="http://www.aboutyun.com/thread-13220-1-1.html" target="_blank" rel="noopener">Hive中导入时间格式的数据显示为null </a></li></ol>]]></content>
    
    <summary type="html">
    
      偶然机会研究Hive JDBC的原理，创建一张含有复杂类型的表，验证JDBC是否可以获取复杂类型的数据。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Hive" scheme="https://xinshiyou.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Springboot报错</title>
    <link href="https://xinshiyou.github.io/2018/08/07/SpringBoot%E6%8A%A5%E9%94%99/"/>
    <id>https://xinshiyou.github.io/2018/08/07/SpringBoot%E6%8A%A5%E9%94%99/</id>
    <published>2018-08-07T02:10:10.000Z</published>
    <updated>2020-06-13T11:25:25.011Z</updated>
    
    <content type="html"><![CDATA[<h2 id="报错一"><a href="#报错一" class="headerlink" title="报错一"></a>报错一</h2><ul><li><em>错误信息</em>:<br>  Cannot determine embedded database driver class for database type NONE</li><li><em>解决方案</em>：启动类中加入注解：<br>@SpringBootApplication(exclude={DataSourceAutoConfiguration.class,HibernateJpaAutoConfiguration.class})</li></ul><h2 id="报错二"><a href="#报错二" class="headerlink" title="报错二"></a>报错二</h2><ul><li><em>错误信息</em>:<br>  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘httpPutFormContentFilter’ defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedHttpPutFormContentFilter]: Factory method ‘httpPutFormContentFilter’ threw exception; nested exception is java.lang.VerifyError: Cannot inherit from final class</li><li><em>解决方案</em>：<br>  更换Spring-Parent的版本。  <div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">   &#x2F;&#x2F;更改之前   <dependency><groupId>org.springframework.boot<&#x2F;groupId><artifactId>spring-boot-dependencies<&#x2F;artifactId><version>2.0.2.RELEASE<&#x2F;version><scope>import<&#x2F;scope><type>pom<&#x2F;type>   <&#x2F;dependency>      &#x2F;&#x2F; 更改之后    <dependency><groupId>org.springframework.boot<&#x2F;groupId><artifactId>spring-boot-dependencies<&#x2F;artifactId><version>1.5.1.RELEASE<&#x2F;version><scope>import<&#x2F;scope><type>pom<&#x2F;type><&#x2F;dependency></code></pre></div></li></ul><h2 id="报错三"><a href="#报错三" class="headerlink" title="报错三"></a>报错三</h2><ul><li><em>错误信息</em>:<br>  Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.filter.OrderedHttpPutFormContentFilter]: Factory method ‘httpPutFormContentFilter’ threw exception; nested exception is java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z<br>  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:189)<br>  at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588)<br>  … 40 more<br>  Caused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z</li><li><em>解决方案</em>：</li></ul><h2 id="参考汇总"><a href="#参考汇总" class="headerlink" title="参考汇总"></a>参考汇总</h2><ol><li><a href="https://blog.csdn.net/Loser100/article/details/78190703?locationNum=9&fps=1" target="_blank" rel="noopener">SpringBoot常见问题（一）</a></li></ol>]]></content>
    
    <summary type="html">
    
      初识Springboot，各种报错眼花缭乱。有认识不足的低级错误，也有棘手的报错信息。
    
    </summary>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/categories/Java/"/>
    
    
      <category term="问题" scheme="https://xinshiyou.github.io/tags/%E9%97%AE%E9%A2%98/"/>
    
      <category term="Springboot" scheme="https://xinshiyou.github.io/tags/Springboot/"/>
    
  </entry>
  
  <entry>
    <title>Hive JDBC任务执行流程</title>
    <link href="https://xinshiyou.github.io/2018/08/04/Hive-JDBC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
    <id>https://xinshiyou.github.io/2018/08/04/Hive-JDBC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</id>
    <published>2018-08-04T02:10:01.000Z</published>
    <updated>2020-06-08T07:12:03.452Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Hive提供了多种访问方式，其中JDBC是一种。通常通过JDBC访问，可以规避用户对HDFS、Metastore的直接访问。本文研究研究一下HiveJDBC执行任务的流程。</p><h2 id="JDBC执行流程"><a href="#JDBC执行流程" class="headerlink" title="JDBC执行流程"></a>JDBC执行流程</h2><p><img src="004.png" srcset="/img/loading.gif" alt="Hive客户端与服务端的交互"></p><p>&emsp;&emsp;主要流程分为三条线：</p><ol><li>执行任务，无返回<br> 执行完成，获取执行结果[boolean/int]，直接结束</li><li>执行任务，返回数据<br> 执行完成，通过接口获取数据，用户执行其他相关操作</li><li>执行任务，查询日志<br> 执行任务的同时，可以获取执行日志。通过单独的接口，可以分别获取日志与数据。</li></ol><p>&emsp;&emsp;使用JDBC查询日志，存在锁竞争的问题，因而表现出来的现象就是通过JDBC获取日志比较慢。具体可以参考：<a href="https://www.cnblogs.com/oldtrafford/p/8818756.html" target="_blank" rel="noopener">hive-jdbc获取查询日志慢的问题发现与解决</a>。</p>]]></content>
    
    <summary type="html">
    
      本文主要研究HiveServer2提交任务的流程以及任务队列的管理方式。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Hive" scheme="https://xinshiyou.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Hive提交任务流程</title>
    <link href="https://xinshiyou.github.io/2018/08/04/Hive%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B/"/>
    <id>https://xinshiyou.github.io/2018/08/04/Hive%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%B5%81%E7%A8%8B/</id>
    <published>2018-08-04T02:10:01.000Z</published>
    <updated>2020-06-08T07:11:16.899Z</updated>
    
    <content type="html"><![CDATA[<!-- TOC --><ul><li><a href="#1-环境描述">1. 环境描述</a></li><li><a href="#2-初识thrift">2. 初识Thrift</a><ul><li><a href="#21-基本类型">2.1. 基本类型</a></li><li><a href="#22-关键概念">2.2. 关键概念</a><ul><li><a href="#221-关键字">2.2.1. 关键字</a></li><li><a href="#222-thrift三组件">2.2.2. Thrift三组件</a></li><li><a href="#223-简单示例">2.2.3. 简单示例</a></li></ul></li></ul></li><li><a href="#3-hiveserver2提交任务">3. HiveServer2提交任务</a><ul><li><a href="#31-hiveserver2启动流程">3.1. HiveServer2启动流程</a></li><li><a href="#32-提交任务流程">3.2. 提交任务流程</a></li><li><a href="#33-服务器端执行任务流程">3.3. 服务器端执行任务流程</a></li><li><a href="#34-队列管理方式">3.4. 队列管理方式</a></li><li><a href="#35-关闭任务流程">3.5. 关闭任务流程</a></li></ul></li><li><a href="#4-hiveserver2的优缺点">4. HiveServer2的优缺点</a><ul><li><a href="#41-优点">4.1. 优点</a></li><li><a href="#42-缺点">4.2. 缺点</a></li><li><a href="#43-疑问">4.3. 疑问</a></li></ul></li><li><a href="#5-参考文章">5. 参考文章</a></li></ul><!-- /TOC --><h1 id="1-环境描述"><a href="#1-环境描述" class="headerlink" title="1. 环境描述"></a>1. 环境描述</h1><ol><li>JDK版本：<br> <strong>java version “1.8.0_181”</strong><br> <strong>Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</strong><br> <strong>Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)</strong></li><li>Thrift版本：<strong>Thrift version 0.11.0</strong></li><li>Hive版本：<strong>Hive 1.1.0-cdh5.14.2</strong></li></ol><h1 id="2-初识Thrift"><a href="#2-初识Thrift" class="headerlink" title="2. 初识Thrift"></a>2. 初识Thrift</h1><h2 id="2-1-基本类型"><a href="#2-1-基本类型" class="headerlink" title="2.1. 基本类型"></a>2.1. 基本类型</h2><table><thead><tr><th>概念</th><th>Thrift</th><th>Java</th></tr></thead><tbody><tr><td>逻辑变量</td><td>bool</td><td>boolean</td></tr><tr><td>字节变量</td><td>i8</td><td>byte</td></tr><tr><td>16位整数</td><td>i16</td><td>short</td></tr><tr><td>32位整数</td><td>i32</td><td>int</td></tr><tr><td>64位整数</td><td>i64</td><td>long</td></tr><tr><td>浮点数</td><td>double</td><td>double</td></tr><tr><td>字符串</td><td>string</td><td>java.lang.String</td></tr><tr><td>列表</td><td>list</td><td>java.util.List</td></tr><tr><td>集合</td><td>set</td><td>java.util.Set</td></tr><tr><td>映射</td><td>map</td><td>java.util.Map</td></tr></tbody></table><h2 id="2-2-关键概念"><a href="#2-2-关键概念" class="headerlink" title="2.2. 关键概念"></a>2.2. 关键概念</h2><h3 id="2-2-1-关键字"><a href="#2-2-1-关键字" class="headerlink" title="2.2.1. 关键字"></a>2.2.1. 关键字</h3><ol><li>struct</li><li>service</li><li>exception</li><li>required</li><li>optional</li><li>const</li><li>typedef</li><li>include</li></ol><h3 id="2-2-2-Thrift三组件"><a href="#2-2-2-Thrift三组件" class="headerlink" title="2.2.2. Thrift三组件"></a>2.2.2. Thrift三组件</h3><p>&emsp;&emsp;Thrift中比较重要的是TProcess、TProtocol、TTransport三个组件，通过名称就可以可知组件的功能，这里不做细究。Thrift协议栈的层级情况，如下所示：<br><img src="001.png" srcset="/img/loading.gif" alt="Thrift协议栈"><br>其中主要的TProtocol包括：<em>TBinaryProtocol、TCompactProtocol、TJSONProtocol、TProtocolDecorator、TSimpleJSONProtocol</em>，主要的TServer包括<em>TSimpleServer、TThreadPoolServer、TNonblockingServer、TThreadedSelectorServer</em>。<br>&emsp;&emsp;从图中可以看出，Thrift已经帮助做了很多封装与代码的生成。作为使用者，无需细究自动生成代码内部的机制，特别是比较底层的I/O层面操作。通过编写Thrift文件，使用thrift命令可以自动生成相应的Java类，特别是TProcess基本上无需开发者介入，只需要调用即可。</p><h3 id="2-2-3-简单示例"><a href="#2-2-3-简单示例" class="headerlink" title="2.2.3. 简单示例"></a>2.2.3. 简单示例</h3><ol><li>Thrift文件<div class="hljs"><pre class=" language-hljs thrift"><span class="hljs-keyword"><code class="language-hljs thrift"><span class="hljs-keyword">namespace</span> java com.simple.www<span class="hljs-class"><span class="hljs-keyword">service</span> <span class="hljs-title">Hello</span></span>&#123;        <span class="hljs-built_in">string</span> helloString(<span class="hljs-number">1</span>:<span class="hljs-built_in">string</span> para)&#125;</code></pre></div></li><li>服务端代码<div class="hljs"><pre class=" language-hljs java"><span class="hljs-keyword"><code class="language-hljs java"><span class="hljs-keyword">try</span> &#123;TServerTransport serverTransport = <span class="hljs-keyword">new</span> TServerSocket(<span class="hljs-number">7911</span>);Factory proFactory = <span class="hljs-keyword">new</span> TBinaryProtocol.Factory();TProcessor processor = <span class="hljs-keyword">new</span> Hello.Processor<HelloServiceImpl>(<span class="hljs-keyword">new</span> HelloServiceImpl());Args args_ = <span class="hljs-keyword">new</span> Args(serverTransport).processor(processor).protocolFactory(proFactory).executorService(Executors.newFixedThreadPool(<span class="hljs-number">10</span>));TServer server = <span class="hljs-keyword">new</span> TThreadPoolServer(args_);System.out.println(<span class="hljs-string">"Start server on port 7911..."</span>);server.serve();&#125; <span class="hljs-keyword">catch</span> (TTransportException e) &#123;<span class="hljs-comment">// TODO Auto-generated catch block</span>e.printStackTrace();&#125;</code></pre></div></li><li>客户端代码<div class="hljs"><pre class=" language-hljs java"><span class="hljs-keyword"><code class="language-hljs java"><span class="hljs-keyword">try</span> &#123;TTransport transport = <span class="hljs-keyword">new</span> TSocket(<span class="hljs-string">"localhost"</span>, <span class="hljs-number">7911</span>);transport.open();TProtocol protocol = <span class="hljs-keyword">new</span> TBinaryProtocol(transport);Hello.Client client = <span class="hljs-keyword">new</span> Hello.Client(protocol);String res = client.helloString(<span class="hljs-string">"[This is a test helloString]"</span>);System.out.println(<span class="hljs-string">"Result:"</span> + res);transport.close();System.out.println(<span class="hljs-string">"成功关闭:"</span> + transport.isOpen());&#125; <span class="hljs-keyword">catch</span> (TTransportException e) &#123;<span class="hljs-comment">// TODO Auto-generated catch block</span>e.printStackTrace();&#125; <span class="hljs-keyword">catch</span> (TException e) &#123;<span class="hljs-comment">// TODO Auto-generated catch block</span>e.printStackTrace();&#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<span class="hljs-comment">// TODO Auto-generated catch block</span>e.printStackTrace();&#125;</code></pre></div></li></ol><h1 id="3-HiveServer2提交任务"><a href="#3-HiveServer2提交任务" class="headerlink" title="3. HiveServer2提交任务"></a>3. HiveServer2提交任务</h1><p>&emsp;&emsp;本小节，我们考虑以下几个问题：</p><ul><li>HS2启动干了那些事情？</li><li>HSQL任务是如何提交？</li><li>HSQL任务是如何执行？</li><li>HS2如何做队列管理？</li><li>任务执行完成，资源如何释放？</li></ul><h2 id="3-1-HiveServer2启动流程"><a href="#3-1-HiveServer2启动流程" class="headerlink" title="3.1. HiveServer2启动流程"></a>3.1. HiveServer2启动流程</h2><p>&emsp;&emsp;HiveServer2的启动涉及到多个方面的资源，这里不详细讲解，主要描述初始化的大体流程。<br><img src="002.png" srcset="/img/loading.gif" alt="HiveServer2启动初始化过程"></p><ul><li>首先，父类初始化一些核心参数，例如服务端口、本机地址、ServerContext、TServerEventHandler等处理事务的必备组件</li><li>其次，初始化CLIService这个类。这个类主要用作SQL请求的执行，后面说明该类执行任务的流程。接下来根据用户的设置判断启动Http模式的jetty服务，还是启动Thrift监听服务</li><li>最后，构建一个HS2WEB服务，用于展示HS2的信息。这一块就是我们看到的URL: <a href="http://hdfs-nn-1.sv.ebu.alsh.xingbianli.com:10002/hiveserver2.jsp" target="_blank" rel="noopener">http://hdfs-nn-1.sv.ebu.alsh.xingbianli.com:10002/hiveserver2.jsp</a> ，这个服务也是一个内嵌Jetty服务。主要包括：[/jmx–&gt;JMXJsonServlet.class]、[/conf–&gt;ConfServlet]、[/stacks–&gt;StackServlet]，以及日志处理[/logs]和首页[hiveserver2.jsp]。</li></ul><h2 id="3-2-提交任务流程"><a href="#3-2-提交任务流程" class="headerlink" title="3.2. 提交任务流程"></a>3.2. 提交任务流程</h2><p>&emsp;&emsp;HS2服务启动之后，客户端就可以提交任务了。那么任务是如何提交的？这就是本小节的关注重点。客户端提交任务，我们只研究JDBC模块的内容，Beeline方式提交任务可以参考JDBC模式。</p><p>&emsp;&emsp;研读HiveDriver的内容，可以发现客户端与服务端存在如下交互。<br><img src="004.png" srcset="/img/loading.gif" alt="Hive客户端与服务端的交互"></p><p>&emsp;&emsp;从HiveJDBC提交任务的流程来看，主要的工作放在服务端。客户端主要用来发起任务、提交任务、获取任务结果等内容，相对比较简单。</p><h2 id="3-3-服务器端执行任务流程"><a href="#3-3-服务器端执行任务流程" class="headerlink" title="3.3. 服务器端执行任务流程"></a>3.3. 服务器端执行任务流程</h2><p>&emsp;&emsp;客户端提交任务之后，服务端执行任务。执行任务的逻辑与流程主要如下所示<br><img src="003.png" srcset="/img/loading.gif" alt="HiveServer2查询执行流程"></p><h2 id="3-4-队列管理方式"><a href="#3-4-队列管理方式" class="headerlink" title="3.4. 队列管理方式"></a>3.4. 队列管理方式</h2><p>对于HS2的任务队列管理，我们犹如下疑问</p><ol><li>任务提交队列</li><li>任务执行策略：FIFO ? FAIR ?</li><li>结果回调方式</li><li>队列满了如何解决？</li></ol><p>&emsp;&emsp;提交任务就涉及到一个任务队列的管理。本小节主要关注HS2管理任务队列的方式，任务添加策略、执行的策略，以及如何处理一些异常情况。</p><p>&emsp;&emsp;针对我们提出的问题，对源码进行了研究。根据HS2源码的实现，可以看出HS2并没有对客户端提交的任务进行相关的队列处理或进行相关的调度算法实现。以Thrift方式而言，任务队列或者任务并行数的控制是通过Thrift线程并行服务来实现的，既ExecutorService。服务端针对客户端的连接服务是TThreadPoolServer，即面向连接池的服务，因此本质上而言我们可以认为它是一个FIFO的队列。其队列的实现如下所示</p><div class="hljs"><pre class=" language-hljs java">ExecutorService executorService = <span class="hljs-keyword"><code class="language-hljs java">ExecutorService executorService = <span class="hljs-keyword">new</span> ThreadPoolExecutor(minWorkerThreads, maxWorkerThreads,        workerKeepAliveTime, TimeUnit.SECONDS, <span class="hljs-keyword">new</span> SynchronousQueue<Runnable>(),<span class="hljs-keyword">new</span> ThreadFactoryWithGarbageCleanup(threadPoolName));</code></pre></div><p>其中minWorkerThreads是通过<em>hive.server2.thrift.min.worker.threads</em>来设置的，默认值为5；maxWorkerThreads是通过<em>hive.server2.thrift.max.worker.threads</em>来设置，默认值为500。通过源码可以看出，这里的这两个设置控制的是线程池的核心线程数与最大线程数，并不是语义上的最大并行线程数与最小并行线程数。</p><p>&emsp;&emsp;由于服务端的请求是通过Thrift RPC方式并且是异步进行的，所以客户端在实现上是轮训服务端的执行状态，从而客户端看起来是同步进行的。由于客户端的请求要么让Thrift服务处理，要么让jettyServer处理，无论哪种方式如何客户端打开session数量超过maxWorkerThreads，那么客户端的提交请求过程会被堵塞，因而服务端不存在任务队列满了如何处理这种情况。</p><h2 id="3-5-关闭任务流程"><a href="#3-5-关闭任务流程" class="headerlink" title="3.5. 关闭任务流程"></a>3.5. 关闭任务流程</h2><p>&emsp;&emsp;任务运行结束，程序会关闭连接并释放资源。主要关闭流程如下所示。<br><img src="005.png" srcset="/img/loading.gif" alt="HiveServere2关闭流程"><br>这里提到的关闭流程主要指的是正常关闭流程，主要是指关闭Operation、Session等。其中Yarn上运行的任务被Kill这种情况，我们认为是运行认为失败，不被包含在关闭流程中。</p><h1 id="4-HiveServer2的优缺点"><a href="#4-HiveServer2的优缺点" class="headerlink" title="4. HiveServer2的优缺点"></a>4. HiveServer2的优缺点</h1><h2 id="4-1-优点"><a href="#4-1-优点" class="headerlink" title="4.1. 优点"></a>4.1. 优点</h2><ol><li>统一口径：JDBC/Beeline等统一访问，任务集中管理</li><li>支持本地MR：一些简单的任务，可以直接运行在本地，减轻Yarn集群压力</li><li>Thrift协议：支持扩平台、扩语言[Java、Python等]、可远程等优点，继承RPC的各项优点</li><li>HA机制：解决应用端的并发与负载均衡问题</li><li>安全认证：支持多种协议，支持自定义安全认证</li><li>数据隔离：不直接将HDFS与Metastore暴露给用户</li></ol><h2 id="4-2-缺点"><a href="#4-2-缺点" class="headerlink" title="4.2. 缺点"></a>4.2. 缺点</h2><ol><li>内存：可能会OOM。作为一个独立的Java应用，需要根据业务需求，不断调整Java_OPS的设置。如果节点性能较好，尽量配置大一些</li><li>目前HiveJDBC无法获取任务ID，或Yarn上运行的ID信息，并且获取任务执行日志比较困难</li></ol><h2 id="4-3-疑问"><a href="#4-3-疑问" class="headerlink" title="4.3. 疑问"></a>4.3. 疑问</h2><ol><li>目前Thrfit支持TThreadedSelectorServer，为什么还用TThreadPoolServer ？ 即使目前的最新版本Hive 3.1，使用的仍然是TThreadPoolServer</li></ol><h1 id="5-参考文章"><a href="#5-参考文章" class="headerlink" title="5. 参考文章"></a>5. 参考文章</h1><ol><li><a href="https://blog.csdn.net/kesonyk/article/details/50924489" target="_blank" rel="noopener">Thrift RPC详解</a></li><li><a href="http://blog.163.com/kewangwu@126/blog/static/86728471201271353354581/" target="_blank" rel="noopener">Thrift的数据类型</a></li><li><a href="https://blog.csdn.net/zhanglh046/article/details/78572926" target="_blank" rel="noopener">hiveserver2详解</a></li><li><a href="http://lxw1234.com/archives/2016/05/675.htm" target="_blank" rel="noopener">HiveServer2的高可用-HA配置</a></li><li><a href="https://www.cnblogs.com/oldtrafford/p/8818756.html" target="_blank" rel="noopener">hive-jdbc获取查询日志慢的问题发现与解决</a></li></ol>]]></content>
    
    <summary type="html">
    
      本文主要研究HiveServer2提交任务的流程以及任务队列的管理方式。
    
    </summary>
    
    
      <category term="大数据" scheme="https://xinshiyou.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
      <category term="Hive" scheme="https://xinshiyou.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>《模式识别：算法及其实现方法》读书笔记</title>
    <link href="https://xinshiyou.github.io/2018/07/28/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://xinshiyou.github.io/2018/07/28/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2018-07-28T02:10:10.000Z</published>
    <updated>2020-06-01T04:17:18.639Z</updated>
    
    <content type="html"><![CDATA[<ol><li>作者：M.Narasimha Murty, V. Susheela Devi</li><li>翻译：王振永</li><li>出版社：哈尔滨工业大学出版社</li></ol><h1 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h1><p>&emsp;&emsp;模式识别可以定义为基于已知知识或者依据模式标书所抽象出来的统计信息进行数据分类的方法。</p><p>&emsp;&emsp;模式识别有很多重要的应用，例如多媒体文档自动识别(MDR)和自动医疗诊断。在进行MDR时，必须处理文本、音频和视频数据的集合。文本数据可以由对应一个或多个自然语言的字符和数字组成。音频数据可能是语音或音乐。视频数据可能是一个单一的图像或图像序列。</p><p>&emsp;&emsp;一个典型的模式识别应用程序中，需要对原始数据进行吹了，将其转换为一种可被机器使用的形式。音频可悲表示为现行预测编码的系数，而视频数据则可以转换到变换域来表示，比如小波变换和傅里叶变换。信号处理可以将原始输数据转换为矢量数据。</p><p>&emsp;&emsp;模式识别涉及到分类和聚类。在模式识别中，使用一组训练模式或领域知识分配类类标签。聚类可以将数据分区，这有助于我们制定决策，我们感兴趣的决策制定是数据分类。</p><h2 id="什么是模式识别"><a href="#什么是模式识别" class="headerlink" title="什么是模式识别"></a>什么是模式识别</h2><p>&emsp;&emsp;在模式识别中，为模式制定标签。有时候，可以使用分类规则而不进行任务抽象。模式是别的重要方面之一是应用前景，在农业、教育、安全、交通、金融、医疗和娱乐等领域中有着广泛的应用，具体应用包括生物识别、生物信息学、多媒体数据分析、文档识别、故障诊断以及专家系统。分类是人类的一种基本思维模式，所以模式识别可以应用在任务领域。</p><h2 id="模式识别的数据集合"><a href="#模式识别的数据集合" class="headerlink" title="模式识别的数据集合"></a>模式识别的数据集合</h2><p>&emsp;&emsp;在互联网有大量的数据集可供使用。一个受欢迎的网站是UCIrvine的机器学习库(<a href="http://www.ics.uci.edu/MLRepository.html)，它包含许多不同大小的数据集，可以用于各种分类算法。其中很多设置给出了一些分类方法的分类精度，可以作为研究的基准。用于数据挖掘的大型数据集可在网站kdd.ics.uci.edu和www.kdnuggets.com/datasets/中找到。" target="_blank" rel="noopener">www.ics.uci.edu/MLRepository.html)，它包含许多不同大小的数据集，可以用于各种分类算法。其中很多设置给出了一些分类方法的分类精度，可以作为研究的基准。用于数据挖掘的大型数据集可在网站kdd.ics.uci.edu和www.kdnuggets.com/datasets/中找到。</a></p><h2 id="模式识别的理论框架"><a href="#模式识别的理论框架" class="headerlink" title="模式识别的理论框架"></a>模式识别的理论框架</h2><p>&emsp;&emsp;有多重理论框架能解决模式识别问题，其中最主要的两种为：</p><ol><li>统计模式识别</li><li>结构模式识别</li></ol><p>&emsp;&emsp;在这两种方式中，统计模式识别使用更为广泛，在文献中大量出现。</p><h1 id="模式集合的表征"><a href="#模式集合的表征" class="headerlink" title="模式集合的表征"></a>模式集合的表征</h1><p>&emsp;&emsp;模式是一个物理对象或抽象概念。</p><h2 id="模式结合表征的数据结构"><a href="#模式结合表征的数据结构" class="headerlink" title="模式结合表征的数据结构"></a>模式结合表征的数据结构</h2><h3 id="矢量的模式集合表征"><a href="#矢量的模式集合表征" class="headerlink" title="矢量的模式集合表征"></a>矢量的模式集合表征</h3><p>&emsp;&emsp;矢量是一种显而易见的模式表征。</p><h3 id="字符串的模式模式集合表征"><a href="#字符串的模式模式集合表征" class="headerlink" title="字符串的模式模式集合表征"></a>字符串的模式模式集合表征</h3><p>&emsp;&emsp;字符串可以看做某种语言的句子，例如一个DNA序列或蛋白质序列。举例说明，某遗传因子可以被分别由A、G、C和T表示的腺嘌呤、鸟嘌呤、胞嘌呤和胸嘌呤四种含氢基构成的染色体DNA的一片区域。基因数据被排列在一个序列中，例如<br>    GATTGTCAAG…</p><h3 id="模式集合的逻辑表述方法"><a href="#模式集合的逻辑表述方法" class="headerlink" title="模式集合的逻辑表述方法"></a>模式集合的逻辑表述方法</h3><p>&emsp;&emsp;(此处无内容)</p><h3 id="模式的模糊集合及粗糙集合"><a href="#模式的模糊集合及粗糙集合" class="headerlink" title="模式的模糊集合及粗糙集合"></a>模式的模糊集合及粗糙集合</h3><p>&emsp;&emsp;模糊可以用在无法精确表述的情况下，因此可以用来对主观的、不完备的以及不精确的数据进行建模。在一个模糊集合中，对象从属于成员值从0至1变化的集合。</p><h3 id="基于树和图的表征"><a href="#基于树和图的表征" class="headerlink" title="基于树和图的表征"></a>基于树和图的表征</h3><p>&emsp;&emsp;树和图是用来表征模式和模式类别的常见数据结构。树或图中的每一个节点可以表示一个或多个模式。</p><ol><li>最小生成树</li><li>频繁模式树</li></ol><h2 id="模式聚类的表征"><a href="#模式聚类的表征" class="headerlink" title="模式聚类的表征"></a>模式聚类的表征</h2><p>&emsp;&emsp;聚类是将含有相似特征的模式组在一起并将不同特征的对象放在不同的组的过程。这里有两个数据结构，一个是模式的划分P，另一个是一系列簇的代表C。</p><h3 id="相似度量方法"><a href="#相似度量方法" class="headerlink" title="相似度量方法"></a>相似度量方法</h3><p>&emsp;&emsp;为了对模式进行分类，模式之间需要相互比较并与某个标准进行比较。</p><ol><li>基于距离的度量方法<br> &emsp;&emsp;一个量化的方法具有如下性质<ul><li>正自反性d(x,y)=0</li><li>对称性d(x,y)=d(y,x)</li><li>三角不等性d(x,y)&lt;=d(x,z)+d(z,y)<br>&emsp;&emsp;常用的度量方法成为民科夫斯基计量，形式如下<br>$$d^m(X,Y)=(\sum_{k=1}^d|x_k-y_k|^m)^{\frac{1}{m}}$$<br>&emsp;&emsp;当m为1时称它为曼哈顿距离或$L_1$距离。最常用的距离为当m的值为2时的欧式距离或$L_2$距离。可以得到<br>$$d^2(X,Y)=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+…+(x_d-y_d)^2}$$<br>在这种模式下，$L_{\inf}$为<br>$$d^{\infty}=max_{k=1,…,d}|x_k-y_k|$$<br>当使用距离度量时，应当保证所有的特征有相同的取值范围，舍弃那些被认为更重要的具有更大范围的属性，就好像赋予它更大的权重。为保证所有特征具有相同的范围，应当采取特征值标准化。<br>&emsp;&emsp;马氏距离也是一种在分类中常见的距离度量，它可由下式得出<br>$$d^2(X,Y)=(X-Y)^T\sum^{-1}(X-Y)$$<br>其中$\sum$是西方差矩阵。</li></ul></li><li>基于加权距离的度量方法<br> &emsp;&emsp;当认为某个属性更重要时，可以再它们的值上加权重。加权的距离度量形式如下<br> $$d(X,Y)=(\sum_{k-1}^d\omega_k*(x_k-y_k)^m)^{\frac{1}{m}}$$<br> 其中$\omega_k$是第k维相关的权重。</li><li>非度量相似函数<br> &emsp;&emsp;相似函数在此范畴下既不遵从三角不等式也不遵从对称性。这些相似函数往往在图像以及数据串中十分有效。它们对异常值和极端噪声数据具有鲁棒性。<br> &emsp;&emsp;一种不具有对称性的非量化聚利是发散度距离(KL距离)。它是一个从“真实”概念分布p到”目标”概念分布q的自然距离函数。对于离散概率分布，如果$p={p_1,..p_n}$并且$q={q_1,…q_n}$，那么KL距离定义为<br> $$KL(p,q)=\sum_ip_i\log_2(\frac{p_i}{q_i})$$<br> 对于连续概率密度，用积分代替求和。</li><li>编辑距离<br> &emsp;&emsp;编辑距离计算两个字符串之间的距离，它也称为莱文斯汀距离。</li><li>互近邻距离</li><li>概念内聚性</li><li>核函数<br> &emsp;&emsp;核函数可以用来描述模式x和y之间的距离。<ol><li>多项式核函数。x和y之间的相似度可以用多项式核函数表述为$$K(x,y)=\epsilon(x)^{<code>}\epsilon(y)=(x^{</code>}y+1)^2$$<br> 通过这种方法，输入空间中的线性相关矢量转换为核空间的线性无关矢量。</li><li>径向基(RBF)核函数。核定义如下$$K(x,y)=\exp^{\frac{-|x-y|^2}{2\sigma^2}}$$</li></ol></li></ol><h2 id="模式的尺寸"><a href="#模式的尺寸" class="headerlink" title="模式的尺寸"></a>模式的尺寸</h2><p>&emsp;&emsp;样本的大小取决于所考虑的属性。</p><h3 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h3><p>&emsp;&emsp;数据标准化的过程可以使所有的模式具有统一的尺度。</p><h3 id="相似度度量的选择方法"><a href="#相似度度量的选择方法" class="headerlink" title="相似度度量的选择方法"></a>相似度度量的选择方法</h3><p>&emsp;&emsp;相似度计算可以处理不等长度问题，一个相似度计算的例子为编辑距离。</p><h2 id="数据集合的抽象"><a href="#数据集合的抽象" class="headerlink" title="数据集合的抽象"></a>数据集合的抽象</h2><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>&emsp;&emsp;特征提取涉及到对所需样本特征的发掘和提取。特征操作从数据中提取特征以识别或解析有意义的信息。这在图像中有重大意义，因为此时特征提取需要自动识别多种特征。特征提取是模式识别中一部重要的预处理步骤。</p><h3 id="Fisher线性判别法"><a href="#Fisher线性判别法" class="headerlink" title="Fisher线性判别法"></a>Fisher线性判别法</h3><p>&emsp;&emsp;Fisher线性判别法将高纬度数据映射到一条线上并在这个空间上施行分类。如果有两个类别，那么映射最大化了两个类别之间的均值的距离并且最小化了美衣美类别中的方差。能够最大化所有线性映射V的Fisher准则定义如下：$$J(V)=\frac{|mean_1-mean_2|^2}{s_1^2+s_2^2}$$<br>其中，$mean_1$和$mean_2$分别代表类别1和类别2样本的均值；$s_1$与$s_2$分别代表了各自的方法。</p><h3 id="主成分分析法"><a href="#主成分分析法" class="headerlink" title="主成分分析法"></a>主成分分析法</h3><p>&emsp;&emsp;主成分分析(PCA)是一个数学方法，它将大量相关变量转化为小数量的不相关变量，这些不相关变量称为主要成分。最主要成分尽可能地反映了数据中的变化性，次之成分尽可能地反映了剩余的变化。PCA在更低纬的空间内找出了最精确的数据代表。数据被映射到方差最大的方向上。</p><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>&emsp;&emsp;用于分类的特征并不总是有意义的，移除那些对于分类没用的特征，可能会得到哦更高的分类准确度。特征选择则可以加速分类过程，同时确保分类精确是最佳的。特征选择有如下特点</p><ul><li>减少样本分类以及分类设计的开销、维度简化等。使用一个有限的特征集简化样本的描述以及分类复杂度。因此分类将变得更快，使用更少的存储器。</li><li>分类精度的提高。分类精度的提高取决于以下因素<ol><li>样本的大小、特征数量、分类复杂度</li><li>在同一个光以及和的情况下，随着维度的增加，到最近点的距离逐步接近最远点的距离。<br>所有特征的选择基本上都是遍历不同的特征子集。</li></ol></li></ul><h3 id="穷举搜索法"><a href="#穷举搜索法" class="headerlink" title="穷举搜索法"></a>穷举搜索法</h3><p>&emsp;&emsp;穷举搜索法是解决所有特征选择问题的最直接方法，搜索所有特征子集并且找到最佳子集。</p><h3 id="分支定界搜索法"><a href="#分支定界搜索法" class="headerlink" title="分支定界搜索法"></a>分支定界搜索法</h3><p>&emsp;&emsp;分支定界搜索法通过利用在获得最终准则值过程中所产生的一些中间结果避免了穷举搜索。</p><h3 id="最优特征选择法"><a href="#最优特征选择法" class="headerlink" title="最优特征选择法"></a>最优特征选择法</h3><p>&emsp;&emsp;最有特征选择法是一种只选择最有特征的简单方法。独立计算所有特体特征，并选择m个最佳特征。这种方法虽然简单，但是很可能失败，由于特征之间并非完全独立。</p><h3 id="顺序选择法"><a href="#顺序选择法" class="headerlink" title="顺序选择法"></a>顺序选择法</h3><h3 id="浮动顺序选择法"><a href="#浮动顺序选择法" class="headerlink" title="浮动顺序选择法"></a>浮动顺序选择法</h3><h3 id="最大最小特征选择法"><a href="#最大最小特征选择法" class="headerlink" title="最大最小特征选择法"></a>最大最小特征选择法</h3><h3 id="随机搜索法"><a href="#随机搜索法" class="headerlink" title="随机搜索法"></a>随机搜索法</h3><h3 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h3><h2 id="分类分析方法"><a href="#分类分析方法" class="headerlink" title="分类分析方法"></a>分类分析方法</h2><p>&emsp;&emsp;在使用分类器之前，有必要评估它的表现。需要考虑的分类器参数列举如下</p><ol><li>分类器的准确性</li><li>设计时间和分类时间</li><li>所需要的空间</li><li>解释说明能力<br>如果一种对样本的分类方法对使用者解释得很清楚，那么它的解释说明能力就很好。</li><li>噪声容限<br>它是指一个分类器处理异常值和错误分类样本的能力。</li></ol><p>&emsp;&emsp;要想评估一个分类方法有多好，可以凭他提训练集本身。不同的检验方法列举如下</p><ol><li>保持法</li><li>随机子抽样</li><li>分叉校验</li><li>拔靴法</li></ol><h2 id="聚类分析方法"><a href="#聚类分析方法" class="headerlink" title="聚类分析方法"></a>聚类分析方法</h2><h1 id="最近邻分类器"><a href="#最近邻分类器" class="headerlink" title="最近邻分类器"></a>最近邻分类器</h1><h1 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h1><h1 id="隐式马尔科夫模型"><a href="#隐式马尔科夫模型" class="headerlink" title="隐式马尔科夫模型"></a>隐式马尔科夫模型</h1><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h1 id="多分类组合"><a href="#多分类组合" class="headerlink" title="多分类组合"></a>多分类组合</h1><h1 id="聚类方法"><a href="#聚类方法" class="headerlink" title="聚类方法"></a>聚类方法</h1><h1 id="本书总结"><a href="#本书总结" class="headerlink" title="本书总结"></a>本书总结</h1><h1 id="应用实例：手写数字识别"><a href="#应用实例：手写数字识别" class="headerlink" title="应用实例：手写数字识别"></a>应用实例：手写数字识别</h1><h2 id="数字数据的描述"><a href="#数字数据的描述" class="headerlink" title="数字数据的描述"></a>数字数据的描述</h2><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h2 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h2><h2 id="典型模型的选择"><a href="#典型模型的选择" class="headerlink" title="典型模型的选择"></a>典型模型的选择</h2><h2 id="识别结果"><a href="#识别结果" class="headerlink" title="识别结果"></a>识别结果</h2>]]></content>
    
    <summary type="html">
    
      《模式识别：算法及其实现方法》是一本很好的入门书，偏向于理论方向，能够学习模式识别的分类与聚类相关的基础知识及其原理。
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="深度学习" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="MachineLearning" scheme="https://xinshiyou.github.io/tags/MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>DataX之SplitPK原理</title>
    <link href="https://xinshiyou.github.io/2018/07/25/DataX%E4%B9%8BSplitPK%E5%8E%9F%E7%90%86/"/>
    <id>https://xinshiyou.github.io/2018/07/25/DataX%E4%B9%8BSplitPK%E5%8E%9F%E7%90%86/</id>
    <published>2018-07-25T13:10:10.000Z</published>
    <updated>2020-06-01T04:12:27.101Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;DataX的简单介绍，可以参考<a href="https://blog.csdn.net/awdac/article/details/80822233" target="_blank" rel="noopener">Alibaba DataX调研使用</a> ，这里不做详细介绍。在同步数据时，如果数据源是RDBMS，存在配置参数<strong>splitPk</strong>。那么该参数是如何起作用的，如何配置？</p><h2 id="配置方式"><a href="#配置方式" class="headerlink" title="配置方式"></a>配置方式</h2><p>&emsp;&emsp;<strong>splitPk</strong>的配置方式，主要参考(DataX文档)[<a href="https://github.com/alibaba/DataX]。" target="_blank" rel="noopener">https://github.com/alibaba/DataX]。</a></p><ol><li>描述：<br> &emsp;&emsp;MysqlReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。<br> &emsp;&emsp;推荐splitPk用户使用表主键，因为表主键<strong>通常情况下比较均匀</strong>，因此切分出来的分片也不容易出现数据热点。</li><li>目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！</li></ol><h2 id="作用原理"><a href="#作用原理" class="headerlink" title="作用原理"></a>作用原理</h2><h2 id="优点缺点"><a href="#优点缺点" class="headerlink" title="优点缺点"></a>优点缺点</h2><p>&emsp;&emsp;由于DataX是一款通用的插件式异构数据同步工具，因此在处理RDBMS时组装的SQL具有通用性，没有针对个别数据库做处理。因此这就无可避免的造成了解决方案的非最优化性，一些数据库可能会存在更优化的处理方式。</p><p>&emsp;&emsp;DataX的<strong>spliPk</strong>配置，假设切分字段为比较均匀的情况，如果切分字段恰好分布不均匀，那么DataX同步数据存在问题。</p>]]></content>
    
    <summary type="html">
    
      DataX是一款非常受欢迎的异构数据同步工具，了解其原理有助于更好的使用该工具。
    
    </summary>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/categories/Java/"/>
    
    
      <category term="DataX" scheme="https://xinshiyou.github.io/tags/DataX/"/>
    
      <category term="调研" scheme="https://xinshiyou.github.io/tags/%E8%B0%83%E7%A0%94/"/>
    
  </entry>
  
  <entry>
    <title>Maven之Pom配置学习总结</title>
    <link href="https://xinshiyou.github.io/2018/07/17/Maven%E4%B9%8BPom%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <id>https://xinshiyou.github.io/2018/07/17/Maven%E4%B9%8BPom%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</id>
    <published>2018-07-17T06:42:00.000Z</published>
    <updated>2020-06-01T05:23:02.759Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><p>&emsp;&emsp;POM中可以配置一些<em>properties</em>，这些属性一般而言实在各种pom中使用，但也可以在一些配置文件中使用，例如</p><div class="hljs"><pre class=" language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"><code class="language-hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># pom文件配置</span></span><properties><database.driver>com.mysql.jdbc.Driver</database.driver><database.url>jdbc:mysql://localhost:3306/database?autoReconnect=true</database.url><database.username>myusername</database.username><database.password>mypassword</database.password></properties><profiles><profile><id>qa</id><properties><database.driver>com.mysql.jdbc.Driver</database.driver><database.url>jdbc:mysql://qadb01:3306/database?autoReconnect=true</database.url><database.username>qauser</database.username><database.password>qapassword</database.password></properties></profile><profile><id>production</id><properties><database.driver>com.mysql.jdbc.Driver</database.driver><database.url>jdbc:mysql://pdb01:3306/database?autoReconnect=true</database.url><database.username>produser</database.username><database.password>prodpassword</database.password></properties></profile></profiles><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># properties</span></span>driverClassName=$&#123;database.driver&#125;url=$&#123;database.url&#125;username=$&#123;database.username&#125;password=$&#123;database.password&#125;</code></pre></div><p>&emsp;&emsp;通过如上配置，默认情况下直接使用外层的<em>properties</em>属性，但也可以通过制定来更改为我们需要的配置</p><div class="hljs"><pre class=" language-hljs shell"><code class="language-hljs shell">mvn clean install -Pqa/-Pproduction</code></pre></div><p>通过编译之后，可以看到我们设置的变量替换为pom文件中的变量。</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="各种plugin"><a href="#各种plugin" class="headerlink" title="各种plugin"></a>各种plugin</h2><h3 id="maven-antrun-plugin"><a href="#maven-antrun-plugin" class="headerlink" title="maven-antrun-plugin"></a>maven-antrun-plugin</h3><p><strong>maven-antrun-plugin</strong>，主要是用来从Maven内运行Ant任务的功能，甚至可以将Ant脚本嵌入到POM。这个插件不是提供污染POM的手段意图，因此它鼓励所有Ant任务移动到build.xml文件并使用Ant的POM调用它。这个插件的主要目的之一是方便从Ant基础项目迁移到Maven。</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin><artifactId>maven-antrun-plugin</artifactId><executions><execution><phase>validate</phase><goals><goal>run</goal></goals><configuration><tasks><echo>$&#123;PATH&#125;=$&#123;env.PATH&#125;</echo><echo>User<span class="hljs-string">'s Home Directory: $&#123;user.home&#125;</echo></span><echo>Project's Base Director: $&#123;basedir&#125;</echo></tasks></configuration></execution></executions></plugin></code></pre></div><h3 id="maven-clean-plugin"><a href="#maven-clean-plugin" class="headerlink" title="maven-clean-plugin"></a>maven-clean-plugin</h3><p><strong>maven-clean-plugin</strong>最常用的maven插件，主要用于清理target文件等内容。</p><h3 id="maven-resources-plugin"><a href="#maven-resources-plugin" class="headerlink" title="maven-resources-plugin"></a>maven-resources-plugin</h3><p><strong>maven-resources-plugin</strong>用于替换资源文件中的占位符。</p><h3 id="maven-install-plugin"><a href="#maven-install-plugin" class="headerlink" title="maven-install-plugin"></a>maven-install-plugin</h3><p><strong>maven-install-plugin</strong>用于安装jar包，将生成的jar文件复制到maven的本地仓库中。</p><h3 id="maven-compiler-plugin"><a href="#maven-compiler-plugin" class="headerlink" title="maven-compiler-plugin"></a>maven-compiler-plugin</h3><p><strong>maven-compiler-plugin</strong>编译Java源码，一般只需要设置编译的JDK版本即可。</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin>    <groupId>org.apache.maven.plugins</groupId>    <artifactId>maven-compiler-plugin</artifactId>    <version>3.6.0</version>    <configuration>        <source>1.8</source>        <target>1.8</target>    </configuration></plugin></code></pre></div><h3 id="maven-dependency-plugin"><a href="#maven-dependency-plugin" class="headerlink" title="maven-dependency-plugin"></a>maven-dependency-plugin</h3><p><strong>maven-dependency-plugin</strong>用于将依赖的jar包复制到指定的文件夹里去。</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin>    <groupId>org.apache.maven.plugins</groupId>    <artifactId>maven-dependency-plugin</artifactId>    <version>2.10</version>    <executions>        <execution>            <id>copy-dependencies</id>            <phase>package</phase>            <goals>                <goal>copy-dependencies</goal>            </goals>            <configuration>                <outputDirectory>$&#123;project.build.directory&#125;/lib</outputDirectory>            </configuration>        </execution>    </executions></plugin></code></pre></div><h3 id="maven-jar-plugin"><a href="#maven-jar-plugin" class="headerlink" title="maven-jar-plugin"></a>maven-jar-plugin</h3><p><strong>maven-jar-plugin</strong>的主要作用是打包成可运行的jar，打包时制定manifest参数。</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin>    <groupId>org.apache.maven.plugins</groupId>    <artifactId>maven-jar-plugin</artifactId>    <version>2.4</version>    <configuration>        <archive>            <manifest>                <addClasspath>true</addClasspath>                <classpathPrefix>/data/lib</classpathPrefix>                <mainClass>com.zhang.spring.App</mainClass>            </manifest>        </archive>    </configuration></plugin></code></pre></div><h3 id="maven-shade-plugin"><a href="#maven-shade-plugin" class="headerlink" title="maven-shade-plugin"></a>maven-shade-plugin</h3><p><strong>maven-shade-plugin</strong><br>用于把多个jar包，打成1个jar包。一般Java项目都会依赖其他第三方jar包，最终打包时，希望把其他jar包包含在一个jar包里</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin>    <groupId>org.apache.maven.plugins</groupId>    <artifactId>maven-shade-plugin</artifactId>    <version>2.4.3</version>    <executions>        <execution>            <phase>package</phase>            <goals>                <goal>shade</goal>            </goals>            <configuration>                <transformers>                    <transformer                        implementation=<span class="hljs-string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>>                        <manifestEntries>                            <Main-Class>com.meiyou.topword.App</Main-Class>                            <X-Compile-Source-JDK>$&#123;maven.compile.source&#125;</X-Compile-Source-JDK>                            <X-Compile-Target-JDK>$&#123;maven.compile.target&#125;</X-Compile-Target-JDK>                        </manifestEntries>                    </transformer>                </transformers>            </configuration>        </execution>    </executions></plugin></code></pre></div><h3 id="maven-surefire-plugin"><a href="#maven-surefire-plugin" class="headerlink" title="maven-surefire-plugin"></a>maven-surefire-plugin</h3><p><strong>maven-surefire-plugin</strong>主要使用来测试Maven项目的源码，能够兼容Junit3、Junit4以及TestNG等框架。默认情况下，maven-surefire-plugin的Test目标会自动测试源码路径下所有符合一组命名模式的测试类。</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java"><plugin>      <groupId>org.apache.maven.plugins</groupId>      <artifactId>maven-surefire-plugin</artifactId>      <version>2.5</version>      <configuration>          <includes>              <include>**<span class="hljs-comment">/*Tests.java</include>  </span><span class="hljs-comment">        </includes>  </span><span class="hljs-comment">        <excludes>  </span>            <exclude>**/*ServiceTest.java</exclude>              <exclude>**/TempDaoTest.java</exclude>          </excludes>      </configuration>  </plugin></code></pre></div><h3 id="groovy-maven-plugin"><a href="#groovy-maven-plugin" class="headerlink" title="groovy-maven-plugin"></a>groovy-maven-plugin</h3><p><strong>groovy-maven-plugin</strong>主要是用于Maven编译Groovy源代码。</p><h3 id="jruby-maven-plugin"><a href="#jruby-maven-plugin" class="headerlink" title="jruby-maven-plugin"></a>jruby-maven-plugin</h3><p><strong>jruby-maven-plugin</strong>主要用于ruby的源代码编译。</p>]]></content>
    
    <summary type="html">
    
      Maven的Pom配置灵活多样，本文主要是学习POM配置的一些笔记。
    
    </summary>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/categories/Java/"/>
    
    
      <category term="总结" scheme="https://xinshiyou.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="Maven" scheme="https://xinshiyou.github.io/tags/Maven/"/>
    
  </entry>
  
  <entry>
    <title>分布式Java应用读书笔记</title>
    <link href="https://xinshiyou.github.io/2018/07/10/%E5%88%86%E5%B8%83%E5%BC%8FJava%E5%BA%94%E7%94%A8%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://xinshiyou.github.io/2018/07/10/%E5%88%86%E5%B8%83%E5%BC%8FJava%E5%BA%94%E7%94%A8%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2018-07-10T11:38:49.000Z</published>
    <updated>2020-06-08T07:19:49.892Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式Java应用"><a href="#分布式Java应用" class="headerlink" title="分布式Java应用"></a>分布式Java应用</h1><p><img src="001.png" srcset="/img/loading.gif" alt="分布式Java应用"></p><a id="more"></a><h2 id="基于消息方式实现系统间的通信"><a href="#基于消息方式实现系统间的通信" class="headerlink" title="基于消息方式实现系统间的通信"></a>基于消息方式实现系统间的通信</h2><p>&emsp;&emsp;当系统之间要通信时，就向外发送消息，消息可以是字节流、字节数组，甚至是Java对象，其他系统接收到消息后进行相应的业务处理。消息方式的系统间通信，通常是基于网络协议实现，常用的实现系统间通信的协议有:TCP/IP和UDP/IP。</p><p>&emsp;&emsp;TCP/IP和UDP/IP可用于完成数据的传输，但要完成系统间的通信，还需要对数据进行处理。从程序角度而言，BIO就是发起IO的读或写操作时，均为阻塞方式，只有当程序读到了流或将流写入操作系统后，才会释放资源。</p><p>&emsp;&emsp;NIO是基于事件驱动思想的，实现上通常采用Reactor模式，从程序角度而言，当发起IO的读或写操作时，是阻塞的；当socket有流可读或可写入socket时，操作熊会相应的通知到应用程序进行处理。对网络IO而言，主要有链接建立、流读取或流写入三种事件，Linux2.6以后的版本采用了epoll方式来实现NIO。</p><p>&emsp;&emsp;另外一种方式AIO。AIO为异步IO方式，同样基于事件驱动思想，实现上采用了Proactor模式。与NIO相比，AIO具有以下特点</p><ul><li>简化了程序的编写：流的读取与写入都有操作系统来完成</li><li>省去了NIO程序要遍历事件通知队列(selector)的代价</li></ul><h2 id="基于远程调用方式实现系统间的通信"><a href="#基于远程调用方式实现系统间的通信" class="headerlink" title="基于远程调用方式实现系统间的通信"></a>基于远程调用方式实现系统间的通信</h2><h1 id="大型分布式Java应用和SOA"><a href="#大型分布式Java应用和SOA" class="headerlink" title="大型分布式Java应用和SOA"></a>大型分布式Java应用和SOA</h1><h2 id="基于SCA实现SOA平台"><a href="#基于SCA实现SOA平台" class="headerlink" title="基于SCA实现SOA平台"></a>基于SCA实现SOA平台</h2><h2 id="基于ESB实现SOA平台"><a href="#基于ESB实现SOA平台" class="headerlink" title="基于ESB实现SOA平台"></a>基于ESB实现SOA平台</h2><h2 id="基于Tuscany实现SOA平台"><a href="#基于Tuscany实现SOA平台" class="headerlink" title="基于Tuscany实现SOA平台"></a>基于Tuscany实现SOA平台</h2><h2 id="基于Mule实现SOA平台"><a href="#基于Mule实现SOA平台" class="headerlink" title="基于Mule实现SOA平台"></a>基于Mule实现SOA平台</h2><h1 id="深入理解JVM"><a href="#深入理解JVM" class="headerlink" title="深入理解JVM"></a>深入理解JVM</h1><p><img src="003.png" srcset="/img/loading.gif" alt="深入理解JVM"></p><h2 id="Java代码的执行机制"><a href="#Java代码的执行机制" class="headerlink" title="Java代码的执行机制"></a>Java代码的执行机制</h2><h2 id="JVM内存管理"><a href="#JVM内存管理" class="headerlink" title="JVM内存管理"></a>JVM内存管理</h2><p>&emsp;&emsp;Java开发人员不需要显式分配内存和回收内存，而是由JVM来自动管理内存的分配及回收。这对开发人员而言大大降低了编写程序的难度，但副作用可能是在不知不觉中浪费了很多内存，导致JVM花费很多时间进行内存的回收。另外还会带来的副作用是由于不清楚JVM内存的分配和回收机制，造成内存泄漏，最终导致JVM内存不够用。因此对于Java开发人员而言，不能因为JVM自动内存管理就不掌握内存分配和回收的知识了。</p><h3 id="内存空间"><a href="#内存空间" class="headerlink" title="内存空间"></a>内存空间</h3><p>&emsp;&emsp;SunJDK在实现时遵守JVM规范，将内存空间划分为方法区、堆、本地方法栈、PC寄存器及JVM方法栈。</p><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><p>&emsp;&emsp;方法区存在了要记在的类的信息、类中的静态变量、类中定义为final类型的常亮、类中的Field信息、类中的方法信息，当开发人员在程序中通过Class对象的getName、isInterface等方法来获取信息时，这些数据都来自于方法区域。方法区域也是全局共享的，在一定条件下他也会被GC，当方法区域要使用的内存超过其允许的大小是，会抛出OutOfMemory的错误信息。</p><p>&emsp;&emsp;在SunJDK中这块区域对应Permanet Generation，又称为持久代，默认最小值为16MB，最大值为64MB，其可以通过-XX:PermSize及-XX:MaxPermSize来制定最小值和最大值。</p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>&emsp;&emsp;堆用于存储对象实例和数组值，可以认为java中所有通过new创建的对象的内存都在此分配，Hep中对象所占的内存由GC进行回收，在32位操作系统上最大为2GB。在64位操作系统上没有限制，其大小可以通过-Xmx和-Xms来控制。</p><p>&emsp;&emsp;为了让内存回收更加高效，SunJDK自1.2开始对堆采用了分代管理的方式。</p><ol><li>新生代(New Generation)<br> &emsp;&emsp;大多数情况下，java层序中新建的对象都从新生代中分配内存，新生代由Eden Space和两块相同大小的SurvivorSpace构成，可通过-Xmn参数来制定新生代的大小。</li><li>旧生代(Old Generation或Tenuring Generation))<br> &emsp;&emsp;旧生代用户存放新生代中经过多次垃圾回收仍然存货的对象，例如缓存对象，新建的对象也有可能在就剩代中直接分配内存。主要有两种情况：一种为大对象，另一种为大的数组对象，且数组中无引用外部对象。</li></ol><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>&emsp;&emsp;本地方法栈用于支持native方法的执行，存储了每个native方法调用的状态，在SunJDK的实现中本地方法栈和JVM方法栈是同一个。</p><h4 id="PC寄存器和JVM方法栈"><a href="#PC寄存器和JVM方法栈" class="headerlink" title="PC寄存器和JVM方法栈"></a>PC寄存器和JVM方法栈</h4><p>&emsp;&emsp;每个线程均会创建PC寄存器和JVM方法栈，PC寄存器占用的可能为CPU寄存器或操作系统内存，JVM方法栈占用的为操作系统内存，JVM方法栈为线程私有，其在内存分配上非常高效。</p><p>&emsp;&emsp;当JVM方法栈空间不足时，会抛出StackOverflowError的错误，在SunJDK中可以通过-Xss来制定其大小。</p><h2 id="JVM线程资源同步与交互机制"><a href="#JVM线程资源同步与交互机制" class="headerlink" title="JVM线程资源同步与交互机制"></a>JVM线程资源同步与交互机制</h2><h1 id="分布式Java应用和Sun-JDK类库"><a href="#分布式Java应用和Sun-JDK类库" class="headerlink" title="分布式Java应用和Sun JDK类库"></a>分布式Java应用和Sun JDK类库</h1><h2 id="集合包"><a href="#集合包" class="headerlink" title="集合包"></a>集合包</h2><h2 id="并发包"><a href="#并发包" class="headerlink" title="并发包"></a>并发包</h2><h2 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h2><h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><h2 id="寻找性能瓶颈"><a href="#寻找性能瓶颈" class="headerlink" title="寻找性能瓶颈"></a>寻找性能瓶颈</h2><h2 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h2><h1 id="构架高可用的系统"><a href="#构架高可用的系统" class="headerlink" title="构架高可用的系统"></a>构架高可用的系统</h1><h2 id="避免系统出现单点"><a href="#避免系统出现单点" class="headerlink" title="避免系统出现单点"></a>避免系统出现单点</h2><h2 id="提高应用自身的可用性"><a href="#提高应用自身的可用性" class="headerlink" title="提高应用自身的可用性"></a>提高应用自身的可用性</h2><h1 id="构建可伸缩的系统"><a href="#构建可伸缩的系统" class="headerlink" title="构建可伸缩的系统"></a>构建可伸缩的系统</h1><h2 id="垂直伸缩"><a href="#垂直伸缩" class="headerlink" title="垂直伸缩"></a>垂直伸缩</h2><h2 id="水平伸缩"><a href="#水平伸缩" class="headerlink" title="水平伸缩"></a>水平伸缩</h2>]]></content>
    
    <summary type="html">
    
      《分布式Java应用》读书笔记
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Netty权威指南读书笔记</title>
    <link href="https://xinshiyou.github.io/2018/07/09/Netty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://xinshiyou.github.io/2018/07/09/Netty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2018-07-09T11:38:49.000Z</published>
    <updated>2020-06-08T07:07:01.465Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;Netty权威指南，是一本广受欢迎的Netty书籍。博主研读的是2014年6月第一版，第二次印刷的书本。</p><a id="more"></a><h1 id="基础篇-走进Java-NIO"><a href="#基础篇-走进Java-NIO" class="headerlink" title="基础篇  走进Java NIO"></a>基础篇  走进Java NIO</h1><h2 id="Java的I-O演进之路"><a href="#Java的I-O演进之路" class="headerlink" title="Java的I/O演进之路"></a>Java的I/O演进之路</h2><h3 id="I-O入门"><a href="#I-O入门" class="headerlink" title="I/O入门"></a>I/O入门</h3><p>&emsp;&emsp;Java1.4之前，Java的I/O还不完善，开发人员在开发该性能I/O时，会遇到困难：</p><ul><li>没有缓冲区，I/O性能存在问题</li><li>没有Channe概念，只有输入/输出流</li><li>同步阻塞I/O(BIO)通讯，导致通讯线程长时间阻塞</li><li>支持字符集有限，硬件可移植性不好</li></ul><p>&emsp;&emsp;高性能开发领域，很长一段时间里一直被C++/C长期占据，Java的BIO被大家所诟病。</p><h4 id="Linux网络I-O模型"><a href="#Linux网络I-O模型" class="headerlink" title="Linux网络I/O模型"></a>Linux网络I/O模型</h4><ol><li>阻塞I/O模型</li><li>费阻塞I/O模型</li><li>I/O复用模型</li><li>信号驱动I/O模型</li><li>异步I/O模型</li></ol><h4 id="I-O多路复用技术"><a href="#I-O多路复用技术" class="headerlink" title="I/O多路复用技术"></a>I/O多路复用技术</h4><p>&emsp;&emsp;I/O多路复用的应用场景</p><ul><li>服务器需要同时处理多个监听状态或连接状态的套接字</li><li>服务器需要同时处理多种网络协议的套接字</li></ul><p>&emsp;&emsp;Linux网络I/O模型总结：select–&gt;epoll</p><ol><li>支持一个进程打开的socket描述符不受限制(仅受限于系统的最大文件句柄数)</li><li>I/O效率不会随着FD数目的增加而线性下降</li><li>使用mmap加速内核与用户空间的消息传递</li><li>epoll的API更加简单</li></ol><h3 id="Java的I-O演进"><a href="#Java的I-O演进" class="headerlink" title="Java的I/O演进"></a>Java的I/O演进</h3><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h2 id="NIO入门"><a href="#NIO入门" class="headerlink" title="NIO入门"></a>NIO入门</h2><p>&emsp;&emsp;主要讲解BIO、NIO、NIO2.0的使用。主要包括</p><ol><li>传统的BIO模型</li><li>基于NIO的费阻塞编程</li><li>基于NIO2.0的异步费阻塞(AIO)编程</li><li>为什么需要使用NIO</li><li>为什么选择Netty</li></ol><h3 id="传统BIO编程"><a href="#传统BIO编程" class="headerlink" title="传统BIO编程"></a>传统BIO编程</h3><p>&emsp;&emsp;使用传统的BIO模型，最大的问题是缺乏伸缩能力，当客户端并发数增加后，服务端的线程个数和客户端的并发访问数呈1：1的正比关系。有线程是JVM非常宝贵的资源，当线程数膨胀之后，系统的性能将急剧下降。</p><h3 id="伪异步IO编程"><a href="#伪异步IO编程" class="headerlink" title="伪异步IO编程"></a>伪异步IO编程</h3><p>&emsp;&emsp;针对BIO模型的一个优化方案是做线程池。通过线程池控制线程数量，并能够灵活的调整并发线程的数量，防止海量并发接入导致线程耗尽。</p><p>&emsp;&emsp;伪异步IO编程实际上是对BIO的一个简单优化，但它并没有从本质上回避BIO的缺点，可能会造成如下后果</p><ol><li>相应缓慢</li><li>线程池技术，前面进入线程池的任务可能会影响后面任务的运行</li><li>线程池满了之后，后续加入任务会被阻塞</li></ol><h3 id="NIO编程"><a href="#NIO编程" class="headerlink" title="NIO编程"></a>NIO编程</h3><p>&emsp;&emsp;NIO概念的理解。一种是New IO，这也是官方的叫法。另外一种是Non-Block IO，即非阻塞IO。</p><h4 id="NIO类库"><a href="#NIO类库" class="headerlink" title="NIO类库"></a>NIO类库</h4><ol><li>缓冲区Buffer</li></ol><ul><li>ByteBuffer</li><li>CharBuffer</li><li>IntBuffer</li><li>LongBuffer</li><li>FloatBuffer</li><li>DoubleBuffer</li></ul><ol start="2"><li>通道Channel<ul><li>网络读写SelectableChannel</li><li>文件操作的FileChannel</li></ul></li><li>多路复用器Selector</li></ol><h3 id="AIO编程"><a href="#AIO编程" class="headerlink" title="AIO编程"></a>AIO编程</h3><p>&emsp;&emsp;NIO2.0引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道通过两种方式获取操作结果</p><ol><li>java.util.concurrent.Future</li><li>在执行异步操作的时候，传入一个java.nio.channel</li></ol><p>&emsp;&emsp;<em>不同模型的比较</em><br>||异步阻塞IO(BIO)|伪异步IO|非阻塞IO(NIO)|异步IO(AIO)|<br>|:-:|:-:|:-:|:-:|:-:|<br>客户端个数：IO线程数|1:1|M:N(M&gt;N)|M:1(1个IO线程处理多个客户端进程)|M:0(不需要启动额外的线程，被动回调)|<br>IO类型(阻塞)|阻塞IO|阻塞IO|阻塞IO|非阻塞IO|非阻塞IO|<br>IO类型(同步)|同步IO|同步IO|同步IO(多路复用)|异步IO|<br>API使用难度|简单|简单|非常复杂|复杂|<br>调试难度|简单|简答|复杂|复杂|<br>可靠性|非常差|差|高|高|<br>吞吐量|低|中|高|高|</p><h3 id="选择Netty的理由"><a href="#选择Netty的理由" class="headerlink" title="选择Netty的理由"></a>选择Netty的理由</h3><ol><li>为什么不选择原生Java NIO</li></ol><ul><li>NIO的类库和API使用复杂</li><li>具备额外技能作铺垫</li><li>可靠性能差，工作难度较大</li><li>JDK NIO存在BUG</li></ul><ol start="2"><li>为什么选择Netty</li></ol><ul><li>API使用简单，开发门槛较低</li><li>功能强大，预支了多种解码器，支持多种主流协议</li><li>定制能力强</li><li>性能高</li><li>成熟、稳定</li><li>社区活跃，班底迭代周期短，发现的BUG被及时修复</li></ul><h1 id="入门篇-Netty-NIO开发指南"><a href="#入门篇-Netty-NIO开发指南" class="headerlink" title="入门篇 Netty NIO开发指南"></a>入门篇 Netty NIO开发指南</h1><h2 id="Netty入门应用"><a href="#Netty入门应用" class="headerlink" title="Netty入门应用"></a>Netty入门应用</h2><p>&emsp;&emsp;使用Netty实现TimeServer服务器端与客户端通讯服务</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java">## 服务器端代码<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TimerServer</span></span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">bind</span><span class="hljs-params">(<span class="hljs-keyword">int</span> port)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        <span class="hljs-comment">// 配置服务端的NIO线程组</span>        EventLoopGroup bossGroup = <span class="hljs-keyword">new</span> NioEventLoopGroup();        EventLoopGroup workGroup = <span class="hljs-keyword">new</span> NioEventLoopGroup();        <span class="hljs-keyword">try</span>&#123;            ServerBootstrap b = <span class="hljs-keyword">new</span> ServerBootstrap();            b.group(bossGroup,workGroup)            .channel(NioServerSocketChannel<span class="hljs-class">.<span class="hljs-keyword">class</span>)</span><span class="hljs-class">            .<span class="hljs-title">option</span>(<span class="hljs-title">ChannelOption</span>.<span class="hljs-title">SO_BACKLOG</span>,1024)</span><span class="hljs-class">            .<span class="hljs-title">childHandler</span>(<span class="hljs-title">new</span> <span class="hljs-title">ChildChannelHandler</span>())</span>;            <span class="hljs-comment">// 绑定端口，同步等待成功</span>            ChannelFuture f = b.bind(port).sync();            <span class="hljs-comment">// 等待服务端口监听端口关闭</span>            f.channel().closeFuture().sync();        &#125;<span class="hljs-keyword">finally</span>&#123;            <span class="hljs-comment">// 优雅退出，释放线层组资源</span>            bossGroup.shutdownGracefully();            workGroup.shutdownGracefully();        &#125;            &#125;    <span class="hljs-keyword">private</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ChildChannelHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ChannelInitializer</span><<span class="hljs-title">SocketChannel</span>></span>&#123;        <span class="hljs-meta">@override</span>        <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">iniitChannel</span><span class="hljs-params">(SocketChannel args0)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;            args0.pipeline()/addLast(<span class="hljs-keyword">new</span> TimeServerHandler());        &#125;    &#125;    <span class="hljs-comment">/**</span><span class="hljs-comment">    * <span class="hljs-doctag">@desc</span> 测试时间服务器</span><span class="hljs-comment">    */</span>     <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;        <span class="hljs-keyword">int</span> port = <span class="hljs-number">8080</span>;        <span class="hljs-keyword">if</span>(args!=<span class="hljs-keyword">null</span> && args.length><span class="hljs-number">0</span>)&#123;            <span class="hljs-keyword">try</span>&#123;                port = Integer.valueOf(args[<span class="hljs-number">0</span>]);            &#125;<span class="hljs-keyword">catch</span>(NumberFormatException e)&#123;                <span class="hljs-comment">// 采用默认值</span>            &#125;        &#125;        <span class="hljs-keyword">new</span> TimeServer().bind(port);    &#125;&#125;<span class="hljs-comment">/** Netty时间服务器服务端TimeServerHandler */</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TimerServerHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ChannelHandlerAdapter</span></span>&#123;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelRead</span><span class="hljs-params">(ChannelHandlerContext ctx,Object msg)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;            Bytebuf buf = (ByteBuf)msg;        <span class="hljs-keyword">byte</span>[] req = <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[buf.readableBytes()];        buf.readBytes(req);        String body = <span class="hljs-keyword">new</span> String(req,<span class="hljs-string">"UTF-8"</span>);        System.out.println(<span class="hljs-string">"The time server receive order : "</span>+body);        String currentTime = <span class="hljs-string">"QUERY TIME ORDER"</span>.equalsIngnoreCase(body)?<span class="hljs-keyword">new</span> java.util.Date(System.currentTimeMilles()).toString():<span class="hljs-string">"BAD ORDER"</span>;                Bytebuf resp = Unpooled.copiedBuffer(currentTime.getBytes());        ctx.write(resp);    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelReadComplete</span><span class="hljs-params">(ChannelHandlerContext ctx)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        ctx.flush();    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">exceptionCaught</span><span class="hljs-params">(ChannelHandlerContext ctx,Throwable cause)</span></span>&#123;        ctx.close();    &#125;&#125;## 客户端代码<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TimeClient</span></span>&#123;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">connect</span><span class="hljs-params">(<span class="hljs-keyword">int</span> port,String host)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        <span class="hljs-comment">// 配置客户端NIO线程组</span>        EventLoopGroup group = <span class="hljs-keyword">new</span> NioEventLoopGroup();        <span class="hljs-keyword">try</span>&#123;            Bootstrap b = <span class="hljs-keyword">new</span> Bootstrap();            g.group(group)            .channel(NioSocketChannel<span class="hljs-class">.<span class="hljs-keyword">class</span>)</span><span class="hljs-class">            .<span class="hljs-title">option</span>(<span class="hljs-title">ChannelOption</span>.<span class="hljs-title">TCP_NODELAY</span>,<span class="hljs-title">trye</span>)</span><span class="hljs-class">            .<span class="hljs-title">handler</span>(<span class="hljs-title">new</span> <span class="hljs-title">ChannelInitializer</span><<span class="hljs-title">SocketHandler</span>>()</span>&#123;                <span class="hljs-meta">@override</span>                <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">initChannel</span><span class="hljs-params">(SocketChannel ch)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;                    ch.pipeline().addLast(<span class="hljs-keyword">new</span> TimeClientChannel());                &#125;            &#125;);             <span class="hljs-comment">// 发起异步连接操作</span>            ChannelFuture f = b.connect(host,port).sync();            <span class="hljs-comment">// 等待客户端链路关闭</span>            f.channel().closeFuture().sync();        &#125;<span class="hljs-keyword">finally</span>&#123;            group.shutdownGracefully();        &#125;    &#125;    <span class="hljs-comment">/** 主要测试方法 */</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(Stirng[] args)</span></span>&#123;        <span class="hljs-keyword">int</span> port = <span class="hljs-number">8080</span>;        <span class="hljs-comment">// read port from input parameters if possible</span>        <span class="hljs-keyword">new</span> TimeClient().bind(port,hostname[ or <span class="hljs-string">"localhost"</span>]);    &#125;&#125;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TimeClientHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ChannelHandlerAdapter</span></span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ByteBuf firstMessage;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">TimeClientHandler</span><span class="hljs-params">()</span></span>&#123;        <span class="hljs-keyword">byte</span>[] req = <span class="hljs-string">"QUERY TIME ORDER"</span>.getBytes();        firstMessage =Unpooled.buffer(req.length);        firstMessage.writeBytes(req);    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelActive</span><span class="hljs-params">(ChannleHandlerContext ctx)</span> </span>&#123;        ctx.writeAndFlush(firstMessage);    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelRead</span><span class="hljs-params">(ChannelHandlerContext ctx,Object msg)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;        ByteBuf buf = (ByteBuf)msg;        <span class="hljs-keyword">byte</span>[] req = <span class="hljs-keyword">new</span> String(buf.readableBytes());        buf.readBytes(req);        String body = <span class="hljs-keyword">new</span> String(req,<span class="hljs-string">"UTF-8"</span>);        System.out.println(<span class="hljs-string">"Now is : "</span>+body);    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">exceptionCaught</span><span class="hljs-params">(ChannelHandlerContext ctx,Throwable cause)</span></span>&#123;        <span class="hljs-comment">// 释放资源</span>        ctx.close();    &#125;&#125;</code></pre></div><h2 id="TCP黏包-拆包的解决之道"><a href="#TCP黏包-拆包的解决之道" class="headerlink" title="TCP黏包/拆包的解决之道"></a>TCP黏包/拆包的解决之道</h2><p>&emsp;&emsp;使用TCP协议，在发送或传输过程中都需要考虑黏包、拆包问题。</p><h3 id="TCP黏包-拆包"><a href="#TCP黏包-拆包" class="headerlink" title="TCP黏包/拆包"></a>TCP黏包/拆包</h3><p>&emsp;&emsp;TCP是一个流协议，是一串没有边界的字符流。TCP底层并不了解上层数据业务数据的含义，他会根据TCP缓冲区的实践情况进行划分，所以在业务上完整的一个包可能会被拆分成多个包进行发送，也有可能多个小包封装成一个大包进行发送，这就是所谓的黏包、拆包问题。</p><p>&emsp;&emsp;问题产生的原因：</p><ol><li>应用程序write的字节大小大于套接字缓冲区大小</li><li>进行MSS大小的TCP分段</li><li>以太网帧的payload大于MTU进行IP分片</li></ol><p>&emsp;&emsp;解决策略</p><ol><li>消息定长，如果不够空位补齐</li><li>在包尾部增加会回车换行符，例如FTP协议</li><li>将消息分为消息头和消息体，消息头中包含消息的总长度</li><li>更复杂的应用层协议</li></ol><h3 id="Netty解决读半包问题"><a href="#Netty解决读半包问题" class="headerlink" title="Netty解决读半包问题"></a>Netty解决读半包问题</h3><p>&emsp;&emsp;为了解决TCP黏包、拆包问题，Netty引入了多种编码解码器用于处理半包问题，只要能够熟悉掌握这些类库，解决黏包问题非常容易。</p><p>&emsp;&emsp;LineBasedFrameDecoder的原理是依次遍历ByteBuf中的可读字节，判断是否存在换行符”\n”、”\r\n”。如果有，就以此为结束位置，从可读索引到结束位置的字节就组成了一行。</p><p>&emsp;&emsp;StringDecorder的功能非常简单，就是将发送的对象转换成字符串，然后继续条用Handler。LineBasedFrameDecoder+StringDecoder组合就是按照行切分的文本解码器，它用来支持解决TCP的黏包和拆包。</p><h2 id="分隔符和定长符解码器的应用"><a href="#分隔符和定长符解码器的应用" class="headerlink" title="分隔符和定长符解码器的应用"></a>分隔符和定长符解码器的应用</h2><p>&emsp;&emsp;TCP以流的方式进程数据传输，上层的应用协议对消息进行了区分，往往采用如下方式</p><ol><li>消息长度固定</li><li>将回车作为换行符</li><li>将特殊的分隔符作为消息的结束位置</li><li>通过在消息头中定义长度字段来标识消息的长度</li></ol><h3 id="DelimiterBasedFrameDecoder应用开发"><a href="#DelimiterBasedFrameDecoder应用开发" class="headerlink" title="DelimiterBasedFrameDecoder应用开发"></a>DelimiterBasedFrameDecoder应用开发</h3><p>&emsp;&emsp;DelimiterBasedFrameDecoder可以根据自定义分隔符作为结束位置，在使用的时候传入两个参数</p><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">new DelimiterBasedFrameDecoder(1024,Bytebuf:: delimiter)</code></pre></div><p>其中第一个参数表示消息的最大长度，第二参数表示分隔符。</p><h3 id="FixedLengthFrameDecoder应用开发"><a href="#FixedLengthFrameDecoder应用开发" class="headerlink" title="FixedLengthFrameDecoder应用开发"></a>FixedLengthFrameDecoder应用开发</h3><p>&emsp;&emsp;FixedLengthFrameDecoder是固定长度解码器，它能够按照固定的长度对消息进行自动解码，开发者不需要考虑TCP的黏包和拆包问题。</p><div class="hljs"><pre class=" language-hljs plain"><code class="language-hljs plain">new FixedLengthFrameDecoder(10)</code></pre></div><p>其中10表示固定长度。</p><h1 id="中级篇-Netty编解码开发指南"><a href="#中级篇-Netty编解码开发指南" class="headerlink" title="中级篇 Netty编解码开发指南"></a>中级篇 Netty编解码开发指南</h1><p>&emsp;&emsp;了解Netty内置的编码器之后，继续学习Netty的编码解码款框架的应用，例如java序列化、二进制编码、Google Protobuf和JBoss的Marshallling序列化框架。</p><h2 id="编解码技术"><a href="#编解码技术" class="headerlink" title="编解码技术"></a>编解码技术</h2><p>&emsp;&emsp;基于Java提供的对象输入/输出流ObjectInputStreaming和ObjectOutputStreaming，可以直接把Java对象作为可存储的字节流写入文件，也可以传输到网上。对程序员而言，序列化可提高开发效率。</p><p>&emsp;&emsp;Java序列化的目的</p><ol><li>网络传输</li><li>对象持久化</li></ol><h3 id="Java序列化缺点"><a href="#Java序列化缺点" class="headerlink" title="Java序列化缺点"></a>Java序列化缺点</h3><ol><li>无法跨语言</li><li>序列化后的码流太大</li><li>序列化性能太低</li></ol><h3 id="业界主流的编解码框架"><a href="#业界主流的编解码框架" class="headerlink" title="业界主流的编解码框架"></a>业界主流的编解码框架</h3><ol><li><p>Google Protobuf<br> 主要特点</p><ul><li>结构化存储</li><li>搞笑的编解码性能</li><li>语言无关、平台无关、扩展性好</li><li>官方支持Java、C++和Python三种语言<br>为什么不适用XML走位通讯协议？一方面，解析的时间开销；另一方便，XML为了可读性牺牲的空间开销都非常大。<br>protobuf引入了数据描述文件和代码生成机制，主要优点</li><li>文件化的数据结构描述语言，可以实现语言和平台无关，特别适合系统间集成</li><li>通过标识字段的顺序，实现协议的兼容</li><li>代码生成机制，不需要手动编写同样数据结构的C++和Java版本</li><li>方便后续的管理和维护</li></ul></li><li><p>Facebook Thrift<br> thrift主要有一下部分组成</p><ul><li>语言系统以及IDL编译器：负责由用户给定的IDL文件生成相应语言的接口代码</li><li>TProtocal: RPC的协议层，可以选择多个不同的对象序列化方式，如JSON何Binary</li><li>TTransport: RPC的传输层，同样可以选择不同的传输层实现，如socket、NIO、MemeroyBuffer等</li><li>TProcessor:作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口</li><li>TServer: 聚合TProtocal、TTransport和TProcessor等对象<br>Thrift支持三种不同的编解码</li><li>通用的二进制编码</li><li>压缩二进制编解码</li><li>优化的可选字段压缩编解码</li></ul></li><li><p>JBoss Marshalling<br> JBoss Marshalling是一个序列化的API，修正了JDK自带的序列化包的很多问题。相比于前面两种编解码协议，JBoss Marshalling更多是应用于JBoss内部，应用范围有限。</p><h2 id="Java序列化"><a href="#Java序列化" class="headerlink" title="Java序列化"></a>Java序列化</h2></li></ol><p>&emsp;&emsp;Java序列化在Netty NIO框架中的使用方式</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java">## 服务器端：ChannleInitializer<SocketChannel><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">initChannel</span><span class="hljs-params">(SocketChannel ch)</span></span>&#123;    ch.pipeline()        .addLast(<span class="hljs-keyword">new</span> ObjectDecoder(<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span>,Classresolvers.weakCachingConcurrentResolver(<span class="hljs-keyword">this</span>.getClass().getClassLoader())));    ch.pipeline().addLast(<span class="hljs-keyword">new</span> OjectEncoder());    <span class="hljs-comment">// add other handler</span>&#125;</code></pre></div><h2 id="Google-Protobuf编解码"><a href="#Google-Protobuf编解码" class="headerlink" title="Google Protobuf编解码"></a>Google Protobuf编解码</h2><p>&emsp;&emsp;Profotbuf是一个灵活的、小巧的、高效的、结构化的数据序列化框架，相比于XML等传统的序列化工具，它更小、更快、更简单。Profobuf支持一次可以到处使用，甚至跨语言使用，通过代码生成工具可以自动生成不同语言版本的源代码，甚至可以在不同版本的数据结构进程间进行数据传递实现数据结构的前后兼容。</p><h3 id="Protobuf开发环境搭建"><a href="#Protobuf开发环境搭建" class="headerlink" title="Protobuf开发环境搭建"></a>Protobuf开发环境搭建</h3><h3 id="Netty的Protobuf服务端开发"><a href="#Netty的Protobuf服务端开发" class="headerlink" title="Netty的Protobuf服务端开发"></a>Netty的Protobuf服务端开发</h3><p>&emsp;&emsp;各种不同版本的示例程序代码，不同点在于ChannelHandlerAdapter的实现方式。其中本部分基于Protobuf的Netty实现方式如下所示</p><div class="hljs"><pre class=" language-hljs java"><code class="language-hljs java">## 服务器端<span class="hljs-keyword">public</span>  <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ServerHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ChannelHandlerAdapter</span></span>&#123;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelRead</span><span class="hljs-params">(ChannelHandlerContext ctx,Object msg)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;        <span class="hljs-comment">// protobuf object</span>        Test.TestReq req = (Test.TestReq )msg;<span class="hljs-comment">// 直接强制转化为目标类</span>        <span class="hljs-comment">// 其他处理</span>        ctx.writeAndFlush([Target Content]);    &#125;&#125;## 客户端代码类似</code></pre></div><p>&emsp;&emsp;这里使用到的ProtofReq对象，是通过Protobuf自动化生成的类。</p><h2 id="JBoss-Marshelling编解码"><a href="#JBoss-Marshelling编解码" class="headerlink" title="JBoss Marshelling编解码"></a>JBoss Marshelling编解码</h2><p>&emsp;&emsp;JBose Marshalling的序列化编解码框架，应用领域有限不做赘述。</p><h1 id="高级篇-Netty多协议开发和应用"><a href="#高级篇-Netty多协议开发和应用" class="headerlink" title="高级篇 Netty多协议开发和应用"></a>高级篇 Netty多协议开发和应用</h1><h2 id="Http协议开发应用"><a href="#Http协议开发应用" class="headerlink" title="Http协议开发应用"></a>Http协议开发应用</h2><p>&emsp;&emsp;Http协议是建立在TCP传输层协议之上的应用层协议，是一个属于应用层的面向对象的协议。与1990年提出，经过多年的发展逐渐完善。Netty的Http协议栈是基于Netty的NIO通讯框架，因此Netty的Http协议也是异步非阻塞的。</p><h3 id="Http协议介绍"><a href="#Http协议介绍" class="headerlink" title="Http协议介绍"></a>Http协议介绍</h3><p>&emsp;&emsp;Http协议主要有一下特点</p><ul><li>支持Client/Server模式</li><li>简单：客户端发送请求时，只需要制定服务URL，携带必要的请求参数或消息体即可</li><li>灵活-Http允许传输任意类型的数据，传输类型在Http消息头中的Content-Type加以标记</li><li>无状态-Http协议是无状态协议，既对于事物处理没有记忆能力。</li></ul><h4 id="Http请求消息"><a href="#Http请求消息" class="headerlink" title="Http请求消息"></a>Http请求消息</h4><ol><li>消息组成<ul><li>Http请求行</li><li>Http消息头</li><li>Http请求正文</li></ul></li><li>请求方法<ul><li>GET：请求资源</li><li>POST: 请求资源并附加提交数据</li><li>HEAD: 请求消息报头</li><li>PUT: 请求存储一个资源</li><li>DELETE: 请求服务器删除一个资源</li><li>TRACE: 请求服务器会送收到的请求消息，主要用于测试或诊断</li><li>Connect: 保留将来使用</li><li>Options: 请求查询服务器的性能</li></ul></li></ol><h4 id="Http相应消息"><a href="#Http相应消息" class="headerlink" title="Http相应消息"></a>Http相应消息</h4><ol><li>效应状态<ul><li>1XX: 指示消息。请求已接收，继续处理</li><li>2XX: 成功。请求已被成功接收、理解、接收</li><li>3XX：重定向。要完成请求必须进行更进一步的操作</li><li>4XX: 客户端错误。请求有语法错误或请无法实现</li><li>5XX: 服务端错误。服务器未能处理请求</li></ul></li><li>常见相应代码与描述<table><thead><tr><th align="center">状态码</th><th align="left"><center>状态描述</center></th></tr></thead><tbody><tr><td align="center">200</td><td align="left">OK:客户端请求成功</td></tr><tr><td align="center">400</td><td align="left">Bad Request: 客户端请求存在语法错误，不能被服务器所理解</td></tr><tr><td align="center">401</td><td align="left">Unauthorized: 请未经授，这个状态代码必须和WWW-Authenticate报头域一起使用</td></tr><tr><td align="center">403</td><td align="left">Forbidden:服务器收到请求，但拒绝提供服务</td></tr><tr><td align="center">404</td><td align="left">Not Found: 请求资源不存在</td></tr><tr><td align="center">500</td><td align="left">Internal Server Error: 服务器发生不可预期的错误</td></tr><tr><td align="center">503</td><td align="left">Server Unavailabkle: 服务器当前不能处理客户端的请求，一段时间之后可能恢复</td></tr></tbody></table></li></ol><h3 id="Http协议的Netty处理"><a href="#Http协议的Netty处理" class="headerlink" title="Http协议的Netty处理"></a>Http协议的Netty处理</h3><p>&emsp;&emsp;服务器端重点代码</p><div class="hljs"><pre class=" language-hljs java"><span class="hljs-meta">@override</span> <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">initChannel</span><span class="hljs-params">(SocketChannel ch)</span> <span class="hljs-keyword"><code class="language-hljs java"><span class="hljs-meta">@override</span> <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">initChannel</span><span class="hljs-params">(SocketChannel ch)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;    ch.pipleline().addLast(<span class="hljs-string">"http-decoder"</span>,<span class="hljs-keyword">new</span> HttpRequestDecoder());    ch.pipleline().addLast(<span class="hljs-string">"http-aggregator"</span>,<span class="hljs-keyword">new</span> HttpObjectAgregator(<span class="hljs-number">65536</span>));    ch.pipleline().addLast(<span class="hljs-string">"http-encoder"</span>,<span class="hljs-keyword">new</span> HttpResponseEncoder());    ch.pipleline().addLast(<span class="hljs-string">"http-chunked"</span>,<span class="hljs-keyword">new</span> ChunkedWriteHandler());    <span class="hljs-comment">// 自定义: extends SimpleChannelInboundsHandler<FullHttpRequest></span>    ch.pipleline().addLast(<span class="hljs-string">"fileServerHandler"</span>,<span class="hljs-keyword">new</span> HttpFileServerHandler(url);&#125;</code></pre></div><h3 id="Netty-Http-XML协议栈开发"><a href="#Netty-Http-XML协议栈开发" class="headerlink" title="Netty Http+XML协议栈开发"></a>Netty Http+XML协议栈开发</h3><p>&emsp;&emsp;由于Http协议的通用性，异构系统间的通讯交互采用Http协议，通过Http协议承载业务数据进行消息交互。例如流行的Http+XML，或RestFUL+JSON。</p><p>&emsp;&emsp;在java领域，最常用的Http协议栈就是基于Serverlet规范的Tomcat等Web容器。由于Google等大佬的强力推荐，Jetty等轻量级Web容器也得到了广泛的应用。但许多场景下，基于Http的应用都是后台应用，Http仅仅是承载数据交换的一个通道，是一个载体而不是Web容器。这种场景下，一般不需要Tomcat这种重量型的Web容器。</p><p>&emsp;&emsp;另外网络安全日益严峻的今天，重量级的Web容器由于功能繁琐，会存在很多安全漏洞，典型的如Tomcat。这意味着需要为Wb容器做很多安全加固工作去修补这些漏洞，然而开发中并没有用到这些功能，这就带来了并发和维护成本。在这种场景下，选择一个更加轻量级的http协议栈是个更好的选择。</p><p><img src="001.png" srcset="/img/loading.gif" alt="Http+XML协议栈开发"></p><p>Netty Http+XML重点代码</p><div class="hljs"><pre class=" language-hljs java"><span class="hljs-meta"><code class="language-hljs java"><span class="hljs-meta">@override</span><span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">initChannel</span><span class="hljs-params">(SocketChannel ch)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;    ch.pipleline().addLast(<span class="hljs-string">"http-decoder"</span>,<span class="hljs-keyword">new</span> HttpResponseDecoder());    ch.pipleline().addLast(<span class="hljs-string">"http-aggregator"</span>,<span class="hljs-keyword">new</span> HttpObjectAgregator(<span class="hljs-number">65536</span>));    ch.pipleline().addLast(<span class="hljs-string">"xml-decoder"</span>,<span class="hljs-keyword">new</span> HttpXMLResponseDecoder(Order<span class="hljs-class">.<span class="hljs-keyword">class</span>,<span class="hljs-title">true</span>))</span>;    ch.pipleline().addLast(<span class="hljs-string">"http-encoder"</span>,<span class="hljs-keyword">new</span> HttpRequestEncoder());    ch.pipleline().addLast(<span class="hljs-string">"xml-encoder"</span>,<span class="hljs-keyword">new</span> HttpXMLRequestEncoder());    ch.pipleline().addLast(<span class="hljs-string">"fileServerHandler"</span>,<span class="hljs-keyword">new</span> HttpXMLHandler());&#125;</code></pre></div><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;尽管本文中开发的Http+XML协议栈是一个高性能、通用的协议栈，但这里忽略了异常处理、可扩展性的API和配置能力。所以如果想要做产品化的协议栈，还需要一些额外的完善。</p><h2 id="WebSocket协议开发"><a href="#WebSocket协议开发" class="headerlink" title="WebSocket协议开发"></a>WebSocket协议开发</h2><p>&emsp;&emsp;一直以来，网络在很多程度上都是围绕着Http的请求/相应模式而构建的。长期以来存在这个各种技术让服务器得知有数据可用时，立即将数据发送到客户端。最常用的一种技术手段是对服务器发起链接创建假象，被称为长轮循。利用长轮循，客户端可以打开指向服务器的Http连接，而服务器会一直保持链接打开，直到发送响应。服务器只要有数据，就会发送响应。这些问题都存在一个同样的问题，Http协议的开销，到时他们不适用于低延迟应用。</p><p>&emsp;&emsp;为了解决这些问题，WebSocket将网络套接字引入到了客户端和服务器端，浏览器和服务器之间可以通过套接字建立持久的连接，双方随时都可以互发数据给对方，而不是由客户端控制的一对一应答模式。</p><h3 id="Http协议弊端"><a href="#Http协议弊端" class="headerlink" title="Http协议弊端"></a>Http协议弊端</h3><p>&emsp;&emsp;Http主要弊端总结</p><ul><li>半双工模式。不能同时传送数据，意味着一个时刻，只有一个方向上的数据传送</li><li>Http消息冗长复杂。Http消息包括消息头、消息体、换行符等，通常情况下采用文本传输，，相比于其他的二进制通讯，冗长而复杂</li><li>针对服务器推送的黑客攻击，例如长轮询</li></ul><p>&emsp;&emsp;比较新的一种轮询技术是Comet，使用了Ajax。这种技术虽然可达到双工通信，但依然需要发送请求，而且在Comet中，普遍采用了长连接，这也会大量消耗服务器款到和资源。</p><p>&emsp;&emsp;为了解决Http协议效率底下的问题，HTML5定义了WebSocket协议，能更好的节省服务器资源和宽带并达到定时通信。</p><h3 id="WebSocket入门"><a href="#WebSocket入门" class="headerlink" title="WebSocket入门"></a>WebSocket入门</h3><p>&emsp;&emsp;WebSocket主要特点</p><ul><li>单一的TCP连接，采用了全双工模式通信</li><li>对代理、防火墙和路由器透明</li><li>无头部信息、Cookies和身份验证</li><li>无安全开销</li><li>通过Ping/Pong帧保持链路激活</li><li>服务器可以主动传递消息给客户端，不再需要客户端轮询</li></ul><p>&emsp;&emsp;WebSocket的目的是为了取代轮询和Coment技术，使客户端浏览器具备像C/S架构下桌面系统一样的实时通信能力。</p><ol><li>建立连接<br> <strong>客户端–&gt;握手请求–&gt;服务器–&gt;握手相应</strong></li><li>生命周期<br> &emsp;&emsp;握手成功之后，客户端和服务器端就可以通过”messages”的方式进行通信了，一个消息由一个或多个帧组成，WebSocket的消息并不一定对应某一个特定网络层的帧，它可以被分割成多个或被合并。</li><li>关闭连接<br> &emsp;&emsp;为关闭WebSocket连接，客户端和服务端需要通过一个安全的方法关闭底层TCP连接以及TLS会话。如果合适，丢弃任何核能已经接受的字节。<br> &emsp;&emsp;WebSocket的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个关闭控制流，当对接接收到关闭控制帧时，需要主动关闭WebSocket连接。</li></ol><h3 id="Netty-WebSocket开发"><a href="#Netty-WebSocket开发" class="headerlink" title="Netty WebSocket开发"></a>Netty WebSocket开发</h3><p>&emsp;&emsp;Netty基于Http协议开发了WebSocket协议栈，利用Netty的WebSocket协议栈可非常方便的开发出WebSocket客户端和服务器端。</p><p>基于Netty的WebSocket编程主要代码</p><div class="hljs"><pre class=" language-hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WebSocketServerHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">SimpleChannelInBoundHandler</span>&lt;<span class="hljs-title"><code class="language-hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WebSocketServerHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">SimpleChannelInBoundHandler</span>&lt;<span class="hljs-title">Object</span>></span>&#123;    <span class="hljs-keyword">private</span> WebSocketServerHandshaker handshaker;    <span class="hljs-comment">// define Logger</span>    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">messageReceived</span><span class="hljs-params">(ChannelHandlerContext ctx,Object msg)</span></span>&#123;        <span class="hljs-comment">// 传统的Http接口</span>        <span class="hljs-keyword">if</span>(msg <span class="hljs-keyword">instanceof</span> FullHttpRequest)&#123;            handleHttpRequest(ctx,(FullHttpRequest)msg);        &#125;        <span class="hljs-comment">// WebSocket接入</span>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(msg <span class="hljs-keyword">instanceof</span> WebSocketFrame)&#123;            handleWebSocketFrame(ctx,(WebSocketFrame)msg);        &#125;    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">channelReadComplete</span><span class="hljs-params">(ChannelHandlerContext ctx)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        ftx.flush();    &#125;    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">exceptionCaught</span><span class="hljs-params">(ChannelHandlerContext ctx, Throwable e)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        cause.printStackTrace();        ctx.close();    &#125;    <span class="hljs-comment">// define local method</span>    <span class="hljs-comment">// handle websocket http request</span>    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">handleHttpRequst</span><span class="hljs-params">(ChannelHandlerContext ctx,FullHttpRequest req)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        <span class="hljs-comment">// 如果Http编码失败，返回Http异常</span>        <span class="hljs-keyword">if</span>(!req.getDecoderResult().isSuccesss() || (!<span class="hljs-string">"websocket"</span>.equals(req.headers().get(<span class="hljs-string">"Upgrade"</span>))))&#123;            sendHttpResponse(ctx,req,<span class="hljs-keyword">new</span> DefaultFullHttpResponse(HTTP_1_1,BAD_REQUEST));            <span class="hljs-keyword">return</span>;        &#125;        <span class="hljs-comment">// 构造握手相应返回，本机测试</span>        WebSocketServerHandShakerFactory wsFactory = <span class="hljs-keyword">new</span> WebSocketServerHandShakerFactory(<span class="hljs-string">"ws://localhost:8080/websocket"</span>,<span class="hljs-keyword">null</span>,<span class="hljs-keyword">false</span>);        handshaker = wsFactory.newHandshaker(req);        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">null</span>==handshaker)&#123;            WebSocketServerHandShakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel());        &#125;<span class="hljs-keyword">else</span>&#123;            handshaker.handshake(ctx.channel(),req);        &#125;    &#125;    <span class="hljs-comment">// handler websocket request</span>    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">handleWebSocketRequest</span><span class="hljs-params">(ChannelHandlerContext ctx,WebSocketFrame req)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;        <span class="hljs-comment">// 判断是否关闭链路指令</span>        <span class="hljs-keyword">if</span>(frame <span class="hljs-keyword">instanceof</span> CloseWebSocketFrame)&#123;            handshaker.close(ctx.channel(),(CloseWebSocketFrame)farme.retain());            <span class="hljs-keyword">return</span>;        &#125;        <span class="hljs-comment">// 判断是否Ping消息</span>        <span class="hljs-keyword">if</span>(frame <span class="hljs-keyword">instanceof</span> PingWebSocketFrame)&#123;            ctx.channel().write(<span class="hljs-keyword">new</span> PongWebSocketFrame(frame.contenet().retain()));            <span class="hljs-keyword">return</span>;        &#125;        <span class="hljs-comment">// 本利仅支持文本消息，比支持二进制消息</span>    <span class="hljs-keyword">if</span>(!(frame <span class="hljs-keyword">instanceof</span> TextWebSocketFrame))&#123;        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> UnsupportedOperationException(String.format(<span class="hljs-string">"$s frame types not supported"</span>,frame.getClass().getName()));    &#125;    <span class="hljs-comment">//返回应答消息</span>    String request = ((TextWebSocketFrame)frame).text();    ctx.channel().write(<span class="hljs-keyword">new</span> TextWebSocketFrame(request+<span class="hljs-string">", 欢迎使用Netty WebSocket服务，现在时间："</span>+<span class="hljs-keyword">new</span> java.util.Date().toString());    &#125;    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">sendHttpResponse</span><span class="hljs-params">(ChannelHandlerContext ctx,FullHttpRequest req,FullHttpResponse res)</span></span>&#123;        <span class="hljs-comment">// 返回应答给客户端</span>        <span class="hljs-keyword">if</span>(req.getStatus().code()!=<span class="hljs-number">200</span>)&#123;            ByteBuf buf = Unpooled.copiedBuffer(res.getStatus().toString(),CharsetUtil.UTF_8);            res.content().writeBytes(buf);            buf.release();            setContentLength(res,res.content().readableBytes());        &#125;        <span class="hljs-comment">// 如果是非Kill-Alive，关闭连接</span>        ChannelFuture f = ctx.channel().writeAndFlush(res);        <span class="hljs-keyword">if</span>(!isKeepAlive(req) || res.getStatus.code()!=<span class="hljs-number">200</span>)&#123;            f.addListener(ChannelFutureListener.CLOSE);        &#125;    &#125;&#125;</code></pre></div><h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;本章主要介绍了Http协议的弊端和WebSocket的一些技术背景，随后对WebSocket的优势和基础入门进行了介绍，包括WebSocket的握手请求和相应、连接的建立与关闭、WebSocket的生命周期等内容。</p><h2 id="UDP协议开发"><a href="#UDP协议开发" class="headerlink" title="UDP协议开发"></a>UDP协议开发</h2><p>&emsp;&emsp;UDP是用户数据报协议(User Datagram Protocol, UDP)的简称，其主要作用是将网络数据流量压缩成数据报形式，提供面向事物的简单消息传送服务。与TCP相比，UDP协议直接利用IP协议进行UDP数据报的传输，UDP面向的是无连接、不可靠的数据投递服务。当使用UDP时，用户应用必须负责解决数据报丢失、重复、排序、差错确认等问题。</p><p>&emsp;&emsp;由于UDP具有资源消耗小、处理速度快的优点，所以通常视频、音频等可靠性要求不高的数据传输一般会使用UDP，即便有一定的丢包率，也不会对功能造成严重的影响。</p><h3 id="UDP协议简介"><a href="#UDP协议简介" class="headerlink" title="UDP协议简介"></a>UDP协议简介</h3><p>&emsp;&emsp;UDP数据分为首部和数据两个部分。首部简单，为8个字节，包括</p><ul><li>源端口：源端口号，2个字节，最大值为65535</li><li>目的端口：目的端口号，2个字节，最大为65535</li><li>长度：2个字节，UDP用户数据报的总长度</li><li>校验和：2字节，用于校验UDP数据报的数字段和包含UDP数据报首部的“伪首部”。</li></ul><p>&emsp;&emsp;UDP协议的特点</p><ul><li>UDP传送数据前并不与对方建立连接，即UDP是无连接的。在数据发送前，发送方和接收方相互交换信息是双方同步</li><li>UDP对接受到的数据报不发送确认信号，发送端不知道数据是否被正确接受，也不会重发数据</li><li>UDP发送数据比TCP快，系统开销少：UDP简单、灵活。</li></ul><h3 id="UDP服务端开发"><a href="#UDP服务端开发" class="headerlink" title="UDP服务端开发"></a>UDP服务端开发</h3><p><img src="./Netty%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/002.png" srcset="/img/loading.gif" alt="UDP开发流程"></p><h3 id="UDP客户端开发"><a href="#UDP客户端开发" class="headerlink" title="UDP客户端开发"></a>UDP客户端开发</h3><p>&emsp;&emsp;总体而言UDP开发相对简单，客户端开发可参考服务器端开发代码。</p><h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><p>&emsp;&emsp;由于UDP相比于TCP的应用领域窄一些，所以本章不做详细论述。</p><h2 id="文件传输"><a href="#文件传输" class="headerlink" title="文件传输"></a>文件传输</h2><p>&emsp;&emsp;文件是最常见的数据源之一，在程序中经常需要将数据存储到文件中。在NIO的类库之前，Java所有的文件操作分为两类</p><ul><li>基于字节流的InputStream和OutputStream</li><li>基于字符流的Reader和Writer</li></ul><p>&emsp;&emsp;通过NIO提供的Channel类库，可以方便的以“管道”方式对文件进行各种IO操作，相比于传统的IO操作有了较高改进。</p><h3 id="文件的基础知识"><a href="#文件的基础知识" class="headerlink" title="文件的基础知识"></a>文件的基础知识</h3><p>&emsp;&emsp;文件是计算机中一种基本的数据存储形式，在时间存储数据时，如果对数据进行的读写速度要求不是很高，存储数量也不是很大，使用文件作为一种持久化的方式是比较好的选择。文件需要注意几个概念</p><ul><li>文件路径</li><li>文件名称</li></ul><h3 id="Netty文件传输开发"><a href="#Netty文件传输开发" class="headerlink" title="Netty文件传输开发"></a>Netty文件传输开发</h3><p>&emsp;&emsp;文件传输通常使用FTP或Http附件的方式。事实上通过TCP Socket+File的方式进行文件传输也有一定的应用场景，尽管不是主流，但掌握这种文件阐释方式还是非常重要的，特别是针对跨主机的JVM进城之间进行持久化数据的相互交换。</p><p>&emsp;&emsp;示例Netty程序的应用场景</p><ol><li>Netty文件服务器启动，绑定8000作为内部监听端口</li><li>在CMD控制台上，通过telnet和文件服务器建立tcp连接</li><li>在控制台输入需要下载的文件绝对路径</li><li>文件服务器接受到请求消息后进行合法性判断，如果文件存在，则将文件发送给CDM控制台</li><li>CMD控制台打印文件名和文件内存</li></ol><p>&emsp;&emsp;主要处理类</p><div class="hljs"><pre class=" language-hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FileSererHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">SimpleChannelInBoundHandler</span>&lt;<span class="hljs-title"><code class="language-hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FileSererHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">SimpleChannelInBoundHandler</span>&lt;<span class="hljs-title">String</span>></span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String CR = System.getProperty(<span class="hljs-string">"line.separator"</span>);    <span class="hljs-meta">@override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">messageReceived</span><span class="hljs-params">(ChannelHandlerContext ctx,String msg)</span></span>&#123;        File f = <span class="hljs-keyword">new</span> File(msg);        <span class="hljs-keyword">if</span>(!f.exists())&#123;            ctx.writeAndFlush(<span class="hljs-string">"Not a file :"</span>+f+CR);            <span class="hljs-keyword">return</span>;        &#125;        <span class="hljs-keyword">if</span>(!f.isFile())&#123;            ctx.writeAndFlush(<span class="hljs-string">"File not found :"</span>+f+CR);            <span class="hljs-keyword">return</span>;        &#125;        ctx.write(f+<span class="hljs-string">" "</span>+f.length()+CR);        RandomAccessFile raf = <span class="hljs-keyword">new</span> RandomAccessFile(msg,<span class="hljs-string">'r'</span>);        FileRegion fr = <span class="hljs-keyword">new</span> DefaultFileRegion(raf,getChannel(),<span class="hljs-number">0</span>,raf.length());        ctx.write(region);        ctx.writeAndFlush(CR);        raf.close();    &#125;&#125;</code></pre></div><h2 id="私有协议栈开发"><a href="#私有协议栈开发" class="headerlink" title="私有协议栈开发"></a>私有协议栈开发</h2><p>&emsp;&emsp;通信协议从广义上区分，可以分为共有协议和私有协议。由于私有协议的灵活性，它往往会在某个公司或组织内部使用，按需定制。绝大数私有协议传输层都是基于TCP/IP，所以利用Netty的NIO TCP协议栈可以非常方便的进行私有协议的定制和开发。</p><h3 id="私有协议介绍"><a href="#私有协议介绍" class="headerlink" title="私有协议介绍"></a>私有协议介绍</h3><p>&emsp;&emsp;传统中的Java应用中，通常使用以下四种方式进行跨界点调用</p><ul><li>通过RMI进行远程服务调用</li><li>通过java的socket+java序列化的方式进行扩节点调用</li><li>利用一些开源的RPC，例如Thrift,Avro</li><li>利用标准的共有协议进行调用，例如Http+XML、RestFull+JSON</li></ul><h3 id="Netty协议栈功能设计"><a href="#Netty协议栈功能设计" class="headerlink" title="Netty协议栈功能设计"></a>Netty协议栈功能设计</h3><h4 id="协议栈拓扑图"><a href="#协议栈拓扑图" class="headerlink" title="协议栈拓扑图"></a>协议栈拓扑图</h4><h4 id="协议栈功能描述"><a href="#协议栈功能描述" class="headerlink" title="协议栈功能描述"></a>协议栈功能描述</h4><h4 id="通信模型"><a href="#通信模型" class="headerlink" title="通信模型"></a>通信模型</h4><h4 id="消息定义"><a href="#消息定义" class="headerlink" title="消息定义"></a>消息定义</h4><h4 id="Netty协议栈支持的字段类型"><a href="#Netty协议栈支持的字段类型" class="headerlink" title="Netty协议栈支持的字段类型"></a>Netty协议栈支持的字段类型</h4><h4 id="Netty协议栈的编码规范"><a href="#Netty协议栈的编码规范" class="headerlink" title="Netty协议栈的编码规范"></a>Netty协议栈的编码规范</h4><h4 id="链路的建立"><a href="#链路的建立" class="headerlink" title="链路的建立"></a>链路的建立</h4><h4 id="链路的关闭"><a href="#链路的关闭" class="headerlink" title="链路的关闭"></a>链路的关闭</h4><h4 id="可靠性设计"><a href="#可靠性设计" class="headerlink" title="可靠性设计"></a>可靠性设计</h4><ol><li>心跳机制</li><li>重连集资</li><li>重复登录保护</li><li>消息缓冲重发</li></ol><h4 id="安全性设计"><a href="#安全性设计" class="headerlink" title="安全性设计"></a>安全性设计</h4><p>&emsp;&emsp;安全策略</p><ul><li>IP+白名单</li><li>ASE加密的用户名+密码认证机制</li></ul><h4 id="可靠性设计-1"><a href="#可靠性设计-1" class="headerlink" title="可靠性设计"></a>可靠性设计</h4><h3 id="Netty协议栈开发"><a href="#Netty协议栈开发" class="headerlink" title="Netty协议栈开发"></a>Netty协议栈开发</h3><h1 id="源码分析篇-Netty功能介绍和源码分析"><a href="#源码分析篇-Netty功能介绍和源码分析" class="headerlink" title="源码分析篇 Netty功能介绍和源码分析"></a>源码分析篇 Netty功能介绍和源码分析</h1><h2 id="ByteBuf和相关辅助类"><a href="#ByteBuf和相关辅助类" class="headerlink" title="ByteBuf和相关辅助类"></a>ByteBuf和相关辅助类</h2><p>&emsp;&emsp;</p><h2 id="Channel和Unsafe"><a href="#Channel和Unsafe" class="headerlink" title="Channel和Unsafe"></a>Channel和Unsafe</h2><p>&emsp;&emsp;</p><h2 id="ChannelPipeline和ChannelHandler"><a href="#ChannelPipeline和ChannelHandler" class="headerlink" title="ChannelPipeline和ChannelHandler"></a>ChannelPipeline和ChannelHandler</h2><p>&emsp;&emsp;</p><h2 id="EventLoop和EventLoopGroup"><a href="#EventLoop和EventLoopGroup" class="headerlink" title="EventLoop和EventLoopGroup"></a>EventLoop和EventLoopGroup</h2><p>&emsp;&emsp;</p><h2 id="Future和Promise"><a href="#Future和Promise" class="headerlink" title="Future和Promise"></a>Future和Promise</h2><p>&emsp;&emsp;</p><h1 id="架构和行业应用篇-Netty高级特性"><a href="#架构和行业应用篇-Netty高级特性" class="headerlink" title="架构和行业应用篇 Netty高级特性"></a>架构和行业应用篇 Netty高级特性</h1><p>&emsp;&emsp;</p><h2 id="Java多线程编程在Netty中的应用"><a href="#Java多线程编程在Netty中的应用" class="headerlink" title="Java多线程编程在Netty中的应用"></a>Java多线程编程在Netty中的应用</h2><p>&emsp;&emsp;作为异步事件驱动、高性能的NIO框架，Netty代码中大量运用了Java多线程编程技巧，并发编程处理的恰当与否，将直接影响到架构的性能。</p><h3 id="Java内存模型与多线程编程"><a href="#Java内存模型与多线程编程" class="headerlink" title="Java内存模型与多线程编程"></a>Java内存模型与多线程编程</h3><h4 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h4><p>&emsp;&emsp;JVM定义了内存规范，规避了各种操作系统、虚拟机实现和硬件的内存访问差异，以确保Java程序在所有操作系统上和平台上能够实现一次编写、到处运行的效果。</p><p>&emsp;&emsp;Java内存模型的制定既要严谨，保证语义无歧义，还要尽量制定的宽松一些，运行硬件和虚拟机厂商有足够的灵活性来充分利用硬件的特性提升Java内存访问性能。</p><ol><li>工作内存和主内存</li><li>Java内存交互协议<ul><li>lock</li><li>unlock</li><li>read</li><li>write</li><li>load</li><li>store</li><li>assign</li><li>use</li></ul></li><li>java的线程 <ul><li>内核线程</li><li>用户线程</li><li>混合实现</li></ul></li></ol><h3 id="Netty的并发编程实践"><a href="#Netty的并发编程实践" class="headerlink" title="Netty的并发编程实践"></a>Netty的并发编程实践</h3><h4 id="对共享的可变数据进行正确的同步"><a href="#对共享的可变数据进行正确的同步" class="headerlink" title="对共享的可变数据进行正确的同步"></a>对共享的可变数据进行正确的同步</h4><h4 id="正确使用锁"><a href="#正确使用锁" class="headerlink" title="正确使用锁"></a>正确使用锁</h4><h4 id="volatile的正确使用"><a href="#volatile的正确使用" class="headerlink" title="volatile的正确使用"></a>volatile的正确使用</h4><p>&emsp;&emsp;volatile修饰之后，具有两种特性</p><ul><li>线程可见性</li><li>禁止指令重排</li></ul><h4 id="CAS指令和元子类"><a href="#CAS指令和元子类" class="headerlink" title="CAS指令和元子类"></a>CAS指令和元子类</h4><p>&emsp;&emsp;互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能的额外损耗，因此这种同步被称为阻塞同步，它是一种悲观的并发策略，称为悲观锁。随着硬件和操作系统指令集的发展和优化，产生了非阻塞同步，被称为乐观锁。</p><p>&emsp;&emsp;目前Java中的非阻塞同步就是CAS，基本上是通过系统操作指令来完成。</p><h4 id="线程安全类的使用"><a href="#线程安全类的使用" class="headerlink" title="线程安全类的使用"></a>线程安全类的使用</h4><p>&emsp;&emsp;在JDK1.5之后，Java平台新增了java.util.concurrent这个包，提供了一些列线程安全集合、容器和线程池，利用这些新的线程安全类极大地降低了Java多线程编程的难度，提升了开发效率。新的并发编程包中的工具可以分为</p><ul><li>线程池Executor Framework以及定时任务相关的类库，包括Timer等</li><li>并发集合，包括List、Queue、Map和Set等</li><li>新的同步器，例如读写锁ReadWriteLock等</li><li>新的原子包装类，例如AtomicInteger等</li></ul><h2 id="Netty架构剖析"><a href="#Netty架构剖析" class="headerlink" title="Netty架构剖析"></a>Netty架构剖析</h2><h3 id="Netty逻辑架构"><a href="#Netty逻辑架构" class="headerlink" title="Netty逻辑架构"></a>Netty逻辑架构</h3><ol><li>reactor通信调度层</li><li>职责链channelpipeline</li><li>业务逻辑编排层</li></ol><h3 id="关键架构质量属性"><a href="#关键架构质量属性" class="headerlink" title="关键架构质量属性"></a>关键架构质量属性</h3><ol><li>高性能</li><li>可靠性<ul><li>链路有效性检测</li><li>内存保护机制</li><li>优雅停机</li><li>可定制型</li><li>可扩展性</li></ul></li></ol><h2 id="Netty行业应用"><a href="#Netty行业应用" class="headerlink" title="Netty行业应用"></a>Netty行业应用</h2><ol><li>Dubbo</li><li>大数据领域</li><li>游戏领域</li></ol><h2 id="Netty未来展望"><a href="#Netty未来展望" class="headerlink" title="Netty未来展望"></a>Netty未来展望</h2>]]></content>
    
    <summary type="html">
    
      《Netty权威指南》读书笔记
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://xinshiyou.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Java" scheme="https://xinshiyou.github.io/tags/Java/"/>
    
      <category term="Netty" scheme="https://xinshiyou.github.io/tags/Netty/"/>
    
  </entry>
  
</feed>
